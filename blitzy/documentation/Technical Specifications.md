# Technical Specification

# 0. Agent Action Plan

## 0.1 Core Feature Objective

Based on the prompt, the Blitzy platform understands that the new feature requirement is to establish a Node.js server tutorial project with the following specific objectives:

- **Initialize a Node.js Project Structure**: Create a foundational Node.js project starting from an empty repository (currently containing only a README.md file)

- **Integrate Express.js Framework**: Add Express.js as the core web framework to handle HTTP routing and middleware functionality, transitioning from a basic Node.js HTTP server approach to a production-ready framework

- **Implement Primary Endpoint**: Create an HTTP GET endpoint at the root path (`/`) that returns the text response "Hello world"

- **Implement Secondary Endpoint**: Create an HTTP GET endpoint at path `/evening` that returns the text response "Good evening"

- **Establish Project Dependencies**: Configure proper dependency management through package.json with Express.js and its dependencies

- **Enable Server Execution**: Ensure the server can be started and accessed via standard Node.js execution commands

#### Implicit Requirements Detected

Through analysis of the user's request and modern Node.js best practices, the following implicit requirements have been identified:

- **Package Management**: Initialize npm package.json with appropriate metadata and scripts for running the server

- **Error Handling**: Implement basic error handling middleware to gracefully manage request errors

- **Port Configuration**: Configure the server to listen on a standard port (default 3000) with the ability to override via environment variables

- **Development Workflow**: Include npm scripts for starting the server in development mode

- **Code Organization**: Structure the project following Node.js conventions with a clear entry point

- **Documentation**: Update README.md to include setup instructions, usage examples, and endpoint documentation

#### Feature Dependencies and Prerequisites

- **Runtime Environment**: Node.js version 18 or higher (currently v20.19.5 available, which satisfies this requirement)

- **Package Manager**: npm (currently v10.8.2 available)

- **Express.js Framework**: Version 5.1.0 or compatible version from the 5.x line, which is the current default on npm

- **Network Access**: Ability to listen on TCP ports for HTTP traffic

- **File System Access**: Permission to create project files including package.json, node_modules, and source code files

## 0.2 Special Instructions and Constraints

#### User-Provided Directives

**Primary Instruction**: The user explicitly stated:
> "this is a tutorial of node js server hosting one endpoint that returns the response 'Hello world'. Could you add expressjs into the project and add another endpoint that return the reponse of 'Good evening'?"

This directive establishes the following critical constraints:

- **Tutorial Nature**: The project serves as an educational example, requiring clear, simple, and well-documented code suitable for learning purposes

- **Framework Selection**: Express.js is specifically requested as the web framework, precluding alternatives like Fastify, Koa, or Hapi

- **Exact Response Text**: The endpoints must return the precise text:
  - First endpoint: `"Hello world"` (note: lowercase 'w' in world)
  - Second endpoint: `"Good evening"` (note: lowercase 'e' in evening)

- **Endpoint Addition Approach**: The second endpoint is an "addition" to the existing concept, suggesting incremental feature development

#### Architectural Requirements

- **Minimalist Approach**: As a tutorial project, maintain simplicity without over-engineering

- **Express.js Conventions**: Follow standard Express.js patterns for route definition and application structure

- **HTTP Method**: Use GET requests for both endpoints (standard for simple response endpoints)

- **Response Type**: Plain text responses (no JSON or HTML required based on user specifications)

#### Technical Constraints

- **Node.js Compatibility**: Must work with Node.js version 20.19.5 (current environment)

- **Express.js Version**: Use Express.js 5.x (latest stable version as of 2025)

- **No Authentication/Authorization**: As a simple tutorial, no security layers are required

- **No Database Integration**: Simple in-memory responses without persistent storage

- **No External Service Dependencies**: Self-contained application without third-party API integrations

#### Development Constraints

- **Single File Simplicity**: For tutorial purposes, the server implementation can exist in a single entry point file

- **Minimal Dependencies**: Only include Express.js and its peer dependencies; avoid unnecessary packages

- **No Build Process**: Use plain JavaScript without transpilation (no TypeScript, Babel, or webpack required)

- **Standard Node.js Module System**: Use CommonJS (require) or ES Modules (import) based on package.json configuration

#### Documentation Requirements

- **Clear Setup Instructions**: Provide step-by-step instructions for first-time users

- **Endpoint Documentation**: Document all available routes with example curl commands or browser URLs

- **Dependency Installation**: Explain the npm install process clearly

- **Running Instructions**: Detail how to start the server and verify it's working

## 0.3 Technical Interpretation

These feature requirements translate to the following technical implementation strategy, mapping each user requirement to specific technical actions:

#### Requirement 1: Node.js Server Tutorial Foundation

**User Intent**: Create a basic Node.js server project

**Technical Implementation**:
- To **establish the project foundation**, we will **create** a package.json file using `npm init` with project metadata including name, version, description, and entry point
- To **define the application entry point**, we will **create** a server.js (or index.js) file that serves as the main executable
- To **enable proper module resolution**, we will **configure** the package.json with appropriate "type" field for ES modules or use CommonJS by default

**Affected Components**:
- `package.json` - Project manifest (NEW)
- `server.js` or `index.js` - Application entry point (NEW)

#### Requirement 2: Add Express.js Framework

**User Intent**: Integrate Express.js for HTTP routing

**Technical Implementation**:
- To **add Express.js as a dependency**, we will **execute** `npm install express@^5.1.0` to install the latest stable version
- To **initialize the Express application**, we will **create** an Express app instance using `const app = express()`
- To **configure the server**, we will **implement** app.listen() to bind the server to a port (default 3000)
- To **enable basic middleware**, we will **optionally add** express.json() for future extensibility

**Affected Components**:
- `package.json` - Add express dependency (MODIFY)
- `server.js` - Import and initialize Express (MODIFY)
- `node_modules/` - Express package and dependencies (NEW - auto-generated)
- `package-lock.json` - Dependency lock file (NEW - auto-generated)

#### Requirement 3: Implement "Hello world" Endpoint

**User Intent**: Create a root endpoint returning "Hello world"

**Technical Implementation**:
- To **define the root route**, we will **create** an Express route handler using `app.get('/', (req, res) => {...})`
- To **send the response**, we will **implement** `res.send('Hello world')` to return plain text
- To **ensure proper HTTP status**, we will **rely on** Express's default 200 OK status for successful responses

**Affected Components**:
- `server.js` - Add GET / route handler (MODIFY)

#### Requirement 4: Add "Good evening" Endpoint

**User Intent**: Create a second endpoint returning "Good evening"

**Technical Implementation**:
- To **define the evening route**, we will **create** an Express route handler using `app.get('/evening', (req, res) => {...})`
- To **send the evening response**, we will **implement** `res.send('Good evening')` to return plain text
- To **maintain route organization**, we will **place** this route handler after the root route in the code

**Affected Components**:
- `server.js` - Add GET /evening route handler (MODIFY)

#### Requirement 5: Enable Server Execution

**User Intent**: Make the server runnable

**Technical Implementation**:
- To **start the HTTP server**, we will **implement** `app.listen(port, callback)` with configurable port from environment variable or default 3000
- To **provide execution feedback**, we will **add** a console.log statement confirming the server is running and on which port
- To **enable npm script execution**, we will **create** a "start" script in package.json pointing to the entry file
- To **support development mode**, we will **optionally add** a "dev" script using nodemon for auto-restart

**Affected Components**:
- `server.js` - Add app.listen() implementation (MODIFY)
- `package.json` - Add "start" and optional "dev" scripts (MODIFY)

#### Requirement 6: Documentation and Developer Experience

**User Intent**: Provide clear instructions for using the tutorial

**Technical Implementation**:
- To **document the project purpose**, we will **modify** README.md with a clear description of the tutorial
- To **provide setup instructions**, we will **add** step-by-step installation and running procedures to README.md
- To **document available endpoints**, we will **create** an API section in README.md listing all routes with example usage
- To **include testing examples**, we will **add** curl command examples for each endpoint

**Affected Components**:
- `README.md` - Complete project documentation (MODIFY)

#### Implementation Flow Summary

```
1. Initialize Project
   └─> npm init -y (creates package.json)

2. Install Dependencies
   └─> npm install express (adds Express.js)

3. Create Server File
   ├─> Import Express
   ├─> Initialize app
   ├─> Define GET / route → "Hello world"
   ├─> Define GET /evening route → "Good evening"
   └─> Start server with app.listen()

4. Update Documentation
   └─> Enhance README.md with usage instructions

5. Test Endpoints
   ├─> Start server: npm start
   ├─> Test http://localhost:3000/ → "Hello world"
   └─> Test http://localhost:3000/evening → "Good evening"
```

This technical interpretation ensures that every aspect of the user's request is translated into concrete, actionable implementation steps with clear file-level changes.

## 0.4 Comprehensive File Analysis

#### Current Repository State

**Search History and Deduplication Check:**

Search #1: get_source_folder_contents - "" (root) - Discover repository structure  
Search #2: read_file - "README.md" - Analyze existing documentation  
Search #3: bash - List all files including hidden - Confirm complete inventory  

**Deduplication Status:**
- Previously Retrieved Files: [README.md]
- Previously Retrieved Folders: ["" (root)]

**Repository Inventory:**

| Path | Type | Status | Purpose |
|------|------|--------|---------|
| README.md | File | EXISTS | Repository title page, requires enhancement |
| .git/ | Folder | EXISTS | Version control metadata (not modified) |

**Analysis**: The repository is in a minimal initial state with only a basic README.md file containing the title "# CheckSameRepoNoPrompt". There are no existing Node.js project files, source code, dependencies, or configuration.

#### Existing Files Requiring Modification

## README.md
- **Current State**: Contains only repository title "# CheckSameRepoNoPrompt"
- **Required Modifications**:
  - Add project description explaining the tutorial purpose
  - Add prerequisites section (Node.js 18+, npm)
  - Add installation instructions (`npm install`)
  - Add usage instructions (`npm start`)
  - Add API endpoint documentation with examples
  - Add example curl commands for testing
  - Optionally add troubleshooting section

**Modification Scope**: Lines 1-2 (entire file will be rewritten with comprehensive content)

#### New Files to be Created

#### Core Application Files

**package.json**
- **Purpose**: Node.js project manifest defining metadata, dependencies, and scripts
- **Location**: Root directory (`./package.json`)
- **Key Content**:
  - Project name: "checksamereponoprompt" or user-specified name
  - Version: "1.0.0"
  - Description: "Node.js Express tutorial with Hello World endpoints"
  - Main entry: "server.js"
  - Scripts: "start" for running the server
  - Dependencies: "express": "^5.1.0"
  - Engine specification: "node": ">=18.0.0"

**server.js** (or **index.js**)
- **Purpose**: Main application entry point containing Express server setup and routes
- **Location**: Root directory (`./server.js`)
- **Key Content**:
  - Express import/require statement
  - Express app initialization
  - GET / route handler returning "Hello world"
  - GET /evening route handler returning "Good evening"
  - Server listen configuration on port 3000 (with PORT env var support)
  - Console logging for server start confirmation

#### Auto-Generated Files (by npm)

**package-lock.json**
- **Purpose**: Locks exact dependency versions for reproducible installs
- **Location**: Root directory (`./package-lock.json`)
- **Generation**: Automatically created by `npm install` command
- **Content**: Complete dependency tree with integrity hashes

**node_modules/**
- **Purpose**: Contains all installed npm packages
- **Location**: Root directory (`./node_modules/`)
- **Generation**: Automatically created by `npm install` command
- **Content**: Express.js and all transitive dependencies
- **Note**: Should be added to .gitignore (if not already)

#### Optional Development Files

**.gitignore** (RECOMMENDED)
- **Purpose**: Exclude generated files from version control
- **Location**: Root directory (`./.gitignore`)
- **Key Content**:
  - `node_modules/` - Exclude dependencies
  - `.env` - Exclude environment variables (if added later)
  - `*.log` - Exclude log files
  - `.DS_Store` - Exclude macOS metadata

**.env.example** (OPTIONAL)
- **Purpose**: Template for environment variables
- **Location**: Root directory (`./.env.example`)
- **Key Content**:
  - `PORT=3000` - Example port configuration
  - Comments explaining each variable

#### File Pattern Search Results

Since this is a new project starting from an empty repository, traditional file pattern searches yield no existing files:

**Existing modules to modify**: None (no src/ structure exists)  
**Test files to update**: None (no test infrastructure exists)  
**Configuration files**: None (no existing config files)  
**Documentation**: README.md only (requires enhancement)  
**Build/deployment**: None (no Docker, CI/CD, or build configs exist)

#### Integration Point Discovery

**Current Integration Points**: None exist

**Future Integration Points** (if project expands):
- API endpoints: Currently GET / and GET /evening
- Middleware stack: Currently none, but Express provides capability
- Error handlers: Currently none, but should be added
- Static file serving: Not required for current scope
- Database connections: Not applicable for current scope
- External APIs: Not applicable for current scope

#### Search Patterns Applied

```bash
# Pattern 1: Node.js project files
find . -name "package.json" -o -name "*.js" -o -name "*.mjs"
Result: No JavaScript files found

#### Pattern 2: Configuration files
find . -name "*.config.*" -o -name "*.json" -o -name "*.yaml"
Result: No configuration files found

#### Pattern 3: Test files
find . -name "*test*.js" -o -name "*spec*.js" -o -path "*/test/*"
Result: No test files found

#### Pattern 4: Documentation
find . -name "*.md" -o -path "*/docs/*"
Result: README.md only
```

#### Complete File Inventory Summary

| Category | Existing Count | To Create | To Modify |
|----------|----------------|-----------|-----------|
| Source Files | 0 | 1 (server.js) | 0 |
| Configuration | 0 | 1 (package.json) | 0 |
| Documentation | 1 | 1 (.gitignore) | 1 (README.md) |
| Dependencies | 0 | Auto-generated | 0 |
| Tests | 0 | 0 (not in scope) | 0 |
| Build/Deploy | 0 | 0 (not required) | 0 |

**Total Files**: 1 existing, 3-4 new files to create, 1 file to modify

## 0.5 Web Search Research Conducted

#### Research Query Executed

**Query**: "Express.js latest version 2025"  
**Purpose**: Identify the current stable version of Express.js and its requirements for implementation

#### Key Research Findings

## Express.js Version Information

<cite index="1-1">Express 5.1.0 is now the default on npm</cite>, representing a major milestone after Express v5's official release in October 2024. This version includes significant improvements and is recommended for new projects.

**Version Timeline**:
- Express 5.0.0: Released October 15, 2024 (after 10 years of development)
- Express 5.1.0: Latest stable release, now default on npm (2025)
- Express 4.x: Still in maintenance mode for legacy projects

## Node.js Version Requirements

<cite index="2-12">Node.js 18 or higher is required</cite> for Express.js 5.x. This represents a significant shift from Express 4, which supported much older Node.js versions.

**Our Environment Compatibility**:
- Current Node.js: v20.19.5 ✓ COMPATIBLE
- Minimum Required: Node.js 18.0.0
- Status: Fully supported, no upgrade needed

#### Key Features and Improvements in Express 5.x

**Promise Support**:
<cite index="5-28,5-29,5-30">Express.js 5 makes it easier to handle errors in async middleware and routes by automatically passing rejected promises to the error-handling middleware, removing the need for try/catch blocks</cite>.

**Security Enhancements**:
<cite index="3-9">Updated to path-to-regexp@8.x, removing sub-expression regex patterns for security reasons (ReDoS mitigation)</cite>.

**Removed Legacy Methods**:
- `app.del()` replaced with `app.delete()`
- Pluralized request methods (e.g., `req.acceptsCharsets()`)
- Dropped deprecated API methods from Express 3/4

**Simplified Error Handling**:
```javascript
// Express 5 - Automatic promise rejection handling
app.get('/data', async (req, res) => {
  const result = await fetchData();
  res.send(result);
});
```

#### Installation Best Practices

**Recommended Installation Command**:
```bash
npm install express
```

This will install Express 5.1.0 (current npm default) with the caret (^) semver range, allowing automatic patch and minor updates while preventing breaking major version changes.

**Package.json Dependency Format**:
```json
"dependencies": {
  "express": "^5.1.0"
}
```

#### Basic Usage Pattern from Official Documentation

<cite index="2-10">Official Express example shows: `import express from 'express' const app = express() app.get('/', (req, res) => { res.send('Hello World') }) app.listen(3000)`</cite>

This pattern directly aligns with our implementation requirements for the tutorial.

#### Implementation Patterns Researched

#### Minimal Express Server Structure

Based on Express.js documentation and community best practices:

**CommonJS Pattern** (Traditional Node.js):
```javascript
const express = require('express');
const app = express();
const port = process.env.PORT || 3000;

app.get('/', (req, res) => {
  res.send('Hello world');
});

app.listen(port, () => {
  console.log(`Server running on port ${port}`);
});
```

**ES Module Pattern** (Modern JavaScript):
```javascript
import express from 'express';
const app = express();
const port = process.env.PORT || 3000;

app.get('/', (req, res) => {
  res.send('Hello world');
});

app.listen(port, () => {
  console.log(`Server running on port ${port}`);
});
```

#### Library Recommendations for Tutorial Project

**Core Dependency**:
- **express** (v5.1.0): Web framework for handling routes and HTTP operations

**Optional Development Dependencies** (NOT required for minimal tutorial):
- **nodemon**: Auto-restart server on file changes (development convenience)
- **dotenv**: Load environment variables from .env file (if environment config needed)

**Recommendation**: For this tutorial's scope, **only Express.js is required**. Additional dependencies would add unnecessary complexity for a learning example.

#### Security Considerations

**ReDoS Protection**:
Express 5 includes built-in protections against Regular Expression Denial of Service attacks through updated path-to-regexp dependency.

**Best Practices for Tutorial Code**:
- Use environment variables for port configuration (PORT env var)
- Avoid hardcoded sensitive values
- Implement basic error handling middleware (recommended but not required for minimal tutorial)
- Keep dependencies minimal to reduce attack surface

#### Common Patterns for HTTP Endpoint Responses

**Text Responses** (our use case):
```javascript
res.send('Hello world');  // Automatically sets Content-Type: text/html
```

**JSON Responses** (alternative approach):
```javascript
res.json({ message: 'Hello world' });  // Sets Content-Type: application/json
```

**Status Codes**:
- Express defaults to 200 OK for successful responses
- Explicit status: `res.status(200).send('Hello world')`

#### Integration Approach Confirmation

Based on research, our implementation approach aligns with:
- Official Express.js documentation examples
- Community best practices for minimal servers
- Modern Node.js application patterns
- Tutorial and educational standards

**Validation**: The planned implementation (single server.js file with two GET routes) represents the simplest, most educational approach recommended by Express.js documentation and community patterns.

## 0.6 New File Requirements

#### New Source Files to Create

## server.js
**Path**: `./server.js`  
**Type**: JavaScript source file (application entry point)  
**Purpose**: Main Express.js server implementation containing route definitions and server initialization

**Specific Content Requirements**:
- Import/require Express.js module
- Initialize Express application instance
- Define GET route for "/" returning "Hello world"
- Define GET route for "/evening" returning "Good evening"
- Configure server to listen on port 3000 (with PORT environment variable override capability)
- Include console output confirming server startup and port number

**Dependencies**: Requires express package to be installed via npm

**Estimated Lines of Code**: 15-25 lines (keeping it concise for tutorial purposes)

**Example Structure**:
```javascript
// Express import
// App initialization  
// Route definitions (2 routes)
// Server listen configuration
```

#### New Configuration Files to Create

## package.json
**Path**: `./package.json`  
**Type**: JSON configuration file (Node.js project manifest)  
**Purpose**: Define project metadata, dependencies, and execution scripts

**Specific Content Requirements**:
- **name**: "checksamereponoprompt" (or alternative following npm naming conventions)
- **version**: "1.0.0" (initial release)
- **description**: "Node.js Express.js tutorial demonstrating basic HTTP endpoints"
- **main**: "server.js" (entry point specification)
- **scripts**:
  - "start": "node server.js" (production start command)
  - Optional "dev": "nodemon server.js" (if nodemon added)
- **keywords**: ["nodejs", "express", "tutorial", "api"]
- **author**: TBD (can be left blank or filled by user)
- **license**: "MIT" (standard open-source license)
- **dependencies**:
  - "express": "^5.1.0" (current npm default version)
- **engines**:
  - "node": ">=18.0.0" (Express 5.x requirement)

**Generation Method**: Can be created via `npm init -y` then manually edited, or created directly

**Estimated Lines**: 20-25 lines (formatted JSON)

## .gitignore
**Path**: `./.gitignore`  
**Type**: Git configuration file  
**Purpose**: Exclude generated and environment-specific files from version control

**Specific Content Requirements**:
```
# Dependencies
node_modules/

#### Environment variables
.env
.env.local

#### Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

#### Operating System
.DS_Store
Thumbs.db

#### IDE
.vscode/
.idea/
*.swp
*.swo

#### Optional
coverage/
.nyc_output/
```

**Purpose of Each Section**:
- node_modules/: Prevents committing ~50-100MB of dependencies
- .env files: Protects sensitive configuration and secrets
- Log files: Excludes runtime-generated logs
- OS files: Prevents OS-specific metadata from being committed
- IDE files: Excludes editor-specific configuration

**Estimated Lines**: 20-25 lines (with comments)

#### Optional New Files (Recommended but Not Required)

### .env.example
**Path**: `./.env.example`  
**Type**: Environment template file  
**Purpose**: Document available environment variables without exposing actual values

**Specific Content Requirements**:
```
# Server Configuration
PORT=3000

#### Add additional environment variables here as the project grows
```

**Note**: This file is committed to version control as a template, while `.env` (actual values) is gitignored

**Estimated Lines**: 5-10 lines

#### Auto-Generated Files (Not Manually Created)

## package-lock.json
**Path**: `./package-lock.json`  
**Type**: JSON lock file (auto-generated by npm)  
**Purpose**: Lock exact versions of all dependencies and sub-dependencies for reproducible builds

**Generation Trigger**: Automatically created when running `npm install`

**Management**: Should be committed to version control; allows team members and CI/CD to install identical dependency versions

**Estimated Size**: 5,000-10,000 lines (depends on express dependency tree)

**Contains**:
- Exact version numbers for express and all transitive dependencies
- Integrity hashes (SHA-512) for each package
- Resolved URLs for package downloads
- Dependency relationship graph

#### node_modules/
**Path**: `./node_modules/`  
**Type**: Directory containing installed packages  
**Purpose**: Houses all npm packages required by the project

**Generation Trigger**: Created by `npm install` command

**Management**: MUST be excluded from version control via .gitignore; regenerated on each machine via npm install

**Expected Contents**:
- express/ - Main Express.js package
- Sub-dependencies of Express (body-parser, cookie, debug, finalhandler, etc.)
- Estimated directory size: 50-100MB
- Estimated package count: 50+ packages (including transitive dependencies)

#### File Creation Sequence

The files must be created in the following order to ensure proper dependency resolution:

1. **package.json** - Must exist before installing dependencies
2. **npm install express** - Downloads dependencies, creates package-lock.json and node_modules/
3. **server.js** - Can now import express since it's installed
4. **.gitignore** - Prevents committing node_modules
5. **README.md** - Update with complete documentation (file exists, will be modified)

#### Summary Table

| File | Type | Creation Method | Version Control | Required |
|------|------|----------------|-----------------|----------|
| server.js | Source | Manual | Commit | YES |
| package.json | Config | Manual/npm init | Commit | YES |
| package-lock.json | Lock | Auto (npm install) | Commit | YES |
| node_modules/ | Directory | Auto (npm install) | Ignore | YES |
| .gitignore | Config | Manual | Commit | RECOMMENDED |
| .env.example | Template | Manual | Commit | OPTIONAL |

**Total New Files**: 3-4 manually created, 2 auto-generated  
**Total New Directories**: 1 (node_modules/)

## 0.7 Dependency Inventory

#### Private and Public Packages

This project uses only public npm packages. No private or internal packages are required.

#### Primary Dependencies

| Registry | Package Name | Version | Purpose |
|----------|--------------|---------|---------|
| npm | express | ^5.1.0 | Fast, unopinionated, minimalist web framework for Node.js providing routing, middleware, and HTTP utilities |

#### Transitive Dependencies (Auto-Installed with Express)

Express.js 5.1.0 includes the following key sub-dependencies (partial list of most significant packages):

| Registry | Package Name | Version (Approximate) | Purpose |
|----------|--------------|----------------------|---------|
| npm | accepts | ~1.3.8 | Higher-level content negotiation |
| npm | array-flatten | 1.1.1 | Flatten nested arrays |
| npm | body-parser | 1.20.x | Node.js body parsing middleware |
| npm | content-disposition | 0.5.4 | Create/parse Content-Disposition header |
| npm | cookie | 0.7.x | HTTP server cookie parsing and serialization |
| npm | cookie-signature | 1.0.6 | Sign and unsign cookies |
| npm | debug | 2.6.9 | Debugging utility |
| npm | encodeurl | ~2.0.0 | Encode URL to percent-encoding |
| npm | escape-html | ~1.0.3 | Escape string for HTML |
| npm | etag | ~1.8.1 | Create simple ETags |
| npm | finalhandler | 1.3.x | Final HTTP responder |
| npm | fresh | 0.5.2 | HTTP response freshness testing |
| npm | merge-descriptors | 1.0.3 | Merge objects using descriptors |
| npm | methods | ~1.1.2 | HTTP methods node supports |
| npm | mime | 1.6.x | Mime type mapping |
| npm | parseurl | ~1.3.3 | Parse URL with memoization |
| npm | path-to-regexp | 8.x.x | Turn path string into regexp |
| npm | proxy-addr | ~2.0.7 | Determine address of proxied request |
| npm | qs | 6.13.x | Querystring parser |
| npm | range-parser | ~1.2.1 | Range header parser |
| npm | safe-buffer | 5.2.1 | Safer Node.js Buffer API |
| npm | send | 0.19.x | Static file server with range support |
| npm | serve-static | 1.16.x | Serve static files |
| npm | setprototypeof | 1.2.0 | Simple module for setting prototype |
| npm | statuses | 2.0.1 | HTTP status utility |
| npm | type-is | ~1.6.18 | Infer content-type of request |
| npm | utils-merge | 1.0.1 | Merge object b with object a |
| npm | vary | ~1.1.2 | Manipulate Vary header |

**Note**: Exact transitive dependency versions are locked in package-lock.json after `npm install`. The versions listed above are approximate based on Express 5.1.0's dependency requirements.

#### Development Dependencies

**Current Scope**: NONE required for basic tutorial

**Optional for Enhanced Development Experience**:

| Registry | Package Name | Version | Purpose | Status |
|----------|--------------|---------|---------|--------|
| npm | nodemon | ^3.0.0 | Auto-restart server on file changes | OPTIONAL |

If nodemon is added:
```json
"devDependencies": {
  "nodemon": "^3.0.0"
}
```

And package.json script would be updated:
```json
"scripts": {
  "start": "node server.js",
  "dev": "nodemon server.js"
}
```

#### Dependency Updates

#### Import Updates

Since this is a new project with no existing imports, all imports are new:

**server.js - New Express Import**:

CommonJS style (default):
```javascript
const express = require('express');
```

OR ES Module style (if package.json has `"type": "module"`):
```javascript
import express from 'express';
```

**No transformation rules needed** - these are initial imports, not updates to existing code.

#### External Reference Updates

No external references exist in the current repository. Once created:

**package.json** - Add dependencies section:
```json
{
  "dependencies": {
    "express": "^5.1.0"
  }
}
```

**README.md** - Document dependency installation:
```
## Installation

Install the required dependencies:

\`\`\`bash
npm install
\`\`\`

This will install:
- Express.js v5.1.0 and its dependencies
```

#### Version Pinning Strategy

**Primary Dependency Versioning**:
- Use caret (^) semver range: `"express": "^5.1.0"`
- Allows: 5.1.x and 5.x.x (patch and minor updates)
- Blocks: 6.0.0+ (major version updates that may break compatibility)
- Rationale: Balances security patches with stability

**Lock File Strategy**:
- Commit package-lock.json to repository
- Ensures all developers and CI/CD use identical dependency versions
- Prevents "works on my machine" issues
- Allows controlled updates via `npm update`

#### Dependency Installation Commands

**Fresh Installation**:
```bash
npm install
```
- Reads package.json
- Installs all dependencies listed
- Generates package-lock.json (if not present)
- Creates node_modules/ directory
- Expected duration: 10-30 seconds depending on network speed

**Install Specific Express Version**:
```bash
npm install express@5.1.0
```
- Installs exactly version 5.1.0
- Updates package.json with ^5.1.0 range
- Updates package-lock.json with exact versions
- Downloads ~50MB of packages

**Verify Installation**:
```bash
npm list express
```
Expected output:
```
checksamereponoprompt@1.0.0 /path/to/project
└── express@5.1.0
```

#### Security Considerations

**Dependency Scanning**:
```bash
npm audit
```
- Checks for known vulnerabilities in dependencies
- Should show 0 vulnerabilities for Express 5.1.0 (latest stable)
- Run periodically to catch newly discovered issues

**Update Strategy**:
```bash
npm update express
```
- Updates to latest version within semver range (^5.1.0 allows up to <6.0.0)
- Updates package-lock.json
- Recommended: Test after updates before committing

#### Total Dependency Count

| Category | Count | Disk Space |
|----------|-------|------------|
| Direct Dependencies | 1 (express) | N/A |
| Transitive Dependencies | ~50 packages | ~50MB |
| Total Packages Installed | ~51 | ~50MB |
| Total Files in node_modules | ~5,000-10,000 | ~50MB |

**Installation Verification**:
After running `npm install`, verify:
- `node_modules/express/` directory exists
- `package-lock.json` file created
- `npm list` shows complete dependency tree
- No errors or warnings in npm output

## 0.8 Existing Code Touchpoints

#### Current Repository State Assessment

**Repository Status**: The repository currently contains only a README.md file with the title "# CheckSameRepoNoPrompt". There is no existing application code, no Node.js project structure, and no established integration points.

**Analysis Result**: Since this is a greenfield project (starting from an empty repository), there are **NO existing code touchpoints** to modify. All implementation will involve creating new files and structures.

#### Direct Modifications Required

## README.md (ONLY EXISTING FILE)
**Path**: `./README.md`  
**Current State**: Contains only repository title  
**Required Modifications**: Complete rewrite with project documentation

**Modification Details**:
- **Location**: Lines 1-2 (entire file)
- **Action**: Expand from 2 lines to ~50-100 lines
- **New Sections to Add**:
  - Project title and description
  - Prerequisites (Node.js 18+, npm)
  - Installation instructions
  - Running the server instructions
  - API endpoint documentation
  - Example usage with curl commands
  - Optional troubleshooting section

**Before**:
```
# CheckSameRepoNoPrompt
```

**After** (structure):
```
# CheckSameRepoNoPrompt

Node.js Express.js tutorial demonstrating basic HTTP endpoints.

#### Prerequisites
...

#### Installation
...

#### Running the Server
...

#### API Endpoints
...

#### Testing
...
```

#### Dependency Injections

**Not Applicable** - There are no existing dependency injection systems, service containers, or inversion of control frameworks in the current repository.

**Future Consideration**: If the project grows, consider implementing:
- Service registration patterns
- Middleware registration in a central configuration file
- Route modularity with express.Router()

#### Database/Schema Updates

**Not Applicable** - No database connections, schema definitions, or data persistence layers exist in the current project scope.

**Reasoning**: The tutorial endpoints return static text responses and do not require data storage.

**Future Consideration**: If database functionality is added later:
- Consider lightweight options like SQLite for tutorials
- Would require additional dependencies (e.g., sqlite3, better-sqlite3)
- Would need migration system (e.g., db-migrate, Knex.js migrations)

#### Integration Point Analysis

Since no existing code infrastructure exists, traditional integration points are not present. However, we can document the **integration points that will be CREATED**:

#### Future Integration Points (Created by This Implementation)

**1. Express Application Instance** (`server.js`)
```javascript
const app = express();
```
- **Purpose**: Central application object for all routing and middleware
- **Integration Capability**: Other modules can import this to add routes/middleware
- **Future Use**: Additional route files can be attached to this app instance

**2. Route Definitions** (`server.js`)
```javascript
app.get('/', ...);
app.get('/evening', ...);
```
- **Purpose**: HTTP endpoint definitions
- **Integration Capability**: New routes can be added alongside existing ones
- **Future Use**: Route modularization into separate files (e.g., routes/index.js)

**3. Server Listen Configuration** (`server.js`)
```javascript
app.listen(port, ...);
```
- **Purpose**: HTTP server initialization
- **Integration Capability**: Can be wrapped for testing or exported for programmatic control
- **Future Use**: Separate server startup from application definition for testing

**4. Environment Variable Configuration**
```javascript
const port = process.env.PORT || 3000;
```
- **Purpose**: External configuration injection
- **Integration Capability**: Other env vars can be added for feature flags, API keys, etc.
- **Future Use**: .env file with dotenv package for local development

#### Modification Strategy for Minimal Project

Since this is a new tutorial project, the strategy is **additive rather than integrative**:

| Traditional Integration Concern | Tutorial Project Status |
|--------------------------------|------------------------|
| Modify existing routes | Not applicable - creating first routes |
| Update service registrations | Not applicable - no service layer |
| Alter middleware stack | Not applicable - no existing middleware |
| Update database schemas | Not applicable - no database |
| Integrate with auth system | Not applicable - no authentication |
| Connect to message queues | Not applicable - no async processing |
| Update API contracts | Not applicable - defining first API |

#### Architectural Integration Considerations

**Module System Integration**:
- **Current**: Will use Node.js native module system (CommonJS or ES Modules)
- **Integration**: server.js can be required/imported by other files if project expands
- **Best Practice**: Export the app instance for testing purposes:
  ```javascript
  module.exports = app; // CommonJS
  // or
  export default app; // ES Module
  ```

**Testing Integration Points** (Not in current scope, but documented for completeness):
- Express app can be tested without starting HTTP server
- Supertest library commonly used for HTTP endpoint testing
- Would require: `const request = require('supertest'); request(app).get('/')...`

#### Configuration Management Integration

**Current**: No configuration management system exists

**Will Create**: Basic environment variable support via process.env

**Not Included** (but common in production):
- dotenv package for .env file loading
- config package for multi-environment configuration
- Centralized config module exporting all settings

#### API Versioning Integration

**Current Scope**: Not applicable for a two-endpoint tutorial

**Future Consideration**: If API grows, consider:
- URL versioning: `/api/v1/resource`, `/api/v2/resource`
- Header versioning: `Accept: application/vnd.api+json; version=1`
- Express.Router() for modular route organization

#### Summary

**Existing Integration Points**: 0  
**New Integration Points Created**: 4 (app instance, routes, server listener, env config)  
**Files Requiring Modification**: 1 (README.md only)  
**Files Requiring Creation**: 3+ (server.js, package.json, .gitignore)

The absence of existing code touchpoints simplifies implementation significantly, as there are no backward compatibility concerns, existing API contracts to maintain, or legacy integration patterns to navigate. This is a clean-slate implementation ideal for a tutorial project.

## 0.9 File-by-File Execution Plan

#### Implementation Overview

Every file listed in this section MUST be created or modified. The implementation follows a logical dependency order to ensure each step builds upon the previous one.

#### Group 1 - Project Foundation

#### CREATE: package.json
**Path**: `./package.json`  
**Execution Order**: #1 (MUST be first - required before installing dependencies)  
**Purpose**: Initialize Node.js project with metadata and dependency specifications

**Implementation Steps**:
1. Create new file at repository root
2. Add JSON structure with proper formatting
3. Define project metadata (name, version, description)
4. Specify main entry point as "server.js"
5. Add npm scripts for running the application
6. Declare express dependency with version ^5.1.0
7. Set Node.js engine requirement to >=18.0.0

**Complete Content**:
```json
{
  "name": "checksamereponoprompt",
  "version": "1.0.0",
  "description": "Node.js Express.js tutorial demonstrating basic HTTP endpoints",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [
    "nodejs",
    "express",
    "tutorial",
    "api",
    "rest"
  ],
  "author": "",
  "license": "MIT",
  "dependencies": {
    "express": "^5.1.0"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
```

**Validation**: Verify valid JSON syntax with `npm pkg get name`

---

#### EXECUTE: npm install
**Command**: `npm install`  
**Execution Order**: #2 (MUST be after package.json creation)  
**Purpose**: Download and install Express.js and all dependencies

**Implementation Steps**:
1. Execute command from repository root: `npm install`
2. Wait for download completion (10-30 seconds)
3. Verify package-lock.json was created
4. Verify node_modules/ directory was created
5. Verify node_modules/express/ exists
6. Check for any error messages or warnings

**Auto-Generated Artifacts**:
- `package-lock.json` - Dependency version lock file (~5,000-10,000 lines)
- `node_modules/` - Directory containing ~51 packages (~50MB)

**Validation**: 
```bash
npm list express
# Expected: express@5.1.0

ls -la node_modules/express
# Expected: Directory exists with Express.js files
```

---

#### Group 2 - Core Application Logic

#### CREATE: server.js
**Path**: `./server.js`  
**Execution Order**: #3 (MUST be after npm install completes)  
**Purpose**: Implement Express server with two HTTP GET endpoints

**Implementation Steps**:
1. Create new file at repository root
2. Import Express.js module at top of file
3. Initialize Express application instance
4. Configure port from environment variable with fallback to 3000
5. Define GET route for "/" returning "Hello world"
6. Define GET route for "/evening" returning "Good evening"
7. Start HTTP server with app.listen()
8. Add console.log to confirm server startup

**Complete Content** (CommonJS):
```javascript
const express = require('express');
const app = express();
const port = process.env.PORT || 3000;

// Root endpoint
app.get('/', (req, res) => {
  res.send('Hello world');
});

// Evening endpoint
app.get('/evening', (req, res) => {
  res.send('Good evening');
});

// Start server
app.listen(port, () => {
  console.log(`Server is running on http://localhost:${port}`);
});
```

**Alternative Content** (ES Module - if package.json has `"type": "module"`):
```javascript
import express from 'express';
const app = express();
const port = process.env.PORT || 3000;

// Root endpoint
app.get('/', (req, res) => {
  res.send('Hello world');
});

// Evening endpoint
app.get('/evening', (req, res) => {
  res.send('Good evening');
});

// Start server
app.listen(port, () => {
  console.log(`Server is running on http://localhost:${port}`);
});
```

**Validation**:
```bash
node server.js
# Expected: "Server is running on http://localhost:3000"

curl http://localhost:3000/
# Expected: "Hello world"

curl http://localhost:3000/evening
# Expected: "Good evening"
```

---

#### Group 3 - Version Control Configuration

#### CREATE: .gitignore
**Path**: `./.gitignore`  
**Execution Order**: #4 (Should be before first git commit after npm install)  
**Purpose**: Prevent committing generated files and dependencies to version control

**Implementation Steps**:
1. Create new file at repository root
2. Add node_modules/ to exclude installed packages
3. Add environment variable files (.env)
4. Add log files (*.log)
5. Add OS-specific files (.DS_Store, Thumbs.db)
6. Add IDE-specific directories (.vscode/, .idea/)

**Complete Content**:
```
# Dependencies
node_modules/

#### Environment variables
.env
.env.local
.env.*.local

#### Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
logs/

#### Operating System
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

#### IDEs
.vscode/
.idea/
*.swp
*.swo
*~
.project
.settings/

#### Testing
coverage/
.nyc_output/

#### Optional
.env.example.local
```

**Validation**:
```bash
git status
# node_modules/ should NOT appear in untracked files
```

---

#### Group 4 - Documentation

#### MODIFY: README.md
**Path**: `./README.md`  
**Execution Order**: #5 (After all core functionality is implemented and tested)  
**Purpose**: Provide comprehensive project documentation for users

**Current Content**:
```
# CheckSameRepoNoPrompt
```

**Implementation Steps**:
1. Preserve existing title line
2. Add project description below title
3. Add Prerequisites section with Node.js/npm requirements
4. Add Installation section with npm install instructions
5. Add Usage section with npm start command
6. Add API Endpoints section documenting both routes
7. Add Testing Examples section with curl commands
8. Optionally add Troubleshooting section

**Complete Replacement Content**:
```
# CheckSameRepoNoPrompt

A Node.js Express.js tutorial project demonstrating basic HTTP endpoint implementation with two simple routes.

#### Description

This project serves as a minimal Express.js tutorial, showcasing how to:
- Set up a Node.js project with Express.js
- Define HTTP GET endpoints
- Return text responses
- Configure the server with environment variables

#### Prerequisites

- **Node.js**: Version 18.0.0 or higher
- **npm**: Version 8.0.0 or higher (comes with Node.js)

Check your versions:
```bash
node --version
npm --version
```

#### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd CheckSameRepoNoPrompt
```

2. Install dependencies:
```bash
npm install
```

This will install Express.js and all required dependencies.

#### Running the Server

Start the server with:
```bash
npm start
```

The server will start on port 3000 by default. You should see:
```
Server is running on http://localhost:3000
```

#### Custom Port

To use a different port, set the PORT environment variable:
```bash
PORT=8080 npm start
```

#### API Endpoints

#### GET /
Returns a "Hello world" greeting.

**Request:**
```bash
curl http://localhost:3000/
```

**Response:**
```
Hello world
```

#### GET /evening
Returns a "Good evening" greeting.

**Request:**
```bash
curl http://localhost:3000/evening
```

**Response:**
```
Good evening
```

#### Testing

You can test the endpoints using:

**Browser:**
- Open http://localhost:3000/ in your browser
- Open http://localhost:3000/evening in your browser

**curl:**
```bash
curl http://localhost:3000/
curl http://localhost:3000/evening
```

**wget:**
```bash
wget -qO- http://localhost:3000/
wget -qO- http://localhost:3000/evening
```

#### Project Structure

```
CheckSameRepoNoPrompt/
├── server.js           # Main application entry point
├── package.json        # Project metadata and dependencies
├── package-lock.json   # Dependency version lock file
├── .gitignore         # Git ignore rules
├── README.md          # This file
└── node_modules/      # Installed dependencies (not committed)
```

#### Troubleshooting

**Error: Cannot find module 'express'**
- Solution: Run `npm install` to install dependencies

**Error: Port 3000 already in use**
- Solution: Either stop the process using port 3000, or use a different port:
  ```bash
  PORT=3001 npm start
  ```

**Error: Node version too old**
- Solution: Upgrade Node.js to version 18 or higher

#### License

MIT
```

**Validation**: Render markdown to verify proper formatting and completeness

---

#### Implementation Approach Summary

**Phase 1 - Foundation**:
1. Create package.json
2. Run npm install

**Phase 2 - Implementation**:
3. Create server.js with Express routes

**Phase 3 - Quality**:
4. Create .gitignore
5. Update README.md with documentation

**Phase 4 - Validation**:
6. Start server and test both endpoints
7. Verify responses match specifications exactly

#### File Creation Order Diagram

```
package.json (CREATE)
    ↓
npm install (EXECUTE)
    ↓
server.js (CREATE)
    ↓
.gitignore (CREATE)
    ↓
README.md (MODIFY)
    ↓
Testing & Verification
```

#### Success Criteria

- [ ] package.json exists with valid JSON and express dependency
- [ ] npm install completes without errors
- [ ] node_modules/ contains express package
- [ ] package-lock.json generated
- [ ] server.js exists with both route definitions
- [ ] .gitignore prevents node_modules from being committed
- [ ] README.md contains complete documentation
- [ ] Server starts successfully: `npm start`
- [ ] GET / returns exactly "Hello world"
- [ ] GET /evening returns exactly "Good evening"
- [ ] Server runs on configurable port via PORT env var

## 0.10 Scope Boundaries

#### Exhaustively In Scope

All items listed below are explicitly included in this implementation and MUST be completed:

#### Core Application Files

- **server.js** - Main Express.js application file
  - Express.js module import/require
  - Express app initialization
  - GET / route handler returning "Hello world"
  - GET /evening route handler returning "Good evening"
  - Port configuration via process.env.PORT with default 3000
  - Server listen implementation
  - Console logging for server startup confirmation

#### Configuration Files

- **package.json** - Node.js project manifest
  - Project name: "checksamereponoprompt"
  - Version: "1.0.0"
  - Description field
  - Main entry point: "server.js"
  - Scripts: "start" command
  - Dependencies: express ^5.1.0
  - Engines: node >=18.0.0
  - Keywords, author, license fields

- **.gitignore** - Version control exclusions
  - node_modules/ directory
  - .env and .env.* files
  - *.log files
  - OS-specific files (.DS_Store, Thumbs.db)
  - IDE directories (.vscode/, .idea/)

#### Auto-Generated Files

- **package-lock.json**
  - Generated by npm install
  - Contains locked dependency versions
  - Should be committed to version control

- **node_modules/**
  - Generated by npm install
  - Contains Express.js and ~50 transitive dependencies
  - Should NOT be committed (excluded by .gitignore)

#### Documentation

- **README.md** (MODIFICATION of existing file)
  - Project title and description
  - Prerequisites section (Node.js 18+, npm)
  - Installation instructions (npm install)
  - Running instructions (npm start)
  - API endpoints documentation:
    - GET / endpoint description with example
    - GET /evening endpoint description with example
  - Testing examples (curl commands, browser URLs)
  - Project structure overview
  - Troubleshooting section
  - License information

#### Dependencies

- **express** package (version ^5.1.0)
  - Primary and only direct dependency
  - Includes all transitive dependencies automatically

#### Endpoint Specifications

- **GET /** route
  - Method: GET
  - Path: /
  - Response: Plain text "Hello world" (exact text, lowercase 'w')
  - Status: 200 OK (default)
  - Content-Type: text/html; charset=utf-8 (Express default for res.send())

- **GET /evening** route
  - Method: GET
  - Path: /evening
  - Response: Plain text "Good evening" (exact text, lowercase 'e')
  - Status: 200 OK (default)
  - Content-Type: text/html; charset=utf-8 (Express default for res.send())

#### Environment Configuration

- **PORT environment variable**
  - Used to configure server listening port
  - Default: 3000
  - Override via: `PORT=8080 npm start`
  - Implementation: `const port = process.env.PORT || 3000;`

#### Testing Verification

- **Manual testing of endpoints**
  - Verify GET / returns "Hello world"
  - Verify GET /evening returns "Good evening"
  - Verify server starts without errors
  - Verify PORT environment variable override works

#### Explicitly Out of Scope

The following items are explicitly excluded from this implementation:

#### Additional Features

- ❌ **POST, PUT, DELETE, PATCH endpoints** - Only GET methods are required
- ❌ **Request body parsing** - No endpoints accept request bodies
- ❌ **Query parameter handling** - Endpoints return static responses
- ❌ **Path parameters** - No dynamic route segments needed
- ❌ **Additional routes beyond / and /evening** - Only two routes specified
- ❌ **Middleware beyond Express defaults** - No custom middleware required
- ❌ **CORS configuration** - Not needed for simple tutorial
- ❌ **Rate limiting** - Not applicable for tutorial scope
- ❌ **Request logging** - Beyond scope (console.log on startup only)

#### Data Layer

- ❌ **Database integration** - No persistent storage required
- ❌ **Database migrations** - No database exists
- ❌ **ORM/ODM setup** - No data modeling needed
- ❌ **Caching layer** - Static responses don't require caching
- ❌ **Session storage** - No user sessions needed

#### Security

- ❌ **Authentication** - No login/authentication required
- ❌ **Authorization** - No access control needed
- ❌ **JWT implementation** - No token-based auth
- ❌ **API keys** - No API key validation needed
- ❌ **Input validation** - No user inputs to validate
- ❌ **Input sanitization** - No user-provided data
- ❌ **HTTPS/SSL setup** - HTTP sufficient for tutorial
- ❌ **Security headers** (helmet.js) - Not required for basic tutorial

#### Testing Infrastructure

- ❌ **Unit tests** - Not specified in requirements
- ❌ **Integration tests** - Beyond tutorial scope
- ❌ **Test framework setup** (Jest, Mocha) - Not required
- ❌ **Code coverage tools** - Not applicable
- ❌ **Mocking libraries** - No tests to require mocks
- ❌ **CI/CD testing pipelines** - Not in scope

#### Development Tools

- ❌ **TypeScript** - Plain JavaScript specified
- ❌ **ESLint configuration** - Code linting not required
- ❌ **Prettier setup** - Code formatting not required
- ❌ **Nodemon** - Auto-restart optional, not required
- ❌ **dotenv package** - Basic process.env sufficient
- ❌ **Debugging configuration** - Standard Node.js debugging sufficient
- ❌ **Docker containerization** - Not specified
- ❌ **Docker Compose** - No multi-container setup needed

#### Build and Deployment

- ❌ **Build process** - No transpilation/bundling needed
- ❌ **Webpack/Rollup** - No bundler required
- ❌ **Babel** - No ES6+ transpilation needed
- ❌ **Minification** - Not applicable for server code
- ❌ **Production deployment scripts** - Local development only
- ❌ **Environment-specific configs** - Single environment sufficient
- ❌ **CI/CD pipelines** - Not specified
- ❌ **Monitoring/logging services** - Not required

#### Documentation

- ❌ **API documentation generation** (Swagger/OpenAPI) - Overkill for 2 endpoints
- ❌ **JSDoc comments** - Simple code doesn't require extensive docs
- ❌ **Architecture diagrams** - Single file, no complex architecture
- ❌ **Deployment guides** - Beyond scope
- ❌ **Contributing guidelines** - Not specified

#### Performance Optimization

- ❌ **Clustering** - Not needed for tutorial
- ❌ **Load balancing** - Single instance sufficient
- ❌ **Response compression** - Not required for text responses
- ❌ **Static asset caching** - No static assets
- ❌ **CDN integration** - Not applicable

#### Additional Integrations

- ❌ **Third-party APIs** - Self-contained application
- ❌ **Message queues** - No async processing needed
- ❌ **Email services** - No email functionality
- ❌ **Payment processing** - Not applicable
- ❌ **Analytics** - Not specified
- ❌ **Logging services** (Winston, Bunyan) - Basic console.log sufficient

#### Advanced Express Features

- ❌ **Template engines** (EJS, Pug) - No HTML rendering needed
- ❌ **Static file serving** - No static files to serve
- ❌ **Router modularization** - Single file sufficient for 2 routes
- ❌ **Middleware error handling** - Express defaults sufficient
- ❌ **Custom error pages** - Not required
- ❌ **View rendering** - Plain text responses only

#### Scope Summary Table

| Category | In Scope | Out of Scope |
|----------|----------|--------------|
| **Files** | 5 files (1 modify, 3 create, 1 auto-gen) | Additional config files |
| **Routes** | 2 GET endpoints (/, /evening) | All other HTTP methods/routes |
| **Dependencies** | Express.js only | All other packages |
| **Testing** | Manual verification | Automated test suites |
| **Security** | Basic HTTP | Auth, validation, encryption |
| **Documentation** | README.md | API docs, architecture docs |
| **Deployment** | Local development | Production deployment |

#### Boundary Validation

**If a feature or file is not explicitly listed in "Exhaustively In Scope", it is OUT OF SCOPE.**

This ensures:
- Clear expectations for implementation
- No scope creep beyond user requirements
- Focused, minimal tutorial implementation
- Faster completion with less complexity
- Educational clarity for tutorial users

## 0.11 Special Instructions for Feature Addition

#### Feature-Specific Requirements

#### Tutorial-Focused Implementation

**Educational Clarity Requirement**: This project serves as a Node.js/Express.js tutorial. All implementation decisions must prioritize:

- **Simplicity Over Sophistication**: Choose the most straightforward implementation approach, even if more advanced patterns exist
- **Single-File Organization**: Keep the server implementation in one file (server.js) to make it easy for beginners to understand the complete flow
- **Minimal Dependencies**: Use only Express.js without additional helper libraries that could obscure the core concepts
- **Clear Comments** (optional but recommended): While not required, adding brief comments explaining key sections helps tutorial users
- **No Abstraction Layers**: Avoid creating unnecessary modules, classes, or helper functions that complicate the learning experience

**Example - Avoid Over-Engineering**:
```javascript
// ❌ Too Complex for Tutorial
class RouteController {
  constructor(app) {
    this.app = app;
    this.setupRoutes();
  }
  setupRoutes() {
    this.app.get('/', this.handleRoot.bind(this));
  }
  handleRoot(req, res) {
    res.send('Hello world');
  }
}

// ✅ Appropriate for Tutorial
app.get('/', (req, res) => {
  res.send('Hello world');
});
```

#### Exact Response Text Preservation

**Critical Specification**: The endpoint responses must return the EXACT text as specified:

- **GET / endpoint**: Must return `"Hello world"` - Note lowercase 'w' in "world"
- **GET /evening endpoint**: Must return `"Good evening"` - Note lowercase 'e' in "evening"

**Validation Steps**:
1. Test with: `curl http://localhost:3000/`
2. Verify response is exactly: `Hello world` (not "Hello World" or "hello world")
3. Test with: `curl http://localhost:3000/evening`
4. Verify response is exactly: `Good evening` (not "Good Evening" or "good evening")

**Implementation**:
```javascript
// Correct implementation
app.get('/', (req, res) => {
  res.send('Hello world');  // Lowercase 'w'
});

app.get('/evening', (req, res) => {
  res.send('Good evening');  // Lowercase 'e'
});
```

## Express.js Framework Integration Pattern

**Framework Selection Mandate**: Express.js is explicitly required. Do not substitute with:
- Fastify
- Koa
- Hapi
- Restify
- Native Node.js HTTP module
- Any other web framework

**Express.js Usage Pattern**:
1. Import: `const express = require('express');`
2. Initialize: `const app = express();`
3. Define routes: `app.get(path, handler)`
4. Start server: `app.listen(port, callback)`

**Version Specification**: Use Express.js 5.x (latest stable, currently 5.1.0), which is the npm default as of 2025.

#### Incremental Addition Approach

**Implementation Philosophy**: The user described "add expressjs into the project and add another endpoint", suggesting:

1. **Foundation First**: The first endpoint (GET /) represents the base functionality
2. **Incremental Enhancement**: The second endpoint (GET /evening) demonstrates how to add additional routes
3. **Learning Progression**: The code should show a natural progression from one endpoint to two

**Code Organization**:
```javascript
// First endpoint - Foundation
app.get('/', (req, res) => {
  res.send('Hello world');
});

// Second endpoint - Addition
app.get('/evening', (req, res) => {
  res.send('Good evening');
});
```

This ordering in the code reinforces the incremental nature of the feature addition.

#### Performance Considerations

**Not Applicable**: For a tutorial with two simple endpoints returning static text, performance optimization is out of scope:

- No need for response caching
- No need for compression middleware
- No need for clustering
- No need for load balancing
- No need for database query optimization (no database)

**Rationale**: Premature optimization would detract from the educational clarity of the tutorial.

#### Scalability Considerations

**Future Extensibility** (Documented but Not Implemented):

While the current implementation is minimal, the Express.js architecture allows future expansion:

```javascript
// Current minimal implementation
app.get('/', (req, res) => {
  res.send('Hello world');
});

// Future expansion possibilities (NOT in current scope):
// - app.get('/morning', (req, res) => {...});
// - app.use(express.json()); // for POST endpoints
// - app.use('/api', apiRouter); // route modularization
// - app.use(errorHandler); // centralized error handling
```

**Note**: These expansions should NOT be implemented now but are documented to show the framework's capability.

#### Security Requirements

**Minimal Security Posture**: As a local tutorial project:

- **No Authentication Required**: Endpoints are publicly accessible
- **No Input Validation Required**: No user inputs to validate
- **No Rate Limiting Required**: Local development environment
- **HTTP (not HTTPS) Acceptable**: Secure transport not necessary for localhost

**Future Security Considerations** (if deployed publicly):
- Implement helmet.js for security headers
- Add rate limiting middleware
- Use HTTPS in production
- Implement CORS policies
- Add input validation if endpoints accept data

#### Error Handling Strategy

**Basic Error Handling**: Express.js provides default error handling sufficient for this tutorial:

```javascript
// Express default error handler is sufficient
// Custom error handling NOT required for current scope
```

**Optional Enhancement** (not required):
```javascript
// Optional: Add 404 handler for undefined routes
app.use((req, res) => {
  res.status(404).send('Not Found');
});
```

#### Environment Variable Configuration

**PORT Configuration Pattern**:

```javascript
const port = process.env.PORT || 3000;
```

**Rationale**:
- Allows flexibility for different deployment environments
- Provides sensible default (3000 is common for Node.js)
- Follows twelve-factor app methodology
- Enables testing on different ports without code changes

**Usage**:
```bash
# Use default port 3000
npm start

#### Use custom port
PORT=8080 npm start
```

#### Module System Decision

**Recommendation**: Use CommonJS (traditional Node.js) for maximum compatibility:

```javascript
const express = require('express');
```

**Alternative**: ES Modules (modern JavaScript) - requires `"type": "module"` in package.json:

```javascript
import express from 'express';
```

**Decision Criteria**:
- CommonJS: Works without any package.json configuration
- ES Modules: More modern but requires explicit configuration
- **Recommendation**: Use CommonJS for simplicity unless user specifies otherwise

#### Documentation Standards

**README.md Requirements**:

- **Complete Setup Instructions**: Every step from clone to running
- **Example Commands**: Copy-pasteable curl commands for testing
- **Troubleshooting Section**: Common issues and solutions
- **Prerequisites Clearly Stated**: Node.js version requirement
- **Expected Output**: Show what users should see when successful

**Code Comments** (optional):
- Brief explanations for key sections helpful for learners
- Avoid over-commenting obvious code
- Focus on WHY not WHAT

#### Testing Strategy

**Manual Testing Required**:

```bash
# Start server
npm start

#### Test endpoint 1
curl http://localhost:3000/
#### Expected: Hello world

#### Test endpoint 2
curl http://localhost:3000/evening
#### Expected: Good evening
```

**Validation Checklist**:
- [ ] Server starts without errors
- [ ] Console shows startup message with correct port
- [ ] GET / returns exactly "Hello world"
- [ ] GET /evening returns exactly "Good evening"
- [ ] PORT environment variable override works
- [ ] Browser access works for both endpoints

#### Backward Compatibility

**Not Applicable**: This is a new project with no existing API contracts or users.

Future changes should maintain endpoint behavior:
- GET / should always return "Hello world"
- GET /evening should always return "Good evening"

#### Integration with Existing Features

**Not Applicable**: No existing features to integrate with.

The two endpoints are independent and can be tested separately:
- Endpoint 1 (/) does not depend on endpoint 2
- Endpoint 2 (/evening) does not depend on endpoint 1

#### Implementation Checklist

Before marking this feature complete, verify:

- [ ] Express.js 5.1.0 (or compatible 5.x) installed
- [ ] Node.js 20.19.5 (or 18+) confirmed working
- [ ] server.js uses Express.js framework (not alternatives)
- [ ] Exactly two routes defined: / and /evening
- [ ] Response texts exactly match specification (case-sensitive)
- [ ] PORT environment variable supported with default 3000
- [ ] package.json includes express dependency
- [ ] README.md provides complete tutorial documentation
- [ ] .gitignore prevents committing node_modules
- [ ] Manual testing confirms both endpoints work correctly
- [ ] Code remains simple and tutorial-appropriate



# 1. Introduction

## 1.1 Executive Summary

### 1.1.1 Project Overview

**CheckSameRepoNoPrompt** is a software project currently in its initial development phase. Based on the available repository contents, the project's specific business problem, core objectives, and technical implementation details are not yet documented in the codebase.

### 1.1.2 Current Development Stage

The repository is at an early initialization stage, containing foundational structure with limited implementation artifacts. As documented in `README.md`, the project has been named and established, but comprehensive system specifications, source code implementations, and detailed architectural components are yet to be developed or committed to the repository.

### 1.1.3 Documentation Status

This Technical Specification document represents the initial documentation effort for the CheckSameRepoNoPrompt project. As the project evolves and additional implementation artifacts are added to the repository, this specification will be updated to reflect the system's architecture, capabilities, and technical details.

## 1.2 System Overview

### 1.2.1 Project Context

The CheckSameRepoNoPrompt project is in its formative stage. The business context, market positioning, and integration requirements with existing enterprise systems have not yet been documented in the repository artifacts examined.

**Current Repository State:**
- **Primary Artifact**: Project identifier and naming convention established
- **Documentation**: Minimal placeholder README file present
- **Implementation Status**: Pre-implementation phase

### 1.2.2 High-Level Description

Based on the current repository contents, specific system capabilities, major components, and core technical approaches are not yet defined in committed artifacts. The project structure indicates preparation for future development activities.

### 1.2.3 Success Criteria

Success criteria, measurable objectives, and key performance indicators (KPIs) for the CheckSameRepoNoPrompt project have not been documented in the repository at this time. These elements will be defined and documented as the project requirements are formalized.

## 1.3 Scope

### 1.3.1 Current Scope Status

The functional and technical scope of the CheckSameRepoNoPrompt project is not yet defined in the available repository artifacts. The following sections outline the scope framework that will be populated as project requirements and implementation plans are developed.

### 1.3.2 In-Scope Elements (To Be Defined)

The following categories represent areas where in-scope elements will be documented as the project evolves:

| Category | Status | Documentation Location |
|----------|--------|------------------------|
| Core Features | Not yet defined | Pending requirements documentation |
| User Workflows | Not yet defined | Pending product specifications |
| Technical Requirements | Not yet defined | Pending architecture documentation |

**Implementation Boundaries:**
- System boundaries will be defined upon project requirement finalization
- Target user groups will be identified during stakeholder analysis
- Data domains and coverage will be specified in future iterations

### 1.3.3 Out-of-Scope Elements (To Be Defined)

Explicit exclusions, future phase considerations, and unsupported use cases will be documented as the project scope is formalized and boundaries are established.

### 1.3.4 Scope Evolution

This scope section will be updated to include:
- Detailed feature specifications as development progresses
- Integration points once system architecture is defined
- Explicit in-scope and out-of-scope elements upon requirement completion
- Geographic and market coverage details when business context is established

## 1.4 Document Purpose and Usage

### 1.4.1 Intended Audience

This Technical Specification document is designed for:
- **Development Teams**: To guide implementation once requirements are defined
- **Project Stakeholders**: To understand system capabilities and boundaries
- **Architecture Teams**: To review technical approaches and design decisions
- **Quality Assurance**: To develop testing strategies and acceptance criteria

### 1.4.2 Document Maintenance

As the CheckSameRepoNoPrompt project evolves from its current initialization phase into active development, this Technical Specification will be continuously updated to reflect:
- New source code implementations and architectural components
- Defined business requirements and functional specifications
- Technical decisions and design patterns adopted
- Integration points and system dependencies identified

## 1.5 Next Steps

### 1.5.1 Documentation Roadmap

To complete this Technical Specification, the following artifacts should be added to the repository:
1. **Requirements Documentation**: Business objectives, user stories, and functional requirements
2. **Source Code**: Implementation files that demonstrate system capabilities
3. **Architecture Documentation**: System design, component interactions, and technical approach
4. **Configuration Files**: Technology stack indicators, dependencies, and build configurations

### 1.5.2 Recommended Actions

For comprehensive technical documentation, the project should establish:
- Detailed README.md with project purpose, installation instructions, and usage guidelines
- Source code structure representing system architecture
- Design documents outlining technical decisions and patterns
- Dependency manifests and configuration files

---

#### References

**Files Examined:**
- `README.md` - Project title and initialization marker

**Repository Structure:**
- `` (root directory) - Contains project initialization artifacts

**Note**: This Introduction section is based on the current state of the repository at the time of documentation. As development progresses and additional artifacts are committed, this section should be revised to accurately reflect the implemented system's purpose, scope, and technical details.

# 2. Product Requirements

## 2.1 Product Requirements Overview

### 2.1.1 Requirements Definition Status

The CheckSameRepoNoPrompt project is currently in its pre-implementation phase, with product requirements not yet formalized or documented in the repository. This section establishes the framework and structure that will be populated as product requirements are defined, reviewed, and approved by project stakeholders.

**Current State Analysis:**
- **Requirements Documentation**: No formal requirements specifications exist in the repository
- **Feature Definitions**: No features have been defined or implemented
- **Acceptance Criteria**: No testable acceptance criteria have been established
- **Implementation Artifacts**: No source code or configuration files present beyond project initialization

### 2.1.2 Requirements Documentation Approach

As the CheckSameRepoNoPrompt project evolves, this section will follow a structured approach to requirements documentation:

- **Feature-Based Organization**: Requirements will be grouped by discrete, testable features with unique identifiers
- **Traceability**: Each requirement will maintain linkage to business objectives, technical specifications, and test cases
- **Versioning**: Requirements will be version-controlled with clear status tracking
- **Acceptance Criteria**: Each requirement will include measurable, testable acceptance criteria

### 2.1.3 Requirements Prioritization Framework

When product requirements are defined, they will be categorized using the following framework:

| Priority Level | Definition | Implementation Timing |
|----------------|------------|----------------------|
| Critical | Essential for minimum viable product (MVP); system cannot function without these | Phase 1 - Immediate |
| High | Important features that deliver significant value; required for production release | Phase 1-2 - Near-term |
| Medium | Valuable enhancements that improve user experience or system capability | Phase 2-3 - Mid-term |
| Low | Nice-to-have features that provide incremental value | Phase 3+ - Future |

## 2.2 Feature Catalog

### 2.2.1 Feature Catalog Status

The feature catalog for CheckSameRepoNoPrompt has not yet been populated. This subsection will document all product features once requirements gathering and product planning activities are completed.

**Feature Catalog Structure (Template):**

When features are defined, each will include:

- **Feature Metadata**: Unique ID (F-XXX format), name, category, priority level, and current status
- **Feature Description**: Overview, business value proposition, user benefits, and technical context
- **Dependency Mapping**: Prerequisites, system dependencies, external integrations, and inter-feature relationships
- **Implementation Considerations**: Technical constraints, performance targets, scalability requirements, and security implications

### 2.2.2 Feature Categories Framework

Features will be organized into logical categories for efficient management and implementation planning:

| Category | Purpose | Example Feature Types |
|----------|---------|----------------------|
| Core Functionality | Primary system capabilities that deliver core business value | To be defined |
| User Interface | User-facing components and interaction patterns | To be defined |
| Integration | External system connections and data exchange | To be defined |
| Security & Authentication | Access control, data protection, and compliance | To be defined |
| Administration | System configuration, monitoring, and management | To be defined |
| Reporting & Analytics | Data visualization, reporting, and business intelligence | To be defined |

### 2.2.3 Feature Identification Process

Features will be identified through:

1. **Stakeholder Consultation**: Requirements gathering sessions with business owners and end users
2. **User Story Development**: Conversion of business needs into actionable user stories
3. **Technical Analysis**: Assessment of technical feasibility and architectural implications
4. **Priority Assignment**: Evaluation against business value and implementation complexity

## 2.3 Functional Requirements

### 2.3.1 Functional Requirements Status

No functional requirements have been documented for the CheckSameRepoNoPrompt project at this time. This subsection establishes the framework for functional requirements documentation that will be populated as requirements are defined.

### 2.3.2 Requirements Specification Framework

Functional requirements will follow a standardized format to ensure clarity, testability, and traceability:

**Requirement ID Format**: F-XXX-RQ-YYY
- **F-XXX**: Parent feature identifier
- **RQ**: Requirement designator
- **YYY**: Sequential requirement number within feature

**Requirements Table Structure:**

| Element | Description |
|---------|-------------|
| Requirement ID | Unique identifier following format F-XXX-RQ-YYY |
| Description | Clear, concise statement of what the system must do |
| Acceptance Criteria | Specific, measurable conditions that must be met for requirement completion |
| Priority | Classification as Must-Have, Should-Have, or Could-Have |
| Complexity | Assessment of implementation difficulty (High/Medium/Low) |
| Dependencies | Links to prerequisite requirements or features |

### 2.3.3 Requirements Categories

Functional requirements will be organized into the following categories:

#### 2.3.3.1 Business Logic Requirements

Business logic requirements will define system behaviors, calculations, data transformations, and decision-making processes that implement business rules.

**Documentation Approach:**
- Input parameter specifications
- Processing logic descriptions
- Output format definitions
- Business rule validations
- Error handling procedures

#### 2.3.3.2 Data Requirements

Data requirements will specify data structures, storage mechanisms, data lifecycle management, and data quality standards.

**Documentation Approach:**
- Data models and schemas
- Data validation rules
- Data retention policies
- Data migration requirements
- Data security and privacy constraints

#### 2.3.3.3 Interface Requirements

Interface requirements will define user interfaces, APIs, system integrations, and external communication protocols.

**Documentation Approach:**
- User interface specifications
- API endpoint definitions
- Integration protocols
- Message formats
- Authentication and authorization mechanisms

#### 2.3.3.4 Performance Requirements

Performance requirements will establish response time targets, throughput expectations, resource utilization limits, and scalability benchmarks.

**Documentation Approach:**
- Response time thresholds
- Concurrent user capacity
- Transaction volume limits
- Resource consumption targets
- Scalability requirements

### 2.3.4 Requirements Validation

Each functional requirement will include validation criteria to ensure:

- **Testability**: Requirements can be verified through automated or manual testing
- **Completeness**: All necessary information is provided for implementation
- **Consistency**: Requirements do not conflict with other documented requirements
- **Traceability**: Clear linkage to business objectives and technical specifications
- **Feasibility**: Technical and business viability has been assessed

## 2.4 Feature Relationships and Dependencies

### 2.4.1 Dependency Mapping Status

Feature dependency mapping will be performed once features are defined. This subsection provides the framework for documenting feature relationships and dependencies.

### 2.4.2 Dependency Types

Dependencies will be classified into the following categories:

| Dependency Type | Description | Management Approach |
|----------------|-------------|---------------------|
| Sequential | Feature B requires Feature A to be completed first | Strict ordering in implementation roadmap |
| Parallel | Features can be developed simultaneously without conflict | Coordinate integration points and shared components |
| Optional | Feature B is enhanced by Feature A but can function independently | Document enhancement opportunities |
| Conditional | Feature B dependency on Feature A varies by configuration | Define dependency conditions clearly |

### 2.4.3 Integration Points

Integration points between features will be documented to identify:

- **Shared Data Structures**: Common data models used by multiple features
- **Shared Services**: Backend services leveraged across features
- **Common Components**: Reusable UI components or libraries
- **API Contracts**: Interface agreements between feature modules
- **Event Streams**: Asynchronous communication patterns

### 2.4.4 Dependency Visualization

Feature dependencies will be visualized using dependency graphs once features are defined. The visualization will illustrate:

- Feature hierarchy and grouping
- Prerequisite relationships
- Integration touchpoints
- Critical path features for MVP delivery

## 2.5 Non-Functional Requirements

### 2.5.1 Non-Functional Requirements Overview

Non-functional requirements (NFRs) define system qualities, constraints, and operational characteristics that span across features. These requirements will be documented as system architecture and implementation details are defined.

### 2.5.2 Performance and Scalability

#### 2.5.2.1 Performance Criteria

Performance requirements will establish measurable targets for:

- **Response Time**: Maximum acceptable latency for user interactions and system operations
- **Throughput**: Transaction processing capacity and data transfer rates
- **Resource Utilization**: CPU, memory, storage, and network consumption limits
- **Concurrency**: Maximum simultaneous users and parallel operations

#### 2.5.2.2 Scalability Requirements

Scalability requirements will define system growth capabilities:

- **Horizontal Scaling**: Ability to add compute resources to handle increased load
- **Vertical Scaling**: Capacity to upgrade individual system components
- **Data Scalability**: Support for growing data volumes and complexity
- **Geographic Distribution**: Multi-region or multi-datacenter deployment capabilities

### 2.5.3 Security and Compliance

#### 2.5.3.1 Security Requirements

Security requirements will address:

- **Authentication**: User identity verification mechanisms
- **Authorization**: Access control and permission management
- **Data Protection**: Encryption, data masking, and secure storage
- **Audit Logging**: Security event tracking and compliance monitoring
- **Vulnerability Management**: Security testing and patch management

#### 2.5.3.2 Compliance Requirements

Compliance requirements will specify adherence to:

- Regulatory standards and legal requirements
- Industry best practices and standards
- Data privacy regulations
- Accessibility standards
- Documentation and reporting obligations

### 2.5.4 Reliability and Availability

#### 2.5.4.1 Availability Targets

Availability requirements will define:

- **Uptime Percentage**: Target system availability (e.g., 99.9% uptime)
- **Planned Maintenance**: Acceptable maintenance windows and notification requirements
- **Recovery Time Objective (RTO)**: Maximum acceptable downtime after failure
- **Recovery Point Objective (RPO)**: Maximum acceptable data loss in disaster scenarios

#### 2.5.4.2 Reliability Requirements

Reliability requirements will establish:

- Error rate thresholds
- Fault tolerance mechanisms
- Redundancy strategies
- Failover capabilities
- Backup and recovery procedures

### 2.5.5 Maintainability and Supportability

#### 2.5.5.1 Maintainability Requirements

Maintainability requirements will address:

- **Code Quality**: Standards for code structure, documentation, and testing
- **Modularity**: Design principles for component independence and reusability
- **Observability**: Logging, monitoring, and diagnostic capabilities
- **Version Control**: Change management and versioning strategies

#### 2.5.5.2 Supportability Requirements

Supportability requirements will define:

- Technical support processes and escalation procedures
- Documentation requirements for operations and troubleshooting
- Training materials for administrators and end users
- Monitoring and alerting configurations

## 2.6 Requirements Traceability

### 2.6.1 Traceability Matrix Framework

A requirements traceability matrix will be maintained to track relationships between:

- Business objectives and features
- Features and functional requirements
- Functional requirements and technical specifications
- Requirements and test cases
- Requirements and implementation artifacts

### 2.6.2 Traceability Matrix Structure

The traceability matrix will use the following format:

| Requirement ID | Feature ID | Business Objective | Technical Spec Reference | Test Case IDs | Implementation Status |
|----------------|------------|-------------------|--------------------------|---------------|----------------------|
| To be populated when requirements are defined | - | - | - | - | - |

### 2.6.3 Change Impact Analysis

The traceability matrix will enable:

- **Impact Assessment**: Identify downstream effects of requirement changes
- **Coverage Analysis**: Verify all business objectives are addressed by requirements
- **Gap Identification**: Detect missing requirements or untested functionality
- **Release Planning**: Group requirements by implementation dependencies for release planning

## 2.7 Assumptions and Constraints

### 2.7.1 Project Assumptions

Project assumptions will be documented as they are identified during requirements definition. Assumptions represent conditions believed to be true but not yet verified.

**Assumption Categories:**
- Technical environment and infrastructure assumptions
- User capability and training assumptions
- Data availability and quality assumptions
- Third-party service availability assumptions
- Timeline and resource assumptions

### 2.7.2 Project Constraints

Project constraints represent limitations that impact requirements definition and implementation:

| Constraint Type | Description | To Be Defined |
|----------------|-------------|---------------|
| Technical | Technology stack, platform, or integration limitations | When architecture is finalized |
| Resource | Budget, staffing, or skill constraints | During project planning |
| Time | Delivery deadlines or milestone requirements | When project schedule is set |
| Regulatory | Legal, compliance, or policy restrictions | During compliance review |
| Business | Organizational policies or market conditions | Through stakeholder input |

### 2.7.3 Risk Factors

Risk factors that may impact requirements delivery will be documented and tracked:

- **Technical Risks**: Technology uncertainties, integration complexities, or performance challenges
- **Business Risks**: Market changes, stakeholder availability, or priority shifts
- **Resource Risks**: Staff turnover, budget constraints, or skill gaps
- **External Risks**: Third-party dependencies, regulatory changes, or competitive pressures

## 2.8 Requirements Governance

### 2.8.1 Requirements Management Process

The requirements management process will define:

1. **Requirements Elicitation**: Methods for gathering requirements from stakeholders
2. **Requirements Documentation**: Standards for writing and formatting requirements
3. **Requirements Review**: Approval workflow and review criteria
4. **Requirements Baseline**: Process for establishing approved requirement baselines
5. **Change Management**: Procedures for requesting and approving requirement changes

### 2.8.2 Requirement Status Workflow

Requirements will progress through the following statuses:

| Status | Definition | Approval Required |
|--------|------------|-------------------|
| Proposed | Initial requirement submitted for consideration | No |
| Under Review | Requirement being evaluated by stakeholders | No |
| Approved | Requirement accepted for implementation | Yes |
| In Development | Requirement being actively implemented | N/A |
| Implemented | Requirement coding complete, pending testing | N/A |
| Verified | Requirement tested and acceptance criteria met | Yes |
| Deployed | Requirement released to production | N/A |
| Deferred | Requirement postponed to future release | Yes |
| Rejected | Requirement not approved for implementation | Yes |

### 2.8.3 Requirements Versioning

Requirements versioning will maintain historical records of:

- Requirement evolution and changes over time
- Rationale for requirement modifications
- Impact analysis of requirement changes
- Approval history and stakeholder sign-offs

## 2.9 Future Requirements Documentation

### 2.9.1 Documentation Evolution Plan

As the CheckSameRepoNoPrompt project progresses from its current pre-implementation phase, this Product Requirements section will be systematically populated with:

1. **Feature Definitions**: Complete feature catalog with metadata, descriptions, and dependencies
2. **Functional Requirements**: Detailed requirements tables with acceptance criteria and priorities
3. **Dependency Maps**: Visual representations of feature relationships and integration points
4. **Traceability Matrices**: Complete linkage between business objectives, requirements, and implementations
5. **Non-Functional Requirements**: Specific targets for performance, security, reliability, and maintainability

### 2.9.2 Requirements Documentation Timeline

The requirements documentation will be updated at the following project milestones:

- **Requirements Gathering Phase**: Initial population of feature catalog and high-level requirements
- **Requirements Analysis Phase**: Detailed functional requirements with acceptance criteria
- **Design Phase**: Non-functional requirements and technical constraints
- **Implementation Phase**: Traceability updates and requirement status tracking
- **Testing Phase**: Verification status and acceptance criteria validation
- **Deployment Phase**: Final documentation updates and lessons learned

### 2.9.3 Stakeholder Involvement

Requirements definition and documentation will involve:

- **Product Owners**: Business value definition and priority setting
- **End Users**: User story development and acceptance criteria validation
- **Technical Architects**: Technical feasibility assessment and constraint identification
- **Development Teams**: Complexity estimation and dependency mapping
- **Quality Assurance**: Testability review and acceptance criteria refinement
- **Operations Teams**: Supportability and maintainability requirements

#### References

#### Repository Files Examined

- `README.md` - Project identification and naming; contains only project title with no feature descriptions, requirements specifications, or technical documentation

#### Repository Folders Explored

- `` (root folder) - Complete repository structure examined; contains single file (README.md) with no subdirectories, source code, configuration files, or additional documentation artifacts

#### Technical Specification Sections Referenced

- Section 1.1 Executive Summary - Project development stage and documentation status context
- Section 1.2 System Overview - Current repository state and implementation status
- Section 1.3 Scope - Scope definition framework and boundaries

#### Documentation Notes

This Product Requirements section accurately reflects the current state of the CheckSameRepoNoPrompt repository as of this documentation date. The repository is in its initial setup phase with no defined product requirements, implemented features, or functional specifications. This section provides a comprehensive framework that will be populated as the project evolves and requirements are formally defined, reviewed, and approved by project stakeholders.

# 3. Technology Stack

## 3.1 Technology Stack Overview

### 3.1.1 Current Implementation Status

The CheckSameRepoNoPrompt project is in its pre-implementation phase, with no technology stack currently deployed or configured in the repository. This section documents the **planned technology stack** that will be implemented as the project progresses from its initialization stage to active development and production deployment.

The technology selections documented herein represent architectural decisions made to support the planned system capabilities, with each technology choice justified by industry best practices, ecosystem maturity, and alignment with modern software development standards.

### 3.1.2 Technology Selection Principles

The planned technology stack adheres to the following selection principles:

- **Ecosystem Maturity**: Preference for technologies with established communities, comprehensive documentation, and long-term support commitments
- **Scalability**: Technologies capable of supporting growth from MVP to enterprise-scale deployments
- **Developer Productivity**: Tools and frameworks that accelerate development while maintaining code quality
- **Security First**: Technologies with strong security track records and active vulnerability management
- **Cloud-Native Compatibility**: Components designed for modern cloud infrastructure and containerized deployments
- **Interoperability**: Technologies with well-defined integration patterns and extensive library support

### 3.1.3 Stack Architecture Overview

The planned technology stack follows a modern, cloud-native architecture pattern with clear separation of concerns across multiple tiers:

```mermaid
graph TB
subgraph "Client Layer"
    WEB[Web Application<br/>React + TypeScript]
    MOBILE[Mobile Application<br/>React Native + TypeScript]
    IOS[iOS Native<br/>Swift]
    ANDROID[Android Native<br/>Kotlin]
    MACOS[macOS Application<br/>Objective-C]
    DESKTOP[Desktop Application<br/>Electron.js]
end

subgraph "API Gateway & Authentication"
    AUTH[Auth0<br/>Authentication Service]
    API[API Layer<br/>Flask REST API]
end

subgraph "Application Layer"
    BACKEND[Backend Services<br/>Python + Flask]
    AI[AI/ML Services<br/>LangChain]
end

subgraph "Data Layer"
    MONGO[MongoDB<br/>Primary Database]
    CACHE[Caching Layer<br/>TBD]
end

subgraph "Infrastructure Layer"
    AWS[AWS Cloud Platform]
    DOCKER[Docker Containers]
    TERRAFORM[Infrastructure as Code<br/>Terraform]
    CICD[CI/CD Pipeline<br/>GitHub Actions]
end

WEB --> AUTH
MOBILE --> AUTH
IOS --> AUTH
ANDROID --> AUTH
MACOS --> AUTH
DESKTOP --> AUTH

AUTH --> API
API --> BACKEND
BACKEND --> AI
BACKEND --> MONGO
BACKEND --> CACHE

BACKEND -.runs on.-> DOCKER
DOCKER -.deployed to.-> AWS
TERRAFORM -.provisions.-> AWS
CICD -.automates.-> DOCKER
```

## 3.2 Programming Languages

### 3.2.1 Backend Languages

#### 3.2.1.1 Python (Primary Backend Language)

**Planned Version**: Python 3.11+

**Justification**:
- **Ecosystem Richness**: Extensive libraries for web development, data processing, and AI/ML integration
- **AI/ML Integration**: Native compatibility with LangChain and other AI frameworks, critical for planned intelligent features
- **Rapid Development**: High-level syntax and comprehensive standard library accelerate backend development
- **Community Support**: Large, active community with extensive package ecosystem via PyPI
- **Performance**: Python 3.11+ includes significant performance improvements (10-60% faster than 3.10)
- **Flask Compatibility**: Seamless integration with the planned Flask framework

**Use Cases**:
- RESTful API implementation
- Business logic processing
- AI/ML model integration and orchestration
- Data transformation and validation
- Third-party service integration

**Dependencies**:
- Requires Python 3.11 or higher for optimal performance and security
- Compatible with Flask 2.3+ and LangChain ecosystem
- WSGI server required for production deployment (e.g., Gunicorn, uWSGI)

### 3.2.2 Frontend Languages

#### 3.2.2.1 TypeScript (Web and Mobile Frontend)

**Planned Version**: TypeScript 5.0+

**Justification**:
- **Type Safety**: Static typing reduces runtime errors and improves code maintainability
- **IDE Support**: Enhanced autocomplete, refactoring, and error detection during development
- **JavaScript Superset**: Full JavaScript compatibility while adding enterprise-grade type checking
- **React Compatibility**: First-class support in React ecosystem with comprehensive type definitions
- **Scalability**: Type system supports large-scale application development with multiple teams
- **Documentation**: Types serve as inline documentation, improving code readability

**Use Cases**:
- React web application development
- React Native mobile application development
- Shared type definitions across frontend platforms
- API client type definitions for backend integration

**Dependencies**:
- Node.js 18+ LTS for TypeScript compilation
- Compatible with React 18+ and React Native 0.72+
- Type definitions for third-party libraries via @types packages

#### 3.2.2.2 JavaScript (Runtime Environment)

**Planned Version**: ES2022+ (via Node.js 18+ LTS)

**Justification**:
- **Electron.js Requirement**: Native language for cross-platform desktop application development
- **Universal Runtime**: Enables code sharing between web, mobile, and desktop platforms
- **Performance**: Modern JavaScript engines (V8, JavaScriptCore) provide excellent runtime performance
- **Ecosystem**: NPM ecosystem provides access to millions of packages

**Use Cases**:
- Electron.js desktop application runtime
- Build tooling and development scripts
- Server-side rendering (if implemented)
- Development tooling automation

### 3.2.3 Native Mobile Languages

#### 3.2.3.1 Swift (iOS Native Development)

**Planned Version**: Swift 5.9+

**Justification**:
- **iOS Platform Standard**: Apple's recommended language for native iOS development
- **Performance**: Compiled language with performance comparable to C++
- **Safety**: Strong type system and memory safety features reduce crashes
- **Modern Syntax**: Clean, expressive syntax improves developer productivity
- **SwiftUI Integration**: Native support for Apple's declarative UI framework
- **Interoperability**: Seamless integration with iOS SDK and Apple frameworks

**Use Cases**:
- iOS native features requiring platform-specific APIs
- Performance-critical mobile functionality
- Deep iOS system integration (e.g., ARKit, CoreML, HealthKit)
- Native UI components for optimal user experience

**Dependencies**:
- Xcode 15+ for development and compilation
- iOS 15+ deployment target recommended
- CocoaPods or Swift Package Manager for dependency management

#### 3.2.3.2 Kotlin (Android Native Development)

**Planned Version**: Kotlin 1.9+

**Justification**:
- **Android Platform Standard**: Google's recommended language for Android development
- **Java Interoperability**: Full compatibility with existing Java libraries and Android SDK
- **Modern Language Features**: Null safety, coroutines, and extension functions improve code quality
- **Concise Syntax**: Reduces boilerplate code compared to Java
- **Jetpack Compose**: Native support for Android's modern declarative UI toolkit
- **Performance**: Compiles to efficient JVM bytecode with minimal runtime overhead

**Use Cases**:
- Android native features requiring platform-specific APIs
- Performance-critical mobile functionality
- Deep Android system integration (e.g., sensors, notifications, background services)
- Native UI components optimized for Android

**Dependencies**:
- Android Studio Arctic Fox or later for development
- Android SDK 24+ (Android 7.0+) as minimum deployment target
- Gradle 8+ for build automation
- Kotlin coroutines for asynchronous programming

#### 3.2.3.3 Objective-C (macOS Native Development)

**Planned Version**: Objective-C 2.0 with ARC

**Justification**:
- **Legacy Compatibility**: Extensive existing macOS libraries and frameworks written in Objective-C
- **macOS SDK Access**: Complete access to mature Cocoa and AppKit frameworks
- **Performance**: Compiled language with minimal runtime overhead
- **Stability**: Mature language with decades of macOS development experience
- **Interoperability**: Seamless integration with C and C++ libraries when needed

**Use Cases**:
- macOS-specific desktop application features
- Integration with legacy macOS frameworks
- Performance-critical desktop operations
- Native macOS UI components using AppKit

**Dependencies**:
- Xcode 15+ for development and compilation
- macOS 11+ (Big Sur) deployment target recommended
- CocoaPods or Swift Package Manager for dependency management

### 3.2.4 Language Selection Summary

| Language | Platform | Primary Use Case | Version | Type System |
|----------|----------|------------------|---------|-------------|
| Python | Backend | API, Business Logic, AI/ML | 3.11+ | Dynamic (with type hints) |
| TypeScript | Web/Mobile | React, React Native | 5.0+ | Static |
| JavaScript | Desktop/Tooling | Electron.js, Build Tools | ES2022+ | Dynamic |
| Swift | iOS | Native iOS Features | 5.9+ | Static (Strong) |
| Kotlin | Android | Native Android Features | 1.9+ | Static (Strong) |
| Objective-C | macOS | Native macOS Features | 2.0 | Dynamic (with static typing options) |

## 3.3 Frameworks & Libraries

### 3.3.1 Backend Frameworks

#### 3.3.1.1 Flask (Web Application Framework)

**Planned Version**: Flask 3.0+

**Justification**:
- **Lightweight and Flexible**: Microframework philosophy allows precise control over application architecture
- **RESTful API Support**: Excellent foundation for building REST APIs with minimal overhead
- **Extensibility**: Large ecosystem of extensions (Flask-RESTful, Flask-CORS, Flask-SQLAlchemy)
- **Python Integration**: Native Python framework leveraging language strengths
- **Learning Curve**: Simpler than Django for focused API development
- **Production Ready**: Proven track record in production environments when paired with WSGI servers

**Core Capabilities**:
- HTTP request routing and handling
- RESTful API endpoint definition
- Middleware integration for authentication, logging, and error handling
- Template rendering (if server-side rendering is required)
- Session management and cookie handling
- Blueprint-based application modularization

**Compatibility Requirements**:
- Python 3.11+ runtime environment
- WSGI-compatible web server for production (Gunicorn recommended)
- Compatible with MongoDB via PyMongo or Motor (async driver)
- Integration with Auth0 via Flask-OIDC or similar libraries

**Key Extensions Planned**:
- **Flask-CORS**: Cross-Origin Resource Sharing support for frontend integration
- **Flask-RESTful**: Simplified REST API development with resource-based routing
- **Flask-JWT-Extended**: JWT token management (if Auth0 JWT verification is handled locally)
- **Flask-Limiter**: Rate limiting for API endpoints
- **Flask-Caching**: Response caching integration

#### 3.3.1.2 LangChain (AI/ML Framework)

**Planned Version**: LangChain 0.1.0+

**Justification**:
- **LLM Orchestration**: Purpose-built framework for building applications with large language models
- **Chain Abstraction**: Simplifies complex AI workflows through composable chains
- **Memory Management**: Built-in conversation memory and context management
- **Multi-Model Support**: Compatible with OpenAI, Anthropic, Hugging Face, and local models
- **Tool Integration**: Framework for integrating external tools and APIs with AI models
- **Vector Database Support**: Native integration with vector stores for semantic search
- **Rapid Development**: Abstractions accelerate AI feature development

**Core Capabilities**:
- LLM prompt management and templating
- Conversation chain orchestration
- Document loading and text processing
- Vector embeddings and semantic search
- Agent-based autonomous task execution
- Memory persistence across conversations
- Custom tool and function calling

**Compatibility Requirements**:
- Python 3.11+ runtime
- OpenAI API or compatible LLM provider (API keys required)
- Vector database for embeddings (e.g., Pinecone, Weaviate, or MongoDB Atlas Vector Search)
- Integration with Flask backend via standard Python imports

**Dependencies**:
- OpenAI Python SDK (if using OpenAI models)
- PyMongo or Motor for MongoDB-backed memory persistence
- Vector database client libraries
- Additional model-specific dependencies based on LLM provider selection

### 3.3.2 Frontend Frameworks

#### 3.3.2.1 React (Web Application Framework)

**Planned Version**: React 18.2+

**Justification**:
- **Industry Standard**: Most widely adopted frontend framework with largest ecosystem
- **Component Reusability**: Encapsulated, reusable components accelerate development
- **Virtual DOM**: Efficient rendering and updates for responsive user interfaces
- **TypeScript Support**: First-class TypeScript integration with comprehensive type definitions
- **Concurrent Features**: React 18 concurrent rendering improves perceived performance
- **Large Ecosystem**: Extensive third-party libraries for routing, state management, forms, etc.
- **Developer Tools**: Excellent browser extensions and debugging capabilities
- **Community Support**: Massive community with abundant learning resources and solutions

**Core Capabilities**:
- Component-based UI development
- Declarative rendering with JSX/TSX
- State management (via hooks: useState, useReducer, useContext)
- Side effect handling (useEffect, useLayoutEffect)
- Performance optimization (useMemo, useCallback, React.memo)
- Suspense and lazy loading for code splitting
- Error boundaries for graceful error handling

**Compatibility Requirements**:
- Node.js 18+ LTS for development tooling
- Bundler required (Vite, Webpack, or Parcel)
- TypeScript 5.0+ for type checking
- React Router 6+ for client-side routing
- Compatible with TailwindCSS for styling

**Key Supporting Libraries**:
- **React Router**: Client-side routing and navigation
- **React Query / TanStack Query**: Server state management and API caching
- **Axios**: HTTP client for API communication
- **React Hook Form**: Performant form validation and handling
- **Zustand or Redux Toolkit**: Global state management (if needed)

#### 3.3.2.2 React Native (Mobile Application Framework)

**Planned Version**: React Native 0.72+

**Justification**:
- **Cross-Platform Development**: Single codebase for iOS and Android reduces development effort
- **React Compatibility**: Shared concepts and patterns with React web enable code reuse
- **Native Performance**: Compiles to native components for performance comparable to native apps
- **Hot Reloading**: Fast development iteration with instant preview of changes
- **TypeScript Support**: Full TypeScript compatibility for type-safe mobile development
- **Extensive Libraries**: Rich ecosystem of native modules and community packages
- **Bridge to Native**: Ability to integrate native Swift/Kotlin code when platform-specific features are needed

**Core Capabilities**:
- Cross-platform mobile UI components (View, Text, Image, ScrollView, etc.)
- Native module integration for platform-specific APIs
- Navigation patterns optimized for mobile
- Touch and gesture handling
- Async storage for local data persistence
- Camera, location, and sensor access
- Push notification support
- Deep linking and universal links

**Compatibility Requirements**:
- Node.js 18+ LTS for Metro bundler
- Xcode 15+ for iOS development and testing
- Android Studio for Android development and testing
- TypeScript 5.0+ for type checking
- React Navigation 6+ for mobile navigation patterns

**Key Supporting Libraries**:
- **React Navigation**: Native-like navigation patterns for mobile
- **React Native Paper**: Material Design component library
- **Axios**: HTTP client for API communication
- **AsyncStorage**: Local key-value storage
- **React Native Firebase**: Firebase services integration (if needed)
- **React Native Vector Icons**: Icon library for UI elements

#### 3.3.2.3 Electron.js (Desktop Application Framework)

**Planned Version**: Electron 28+

**Justification**:
- **Cross-Platform Desktop**: Single codebase for Windows, macOS, and Linux desktop applications
- **Web Technology Stack**: Leverages existing React and TypeScript knowledge
- **Native Integration**: Access to filesystem, system tray, notifications, and OS-level features
- **Automatic Updates**: Built-in framework for application auto-updates
- **Distribution**: Simplified packaging and distribution across platforms
- **Chromium-Based**: Consistent rendering across all operating systems

**Core Capabilities**:
- Desktop window management and lifecycle
- Native menu and tray integration
- Filesystem access beyond browser sandbox
- Inter-process communication (IPC) between main and renderer processes
- Native notifications and dialogs
- System clipboard and drag-and-drop
- Hardware acceleration for graphics
- Built-in crash reporting

**Compatibility Requirements**:
- Node.js 18+ LTS for main process
- React 18+ for renderer process UI
- TypeScript 5.0+ for both main and renderer processes
- Electron Forge or Electron Builder for packaging
- Code signing certificates for distribution

**Key Supporting Libraries**:
- **Electron Forge**: Build, package, and distribute Electron apps
- **Electron Builder**: Alternative packaging and distribution tool
- **electron-updater**: Automatic application updates
- **electron-store**: Persistent user settings storage
- **electron-log**: Enhanced logging for desktop applications

### 3.3.3 UI/Styling Frameworks

#### 3.3.3.1 TailwindCSS (Utility-First CSS Framework)

**Planned Version**: TailwindCSS 3.4+

**Justification**:
- **Utility-First Approach**: Rapid UI development with composable utility classes
- **Design Consistency**: Built-in design system ensures visual consistency
- **Minimal CSS**: Eliminates need to write custom CSS for most use cases
- **PurgeCSS Integration**: Automatic removal of unused styles reduces bundle size
- **Responsive Design**: Mobile-first responsive utilities simplify multi-device support
- **Customization**: Highly configurable design tokens for brand alignment
- **TypeScript Support**: Type-safe configuration and IntelliSense support
- **Dark Mode**: Built-in dark mode utilities

**Core Capabilities**:
- Complete utility class library for styling
- Responsive breakpoint system
- Dark mode and theme variants
- Custom design token configuration
- Component composition patterns
- Animation and transition utilities
- Typography and spacing scales
- Grid and flexbox layout utilities

**Compatibility Requirements**:
- PostCSS 8+ for processing
- Compatible with React, React Native (via third-party adapters), and Electron
- Node.js 18+ for build tooling
- Vite or Webpack for build integration

**Integration Considerations**:
- React Native requires alternative solution (e.g., NativeWind) for Tailwind-like syntax
- Desktop Electron apps benefit from full Tailwind feature set
- Configuration shared between web and desktop applications

## 3.4 Open Source Dependencies

### 3.4.1 Dependency Management Strategy

The planned technology stack will utilize multiple package registries and dependency management tools based on platform requirements:

| Platform | Package Manager | Registry | Lock File |
|----------|----------------|----------|-----------|
| Backend (Python) | pip / Poetry | PyPI | requirements.txt / poetry.lock |
| Frontend (Web/Mobile) | npm / yarn | npm Registry | package-lock.json / yarn.lock |
| iOS Native | CocoaPods / SPM | CocoaPods / GitHub | Podfile.lock / Package.resolved |
| Android Native | Gradle | Maven Central | gradle.lock |
| macOS Native | CocoaPods / SPM | CocoaPods / GitHub | Podfile.lock / Package.resolved |

### 3.4.2 Backend Dependencies (Python/PyPI)

#### 3.4.2.1 Core Framework Dependencies

**Flask Ecosystem**:
- **flask** (3.0+): Core web framework
- **werkzeug** (3.0+): WSGI utilities (Flask dependency)
- **flask-cors** (4.0+): Cross-origin resource sharing support
- **flask-restful** (0.3.10+): REST API utilities
- **gunicorn** (21.2+): Production WSGI server

**AI/ML Dependencies**:
- **langchain** (0.1.0+): LLM orchestration framework
- **openai** (1.0+): OpenAI API client (if using OpenAI models)
- **tiktoken** (0.5+): Token counting for LLM context management
- **anthropic** (0.8+): Anthropic API client (optional, if using Claude)

**Database and Data Processing**:
- **pymongo** (4.6+): MongoDB Python driver
- **motor** (3.3+): Async MongoDB driver (if async support needed)
- **pydantic** (2.5+): Data validation and serialization
- **marshmallow** (3.20+): Object serialization/deserialization (alternative to Pydantic)

**Authentication and Security**:
- **authlib** (1.3+): OAuth and OIDC client for Auth0 integration
- **pyjwt** (2.8+): JWT token encoding/decoding
- **cryptography** (41.0+): Cryptographic operations
- **python-dotenv** (1.0+): Environment variable management

**Utilities**:
- **requests** (2.31+): HTTP client library
- **python-dateutil** (2.8+): Date and time utilities
- **click** (8.1+): CLI creation toolkit
- **python-json-logger** (2.0+): Structured logging

#### 3.4.2.2 Development and Testing Dependencies

- **pytest** (7.4+): Testing framework
- **pytest-cov** (4.1+): Code coverage reporting
- **pytest-asyncio** (0.21+): Async test support
- **black** (23.12+): Code formatting
- **flake8** (6.1+): Linting
- **mypy** (1.7+): Static type checking
- **pre-commit** (3.6+): Git hook automation

### 3.4.3 Frontend Dependencies (JavaScript/npm)

#### 3.4.3.1 Web Application Dependencies

**React Core**:
- **react** (18.2+): React library
- **react-dom** (18.2+): React DOM bindings
- **typescript** (5.0+): TypeScript compiler

**Routing and State Management**:
- **react-router-dom** (6.20+): Client-side routing
- **@tanstack/react-query** (5.0+): Server state management
- **zustand** (4.4+): Lightweight state management (optional)

**API and Data Fetching**:
- **axios** (1.6+): HTTP client
- **swr** (2.2+): Data fetching hooks (alternative to React Query)

**Forms and Validation**:
- **react-hook-form** (7.48+): Form handling
- **zod** (3.22+): Schema validation

**UI and Styling**:
- **tailwindcss** (3.4+): Utility-first CSS framework
- **clsx** (2.0+): Conditional className construction
- **tailwind-merge** (2.1+): Merge Tailwind classes intelligently

**Authentication**:
- **@auth0/auth0-react** (2.2+): Auth0 React SDK

**Development Tools**:
- **vite** (5.0+): Build tool and dev server
- **@vitejs/plugin-react** (4.2+): React plugin for Vite
- **eslint** (8.55+): JavaScript/TypeScript linting
- **prettier** (3.1+): Code formatting
- **@types/react** (18.2+): React TypeScript definitions
- **@types/react-dom** (18.2+): React DOM TypeScript definitions

#### 3.4.3.2 Mobile Application Dependencies

**React Native Core**:
- **react-native** (0.72+): React Native framework
- **react** (18.2+): React library

**Navigation**:
- **@react-navigation/native** (6.1+): Navigation framework
- **@react-navigation/stack** (6.3+): Stack navigator
- **@react-navigation/bottom-tabs** (6.5+): Tab navigator

**UI Components**:
- **react-native-paper** (5.11+): Material Design components
- **react-native-vector-icons** (10.0+): Icon library

**Storage and State**:
- **@react-native-async-storage/async-storage** (1.21+): Async storage
- **@tanstack/react-query** (5.0+): Server state management

**Platform Services**:
- **react-native-firebase** (18.7+): Firebase integration (optional)
- **@react-native-community/netinfo** (11.1+): Network status
- **react-native-permissions** (3.10+): Permission management

**Development Tools**:
- **metro** (0.80+): JavaScript bundler
- **@react-native-community/cli** (12.0+): React Native CLI

#### 3.4.3.3 Desktop Application Dependencies

**Electron Core**:
- **electron** (28+): Electron framework

**Build and Packaging**:
- **electron-forge** (7.0+): Build and package tool
- **electron-builder** (24.9+): Alternative packager

**Desktop-Specific**:
- **electron-store** (8.1+): Persistent settings storage
- **electron-updater** (6.1+): Auto-update functionality
- **electron-log** (5.0+): Enhanced logging

### 3.4.4 Native Mobile Dependencies

#### 3.4.4.1 iOS Dependencies (CocoaPods)

- **Alamofire** (~> 5.8): Networking library
- **SwiftyJSON** (~> 5.0): JSON parsing
- **KeychainAccess** (~> 4.2): Secure credential storage
- **SnapKit** (~> 5.6): Auto Layout DSL (if not using SwiftUI)

#### 3.4.4.2 Android Dependencies (Gradle/Maven)

```
dependencies {
    // Kotlin
    implementation("org.jetbrains.kotlin:kotlin-stdlib:1.9+")
    implementation("org.jetbrains.kotlinx:kotlinx-coroutines-android:1.7+")
    
    // AndroidX
    implementation("androidx.core:core-ktx:1.12+")
    implementation("androidx.appcompat:appcompat:1.6+")
    implementation("androidx.lifecycle:lifecycle-runtime-ktx:2.6+")
    
    // Jetpack Compose (if used)
    implementation("androidx.compose.ui:ui:1.5+")
    implementation("androidx.compose.material3:material3:1.1+")
    
    // Networking
    implementation("com.squareup.retrofit2:retrofit:2.9+")
    implementation("com.squareup.okhttp3:okhttp:4.12+")
    
    // JSON Processing
    implementation("com.google.code.gson:gson:2.10+")
    
    // Dependency Injection (optional)
    implementation("com.google.dagger:hilt-android:2.48+")
}
```

### 3.4.5 Dependency Version Management

**Version Constraints**:
- Use semantic versioning with appropriate constraint operators
- Pin major versions to prevent breaking changes
- Allow minor and patch updates for security fixes
- Document specific version requirements for compatibility

**Security Updates**:
- Regular dependency audits using platform-specific tools (npm audit, pip-audit, bundle-audit)
- Automated dependency update PRs via Dependabot or Renovate
- Security vulnerability scanning in CI/CD pipeline
- SBOM (Software Bill of Materials) generation for compliance

## 3.5 Third-Party Services

### 3.5.1 Authentication Services

#### 3.5.1.1 Auth0 (Identity and Access Management)

**Service Type**: Authentication and Authorization Platform

**Justification**:
- **Enterprise-Grade Security**: Industry-leading authentication service with SOC 2 Type II compliance
- **Multi-Platform Support**: SDKs available for web, mobile (iOS/Android), and backend integration
- **OAuth 2.0 / OIDC**: Standards-compliant authentication protocols
- **Social Login**: Pre-built integrations with Google, Facebook, Apple, GitHub, etc.
- **MFA Support**: Built-in multi-factor authentication with SMS, email, and authenticator apps
- **User Management**: Comprehensive user database with profile management
- **Scalability**: Handles authentication load without infrastructure management
- **Customization**: Extensible through Rules, Hooks, and Actions for custom authentication logic

**Integration Points**:
- **Web Application**: `@auth0/auth0-react` SDK for React integration
- **Mobile Applications**: 
  - React Native: `@auth0/react-native-auth0`
  - iOS Native: `Auth0.swift` SDK
  - Android Native: `Auth0.Android` SDK
- **Backend API**: Token verification and user session validation
- **Desktop Application**: Electron integration via web-based authentication flow

**Configuration Requirements**:
- Auth0 tenant setup with custom domain (recommended for production)
- Application registration for each platform (Web, iOS, Android, Desktop)
- API resource configuration for backend authorization
- JWT signing keys for token verification
- Callback URLs and CORS configuration for each client application

**Planned Features to Utilize**:
- User registration and login
- Password reset flows
- Social identity provider integration
- Single sign-on (SSO) across platforms
- Role-based access control (RBAC)
- JWT token issuance and refresh
- User profile management

**Cost Considerations**:
- Auth0 offers free tier for development (7,000 active users)
- Production pricing scales with monthly active users
- Advanced features (MFA, custom domains) may require paid tiers

### 3.5.2 Cloud Services

#### 3.5.2.1 Amazon Web Services (AWS) - Cloud Platform

**Service Type**: Cloud Infrastructure Provider

**Justification**:
- **Market Leader**: Largest cloud provider with most comprehensive service catalog
- **Global Reach**: Multiple regions and availability zones for low-latency access
- **Service Breadth**: Complete ecosystem from compute to AI/ML services
- **Maturity**: Proven track record with enterprise-grade SLAs
- **Integration**: Native integrations with deployment and monitoring tools
- **Cost Management**: Granular pricing with multiple instance types and pricing models

**Planned AWS Services**:

**Compute Services**:
- **Amazon ECS (Elastic Container Service)**: Docker container orchestration
- **AWS Fargate**: Serverless compute engine for containers (eliminates EC2 management)
- **Amazon EC2**: Virtual servers for control plane or specialized workloads (if needed)
- **AWS Lambda**: Serverless functions for event-driven processing (optional)

**Networking**:
- **Amazon VPC (Virtual Private Cloud)**: Isolated network environment
- **Elastic Load Balancing (ALB)**: Application load balancer for traffic distribution
- **Amazon Route 53**: DNS management and routing
- **AWS CloudFront**: CDN for static asset delivery

**Storage**:
- **Amazon S3**: Object storage for file uploads, backups, and static assets
- **Amazon EBS**: Block storage for persistent container volumes (if needed)

**Database**:
- **MongoDB Atlas on AWS**: Managed MongoDB hosting (alternative to self-hosted)

**Security and IAM**:
- **AWS IAM**: Identity and access management for AWS resources
- **AWS Secrets Manager**: Secure credential and API key storage
- **AWS Certificate Manager**: SSL/TLS certificate provisioning and management
- **AWS WAF**: Web application firewall for API protection

**Monitoring and Logging**:
- **Amazon CloudWatch**: Metrics, logs, and monitoring
- **AWS X-Ray**: Distributed tracing for performance analysis
- **CloudWatch Logs**: Centralized log aggregation

**CI/CD Integration**:
- **Amazon ECR (Elastic Container Registry)**: Docker image repository
- **AWS CodeDeploy**: Deployment automation (optional, if not using GitHub Actions exclusively)

**Integration Requirements**:
- AWS account with appropriate IAM roles and policies
- Terraform-managed infrastructure (see Infrastructure as Code section)
- VPC configuration with public and private subnets
- Security groups for network access control
- S3 buckets with appropriate access policies

### 3.5.3 AI/ML Services

#### 3.5.3.1 OpenAI API (Primary LLM Provider - Optional)

**Service Type**: Large Language Model API

**Justification** (if utilized):
- **State-of-the-Art Models**: Access to GPT-4 and future model iterations
- **API Simplicity**: RESTful API with comprehensive documentation
- **LangChain Integration**: Native support in LangChain framework
- **Function Calling**: Structured outputs and tool integration capabilities
- **Embeddings**: Text embeddings for semantic search via text-embedding-ada-002

**Potential Use Cases**:
- Conversational AI features
- Content generation and summarization
- Semantic search and document analysis
- Code generation assistance
- Natural language understanding

**Integration**:
- OpenAI Python SDK integrated into backend services
- LangChain abstraction layer for model-agnostic development
- API key management via AWS Secrets Manager
- Rate limiting and cost monitoring

**Note**: Final LLM provider selection depends on specific feature requirements and cost analysis

### 3.5.4 Monitoring and Observability Services

#### 3.5.4.1 Monitoring Strategy (To Be Determined)

**Planned Monitoring Capabilities**:
- Application performance monitoring (APM)
- Error tracking and alerting
- User session replay (for web/desktop)
- Real-time performance metrics
- Custom event tracking
- Log aggregation and analysis

**Potential Services**:
- **DataDog**: Comprehensive monitoring platform with APM, logs, and infrastructure monitoring
- **Sentry**: Error tracking and performance monitoring
- **LogRocket**: Session replay and frontend monitoring
- **CloudWatch**: AWS-native monitoring (baseline)

**Integration Requirements**:
- SDK integration in frontend and backend applications
- Log forwarding from containers to monitoring service
- Alert configuration for critical errors and performance degradation
- Dashboard creation for key metrics

### 3.5.5 Email and Communication Services

#### 3.5.5.1 Email Service (To Be Determined)

**Planned Email Capabilities**:
- Transactional emails (registration, password reset, notifications)
- Templating system for email content
- Delivery tracking and analytics
- High deliverability rates

**Potential Services**:
- **SendGrid**: Email delivery platform with comprehensive API
- **Amazon SES**: Cost-effective email service integrated with AWS
- **Mailgun**: Email service with powerful API and analytics

### 3.5.6 Service Integration Architecture

```mermaid
graph TB
    subgraph "External Services"
        AUTH0[Auth0<br/>Authentication]
        AWS_CLOUD[AWS Cloud Platform]
        OPENAI[OpenAI API<br/>Optional]
        MONITORING[Monitoring Service<br/>TBD]
        EMAIL[Email Service<br/>TBD]
    end
    
    subgraph "Application Services"
        WEB[Web App]
        MOBILE[Mobile Apps]
        DESKTOP[Desktop App]
        API[Backend API]
    end
    
    subgraph "AWS Services"
        ECS[ECS/Fargate<br/>Container Runtime]
        S3[S3 Storage]
        ECR[ECR Registry]
        ALB[Load Balancer]
        CLOUDWATCH[CloudWatch<br/>Logs & Metrics]
        SECRETS[Secrets Manager]
    end
    
    WEB --> AUTH0
    MOBILE --> AUTH0
    DESKTOP --> AUTH0
    
    WEB --> ALB
    MOBILE --> ALB
    DESKTOP --> ALB
    
    ALB --> API
    API --> ECS
    
    API --> AUTH0
    API --> OPENAI
    API --> S3
    API --> EMAIL
    
    ECS --> CLOUDWATCH
    API --> MONITORING
    WEB --> MONITORING
    MOBILE --> MONITORING
    DESKTOP --> MONITORING
    
    API --> SECRETS
    
    AWS_CLOUD -.manages.-> ECS
    AWS_CLOUD -.manages.-> S3
    AWS_CLOUD -.manages.-> ECR
    AWS_CLOUD -.manages.-> ALB
    AWS_CLOUD -.manages.-> CLOUDWATCH
    AWS_CLOUD -.manages.-> SECRETS
```

## 3.6 Databases & Storage

### 3.6.1 Primary Database

#### 3.6.1.1 MongoDB (NoSQL Document Database)

**Planned Version**: MongoDB 7.0+

**Deployment Strategy**: MongoDB Atlas (Managed Service on AWS) or Self-Hosted on AWS ECS

**Justification**:
- **Schema Flexibility**: Document model accommodates evolving data structures without migrations
- **Developer Productivity**: JSON-like documents map naturally to application objects
- **Horizontal Scalability**: Built-in sharding for distributed data storage
- **Rich Query Language**: Powerful aggregation framework for complex queries
- **Python Integration**: Excellent PyMongo and Motor driver support
- **Indexing**: Flexible indexing strategies including compound, text, and geospatial indexes
- **ACID Transactions**: Multi-document transaction support for data consistency
- **Change Streams**: Real-time data change notifications for reactive applications

**Planned Usage Patterns**:

**Collections and Data Models**:
- **Users Collection**: User profiles, preferences, and metadata (supplementing Auth0)
- **Conversations Collection**: AI conversation history and context
- **Documents Collection**: User-uploaded documents and content
- **Analytics Collection**: Application usage and event tracking data
- **Sessions Collection**: User session data and state management

**Performance Optimizations**:
- **Indexing Strategy**: Indexes on frequently queried fields (user_id, created_at, status)
- **Aggregation Pipelines**: Complex data transformations and analytics queries
- **Sharding Key Selection**: Appropriate shard key for horizontal scaling (likely user_id or tenant_id)
- **Read Preferences**: Read preference configuration for performance vs. consistency tradeoffs

**Compatibility Requirements**:
- **Python Drivers**:
  - PyMongo 4.6+ for synchronous operations
  - Motor 3.3+ for async/await support with FastAPI/AsyncIO
- **Connection Pooling**: Configured connection pools for efficient resource utilization
- **Authentication**: MongoDB user authentication with role-based access control
- **Encryption**: TLS/SSL for data in transit, encryption at rest for sensitive data

**High Availability Configuration**:
- **Replica Sets**: Minimum 3-node replica set for production (Primary + 2 Secondaries)
- **Automatic Failover**: Replica set election for high availability
- **Backup Strategy**: Daily automated backups with point-in-time recovery capability
- **Geographic Distribution**: Multi-region deployment for disaster recovery (production)

**MongoDB Atlas Features** (if using managed service):
- Automated backups and point-in-time recovery
- Performance advisor for query optimization
- Real-time performance monitoring
- Automated security patching
- Horizontal scaling without downtime
- MongoDB Atlas Vector Search for AI embeddings (LangChain integration)

### 3.6.2 Vector Database for AI Features

#### 3.6.2.1 Vector Storage Strategy (To Be Determined)

**Requirement**: Store and query high-dimensional vector embeddings for semantic search, document similarity, and AI context retrieval.

**Option 1: MongoDB Atlas Vector Search**:
- **Advantage**: Integrated with primary database, no additional service required
- **Use Case**: Unified storage for documents and their embeddings
- **LangChain Support**: Native integration available

**Option 2: Dedicated Vector Database**:
- **Pinecone**: Fully managed vector database with high performance
- **Weaviate**: Open-source vector search engine with ML model integration
- **Qdrant**: Open-source vector search engine optimized for LangChain

**Selection Criteria**:
- Scale of vector operations (queries per second)
- Cost considerations (managed service vs. self-hosted)
- Integration complexity with LangChain
- Query performance requirements

### 3.6.3 Caching Strategy

#### 3.6.3.1 Application-Level Caching

**Planned Solution**: To Be Determined (Redis or Memcached)

**Use Cases**:
- API response caching for frequently accessed data
- Session data storage (if not using Auth0 session management)
- Rate limiting counters
- Temporary data storage (verification codes, OTP)
- LLM response caching to reduce API costs

**Redis Advantages** (likely choice):
- **Data Structures**: Rich data types (strings, hashes, lists, sets, sorted sets)
- **Persistence**: Optional data persistence for durability
- **Pub/Sub**: Built-in publish/subscribe messaging
- **Lua Scripting**: Complex atomic operations
- **Cluster Support**: Redis Cluster for horizontal scaling

**Deployment Options**:
- **Amazon ElastiCache for Redis**: Managed Redis service on AWS
- **Self-Hosted Redis**: Redis container on ECS with persistent volumes
- **Redis Enterprise Cloud**: Third-party managed Redis with advanced features

**Cache Invalidation Strategy**:
- Time-based expiration (TTL) for time-sensitive data
- Event-based invalidation on data updates
- Cache-aside pattern for database query caching
- LRU eviction policy for memory management

### 3.6.4 Object Storage

#### 3.6.4.1 Amazon S3 (Simple Storage Service)

**Use Cases**:
- User-uploaded files (documents, images, media)
- Application static assets (if not using CDN directly)
- Database backups and archives
- Log file archival
- ML model storage (if custom models are trained)
- Terraform state file storage (with versioning and locking)

**Planned S3 Bucket Strategy**:

**Bucket Organization**:
- **app-uploads-prod**: User-generated content (production)
- **app-uploads-staging**: User-generated content (staging)
- **app-static-assets**: Frontend build artifacts and static resources
- **app-backups**: Database backups and disaster recovery archives
- **app-logs**: Application and infrastructure log archives
- **terraform-state**: Terraform state files with versioning

**Security Configuration**:
- Bucket policies restricting public access (private by default)
- IAM roles for application access (no hardcoded credentials)
- Presigned URLs for temporary client-side upload/download
- Server-side encryption (SSE-S3 or SSE-KMS)
- Versioning enabled for critical buckets (backups, state files)
- Lifecycle policies for cost optimization (transition to Glacier)

**Integration**:
- **Boto3** (Python AWS SDK) for backend S3 operations
- **Presigned URLs**: Secure client-side uploads without proxying through backend
- **CloudFront**: CDN distribution for frequently accessed static assets

**Performance Optimizations**:
- Multipart upload for large files (>100MB)
- Transfer acceleration for global user base (if needed)
- Object metadata for efficient querying

### 3.6.5 Data Persistence Architecture

```mermaid
graph TB
    subgraph "Application Layer"
        API[Backend API<br/>Flask]
        AI[AI Services<br/>LangChain]
    end
    
    subgraph "Primary Data Storage"
        MONGO[(MongoDB 7.0+<br/>Document Database)]
        VECTOR[(Vector Database<br/>Embeddings)]
    end
    
    subgraph "Caching Layer"
        REDIS[Redis<br/>Cache & Sessions]
    end
    
    subgraph "Object Storage"
        S3[Amazon S3<br/>Files & Assets]
        S3_BACKUP[S3<br/>Backups]
    end
    
    subgraph "Monitoring"
        CLOUDWATCH[CloudWatch<br/>Metrics & Logs]
    end
    
    API -->|Read/Write| MONGO
    API -->|Read/Write| REDIS
    API -->|Upload/Download| S3
    
    AI -->|Store Embeddings| VECTOR
    AI -->|Retrieve Context| MONGO
    AI -->|Cache Responses| REDIS
    
    MONGO -->|Automated Backups| S3_BACKUP
    
    MONGO -->|Metrics| CLOUDWATCH
    REDIS -->|Metrics| CLOUDWATCH
    S3 -->|Access Logs| CLOUDWATCH
    
    REDIS -.Cache Aside.-> MONGO
```

### 3.6.6 Data Persistence Strategy Summary

| Data Type | Storage Solution | Persistence | Scalability | Primary Use Case |
|-----------|-----------------|-------------|-------------|------------------|
| User Data | MongoDB | Durable | Horizontal (Sharding) | User profiles, preferences |
| AI Conversations | MongoDB | Durable | Horizontal | Chat history, context |
| Vector Embeddings | Vector DB (TBD) | Durable | Horizontal | Semantic search |
| Session Data | Redis | Ephemeral/Optional | Vertical + Cluster | User sessions, cache |
| API Cache | Redis | Ephemeral | Vertical + Cluster | Response caching |
| File Uploads | S3 | Durable | Unlimited | Documents, media |
| Backups | S3 + Glacier | Durable | Unlimited | Disaster recovery |
| Static Assets | S3 + CloudFront | Durable | Unlimited | Frontend builds |

## 3.7 Development & Deployment

### 3.7.1 Development Tools and Environment

#### 3.7.1.1 Version Control

**Git**: Distributed version control system
- **Hosting**: GitHub (implied by GitHub Actions CI/CD)
- **Branching Strategy**: To be defined (likely Git Flow or GitHub Flow)
- **Protected Branches**: Main/production branches with required reviews
- **Commit Conventions**: Conventional Commits for automated changelog generation

#### 3.7.1.2 Integrated Development Environments (IDEs)

**Recommended IDEs**:
- **Visual Studio Code**: Universal editor for Python, TypeScript, JavaScript
  - Extensions: Python, ESLint, Prettier, Docker, Terraform
- **PyCharm**: Python-focused IDE for backend development
- **Xcode**: Required for iOS and macOS development
- **Android Studio**: Required for Android development

#### 3.7.1.3 Local Development Environment

**Prerequisites**:
- **Python 3.11+**: Backend development runtime
- **Node.js 18+ LTS**: Frontend development and tooling
- **Docker Desktop**: Local container development
- **Git**: Version control client

**Environment Configuration**:
- **.env Files**: Environment-specific configuration (not committed)
- **Docker Compose**: Local multi-service orchestration
- **Local MongoDB**: MongoDB container for development database
- **Local Redis**: Redis container for caching during development

**Development Workflow**:
1. Clone repository
2. Install dependencies (pip/poetry for backend, npm/yarn for frontend)
3. Configure environment variables (.env files)
4. Start local services (docker-compose up)
5. Run development servers (Flask dev server, Vite dev server)
6. Hot module replacement for rapid iteration

### 3.7.2 Build System and Tooling

#### 3.7.2.1 Backend Build System

**Python Packaging**:
- **Poetry** (recommended) or **pip**: Dependency management
- **setuptools**: Package distribution (if building distributable packages)
- **Build Outputs**: Python wheel (.whl) files for deployment
- **Virtual Environments**: venv or Poetry-managed environments for isolation

**Build Process**:
1. Install dependencies from requirements.txt or pyproject.toml
2. Run linters and formatters (Black, Flake8, mypy)
3. Execute test suite (pytest)
4. Generate coverage reports
5. Build Docker image with compiled dependencies

#### 3.7.2.2 Frontend Build System

**Web Application (React)**:
- **Build Tool**: Vite 5.0+ (modern, fast bundler)
- **TypeScript Compilation**: tsc for type checking
- **Asset Processing**: Vite plugins for images, fonts, etc.
- **Output**: Static HTML, JavaScript bundles, CSS files
- **Bundle Optimization**: Code splitting, tree shaking, minification

**Build Process**:
1. Install dependencies (npm install)
2. Run linters (ESLint) and formatters (Prettier)
3. Type check with TypeScript compiler
4. Execute test suite (Jest or Vitest)
5. Build production bundle (vite build)
6. Generate source maps for debugging
7. Output to `dist/` directory

**Mobile Application (React Native)**:
- **Build Tool**: Metro bundler (React Native default)
- **Native Builds**:
  - iOS: Xcode build system (xcodebuild or fastlane)
  - Android: Gradle build system
- **Code Signing**: iOS provisioning profiles, Android keystore
- **Output**: 
  - iOS: IPA file for App Store
  - Android: APK or AAB file for Google Play

**Desktop Application (Electron)**:
- **Build Tool**: Electron Forge or Electron Builder
- **Packaging**: Platform-specific installers (DMG for macOS, EXE for Windows, AppImage/deb for Linux)
- **Code Signing**: Platform-specific signing certificates for distribution
- **Auto-Update**: Built-in update mechanism for seamless updates

### 3.7.3 Containerization

#### 3.7.3.1 Docker (Container Platform)

**Planned Version**: Docker 24+

**Justification**:
- **Environment Consistency**: Identical runtime across development, staging, and production
- **Dependency Isolation**: All dependencies packaged within container image
- **Portable Deployment**: Deploy anywhere Docker is supported (AWS ECS, local, Kubernetes)
- **Version Control**: Docker images tagged with version numbers for rollback capability
- **Microservices Ready**: Each service can be independently containerized and scaled
- **CI/CD Integration**: Automated image building and pushing in GitHub Actions

**Dockerfile Strategy**:

**Backend (Python/Flask) Dockerfile**:
```dockerfile
# Multi-stage build for optimized image size
FROM python:3.11-slim as builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /root/.local /root/.local
COPY . .
ENV PATH=/root/.local/bin:$PATH
EXPOSE 5000
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "4", "app:app"]
```

**Frontend (React) - Multi-Stage Build**:
```dockerfile
# Build stage
FROM node:18-alpine as builder
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

#### Serve stage with nginx
FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

**Container Image Management**:
- **Registry**: Amazon ECR (Elastic Container Registry)
- **Tagging Strategy**: 
  - `latest`: Most recent build
  - `{git-sha}`: Specific commit for traceability
  - `{version}`: Semantic version tags
- **Image Scanning**: AWS ECR image scanning for vulnerabilities
- **Retention Policy**: Keep last 10 images, remove older images

#### 3.7.3.2 Docker Compose (Local Development)

**Purpose**: Multi-container local development environment

**docker-compose.yml Structure**:
```yaml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "5000:5000"
    environment:
      - MONGODB_URI=mongodb://mongodb:27017/appdb
      - REDIS_URL=redis://redis:6379
    depends_on:
      - mongodb
      - redis
  
  mongodb:
    image: mongo:7.0
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
  
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules

volumes:
  mongo-data:
```

### 3.7.4 Infrastructure as Code

#### 3.7.4.1 Terraform (IaC Tool)

**Planned Version**: Terraform 1.6+

**Justification**:
- **Declarative Infrastructure**: Define infrastructure as code for version control and review
- **AWS Provider**: Comprehensive AWS resource support
- **State Management**: Remote state storage in S3 with DynamoDB locking
- **Modular Architecture**: Reusable modules for different environments
- **Drift Detection**: Identify differences between desired and actual infrastructure
- **Multi-Environment**: Separate workspaces for development, staging, production

**Terraform Project Structure**:
```
terraform/
├── modules/
│   ├── networking/        # VPC, subnets, security groups
│   ├── compute/           # ECS cluster, Fargate tasks
│   ├── database/          # MongoDB (if self-hosted)
│   ├── storage/           # S3 buckets
│   └── monitoring/        # CloudWatch alarms
├── environments/
│   ├── dev/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── terraform.tfvars
│   ├── staging/
│   └── production/
├── backend.tf             # S3 backend configuration
└── providers.tf           # AWS provider configuration
```

**Key Terraform Modules**:

**Networking Module**:
- VPC with public and private subnets
- Internet Gateway and NAT Gateway
- Route tables and associations
- Security groups for services

**Compute Module**:
- ECS cluster definition
- Fargate task definitions for backend services
- Service definitions with auto-scaling
- Application Load Balancer (ALB)
- Target groups and health checks

**Storage Module**:
- S3 buckets with appropriate policies
- Bucket versioning and lifecycle rules
- CloudFront distribution (if needed)

**Database Module** (if self-hosting MongoDB):
- ECS task for MongoDB container
- EBS volumes for data persistence
- Security groups restricting database access
- Backup configuration

**State Management**:
- **Backend**: S3 bucket for Terraform state files
- **Locking**: DynamoDB table for state locking (prevents concurrent modifications)
- **Encryption**: Server-side encryption for state files
- **Versioning**: S3 versioning enabled for state recovery

### 3.7.5 Continuous Integration and Continuous Deployment (CI/CD)

#### 3.7.5.1 GitHub Actions (CI/CD Platform)

**Justification**:
- **Native Integration**: Built into GitHub repository hosting
- **YAML Configuration**: Declarative pipeline definition as code
- **Matrix Builds**: Test across multiple versions/platforms simultaneously
- **Secrets Management**: Secure storage of credentials and API keys
- **Marketplace**: Extensive ecosystem of pre-built actions
- **Free Tier**: Generous free minutes for open-source and small projects

**CI/CD Pipeline Strategy**:

**Pipeline Stages**:
1. **Lint and Format**: Code quality checks
2. **Test**: Automated test suite execution
3. **Build**: Compile/bundle applications
4. **Containerize**: Build Docker images
5. **Push**: Push images to Amazon ECR
6. **Deploy**: Deploy to target environment (dev/staging/production)

**Backend CI/CD Workflow** (.github/workflows/backend-ci-cd.yml):
```yaml
name: Backend CI/CD

on:
  push:
    branches: [main, develop]
    paths:
      - 'backend/**'
  pull_request:
    branches: [main]
    paths:
      - 'backend/**'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      
      - name: Run linters
        run: |
          cd backend
          black --check .
          flake8 .
          mypy .
      
      - name: Run tests
        run: |
          cd backend
          pytest --cov=. --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./backend/coverage.xml

  build-and-deploy:
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      
      - name: Build and push Docker image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: backend
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG backend/
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
      
      - name: Deploy to ECS
        run: |
          # Update ECS service with new image
          aws ecs update-service --cluster prod-cluster --service backend-service --force-new-deployment
```

**Frontend CI/CD Workflow** (.github/workflows/frontend-ci-cd.yml):
```yaml
name: Frontend CI/CD

on:
  push:
    branches: [main, develop]
    paths:
      - 'frontend/**'
  pull_request:
    branches: [main]
    paths:
      - 'frontend/**'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: Install dependencies
        run: |
          cd frontend
          npm ci
      
      - name: Run linters
        run: |
          cd frontend
          npm run lint
          npm run format:check
      
      - name: Type check
        run: |
          cd frontend
          npm run type-check
      
      - name: Run tests
        run: |
          cd frontend
          npm run test:ci
      
      - name: Build
        run: |
          cd frontend
          npm run build

  deploy:
    needs: test
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Build frontend
        run: |
          cd frontend
          npm ci
          npm run build
      
      - name: Deploy to S3 and CloudFront
        run: |
          aws s3 sync frontend/dist s3://app-frontend-prod --delete
          aws cloudfront create-invalidation --distribution-id DIST_ID --paths "/*"
```

**Mobile CI/CD Workflow** (React Native):
```yaml
name: Mobile CI/CD

on:
  push:
    branches: [main]
    paths:
      - 'mobile/**'

jobs:
  build-ios:
    runs-on: macos-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: |
          cd mobile
          npm ci
          cd ios
          pod install
      
      - name: Build iOS
        run: |
          cd mobile/ios
          xcodebuild -workspace App.xcworkspace -scheme App -configuration Release

  build-android:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Set up JDK
        uses: actions/setup-java@v3
        with:
          java-version: '17'
          distribution: 'temurin'
      
      - name: Install dependencies
        run: |
          cd mobile
          npm ci
      
      - name: Build Android
        run: |
          cd mobile/android
          ./gradlew assembleRelease
```

**Infrastructure CI/CD Workflow** (Terraform):
```yaml
name: Infrastructure CI/CD

on:
  push:
    branches: [main]
    paths:
      - 'terraform/**'
  pull_request:
    branches: [main]
    paths:
      - 'terraform/**'

jobs:
  terraform:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.6.0
      
      - name: Terraform Format
        run: terraform fmt -check -recursive terraform/
      
      - name: Terraform Init
        run: |
          cd terraform/environments/production
          terraform init
      
      - name: Terraform Validate
        run: |
          cd terraform/environments/production
          terraform validate
      
      - name: Terraform Plan
        run: |
          cd terraform/environments/production
          terraform plan -out=tfplan
      
      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          cd terraform/environments/production
          terraform apply -auto-approve tfplan
```

#### 3.7.5.2 Deployment Strategy

**Environments**:
- **Development**: Automatic deployment on push to `develop` branch
- **Staging**: Automatic deployment on push to `staging` branch
- **Production**: Automatic deployment on push to `main` branch (after approval)

**Deployment Patterns**:
- **Rolling Deployment**: Default ECS deployment strategy (gradually replace old tasks)
- **Blue-Green Deployment**: Option for zero-downtime production deployments
- **Canary Deployment**: Gradual traffic shift for high-risk changes

**Rollback Strategy**:
- Docker image tags allow instant rollback to previous version
- ECS task definition revisions provide rollback capability
- Database migrations should be backward-compatible

**Deployment Approval**:
- Production deployments require manual approval (GitHub Environments)
- Staging deployments are automatic for testing
- Development deployments are continuous

### 3.7.6 Development and Deployment Architecture

```mermaid
graph TB
    subgraph "Development"
        DEV[Developer Workstation]
        LOCALDEV[Local Docker Compose]
    end
    
    subgraph "Version Control"
        GITHUB[GitHub Repository]
    end
    
    subgraph "CI/CD Pipeline - GitHub Actions"
        LINT[Lint & Format]
        TEST[Run Tests]
        BUILD[Build Artifacts]
        DOCKER[Build Docker Images]
        PUSH[Push to ECR]
        DEPLOY[Deploy to ECS]
    end
    
    subgraph "Container Registry"
        ECR[Amazon ECR]
    end
    
    subgraph "Infrastructure - AWS"
        TERRAFORM[Terraform IaC]
        ECS[ECS Fargate]
        ALB[Load Balancer]
        S3[S3 Storage]
    end
    
    subgraph "Monitoring"
        CLOUDWATCH[CloudWatch]
        MONITORING[Monitoring Service]
    end
    
    DEV -->|git push| GITHUB
    GITHUB -->|webhook trigger| LINT
    LINT --> TEST
    TEST --> BUILD
    BUILD --> DOCKER
    DOCKER --> PUSH
    PUSH --> ECR
    ECR --> DEPLOY
    DEPLOY --> ECS
    
    TERRAFORM -.provisions.-> ECS
    TERRAFORM -.provisions.-> ALB
    TERRAFORM -.provisions.-> S3
    
    ECS --> CLOUDWATCH
    ECS --> MONITORING
    
    DEV -.local dev.-> LOCALDEV
```

### 3.7.7 Development and Deployment Tools Summary

| Category | Tool | Version | Purpose |
|----------|------|---------|---------|
| Version Control | Git | 2.40+ | Source code management |
| Repository Hosting | GitHub | - | Code hosting, collaboration |
| Containerization | Docker | 24+ | Application containerization |
| Container Registry | Amazon ECR | - | Docker image storage |
| Local Orchestration | Docker Compose | 2.20+ | Multi-container local dev |
| Infrastructure as Code | Terraform | 1.6+ | AWS infrastructure provisioning |
| CI/CD Platform | GitHub Actions | - | Automated testing and deployment |
| Backend Build | Poetry/pip | - | Python dependency management |
| Frontend Build | Vite | 5.0+ | Web application bundling |
| Mobile Build (iOS) | Xcode | 15+ | iOS application compilation |
| Mobile Build (Android) | Gradle | 8+ | Android application compilation |
| Code Quality | ESLint, Prettier, Black | Latest | Linting and formatting |
| Testing | pytest, Jest/Vitest | Latest | Automated testing |

## 3.8 Technology Integration and Compatibility

### 3.8.1 Integration Matrix

The following matrix illustrates the planned integration points between major technology components:

| Component | Integrates With | Integration Method | Authentication |
|-----------|----------------|-------------------|----------------|
| React Web App | Flask API | REST API (HTTPS) | Auth0 JWT |
| React Web App | Auth0 | OIDC/OAuth 2.0 | Client SDK |
| React Native | Flask API | REST API (HTTPS) | Auth0 JWT |
| React Native | Auth0 | OIDC/OAuth 2.0 | Native SDK |
| iOS App | Flask API | REST API (HTTPS) | Auth0 JWT |
| iOS App | Auth0 | OIDC/OAuth 2.0 | Native SDK |
| Android App | Flask API | REST API (HTTPS) | Auth0 JWT |
| Android App | Auth0 | OIDC/OAuth 2.0 | Native SDK |
| Electron App | Flask API | REST API (HTTPS) | Auth0 JWT |
| Flask API | MongoDB | PyMongo Driver | User/Password |
| Flask API | Redis | redis-py Client | Optional Password |
| Flask API | S3 | Boto3 SDK | IAM Role |
| Flask API | Auth0 | JWT Verification | API Key |
| Flask API | OpenAI | REST API (HTTPS) | API Key |
| LangChain | OpenAI | Python SDK | API Key |
| LangChain | MongoDB | PyMongo Driver | User/Password |
| GitHub Actions | AWS | AWS CLI | Access Keys |
| Terraform | AWS | AWS Provider | Access Keys |
| ECS | ECR | Docker Pull | IAM Role |
| CloudWatch | All Services | AWS SDK | IAM Role |

### 3.8.2 API Contract and Versioning

**API Versioning Strategy**:
- **URL-Based Versioning**: `/api/v1/resource` pattern for major version changes
- **Backward Compatibility**: Maintain previous API versions during transition periods
- **Deprecation Policy**: 6-month notice before removing deprecated endpoints
- **Version Discovery**: `/api/version` endpoint reports current API version

**API Documentation**:
- **OpenAPI/Swagger**: Planned API specification format
- **Auto-Generated Docs**: Swagger UI or ReDoc for interactive API documentation
- **Type Definitions**: Shared type definitions between frontend and backend

### 3.8.3 Security Considerations

**Authentication and Authorization**:
- All API endpoints require Auth0 JWT authentication (except public health checks)
- JWT tokens include user roles and permissions for RBAC
- Token refresh strategy to maintain session without re-authentication
- Secure token storage on clients (httpOnly cookies for web, secure storage for mobile)

**Data in Transit**:
- HTTPS/TLS 1.3 for all external communications
- Certificate management via AWS Certificate Manager
- API Gateway terminates TLS at load balancer

**Data at Rest**:
- MongoDB encryption at rest (if using Atlas or self-hosted with encryption)
- S3 server-side encryption (SSE-S3 or SSE-KMS)
- Secrets stored in AWS Secrets Manager
- Environment variables never committed to version control

**Dependency Security**:
- Automated vulnerability scanning (npm audit, pip-audit)
- Dependabot for automated security updates
- Regular dependency updates and security patching
- Container image scanning in ECR

**API Security**:
- Rate limiting to prevent abuse (Flask-Limiter or API Gateway)
- CORS configuration restricting allowed origins
- Input validation and sanitization (Pydantic, Zod)
- SQL injection prevention through ORM/ODM usage
- XSS prevention through output escaping

### 3.8.4 Cross-Platform Considerations

**Code Sharing Opportunities**:
- **Type Definitions**: Shared TypeScript interfaces for API contracts
- **Business Logic**: Shared utilities in TypeScript (web, mobile, desktop)
- **Component Libraries**: Shared React components between web and Electron
- **API Client**: Shared API client logic across all frontend platforms

**Platform-Specific Considerations**:
- **iOS**: Swift code for native features (Face ID, ARKit, HealthKit)
- **Android**: Kotlin code for native features (biometrics, sensors)
- **macOS**: Objective-C for AppKit integration
- **Web**: Progressive Web App (PWA) capabilities for offline support
- **Desktop**: Electron-specific APIs (file system, native menus)

**Performance Optimization**:
- Lazy loading and code splitting on web and desktop
- Image optimization and CDN delivery
- API response caching with Redis
- Database query optimization with proper indexing
- Mobile-specific optimizations (bundle size, startup time)

## 3.9 Version Management and Upgrade Strategy

### 3.9.1 Technology Version Constraints

**Backend (Python)**:
- Python: `>=3.11,<4.0` (utilize 3.11+ performance improvements)
- Flask: `^3.0` (caret allows minor and patch updates)
- LangChain: `^0.1.0` (allow updates within 0.x series)
- PyMongo: `^4.6` (maintain MongoDB driver compatibility)

**Frontend (JavaScript/TypeScript)**:
- Node.js: `>=18.0.0 <21.0.0` (LTS versions only)
- React: `^18.2.0` (stable on React 18)
- TypeScript: `^5.0.0` (utilize latest language features)
- Vite: `^5.0.0` (modern bundler)

**Infrastructure**:
- Docker: `>=24.0` (latest stable)
- Terraform: `~>1.6.0` (tilde allows patch updates within 1.6)
- MongoDB: `^7.0` (LTS version)
- Redis: `^7.0` (stable release)

### 3.9.2 Upgrade Policy

**Regular Updates**:
- **Patch Updates**: Automatic via Dependabot (security and bug fixes)
- **Minor Updates**: Quarterly review and upgrade cycle
- **Major Updates**: Planned upgrades with compatibility testing

**LTS Strategy**:
- Prefer LTS (Long Term Support) versions for critical infrastructure
- Node.js: Use LTS releases (18.x, 20.x)
- Python: Use stable releases (3.11, 3.12)
- Database: Use LTS versions (MongoDB 7.0 LTS)

**Testing Strategy for Upgrades**:
1. Review changelog and breaking changes
2. Update in development environment
3. Run full test suite
4. Deploy to staging for integration testing
5. Monitor for issues
6. Deploy to production with rollback plan

### 3.9.3 Deprecation Management

**Monitoring Deprecated Features**:
- Track deprecation warnings in logs
- Quarterly review of deprecated dependencies
- Proactive migration before breaking changes

**Communication**:
- Document deprecated features in changelog
- Provide migration guides for major changes
- Maintain backward compatibility during transition

## 3.10 Technology Stack Justification Summary

### 3.10.1 Backend Technology Rationale

The planned backend stack (Python + Flask + LangChain) provides:
- **Rapid Development**: Python's expressiveness and Flask's simplicity accelerate API development
- **AI/ML Integration**: Native LangChain support enables sophisticated AI features
- **Ecosystem Maturity**: Extensive library support for all planned features
- **Scalability Path**: Transition from monolith to microservices possible with Flask blueprints
- **Developer Availability**: Large talent pool familiar with Python and Flask

### 3.10.2 Frontend Technology Rationale

The planned multi-platform frontend strategy provides:
- **Cross-Platform Coverage**: Single codebase approach where possible (React, React Native, Electron)
- **Native Performance**: Platform-specific code (Swift, Kotlin) where optimal UX requires it
- **Developer Productivity**: Shared skills and patterns across platforms
- **Type Safety**: TypeScript reduces runtime errors across all JavaScript/TypeScript platforms
- **Modern UX**: React's component model and ecosystem enable rich, responsive interfaces

### 3.10.3 Infrastructure Technology Rationale

The planned cloud infrastructure provides:
- **Managed Services**: Reduce operational overhead with AWS managed services
- **Containerization**: Docker ensures consistent environments from development to production
- **Infrastructure as Code**: Terraform enables reproducible, version-controlled infrastructure
- **Automation**: GitHub Actions provides complete CI/CD without additional service costs
- **Scalability**: AWS and container orchestration support growth from MVP to enterprise scale

### 3.10.4 Alternative Technologies Considered

| Category | Selected | Alternatives Considered | Selection Rationale |
|----------|----------|------------------------|---------------------|
| Backend Framework | Flask | FastAPI, Django | Flask's simplicity and extensive ecosystem; FastAPI considered for async if needed |
| Frontend Library | React | Vue, Svelte, Angular | Largest ecosystem, most mature tooling, widest talent pool |
| Database | MongoDB | PostgreSQL, MySQL | Schema flexibility for evolving product; document model fits use cases |
| Cloud Provider | AWS | Azure, GCP | Market leader, most comprehensive service catalog, team familiarity |
| CI/CD | GitHub Actions | GitLab CI, CircleCI | Native GitHub integration, cost-effective, sufficient features |
| IaC Tool | Terraform | CloudFormation, Pulumi | Cloud-agnostic, HCL is declarative and readable, mature ecosystem |
| Authentication | Auth0 | Cognito, Firebase Auth | Superior developer experience, multi-platform SDKs, feature richness |

## 3.11 References

### 3.11.1 Repository Artifacts Referenced

- `README.md` - Project identification and initialization status

### 3.11.2 Technical Specification Sections Referenced

- Section 1.1 Executive Summary - Project overview and current development stage
- Section 1.2 System Overview - Project context and implementation status
- Section 2.1 Product Requirements Overview - Requirements definition status and framework

### 3.11.3 External Technology Documentation

The following technologies are planned for implementation. Refer to official documentation for detailed specifications:

**Backend Technologies**:
- Python: https://www.python.org/
- Flask: https://flask.palletsprojects.com/
- LangChain: https://python.langchain.com/
- PyMongo: https://pymongo.readthedocs.io/

**Frontend Technologies**:
- React: https://react.dev/
- TypeScript: https://www.typescriptlang.org/
- TailwindCSS: https://tailwindcss.com/
- React Native: https://reactnative.dev/
- Electron: https://www.electronjs.org/

**Native Development**:
- Swift: https://swift.org/
- Kotlin: https://kotlinlang.org/

**Infrastructure**:
- AWS: https://aws.amazon.com/
- Docker: https://docs.docker.com/
- Terraform: https://www.terraform.io/
- GitHub Actions: https://docs.github.com/en/actions

**Data Storage**:
- MongoDB: https://www.mongodb.com/docs/
- Redis: https://redis.io/docs/

**Third-Party Services**:
- Auth0: https://auth0.com/docs/

### 3.11.4 Default Technology Stack Reference

This section documents the planned technology stack based on the default technology stack specification provided for this project. All technologies listed are planned for future implementation as the CheckSameRepoNoPrompt project progresses from its current pre-implementation phase to active development and deployment.

# 4. Process Flowchart

## 4.1 Process Flow Overview and Project Context

### 4.1.1 Documentation Scope

This Process Flowchart section documents the planned workflows and process flows for the CheckSameRepoNoPrompt project based on its designed architecture and technology stack. As documented in the Executive Summary and System Overview, **the project is currently in its initial development phase with no functional implementation in the repository**. 

The process flows documented in this section are derived from:
- **Planned technology architecture** documented in Section 3 (Technology Stack)
- **Implemented CI/CD workflows** specified in Section 3.7 (Development & Deployment)
- **Intended integration patterns** outlined in Section 3.8 (Technology Integration and Compatibility)
- **Data persistence strategies** defined in Section 3.6 (Databases & Storage)

All workflows marked as "Planned" represent the intended implementation based on the architectural design, while workflows marked as "Implemented" refer to CI/CD pipeline definitions that exist as configuration specifications.

### 4.1.2 Planned Architecture Foundation

The process flows in this section are built upon the following architectural components:

**Client Layer**: Multi-platform client applications (Web: React + TypeScript, Mobile: React Native + Native iOS/Android, Desktop: Electron + macOS native)

**Authentication Layer**: Auth0 identity and access management using OAuth 2.0/OIDC protocols

**API Layer**: Flask 3.0+ RESTful API with Python 3.11+ backend

**AI/ML Layer**: LangChain 0.1.0+ for LLM orchestration with optional OpenAI integration

**Data Layer**: MongoDB 7.0+ primary database, Redis 7+ caching, Amazon S3 object storage

**Infrastructure Layer**: AWS ECS Fargate, Application Load Balancer, Route 53, CloudWatch

**CI/CD Layer**: GitHub Actions workflows for automated testing and deployment

### 4.1.3 Process Flow Categories

This section organizes workflows into the following categories:

1. **CI/CD Workflows**: Automated build, test, and deployment pipelines (GitHub Actions specifications)
2. **Authentication Flows**: User authentication and authorization processes (Auth0 integration)
3. **API Processing Flows**: Request handling, validation, and response generation
4. **AI/ML Workflows**: LangChain-based intelligent processing pipelines
5. **Data Persistence Flows**: Database operations and caching strategies
6. **State Management Patterns**: Application state transitions and lifecycle
7. **Error Handling Procedures**: Error detection, recovery, and fallback mechanisms
8. **Integration Workflows**: Inter-component communication and external service integration

## 4.2 CI/CD Workflows (Implemented Pipeline Specifications)

### 4.2.1 Backend Deployment Pipeline

The backend CI/CD pipeline is defined in `.github/workflows/backend-ci-cd.yml` and implements a comprehensive continuous integration and deployment workflow for the Flask API.

#### 4.2.1.1 Pipeline Trigger Conditions

**Trigger Events**:
- Push to `main` or `develop` branches (paths: `backend/**`)
- Pull requests targeting `main` branch (paths: `backend/**`)

**Workflow Execution**: Runs on `ubuntu-latest` GitHub-hosted runners with Python 3.11 environment

#### 4.2.1.2 Backend Pipeline Flow Diagram

```mermaid
flowchart TD
    Start([Developer Pushes Code]) --> Trigger[GitHub Webhook<br/>Activates Workflow]
    Trigger --> Checkout[Checkout Repository<br/>actions/checkout@v3]
    Checkout --> SetupPython[Setup Python 3.11<br/>actions/setup-python@v4]
    SetupPython --> InstallDeps[Install Dependencies<br/>pip install -r requirements.txt]
    
    InstallDeps --> QualityPhase[Code Quality Phase]
    
    subgraph QualityPhase["Code Quality Checks"]
        RunBlack[Black Formatter<br/>Check Mode]
        RunFlake8[Flake8 Linter<br/>Style Enforcement]
        RunMypy[mypy Type Checker<br/>Static Analysis]
    end
    
    QualityPhase --> QualityCheck{All Quality<br/>Checks Pass?}
    QualityCheck -->|No| FailQuality[❌ Workflow Failed<br/>Notify Developer]
    QualityCheck -->|Yes| TestPhase[Testing Phase]
    
    subgraph TestPhase["Test Execution"]
        RunPytest[pytest Execution<br/>with Coverage]
        GenerateCoverage[Generate Coverage Report<br/>XML Format]
    end
    
    TestPhase --> TestCheck{All Tests<br/>Pass?}
    TestCheck -->|No| FailTests[❌ Workflow Failed<br/>Display Test Results]
    TestCheck -->|Yes| UploadCoverage[Upload Coverage<br/>to Codecov]
    
    UploadCoverage --> BranchCheck{Is Main<br/>Branch Push?}
    BranchCheck -->|No| PRComplete[✅ PR Validation Complete<br/>Ready for Review]
    BranchCheck -->|Yes| DeployPhase[Deployment Phase]
    
    subgraph DeployPhase["Build & Deploy"]
        ConfigAWS[Configure AWS Credentials<br/>from GitHub Secrets]
        LoginECR[Login to Amazon ECR<br/>aws ecr get-login-password]
        BuildImage[Build Docker Image<br/>Multi-stage Dockerfile]
        TagImage[Tag Image<br/>git-sha + latest]
        PushECR[Push to ECR<br/>Both Tags]
        UpdateECS[Update ECS Service<br/>Force New Deployment]
    end
    
    DeployPhase --> DeployMonitor[Monitor ECS Deployment]
    DeployMonitor --> HealthCheck{ECS Health<br/>Checks Pass?}
    HealthCheck -->|No| Rollback[⚠️ Automatic Rollback<br/>Previous Task Definition]
    HealthCheck -->|Yes| DeploySuccess[✅ Deployment Complete<br/>Notify Team]
    
    Rollback --> AlertOps[Alert Operations Team<br/>Deployment Failed]
    
    FailQuality --> End([End])
    FailTests --> End
    PRComplete --> End
    DeploySuccess --> End
    AlertOps --> End
    
    style QualityPhase fill:#fff3e0
    style TestPhase fill:#e3f2fd
    style DeployPhase fill:#e8f5e9
    style DeploySuccess fill:#c8e6c9
    style Rollback fill:#ffcdd2
```

#### 4.2.1.3 Backend Pipeline Stages Detail

**Stage 1: Code Quality Enforcement**

```
Step 1: Black Formatter Check
- Command: black --check backend/
- Purpose: Ensure consistent Python code formatting
- Failure Action: Display formatting violations, fail workflow
- Exit Code: Non-zero if formatting issues detected

Step 2: Flake8 Linting
- Command: flake8 backend/ --max-line-length=88
- Purpose: Enforce PEP 8 style guide and detect code smells
- Failure Action: Display linting errors with file locations, fail workflow
- Exit Code: Non-zero if linting violations found

Step 3: mypy Type Checking
- Command: mypy backend/ --strict
- Purpose: Static type analysis for type safety
- Failure Action: Display type errors, fail workflow
- Exit Code: Non-zero if type errors detected
```

**Stage 2: Test Execution and Coverage**

```
Step 1: Execute Test Suite
- Command: pytest backend/tests/ --cov=backend --cov-report=xml --cov-report=term
- Purpose: Run unit, integration, and functional tests
- Coverage Threshold: Configurable minimum (e.g., 80%)
- Failure Action: Display failed test details, fail workflow

Step 2: Coverage Reporting
- Upload: XML coverage report to Codecov
- Action: codecov/codecov-action@v3
- Purpose: Track coverage trends, PR comments for coverage changes
- Failure Handling: Non-blocking (warning only if upload fails)
```

**Stage 3: Containerization and Deployment** (Main branch only)

```
Step 1: AWS Authentication
- Action: aws-actions/configure-aws-credentials@v2
- Credentials Source: GitHub Secrets (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
- Region: Configured from secrets (AWS_REGION)
- Session Duration: Temporary credentials for workflow execution

Step 2: ECR Authentication
- Command: aws ecr get-login-password | docker login
- Registry: AWS account-specific ECR registry
- Token Validity: 12 hours

Step 3: Docker Image Build
- Context: backend/ directory
- Dockerfile: Multi-stage build for optimization
  * Stage 1: Python base image, install dependencies
  * Stage 2: Copy application code, configure Gunicorn
- Build Args: Environment variables, version tags

Step 4: Image Tagging Strategy
- Primary Tag: Git commit SHA (e.g., 1a2b3c4d)
- Secondary Tag: latest
- Purpose: SHA enables precise rollback, latest for convenience

Step 5: ECR Push
- Push Order: SHA tag first, then latest tag
- Verification: Confirm image manifest uploaded
- Failure Handling: Retry push with exponential backoff

Step 6: ECS Service Update
- Command: aws ecs update-service --force-new-deployment
- Cluster: Production ECS cluster
- Service: Backend API service
- Deployment Strategy: Rolling deployment
  * Minimum healthy percent: 100%
  * Maximum percent: 200%
  * Start new tasks → Health check → Stop old tasks
- Timeout: 10 minutes for deployment completion

Step 7: Deployment Verification
- Monitor: ECS task status transitions
- Health Check: Application /health endpoint
- Success Criteria: All tasks reach RUNNING state, health checks pass
- Failure Criteria: Tasks fail to start or health checks fail
- Rollback Trigger: ECS automatic rollback on health check failure
```

#### 4.2.1.4 Backend Pipeline Decision Points

| Decision Point | Condition | Action if True | Action if False |
|----------------|-----------|----------------|-----------------|
| Code Quality Pass? | Black, Flake8, mypy exit code 0 | Continue to Testing | Fail workflow, block merge |
| All Tests Pass? | pytest exit code 0, coverage ≥ threshold | Continue to Coverage Upload | Fail workflow, display failures |
| Is Main Branch? | GitHub ref == refs/heads/main | Proceed to Deployment | Stop (PR validation complete) |
| AWS Auth Success? | Credentials valid, permissions sufficient | Continue to ECR Login | Fail deployment, check secrets |
| Docker Build Success? | Build exit code 0, image created | Continue to Tag/Push | Fail deployment, show build logs |
| ECS Health Checks Pass? | All tasks healthy within timeout | Complete deployment | Rollback to previous version |

#### 4.2.1.5 Backend Error Handling and Recovery

**Linting/Formatting Failures**:
- Action: Fail workflow immediately, provide detailed error output
- Developer Action: Run `black backend/` and `flake8 backend/` locally, fix issues, recommit
- Prevention: Pre-commit hooks to enforce formatting before push

**Test Failures**:
- Action: Display failed test names, assertions, stack traces
- Developer Action: Fix failing tests, ensure local test pass before push
- Prevention: Run `pytest` locally before committing

**AWS Authentication Failures**:
- Causes: Expired credentials, incorrect secrets, insufficient IAM permissions
- Action: Fail deployment, alert DevOps team
- Recovery: Rotate secrets, verify IAM role policies

**Docker Build Failures**:
- Causes: Dependency installation errors, syntax errors, missing files
- Action: Display full build logs, fail deployment
- Recovery: Test Dockerfile locally with `docker build`, fix issues

**ECR Push Failures**:
- Causes: Network timeout, ECR repository not found, authentication expired
- Action: Retry push up to 3 times with exponential backoff (5s, 15s, 45s)
- Recovery: Verify ECR repository exists, check network connectivity

**ECS Deployment Failures**:
- Causes: Health check failures, insufficient capacity, task definition errors
- Action: ECS automatic rollback to previous stable task definition
- Recovery: Check CloudWatch logs, investigate health check failures, fix and redeploy
- Notification: Slack/email alert to operations team

### 4.2.2 Frontend Deployment Pipeline

The frontend CI/CD pipeline is defined in `.github/workflows/frontend-ci-cd.yml` and automates the build, test, and deployment of the React web application to AWS S3 with CloudFront CDN.

#### 4.2.2.1 Pipeline Trigger Conditions

**Trigger Events**:
- Push to `main` or `develop` branches (paths: `frontend/**`)
- Pull requests targeting `main` branch (paths: `frontend/**`)

**Workflow Execution**: Runs on `ubuntu-latest` with Node.js 18.x environment

#### 4.2.2.2 Frontend Pipeline Flow Diagram

```mermaid
flowchart TD
    Start([Developer Pushes Frontend Code]) --> Trigger[GitHub Webhook<br/>Triggers Workflow]
    Trigger --> Checkout[Checkout Repository<br/>actions/checkout@v3]
    Checkout --> SetupNode[Setup Node.js 18<br/>actions/setup-node@v3]
    SetupNode --> CacheCheck{npm Cache<br/>Available?}
    CacheCheck -->|Yes| RestoreCache[Restore Cache<br/>node_modules/]
    CacheCheck -->|No| FreshInstall[Fresh Install]
    RestoreCache --> InstallDeps[Install Dependencies<br/>npm ci]
    FreshInstall --> InstallDeps
    
    InstallDeps --> LintPhase[Code Quality Phase]
    
    subgraph LintPhase["Frontend Quality Checks"]
        RunESLint[ESLint Linting<br/>npm run lint]
        RunPrettier[Prettier Format Check<br/>npm run format:check]
        RunTypeCheck[TypeScript Check<br/>tsc --noEmit]
    end
    
    LintPhase --> LintPass{Quality<br/>Checks Pass?}
    LintPass -->|No| FailLint[❌ Workflow Failed<br/>Show Lint Errors]
    LintPass -->|Yes| TestPhase[Test Execution Phase]
    
    subgraph TestPhase["Frontend Testing"]
        RunTests[Run Test Suite<br/>npm run test]
        ComponentTests[Component Tests<br/>React Testing Library]
        IntegrationTests[Integration Tests<br/>User Flows]
    end
    
    TestPhase --> TestPass{All Tests<br/>Pass?}
    TestPass -->|No| FailTests[❌ Workflow Failed<br/>Show Test Failures]
    TestPass -->|Yes| BuildPhase[Build Phase]
    
    subgraph BuildPhase["Production Build"]
        ViteBuild[Vite Build<br/>npm run build]
        OptimizeAssets[Asset Optimization<br/>Minification, Splitting]
        GenerateMaps[Source Maps<br/>Generation]
    end
    
    BuildPhase --> BuildSuccess{Build<br/>Successful?}
    BuildSuccess -->|No| FailBuild[❌ Build Failed<br/>Show Build Errors]
    BuildSuccess -->|Yes| BranchCheck{Is Main<br/>Branch?}
    
    BranchCheck -->|No| PRValidation[✅ PR Validation Complete]
    BranchCheck -->|Yes| DeployPhase[Deployment Phase]
    
    subgraph DeployPhase["S3 & CloudFront Deploy"]
        ConfigAWS[Configure AWS<br/>Credentials]
        SyncS3[Sync dist/ to S3<br/>aws s3 sync --delete]
        SetHeaders[Set Cache Headers<br/>max-age, immutable]
        InvalidateCF[Invalidate CloudFront<br/>/* all paths]
        WaitInvalidation[Wait for Invalidation<br/>Complete]
    end
    
    DeployPhase --> DeployCheck{Deployment<br/>Successful?}
    DeployCheck -->|No| FailDeploy[❌ Deployment Failed<br/>Alert Team]
    DeployCheck -->|Yes| VerifyDeploy[Verify Deployment<br/>Check S3 Objects]
    VerifyDeploy --> DeploySuccess[✅ Deployment Complete<br/>Site Live]
    
    FailLint --> End([End])
    FailTests --> End
    FailBuild --> End
    PRValidation --> End
    FailDeploy --> End
    DeploySuccess --> End
    
    style LintPhase fill:#fff3e0
    style TestPhase fill:#e3f2fd
    style BuildPhase fill:#f3e5f5
    style DeployPhase fill:#e8f5e9
    style DeploySuccess fill:#c8e6c9
```

#### 4.2.2.3 Frontend Pipeline Stages Detail

**Stage 1: Frontend Code Quality**

```
Step 1: ESLint Linting
- Command: npm run lint (eslint src/ --ext .ts,.tsx)
- Configuration: .eslintrc.json with React and TypeScript rules
- Checks: Syntax errors, code smells, React best practices, accessibility issues
- Failure Action: Display violations with file/line numbers, fail workflow

Step 2: Prettier Format Check
- Command: npm run format:check (prettier --check "src/**/*.{ts,tsx,css}")
- Purpose: Ensure consistent code formatting across codebase
- Auto-fix: Developers run `npm run format` to auto-format
- Failure Action: List unformatted files, fail workflow

Step 3: TypeScript Type Check
- Command: tsc --noEmit (compile without emitting files)
- Configuration: tsconfig.json with strict mode enabled
- Checks: Type errors, interface compliance, null safety
- Failure Action: Display type errors with file locations, fail workflow
```

**Stage 2: Frontend Testing**

```
Step 1: Unit and Component Tests
- Framework: Jest or Vitest (based on Vite setup)
- Testing Library: React Testing Library
- Command: npm run test -- --coverage --passWithNoTests
- Test Types:
  * Component rendering tests
  * User interaction simulations
  * State management tests
  * Hook behavior tests
- Coverage Report: HTML and JSON formats
- Failure Action: Display failed test details, fail workflow

Step 2: Integration Tests
- Purpose: Test user flows and component interactions
- Examples: Authentication flow, form submission, navigation
- Mocking: API calls mocked with MSW (Mock Service Worker)
- Failure Action: Display failed scenarios, fail workflow
```

**Stage 3: Production Build**

```
Step 1: Vite Production Build
- Command: npm run build (vite build)
- Output Directory: dist/
- Optimizations:
  * Tree shaking to remove unused code
  * Code splitting for lazy loading
  * Asset minification (JS, CSS)
  * Image optimization
  * Hash-based file names for cache busting

Step 2: Build Artifacts
- Generated Files:
  * dist/index.html (entry point)
  * dist/assets/*.js (JavaScript bundles)
  * dist/assets/*.css (stylesheets)
  * dist/assets/*.{png,svg,jpg} (images)
- Source Maps: Generated for production debugging (.map files)
- Build Size Analysis: Bundle size report for optimization insights

Step 3: Build Verification
- Size Check: Warn if bundle size exceeds threshold (e.g., 500KB)
- Asset Check: Verify critical assets (index.html, main bundle) exist
- Failure Action: If build fails, display Vite error messages, fail workflow
```

**Stage 4: S3 and CloudFront Deployment** (Main branch only)

```
Step 1: AWS Authentication
- Action: aws-actions/configure-aws-credentials@v2
- Credentials: GitHub Secrets (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
- Region: us-east-1 (or configured region)

Step 2: S3 Bucket Sync
- Command: aws s3 sync dist/ s3://app-static-assets/ --delete
- Flags:
  * --delete: Remove files in S3 not present in dist/
  * --cache-control: Set appropriate cache headers
    - HTML files: max-age=0, must-revalidate (always check for updates)
    - JS/CSS bundles: max-age=31536000, immutable (1-year cache, hash-based names)
    - Images: max-age=86400 (1-day cache)
- Verification: Compare S3 object count with local dist/ file count

Step 3: CloudFront Cache Invalidation
- Command: aws cloudfront create-invalidation --paths "/*"
- Distribution: Production CloudFront distribution ID (from secrets)
- Purpose: Immediately purge cached content so users receive updated version
- Wait: Poll invalidation status until completed (typically 1-2 minutes)
- Failure Handling: Warn if invalidation fails but don't fail workflow (users may see cached content temporarily)

Step 4: Deployment Verification
- Check S3: Verify index.html uploaded successfully
- Check CloudFront: Optionally, make HTTP request to CloudFront URL to verify content
- Success Criteria: All files synced, invalidation completed
```

#### 4.2.2.4 Frontend Pipeline Decision Points

| Decision Point | Condition | Action if True | Action if False |
|----------------|-----------|----------------|-----------------|
| ESLint Pass? | No linting errors | Continue to Prettier | Fail workflow, show errors |
| Prettier Pass? | All files formatted | Continue to TypeScript | Fail workflow, list unformatted files |
| TypeScript Pass? | No type errors | Continue to Tests | Fail workflow, show type errors |
| Tests Pass? | All tests pass, coverage ≥ threshold | Continue to Build | Fail workflow, show failed tests |
| Build Success? | Vite build completes | Check branch | Fail workflow, show build errors |
| Is Main Branch? | ref == refs/heads/main | Deploy to S3 | Stop (PR validation) |
| S3 Sync Success? | All files uploaded | Invalidate CloudFront | Fail deployment, retry |
| CloudFront Invalidation? | Invalidation created | Wait for completion | Warn (non-blocking) |

#### 4.2.2.5 Frontend Error Handling and Recovery

**Linting Failures**:
- ESLint Errors: Fix code issues, run `npm run lint -- --fix` for auto-fixable issues
- Prettier Errors: Run `npm run format` to auto-format all files
- Prevention: Use editor extensions (ESLint, Prettier) for real-time feedback

**TypeScript Errors**:
- Type Errors: Fix type annotations, ensure strict type compliance
- Prevention: Enable TypeScript checking in IDE, run `tsc --watch` during development

**Test Failures**:
- Failed Tests: Debug failing tests, ensure local tests pass (`npm run test`)
- Coverage Drop: Add tests for uncovered code paths
- Prevention: Run tests before committing, use test-driven development (TDD)

**Build Failures**:
- Dependency Errors: Check package.json, run `npm install` to resolve dependencies
- Asset Errors: Verify asset imports, check file paths
- Prevention: Test build locally with `npm run build` before pushing

**S3 Sync Failures**:
- Authentication: Verify AWS credentials, check IAM permissions
- Bucket Access: Ensure S3 bucket exists, check bucket policies
- Recovery: Retry sync, verify network connectivity

**CloudFront Invalidation Failures**:
- Distribution Not Found: Verify distribution ID in secrets
- Permission Denied: Check IAM permissions for CloudFront invalidation
- Recovery: Manual invalidation via AWS Console if automated fails
- Impact: Users may see cached old content until TTL expires

### 4.2.3 Mobile Application Build Pipeline

The mobile CI/CD pipeline is defined in `.github/workflows/mobile-ci-cd.yml` and automates building iOS and Android applications from the React Native codebase with platform-specific native code.

#### 4.2.3.1 Pipeline Trigger Conditions

**Trigger Events**:
- Push to `main` or `develop` branches (paths: `mobile/**`)
- Pull requests targeting `main` branch (paths: `mobile/**`)

**Workflow Execution**: 
- iOS builds: `macos-latest` runners (required for Xcode)
- Android builds: `ubuntu-latest` runners

#### 4.2.3.2 Mobile Pipeline Flow Diagram

```mermaid
flowchart TD
    Start([Developer Pushes Mobile Code]) --> Trigger[GitHub Webhook<br/>Triggers Workflow]
    Trigger --> PlatformSplit{Build<br/>Platform?}
    
    PlatformSplit -->|iOS| iOSPath[iOS Build Path]
    PlatformSplit -->|Android| AndroidPath[Android Build Path]
    
    subgraph iOSBuild["iOS Build Process (macOS Runner)"]
        CheckoutiOS[Checkout Code<br/>actions/checkout@v3]
        SetupNodeiOS[Setup Node.js 18]
        InstallDepsiOS[Install npm Dependencies<br/>npm ci mobile/]
        InstallPods[Install CocoaPods<br/>cd mobile/ios && pod install]
        SelectXcode[Select Xcode Version<br/>xcode-select]
        BuildiOS[Build with Xcode<br/>xcodebuild clean build]
        SigniOS[Code Signing<br/>Certificates & Profiles]
        ArchiveiOS[Create Archive<br/>.ipa file]
    end
    
    subgraph AndroidBuild["Android Build Process (Ubuntu Runner)"]
        CheckoutAndroid[Checkout Code<br/>actions/checkout@v3]
        SetupJDK[Setup JDK 17<br/>actions/setup-java@v3]
        SetupNodeAndroid[Setup Node.js 18]
        InstallDepsAndroid[Install npm Dependencies<br/>npm ci mobile/]
        GrantPermissions[Grant Gradle Permissions<br/>chmod +x gradlew]
        BuildAndroid[Build with Gradle<br/>./gradlew assembleRelease]
        SignAndroid[Sign APK/AAB<br/>Keystore]
    end
    
    iOSPath --> iOSBuild
    AndroidPath --> AndroidBuild
    
    iOSBuild --> iOSSuccess{iOS Build<br/>Success?}
    AndroidBuild --> AndroidSuccess{Android Build<br/>Success?}
    
    iOSSuccess -->|No| FailiOS[❌ iOS Build Failed<br/>Show Xcode Errors]
    iOSSuccess -->|Yes| UploadiOS[Upload iOS Artifact<br/>.ipa file]
    
    AndroidSuccess -->|No| FailAndroid[❌ Android Build Failed<br/>Show Gradle Errors]
    AndroidSuccess -->|Yes| UploadAndroid[Upload Android Artifact<br/>.apk/.aab file]
    
    UploadiOS --> BranchCheckiOS{Is Main<br/>Branch?}
    UploadAndroid --> BranchCheckAndroid{Is Main<br/>Branch?}
    
    BranchCheckiOS -->|No| PRCompleteiOS[✅ iOS PR Validation]
    BranchCheckiOS -->|Yes| DeployiOS[Deploy to TestFlight<br/>Optional]
    
    BranchCheckAndroid -->|No| PRCompleteAndroid[✅ Android PR Validation]
    BranchCheckAndroid -->|Yes| DeployAndroid[Deploy to Play Console<br/>Optional]
    
    DeployiOS --> NotifyiOS[Notify Team<br/>iOS Build Available]
    DeployAndroid --> NotifyAndroid[Notify Team<br/>Android Build Available]
    
    FailiOS --> End([End])
    FailAndroid --> End
    PRCompleteiOS --> End
    PRCompleteAndroid --> End
    NotifyiOS --> End
    NotifyAndroid --> End
    
    style iOSBuild fill:#e3f2fd
    style AndroidBuild fill:#c8e6c9
```

#### 4.2.3.3 iOS Build Process Detail

**Stage 1: Environment Setup**

```
Step 1: Checkout Code
- Action: actions/checkout@v3
- Depth: Full history for versioning

Step 2: Setup Node.js
- Version: 18.x
- Cache: npm cache for faster installs

Step 3: Install JavaScript Dependencies
- Command: npm ci (in mobile/ directory)
- Purpose: Install React Native and JavaScript libraries
- Lock File: package-lock.json ensures reproducible builds

Step 4: Install Native iOS Dependencies
- Command: cd mobile/ios && pod install
- Tool: CocoaPods for iOS dependency management
- Pods: React Native iOS native modules
- Output: Podfile.lock, Pods/ directory
```

**Stage 2: Xcode Build**

```
Step 1: Select Xcode Version
- Command: sudo xcode-select -s /Applications/Xcode_XX.X.app
- Purpose: Ensure consistent Xcode version across builds
- Version: Latest stable Xcode (e.g., 15.0)

Step 2: Clean Build Directory
- Command: xcodebuild clean -workspace mobile/ios/App.xcworkspace -scheme App
- Purpose: Remove previous build artifacts

Step 3: Build Application
- Command: xcodebuild build -workspace mobile/ios/App.xcworkspace -scheme App -configuration Release -sdk iphoneos
- Configuration: Release (optimized build)
- SDK: iphoneos (for device builds)
- Output: App.app bundle

Step 4: Code Signing (if deploying)
- Certificates: Imported from GitHub Secrets
- Provisioning Profile: Distribution profile for App Store or Ad Hoc
- Signing Identity: Distribution certificate
- Command: xcodebuild -exportArchive

Step 5: Create Archive
- Command: xcodebuild archive -archivePath build/App.xcarchive
- Output: .ipa file for distribution
```

**Stage 3: iOS Artifact Upload**

```
Step 1: Upload Build Artifact
- Action: actions/upload-artifact@v3
- Artifact Name: ios-app-release-{git-sha}.ipa
- Path: build/App.ipa
- Retention: 90 days

Step 2: Optional TestFlight Deployment (Main Branch)
- Tool: fastlane pilot (if configured)
- Command: fastlane pilot upload
- Purpose: Distribute beta build to internal testers
- Notification: Testers receive TestFlight invitation
```

#### 4.2.3.4 Android Build Process Detail

**Stage 1: Environment Setup**

```
Step 1: Checkout Code
- Action: actions/checkout@v3

Step 2: Setup Java Development Kit
- Action: actions/setup-java@v3
- Version: JDK 17 (required for Android Gradle Plugin 8+)
- Distribution: temurin (Eclipse Temurin OpenJDK)

Step 3: Setup Node.js
- Version: 18.x
- Cache: npm cache

Step 4: Install JavaScript Dependencies
- Command: npm ci (in mobile/ directory)
- Purpose: Install React Native and JavaScript libraries
```

**Stage 2: Gradle Build**

```
Step 1: Grant Gradle Wrapper Permissions
- Command: chmod +x mobile/android/gradlew
- Purpose: Ensure gradlew script is executable

Step 2: Build Release APK/AAB
- Command: cd mobile/android && ./gradlew assembleRelease (for APK)
- Command: cd mobile/android && ./gradlew bundleRelease (for AAB)
- Configuration: Release variant with ProGuard/R8 minification
- Build Type:
  * APK: For direct distribution, testing
  * AAB: For Google Play Store submission (Android App Bundle)
- Output:
  * APK: mobile/android/app/build/outputs/apk/release/app-release.apk
  * AAB: mobile/android/app/build/outputs/bundle/release/app-release.aab

Step 3: Sign APK/AAB (if deploying)
- Keystore: Imported from GitHub Secrets (base64 encoded)
- Key Alias: Release key alias
- Passwords: Stored in GitHub Secrets
- Signing: Gradle signing configuration in build.gradle
```

**Stage 3: Android Artifact Upload**

```
Step 1: Upload Build Artifact
- Action: actions/upload-artifact@v3
- Artifact Name: android-app-release-{git-sha}.apk
- Path: mobile/android/app/build/outputs/apk/release/app-release.apk
- Retention: 90 days

Step 2: Optional Play Console Deployment (Main Branch)
- Tool: fastlane supply (if configured)
- Command: fastlane supply --aab mobile/android/app/build/outputs/bundle/release/app-release.aab
- Track: Internal testing or beta track
- Notification: Testers receive Play Console invitation
```

#### 4.2.3.5 Mobile Pipeline Decision Points

| Decision Point | Condition | Action if True | Action if False |
|----------------|-----------|----------------|-----------------|
| Platform? | iOS or Android | Route to platform-specific build | N/A (parallel builds) |
| iOS Build Success? | xcodebuild exit code 0 | Upload artifact | Fail workflow, show Xcode errors |
| Android Build Success? | gradlew exit code 0 | Upload artifact | Fail workflow, show Gradle errors |
| Code Signing Valid? | Certificates/keystores present | Sign build | Use debug signing or fail |
| Is Main Branch? | ref == refs/heads/main | Deploy to store | Stop (PR validation) |

#### 4.2.3.6 Mobile Error Handling and Recovery

**iOS Build Failures**:
- CocoaPods Errors: Update pod versions, run `pod repo update`, clear cache
- Xcode Build Errors: Check Swift/Objective-C syntax, verify native module compatibility
- Code Signing Errors: Verify certificates not expired, provisioning profile valid
- Recovery: Test build locally with Xcode, check build logs for specific errors

**Android Build Failures**:
- Gradle Dependency Errors: Check repositories, update Gradle and plugin versions
- Kotlin Compilation Errors: Fix Kotlin syntax, ensure compatibility with React Native version
- ProGuard/R8 Errors: Update ProGuard rules, exclude problematic classes
- Recovery: Test build locally with Android Studio, run `./gradlew assembleRelease`

**Signing Failures**:
- iOS: Verify certificates in Keychain, check provisioning profile expiration
- Android: Verify keystore password, key alias correct, keystore not corrupted
- Recovery: Regenerate certificates/keystores if necessary, update GitHub Secrets

### 4.2.4 Infrastructure Provisioning Pipeline

The infrastructure CI/CD pipeline is defined in `.github/workflows/infrastructure-ci-cd.yml` and automates Terraform-based infrastructure provisioning and updates on AWS.

#### 4.2.4.1 Pipeline Trigger Conditions

**Trigger Events**:
- Push to `main` branch (paths: `terraform/**`)
- Pull requests targeting `main` branch (paths: `terraform/**`)

**Workflow Execution**: Runs on `ubuntu-latest` with Terraform CLI

#### 4.2.4.2 Infrastructure Pipeline Flow Diagram

```mermaid
flowchart TD
    Start([Infrastructure Code Change]) --> Trigger[GitHub Webhook<br/>Triggers Workflow]
    Trigger --> Checkout[Checkout Repository<br/>actions/checkout@v3]
    Checkout --> SetupTF[Setup Terraform CLI<br/>hashicorp/setup-terraform@v2]
    
    SetupTF --> TFFormat[Terraform Format Check<br/>terraform fmt -check -recursive]
    TFFormat --> FormatCheck{Format<br/>Compliant?}
    FormatCheck -->|No| FailFormat[❌ Format Check Failed<br/>Run terraform fmt]
    FormatCheck -->|Yes| ConfigAWS[Configure AWS Credentials<br/>from GitHub Secrets]
    
    ConfigAWS --> TFInit[Terraform Init<br/>terraform init]
    TFInit --> InitCheck{Init<br/>Success?}
    InitCheck -->|No| FailInit[❌ Init Failed<br/>Check Backend Config]
    InitCheck -->|Yes| TFValidate[Terraform Validate<br/>terraform validate]
    
    TFValidate --> ValidateCheck{Validation<br/>Passed?}
    ValidateCheck -->|No| FailValidate[❌ Validation Failed<br/>Check Syntax]
    ValidateCheck -->|Yes| TFPlan[Terraform Plan<br/>terraform plan -out=tfplan]
    
    TFPlan --> PlanCheck{Plan<br/>Generated?}
    PlanCheck -->|No| FailPlan[❌ Plan Failed<br/>Check Resources]
    PlanCheck -->|Yes| SavePlan[Save Plan Artifact<br/>Upload to GitHub]
    
    SavePlan --> BranchCheck{Is Main<br/>Branch Push?}
    BranchCheck -->|No| PRComment[Post Plan to PR<br/>Comment for Review]
    BranchCheck -->|Yes| TFApply[Terraform Apply<br/>terraform apply -auto-approve]
    
    PRComment --> PRComplete[✅ PR Plan Ready for Review]
    
    TFApply --> ApplyCheck{Apply<br/>Success?}
    ApplyCheck -->|No| FailApply[❌ Apply Failed<br/>Check Error Logs]
    ApplyCheck -->|Yes| VerifyInfra[Verify Infrastructure<br/>Check Resource State]
    
    VerifyInfra --> UpdateState[Update Terraform State<br/>S3 Backend]
    UpdateState --> ApplySuccess[✅ Infrastructure Updated<br/>Notify Team]
    
    FailFormat --> End([End])
    FailInit --> End
    FailValidate --> End
    FailPlan --> End
    PRComplete --> End
    FailApply --> End
    ApplySuccess --> End
    
    style TFFormat fill:#fff3e0
    style TFInit fill:#e3f2fd
    style TFValidate fill:#e3f2fd
    style TFPlan fill:#f3e5f5
    style TFApply fill:#e8f5e9
    style ApplySuccess fill:#c8e6c9
```

#### 4.2.4.3 Infrastructure Pipeline Stages Detail

**Stage 1: Terraform Validation**

```
Step 1: Terraform Format Check
- Command: terraform fmt -check -recursive terraform/
- Purpose: Ensure consistent HCL formatting across all .tf files
- Failure Action: List unformatted files, fail workflow
- Auto-fix: Developers run `terraform fmt -recursive` locally

Step 2: Terraform Init
- Command: terraform init -backend-config="bucket=terraform-state-bucket"
- Purpose: Initialize Terraform working directory
- Actions:
  * Download provider plugins (AWS provider)
  * Configure S3 backend for state storage
  * Initialize DynamoDB state locking
- Backend Configuration:
  * S3 Bucket: terraform-state-{account-id}
  * Key: env/{environment}/terraform.tfstate
  * DynamoDB Table: terraform-state-lock
  * Region: us-east-1 (or configured region)

Step 3: Terraform Validate
- Command: terraform validate
- Purpose: Validate Terraform configuration syntax and internal consistency
- Checks:
  * Valid HCL syntax
  * Required provider arguments
  * Resource attribute references
  * Variable type constraints
- Failure Action: Display validation errors, fail workflow
```

**Stage 2: Terraform Planning**

```
Step 1: Generate Execution Plan
- Command: terraform plan -out=tfplan -var-file="env/production.tfvars"
- Purpose: Show what changes Terraform will make to infrastructure
- Output: Binary plan file (tfplan) and human-readable plan text
- Plan Includes:
  * Resources to create (+ symbol)
  * Resources to update (~ symbol)
  * Resources to destroy (- symbol)
  * Resources to replace (-/+ symbol)

Step 2: Save Plan Artifact
- Action: actions/upload-artifact@v3
- Artifact: tfplan binary file
- Retention: 30 days
- Purpose: Allows reviewing exact plan that will be applied

Step 3: Post Plan to PR (if Pull Request)
- Action: Post plan output as PR comment
- Format: Markdown code block with plan summary
- Purpose: Enable team review before merge and apply
- Content:
  * Number of resources to add/change/destroy
  * Summary of major changes
  * Estimated cost impact (if using Infracost)
```

**Stage 3: Terraform Apply** (Main branch only)

```
Step 1: Apply Infrastructure Changes
- Command: terraform apply -auto-approve tfplan
- Purpose: Execute planned infrastructure changes
- Auto-approve: Skip manual confirmation (plan already reviewed in PR)
- Execution:
  * Create/update/destroy resources in order
  * Handle dependencies between resources
  * Update Terraform state after each operation

Step 2: Monitor Apply Progress
- Output: Real-time resource creation/update logs
- Timeout: 30 minutes (configurable)
- Error Handling: If any resource fails, subsequent resources may be skipped

Step 3: Update Terraform State
- State Storage: S3 backend (automatic with backend configuration)
- State Locking: DynamoDB lock acquired during apply, released after
- State File: Updated to reflect current infrastructure
- State Backup: S3 versioning enabled for state file recovery

Step 4: Verify Infrastructure
- Health Checks: Verify critical resources created successfully
- Examples:
  * ECS cluster and services are active
  * ALB is healthy and routing traffic
  * RDS instances are available
  * S3 buckets have correct policies
- Failure: If verification fails, alert DevOps team (but apply already completed)
```

#### 4.2.4.4 Infrastructure Pipeline Decision Points

| Decision Point | Condition | Action if True | Action if False |
|----------------|-----------|----------------|-----------------|
| Format Check Pass? | All .tf files formatted | Continue to Init | Fail workflow, list unformatted files |
| Terraform Init Success? | Backend configured, plugins downloaded | Continue to Validate | Fail workflow, check backend config |
| Validation Pass? | Syntax valid, references correct | Continue to Plan | Fail workflow, show validation errors |
| Plan Success? | Plan generated without errors | Save plan | Fail workflow, check resource configs |
| Is Main Branch Push? | ref == refs/heads/main | Apply changes | Post plan to PR, stop |
| Apply Success? | All resources created/updated | Update state, notify | Fail workflow, alert team |

#### 4.2.4.5 Infrastructure Error Handling and Recovery

**Format Check Failures**:
- Cause: Unformatted .tf files
- Action: Run `terraform fmt -recursive terraform/` locally, commit formatted files
- Prevention: Use Terraform editor extensions for auto-formatting

**Init Failures**:
- Backend Configuration Errors: Verify S3 bucket exists, correct permissions
- Plugin Download Errors: Check network, verify provider versions compatible
- State Lock Errors: Clear stale locks in DynamoDB if safe
- Recovery: Fix backend configuration, retry init

**Validation Failures**:
- Syntax Errors: Fix HCL syntax, check variable references
- Provider Errors: Update provider version, check required arguments
- Recovery: Fix validation errors, test locally with `terraform validate`

**Plan Failures**:
- Resource Configuration Errors: Invalid resource arguments, missing required fields
- Provider API Errors: AWS API rate limiting, permissions issues
- State Conflicts: State and actual infrastructure out of sync
- Recovery: Fix resource configurations, refresh state with `terraform refresh`

**Apply Failures**:
- Resource Creation Errors: AWS quota limits, insufficient permissions, resource conflicts
- Dependency Errors: Circular dependencies, missing dependent resources
- Timeout Errors: Long-running operations exceed timeout
- Recovery Steps:
  1. Check CloudWatch logs for detailed AWS error messages
  2. Fix configuration issues
  3. Run `terraform plan` again to verify fix
  4. Push corrected code to trigger new apply
  5. If partially applied, Terraform state reflects actual infrastructure
  6. Next apply will reconcile differences

**State Locking Errors**:
- Cause: Previous run didn't release lock, concurrent runs
- Detection: Error message "Error acquiring the state lock"
- Recovery:
  1. Verify no Terraform operations are running
  2. Manually delete lock entry from DynamoDB table (terraform-state-lock)
  3. Retry apply
- Prevention: Ensure workflows don't run concurrently, use queue if needed

## 4.3 Authentication and Authorization Flows (Planned)

### 4.3.1 User Authentication Workflow

The planned authentication workflow leverages Auth0 as the identity provider with OAuth 2.0 and OpenID Connect protocols to provide secure, multi-platform user authentication.

#### 4.3.1.1 Authentication Flow Diagram

```mermaid
sequenceDiagram
    participant User
    participant Client as Client Application<br/>(Web/Mobile/Desktop)
    participant Auth0 as Auth0<br/>Identity Provider
    participant API as Backend API<br/>(Flask)
    participant DB as MongoDB<br/>Database

    Note over User,DB: Initial Application Access
    
    User->>Client: Launch Application
    Client->>Client: Check Local Storage<br/>for JWT Token
    
    alt Token Exists and Valid
        Client->>API: API Request<br/>(Authorization: Bearer {JWT})
        API->>API: Validate JWT Signature<br/>Check Expiration
        API->>DB: Query User Data
        DB->>API: Return User Profile
        API->>Client: Return Protected Resource
        Client->>User: Display Application
    else Token Expired or Invalid
        Client->>Client: Attempt Token Refresh
        Client->>Auth0: Refresh Token Request<br/>(grant_type=refresh_token)
        
        alt Refresh Token Valid
            Auth0->>Auth0: Validate Refresh Token
            Auth0->>Client: New Access Token<br/>+ Refresh Token
            Client->>Client: Store New Tokens
            Client->>User: Continue to Application
        else Refresh Token Invalid
            Client->>User: Redirect to Login
        end
    else No Token Present
        Client->>User: Redirect to Login
    end
    
    Note over User,DB: Login Flow
    
    User->>Client: Click "Login" Button
    Client->>Auth0: Redirect to Universal Login<br/>(response_type=code, scope=openid profile email)
    Auth0->>User: Display Login Page
    
    User->>Auth0: Enter Credentials<br/>(Email/Password or Social)
    Auth0->>Auth0: Validate Credentials
    
    alt Credentials Invalid
        Auth0->>User: Display Error<br/>"Invalid credentials"
        User->>Auth0: Retry Login
    else MFA Enabled
        Auth0->>User: Prompt for MFA Code<br/>(SMS/Authenticator App)
        User->>Auth0: Provide MFA Code
        Auth0->>Auth0: Validate MFA Code
        
        alt MFA Invalid
            Auth0->>User: Display Error<br/>"Invalid MFA code"
            User->>Auth0: Retry MFA
        end
    end
    
    Auth0->>Client: Authorization Code<br/>(via Callback URL)
    Client->>Auth0: Exchange Code for Tokens<br/>(grant_type=authorization_code)
    Auth0->>Auth0: Validate Authorization Code
    Auth0->>Client: Access Token (JWT)<br/>+ Refresh Token<br/>+ ID Token
    
    Client->>Client: Validate ID Token<br/>Extract User Info
    Client->>Client: Store Tokens Securely<br/>(Keychain/Keystore/Secure Storage)
    
    Client->>API: Create/Update User Profile<br/>(Authorization: Bearer {JWT})
    API->>API: Validate JWT<br/>Extract Auth0 User ID
    API->>DB: Upsert User Document<br/>(auth0_id, email, name, metadata)
    DB->>API: Confirm User Stored
    API->>Client: Return User Profile
    
    Client->>User: Redirect to Main Application
    User->>Client: Interact with Application
```

#### 4.3.1.2 Authentication States and Transitions

```mermaid
stateDiagram-v2
    [*] --> Unauthenticated: Application Launch
    
    Unauthenticated --> Authenticating: User Clicks Login
    Authenticating --> Auth0Login: Redirect to Auth0
    
    Auth0Login --> CredentialEntry: Display Login Form
    CredentialEntry --> CredentialValidation: Submit Credentials
    
    CredentialValidation --> MFARequired: MFA Enabled
    CredentialValidation --> TokenIssuance: MFA Disabled + Valid
    CredentialValidation --> CredentialEntry: Invalid Credentials
    
    MFARequired --> MFAEntry: Prompt MFA Code
    MFAEntry --> MFAValidation: Submit MFA Code
    MFAValidation --> TokenIssuance: Valid MFA
    MFAValidation --> MFAEntry: Invalid MFA (Retry)
    
    TokenIssuance --> Authenticated: Store JWT + Refresh Token
    Authenticated --> [*]: User Session Active
    
    Authenticated --> TokenExpired: JWT Expires (15 min)
    TokenExpired --> TokenRefreshing: Auto Refresh Attempt
    
    TokenRefreshing --> Authenticated: Refresh Success (New JWT)
    TokenRefreshing --> Unauthenticated: Refresh Failed (Re-login Required)
    
    Authenticated --> Unauthenticated: User Logout
    Authenticated --> Unauthenticated: Refresh Token Expired (7 days)
```

#### 4.3.1.3 Token Management Strategy

**JWT Access Token**:
- **Purpose**: Authorize API requests
- **Lifetime**: 15 minutes (short-lived for security)
- **Storage**: 
  - Web: localStorage or sessionStorage
  - Mobile: iOS Keychain, Android Keystore
  - Desktop: Electron SafeStorage
- **Structure**:
  ```json
  {
    "header": {
      "alg": "RS256",
      "typ": "JWT",
      "kid": "key-id"
    },
    "payload": {
      "iss": "https://your-tenant.auth0.com/",
      "sub": "auth0|123456",
      "aud": "your-api-identifier",
      "iat": 1672531200,
      "exp": 1672532100,
      "azp": "your-client-id",
      "scope": "openid profile email",
      "permissions": ["read:data", "write:data"]
    },
    "signature": "..."
  }
  ```
- **Usage**: Included in `Authorization: Bearer {token}` header for all API requests

**Refresh Token**:
- **Purpose**: Obtain new access tokens without re-authentication
- **Lifetime**: 7 days (configurable, up to 90 days)
- **Storage**: Same secure storage as access token
- **Rotation**: Auth0 can be configured for refresh token rotation (new refresh token issued with each refresh)
- **Revocation**: Can be revoked via Auth0 Management API for security

**ID Token**:
- **Purpose**: Contains user profile information (OpenID Connect)
- **Lifetime**: Same as access token (15 minutes)
- **Usage**: Client-side user info display, not for API authorization
- **Claims**: email, name, picture, email_verified, sub (Auth0 user ID)

#### 4.3.1.4 Multi-Platform Authentication Considerations

**Web Application (React)**:
```
Implementation: Auth0 React SDK (@auth0/auth0-react)

Configuration:
- Domain: {tenant}.auth0.com
- Client ID: Web application client ID from Auth0
- Redirect URI: https://app.example.com/callback
- Logout URI: https://app.example.com/

Flow: Authorization Code Flow with PKCE (Proof Key for Code Exchange)
Security: PKCE prevents authorization code interception attacks

Storage: sessionStorage or localStorage (debate: XSS risk vs. persistence)
```

**Mobile Applications (React Native)**:
```
Implementation: Auth0 React Native SDK (react-native-auth0)

Configuration:
- iOS: Custom URL scheme (com.yourapp://{tenant}.auth0.com/ios/com.yourapp/callback)
- Android: Intent filter for deep links

Flow: Authorization Code Flow with PKCE
Security: Native secure storage (Keychain/Keystore) for tokens

Biometric Authentication: Optional Face ID/Touch ID for convenient login
```

**iOS Native**:
```
Implementation: Auth0.swift SDK

Configuration:
- Callback URL: Custom URL scheme registered in Info.plist
- Bundle Identifier: com.yourcompany.yourapp

Flow: Authorization Code Flow with PKCE via ASWebAuthenticationSession
Security: Keychain storage for tokens, biometric protection

Universal Links: Seamless authentication experience
```

**Android Native**:
```
Implementation: Auth0.Android SDK

Configuration:
- Callback URL: Custom scheme or App Links
- Package Name: com.yourcompany.yourapp

Flow: Authorization Code Flow with PKCE via Chrome Custom Tabs
Security: Android Keystore for token storage, biometric protection

App Links: Deep linking for authentication callbacks
```

**Desktop Applications (Electron)**:
```
Implementation: Auth0 SPA SDK (@auth0/auth0-spa-js) with Electron adaptations

Configuration:
- Custom protocol handler (yourapp://callback)
- Electron deep linking for auth callbacks

Flow: Authorization Code Flow with PKCE
Security: Electron SafeStorage API for encrypted token storage

Considerations: Handle authentication in BrowserWindow, intercept redirects
```

### 4.3.2 JWT Token Validation Flow

The backend API validates JWT tokens on every authenticated request to ensure request authenticity and extract user context.

#### 4.3.2.1 Token Validation Process Diagram

```mermaid
flowchart TD
    Start([API Request Received]) --> ExtractHeader[Extract Authorization Header]
    ExtractHeader --> HeaderExists{Header<br/>Present?}
    
    HeaderExists -->|No| Return401Missing[Return 401 Unauthorized<br/>Error: Missing Authorization header]
    HeaderExists -->|Yes| ParseHeader["Parse Header<br/>Format: Bearer {token}"]
    
    ParseHeader --> FormatValid{Format<br/>Valid?}
    FormatValid -->|No| Return401Format[Return 401 Unauthorized<br/>Error: Invalid Authorization format]
    FormatValid -->|Yes| ExtractToken[Extract JWT Token<br/>from Bearer scheme]
    
    ExtractToken --> DecodeToken[Decode JWT<br/>Extract Header, Payload, Signature]
    DecodeToken --> CheckAlgorithm{Algorithm<br/>is RS256?}
    
    CheckAlgorithm -->|No| Return401Algo[Return 401 Unauthorized<br/>Error: Unsupported algorithm]
    CheckAlgorithm -->|Yes| FetchJWKS[Fetch Auth0 JWKS<br/>Public Key Set]
    
    FetchJWKS --> JWKSSuccess{JWKS<br/>Retrieved?}
    JWKSSuccess -->|No| Return503[Return 503 Service Unavailable<br/>Error: Cannot verify token]
    JWKSSuccess -->|Yes| SelectKey[Select Public Key<br/>by kid from JWT header]
    
    SelectKey --> VerifySignature[Verify JWT Signature<br/>with Public Key]
    VerifySignature --> SignatureValid{Signature<br/>Valid?}
    
    SignatureValid -->|No| Return401Sig[Return 401 Unauthorized<br/>Error: Invalid token signature]
    SignatureValid -->|Yes| CheckExpiration[Check Expiration<br/>exp claim vs. current time]
    
    CheckExpiration --> NotExpired{Token Not<br/>Expired?}
    NotExpired -->|No| Return401Exp[Return 401 Unauthorized<br/>Error: Token expired]
    NotExpired -->|Yes| CheckIssuer[Verify Issuer<br/>iss claim matches Auth0 domain]
    
    CheckIssuer --> IssuerValid{Issuer<br/>Valid?}
    IssuerValid -->|No| Return401Iss[Return 401 Unauthorized<br/>Error: Invalid issuer]
    IssuerValid -->|Yes| CheckAudience[Verify Audience<br/>aud claim matches API identifier]
    
    CheckAudience --> AudienceValid{Audience<br/>Valid?}
    AudienceValid -->|No| Return401Aud[Return 401 Unauthorized<br/>Error: Invalid audience]
    AudienceValid -->|Yes| ExtractClaims[Extract User Claims<br/>sub, permissions, scope]
    
    ExtractClaims --> StoreContext[Store User Context<br/>in Request Object]
    StoreContext --> ProceedRequest[✅ Proceed to<br/>Business Logic]
    
    Return401Missing --> End([End Request])
    Return401Format --> End
    Return401Algo --> End
    Return503 --> End
    Return401Sig --> End
    Return401Exp --> End
    Return401Iss --> End
    Return401Aud --> End
    ProceedRequest --> End
    
    style ProceedRequest fill:#c8e6c9
    style Return401Missing fill:#ffcdd2
    style Return401Format fill:#ffcdd2
    style Return401Algo fill:#ffcdd2
    style Return503 fill:#ffecb3
    style Return401Sig fill:#ffcdd2
    style Return401Exp fill:#ffcdd2
    style Return401Iss fill:#ffcdd2
    style Return401Aud fill:#ffcdd2
```

#### 4.3.2.2 JWT Validation Implementation Pattern

**Flask-JWT-Extended Integration**:
```
Step 1: Configure Extension
- Configure JWT_SECRET_KEY (or JWT_PUBLIC_KEY for RS256)
- Configure JWT_ALGORITHM: RS256
- Configure JWT_IDENTITY_CLAIM: sub (Auth0 user ID)
- Configure JWT_ISSUER: https://{tenant}.auth0.com/
- Configure JWT_AUDIENCE: API identifier from Auth0

Step 2: Protect Routes with Decorator
- @jwt_required() decorator on protected endpoints
- Automatically validates JWT before route execution
- Raises JWTExtendedException on validation failure

Step 3: Access User Identity
- get_jwt_identity() returns subject claim (Auth0 user ID)
- get_jwt() returns full JWT payload (claims dictionary)
- Use for authorization checks and user context

Step 4: Custom Claims Validation
- @jwt_required() with custom validators for permissions
- Example: Check if 'write:data' in jwt['permissions']
```

**JWKS Caching Strategy**:
```
Purpose: Avoid fetching Auth0 public keys on every request

Implementation:
1. Fetch JWKS from https://{tenant}.auth0.com/.well-known/jwks.json
2. Cache public keys in Redis with TTL (e.g., 1 hour)
3. On JWT validation, retrieve public key from cache
4. If cache miss or key rotation detected, fetch fresh JWKS
5. Update cache with new keys

Benefits:
- Reduced latency (no external HTTP call per request)
- Improved performance (in-memory key lookup)
- Resilience (cached keys work even if Auth0 temporarily unreachable)
```

### 4.3.3 API Authorization Flow

After authentication, authorization determines what actions a user can perform based on their permissions and roles.

#### 4.3.3.1 Authorization Decision Flow

```mermaid
flowchart TD
    Start([Authenticated Request]) --> ExtractPerms[Extract Permissions<br/>from JWT Claims]
    ExtractPerms --> RouteReq{What<br/>Operation?}
    
    RouteReq -->|Read Operation| CheckRead[Check Read Permission]
    RouteReq -->|Write Operation| CheckWrite[Check Write Permission]
    RouteReq -->|Delete Operation| CheckDelete[Check Delete Permission]
    RouteReq -->|Admin Operation| CheckAdmin[Check Admin Permission]
    
    CheckRead --> HasReadPerm{Has read:resource<br/>Permission?}
    HasReadPerm -->|No| Return403Read[Return 403 Forbidden<br/>Insufficient permissions]
    HasReadPerm -->|Yes| ResourceLevel[Resource-Level Check]
    
    CheckWrite --> HasWritePerm{Has write:resource<br/>Permission?}
    HasWritePerm -->|No| Return403Write[Return 403 Forbidden<br/>Insufficient permissions]
    HasWritePerm -->|Yes| ResourceLevel
    
    CheckDelete --> HasDeletePerm{Has delete:resource<br/>Permission?}
    HasDeletePerm -->|No| Return403Delete[Return 403 Forbidden<br/>Insufficient permissions]
    HasDeletePerm -->|Yes| ResourceLevel
    
    CheckAdmin --> HasAdminPerm{Has admin<br/>Permission?}
    HasAdminPerm -->|No| Return403Admin[Return 403 Forbidden<br/>Admin access required]
    HasAdminPerm -->|Yes| ExecuteOp[Execute Admin Operation]
    
    ResourceLevel --> FetchResource[Fetch Resource<br/>from Database]
    FetchResource --> ResourceExists{Resource<br/>Exists?}
    
    ResourceExists -->|No| Return404[Return 404 Not Found<br/>Resource does not exist]
    ResourceExists -->|Yes| CheckOwnership{User Owns<br/>Resource?}
    
    CheckOwnership -->|No| CheckShared{Resource<br/>Shared with User?}
    CheckOwnership -->|Yes| ExecuteOp
    
    CheckShared -->|No| Return403Owner[Return 403 Forbidden<br/>Access denied to resource]
    CheckShared -->|Yes| ExecuteOp
    
    ExecuteOp --> LogAccess[Log Access Event<br/>Audit Trail]
    LogAccess --> Success[✅ Operation Successful<br/>Return Result]
    
    Return403Read --> End([End Request])
    Return403Write --> End
    Return403Delete --> End
    Return403Admin --> End
    Return404 --> End
    Return403Owner --> End
    Success --> End
    
    style ExecuteOp fill:#e8f5e9
    style Success fill:#c8e6c9
    style Return403Read fill:#ffcdd2
    style Return403Write fill:#ffcdd2
    style Return403Delete fill:#ffcdd2
    style Return403Admin fill:#ffcdd2
    style Return403Owner fill:#ffcdd2
    style Return404 fill:#fff9c4
```

#### 4.3.3.2 Permission-Based Access Control (PBAC)

**Permission Naming Convention**:
```
Format: {action}:{resource}

Examples:
- read:documents - Read access to documents
- write:documents - Create/update documents
- delete:documents - Delete documents
- read:users - View user profiles
- write:users - Update user profiles
- admin:system - Full administrative access
```

**Permission Assignment via Auth0**:
```
Method 1: Role-Based Access Control (RBAC)
- Define roles in Auth0 (e.g., "User", "Editor", "Admin")
- Assign permissions to roles
- Assign roles to users
- JWT includes permissions array with all granted permissions

Method 2: Direct Permission Assignment
- Assign specific permissions directly to users
- More granular control, less manageable at scale

Method 3: Hybrid Approach
- Base permissions via roles
- Additional permissions for specific users
```

**Authorization Decorator Pattern** (Flask):
```
Implementation:
1. Create custom decorator @require_permissions(permissions_list)
2. Decorator extracts JWT permissions from request context
3. Check if required permissions are subset of user permissions
4. If check passes, execute route function
5. If check fails, return 403 Forbidden with error details

Usage Example:
@app.route('/api/v1/documents', methods=['POST'])
@jwt_required()
@require_permissions(['write:documents'])
def create_document():
    # User has write:documents permission, proceed
    pass
```

#### 4.3.3.3 Resource-Level Authorization

**Ownership-Based Access**:
```
Scenario: User requests to update a document

Steps:
1. Extract user ID from JWT (sub claim: auth0|123456)
2. Fetch document from MongoDB by document ID
3. Compare document.owner_id with JWT sub claim
4. If match → Allow operation
5. If mismatch → Check if document is shared with user
6. If not shared → Return 403 Forbidden

Implementation:
def check_resource_ownership(resource_id, user_id):
    resource = db.documents.find_one({"_id": resource_id})
    if not resource:
        return False, "Resource not found"
    if resource['owner_id'] == user_id:
        return True, "Owner access"
    if user_id in resource.get('shared_with', []):
        return True, "Shared access"
    return False, "Access denied"
```

**Hierarchical Permissions**:
```
Scenario: Admin users can access all resources

Implementation:
1. Check if user has admin:system permission
2. If admin → Skip ownership check, grant access
3. If not admin → Proceed with standard ownership check

Permission Hierarchy:
- admin:system > write:{resource} > read:{resource}
- Admin permission implies all lower permissions
```

## 4.4 API Request Processing Flows (Planned)

### 4.4.1 Standard API Request Flow

The planned standard API request processing flow handles typical CRUD operations with authentication, validation, database interaction, and caching.

#### 4.4.1.1 Complete API Request Flow Diagram

```mermaid
sequenceDiagram
    participant Client
    participant ALB as Application<br/>Load Balancer
    participant API as Flask API<br/>Backend
    participant Cache as Redis<br/>Cache
    participant DB as MongoDB<br/>Database
    participant Logger as CloudWatch<br/>Logs

    Note over Client,Logger: Standard API Request Processing
    
    Client->>ALB: HTTPS Request<br/>(Authorization: Bearer {JWT})
    ALB->>ALB: TLS Termination<br/>SSL Certificate Validation
    ALB->>ALB: Rate Limiting Check<br/>(Initial Layer)
    
    ALB->>API: Forward Request<br/>to Healthy Instance
    API->>Logger: Log Request<br/>(Request ID, User, Endpoint, Timestamp)
    
    API->>API: Validate JWT Token<br/>(See Section 4.3.2)
    
    alt JWT Invalid or Expired
        API->>Client: 401 Unauthorized<br/>Error: Invalid token
        API->>Logger: Log Auth Failure
    else JWT Valid
        API->>API: Extract User Context<br/>(User ID, Permissions)
        API->>API: Check Rate Limit<br/>(Redis-based per user)
        
        alt Rate Limit Exceeded
            API->>Client: 429 Too Many Requests<br/>Retry-After: 60
            API->>Logger: Log Rate Limit Event
        else Rate Limit OK
            API->>API: Parse Request Body<br/>Extract Parameters
            API->>API: Validate Input Schema<br/>(Pydantic Validation)
            
            alt Validation Failed
                API->>Client: 400 Bad Request<br/>Field-specific errors
                API->>Logger: Log Validation Error
            else Validation Passed
                API->>API: Check Authorization<br/>(See Section 4.3.3)
                
                alt Permission Denied
                    API->>Client: 403 Forbidden<br/>Insufficient permissions
                    API->>Logger: Log Authorization Failure
                else Permission Granted
                    Note over API,DB: Business Logic Execution
                    
                    API->>API: Generate Cache Key<br/>(endpoint + params + user_id)
                    API->>Cache: Check Cache<br/>GET cache_key
                    
                    alt Cache Hit
                        Cache->>API: Return Cached Response
                        API->>API: Add Cache Headers<br/>(X-Cache: HIT)
                        API->>Client: 200 OK<br/>Cached Data
                        API->>Logger: Log Cache Hit
                    else Cache Miss
                        Cache->>API: Cache Miss (null)
                        API->>DB: Execute Query<br/>(Find/Aggregate)
                        
                        alt Query Error
                            DB->>API: Database Error
                            API->>API: Log Error Details
                            API->>Client: 500 Internal Server Error<br/>Generic message
                            API->>Logger: Log Database Error (with details)
                        else Query Success
                            DB->>API: Return Query Results
                            API->>API: Transform Data<br/>(DB format → API format)
                            API->>API: Apply Field-Level Permissions<br/>(Redact sensitive fields if needed)
                            
                            API->>Cache: Store in Cache<br/>SETEX cache_key TTL value
                            Cache->>API: Cache Stored
                            
                            API->>API: Prepare Response<br/>(Headers, Status, Body)
                            API->>API: Add Cache Headers<br/>(X-Cache: MISS, Cache-Control)
                            API->>Client: 200 OK<br/>Response Data
                            API->>Logger: Log Successful Request<br/>(Duration, Cache Miss)
                        end
                    end
                end
            end
        end
    end
    
    Client->>Client: Parse Response<br/>Update UI State
```

#### 4.4.1.2 Request Processing Stages

**Stage 1: Request Reception and Initial Validation**

```
Step 1: Load Balancer Processing
- TLS Termination: Decrypt HTTPS traffic, validate SSL certificate
- Health Check: Route only to healthy backend instances
- Initial Rate Limiting: Prevent DDoS at infrastructure level
- Forwarding: Add X-Forwarded-For header with client IP
- Target Selection: Round-robin or least connections algorithm

Step 2: Request Logging
- Generate Request ID: UUID for tracing request through system
- Log Entry: Timestamp, Request ID, Client IP, Endpoint, Method, User Agent
- Purpose: Debugging, analytics, audit trail
- Destination: CloudWatch Logs with structured JSON format

Step 3: JWT Authentication
- Extract Authorization header: "Bearer {token}"
- Validate JWT: Signature, expiration, issuer, audience (see Section 4.3.2)
- Extract User Context: User ID, permissions, roles
- Result: Request context populated with authenticated user info
```

**Stage 2: Rate Limiting and Input Validation**

```
Step 1: Rate Limiting (Flask-Limiter + Redis)
- Key: user_id from JWT (or IP for unauthenticated endpoints)
- Strategy: Token bucket or fixed window
- Limits:
  * General endpoints: 100 requests per minute
  * Write operations: 20 requests per minute
  * AI/LLM endpoints: 10 requests per minute (due to cost)
- Storage: Redis for distributed rate limiting across instances
- Response if exceeded: 429 Too Many Requests with Retry-After header

Step 2: Input Parsing
- Content-Type: application/json (expected)
- Parse JSON: Flask request.get_json()
- Query Parameters: Extract from request.args
- Path Parameters: Extract from route variables

Step 3: Schema Validation (Pydantic)
- Define: Pydantic models for each endpoint's expected input
- Validate: Type checking, required fields, format validation (email, URL)
- Constraints: Min/max length, regex patterns, enum values
- Response if failed: 400 Bad Request with field-specific error messages
  Example: {"errors": {"email": "Invalid email format", "age": "Must be >= 18"}}
```

**Stage 3: Authorization and Business Logic**

```
Step 1: Permission Check
- Extract Required Permissions: Based on endpoint and operation
- Compare with User Permissions: From JWT claims
- Resource-Level Authorization: Check resource ownership if applicable
- Response if denied: 403 Forbidden with reason

Step 2: Business Logic Execution
- Domain Logic: Apply business rules specific to the operation
- Examples:
  * Create: Check for duplicates, generate IDs, set timestamps
  * Read: Apply filters, pagination, sorting
  * Update: Validate state transitions, update timestamps
  * Delete: Check dependencies, soft delete vs. hard delete
- Validation: Additional business rule validation beyond schema
```

**Stage 4: Data Layer Interaction**

```
Step 1: Cache Check (Read Operations)
- Generate Cache Key: f"{endpoint}:{user_id}:{sorted_params_hash}"
- Redis GET: Retrieve cached response if exists
- Cache TTL Strategy:
  * Frequently accessed, rarely changed: 1 hour
  * User-specific data: 5 minutes
  * Real-time data: No cache or 30 seconds

Step 2: Database Query (Cache Miss or Write Operation)
- Build Query: Using PyMongo or Motor driver
- Execute: Find, aggregate, insert, update, or delete operation
- Indexing: Utilize MongoDB indexes for performance
- Error Handling: Catch database exceptions, log details, return generic error

Step 3: Data Transformation
- DB Format → API Format: Convert MongoDB documents to API response schema
- Field Mapping: Rename fields, nest objects, format dates
- Filtering: Remove sensitive fields (passwords, internal IDs)
- Pagination: Apply limit, skip, and generate pagination metadata

Step 4: Cache Population (Read Operations)
- Store in Redis: SET cache_key response_json EX ttl_seconds
- Serialization: JSON serialization of response data
- Invalidation: On write operations, delete related cache keys
```

**Stage 5: Response Preparation and Delivery**

```
Step 1: Response Formatting
- HTTP Status Code: 200 OK, 201 Created, 204 No Content, etc.
- Response Body: JSON formatted data
- Headers:
  * Content-Type: application/json
  * Cache-Control: max-age={seconds}, public/private
  * X-Cache: HIT or MISS (cache status)
  * X-Request-ID: Request tracing ID
  * X-RateLimit-Remaining: Remaining rate limit quota

Step 2: Logging
- Log Response: Status code, duration, cache status
- Metrics: Increment success/error counters for monitoring
- CloudWatch: Structured log entry for analysis

Step 3: Client Delivery
- ALB: Forwards response to client
- TLS Encryption: Re-encrypt response with HTTPS
- Client: Receives response, updates UI
```

### 4.4.2 Cached Request Flow Optimization

The caching strategy optimizes API performance by serving frequently accessed data from Redis cache, reducing database load and improving response times.

#### 4.4.2.1 Cache Strategy Decision Flow

```mermaid
flowchart TD
    Start([API Request Received]) --> AuthCheck[Authenticate & Authorize<br/>Request]
    AuthCheck --> DetermineOp{Request<br/>Type?}
    
    DetermineOp -->|Read Operation| CacheStrategy[Apply Cache Strategy]
    DetermineOp -->|Write Operation| SkipCache[Skip Cache<br/>Go Directly to DB]
    
    CacheStrategy --> GenerateKey[Generate Cache Key<br/>endpoint:user:params_hash]
    GenerateKey --> CheckCache[Redis GET cache_key]
    
    CheckCache --> CacheResult{Cache<br/>Result?}
    CacheResult -->|Hit| ValidateAge[Check Cache Age<br/>TTL Remaining]
    CacheResult -->|Miss| QueryDB[Query MongoDB]
    
    ValidateAge --> AgeCheck{Cache<br/>Still Valid?}
    AgeCheck -->|Yes| ReturnCached[Return Cached Response<br/>X-Cache: HIT]
    AgeCheck -->|No| RefreshCache[Refresh Cache<br/>Query DB]
    
    RefreshCache --> QueryDB
    QueryDB --> DBResult{Query<br/>Success?}
    
    DBResult -->|No| CheckStaleCache{Stale Cache<br/>Available?}
    CheckStaleCache -->|Yes| ReturnStale[Return Stale Cache<br/>X-Cache: STALE]
    CheckStaleCache -->|No| ReturnError[Return 500 Error]
    
    DBResult -->|Yes| TransformData[Transform Data<br/>to API Format]
    TransformData --> DetermineTTL[Determine Cache TTL<br/>Based on Data Type]
    
    DetermineTTL --> StoreTTL{TTL Strategy?}
    StoreTTL -->|Static Data| SetLongTTL[Set Long TTL<br/>1-24 hours]
    StoreTTL -->|User Data| SetMediumTTL[Set Medium TTL<br/>5-15 minutes]
    StoreTTL -->|Real-Time Data| SetShortTTL[Set Short TTL<br/>30-60 seconds]
    StoreTTL -->|No Cache| SkipStore[Skip Cache Storage]
    
    SetLongTTL --> StoreCache[Redis SETEX<br/>cache_key TTL data]
    SetMediumTTL --> StoreCache
    SetShortTTL --> StoreCache
    
    StoreCache --> ReturnFresh[Return Fresh Response<br/>X-Cache: MISS]
    SkipStore --> ReturnFresh
    
    SkipCache --> WriteDB[Execute Write Operation<br/>INSERT/UPDATE/DELETE]
    WriteDB --> WriteSuccess{Write<br/>Success?}
    
    WriteSuccess -->|No| ReturnWriteError[Return 500/409 Error]
    WriteSuccess -->|Yes| InvalidateCache[Invalidate Related<br/>Cache Entries]
    
    InvalidateCache --> FindKeys[Find Cache Keys<br/>Matching Pattern]
    FindKeys --> DeleteKeys[Redis DEL<br/>matching keys]
    DeleteKeys --> ReturnWriteSuccess[Return Write Success<br/>201/200/204]
    
    ReturnCached --> End([End])
    ReturnStale --> End
    ReturnError --> End
    ReturnFresh --> End
    ReturnWriteError --> End
    ReturnWriteSuccess --> End
    
    style ReturnCached fill:#c8e6c9
    style ReturnFresh fill:#fff9c4
    style CacheStrategy fill:#e1f5ff
    style StoreTTL fill:#e1f5ff
```

#### 4.4.2.2 Cache Key Generation Strategy

**Cache Key Pattern**:
```
Format: {namespace}:{endpoint}:{user_id}:{params_hash}

Components:
- namespace: "api" (consistent prefix for all API caches)
- endpoint: API endpoint path (e.g., "documents", "users/profile")
- user_id: Auth0 user ID from JWT (for user-specific data)
- params_hash: MD5 hash of sorted query parameters

Examples:
- api:documents:auth0|123456:d41d8cd98f00b204e9800998ecf8427e
- api:users/profile:auth0|123456:no_params
- api:search:auth0|123456:f4b5e7c9a1d2e3b4c5a6e7d8f9a0b1c2 (includes search query hash)

Benefits:
- Unique per user (prevents data leakage)
- Consistent across requests (cache hit rate optimization)
- Parameterized (different parameters = different cache)
```

**Params Hash Calculation**:
```
Algorithm:
1. Extract query parameters from request
2. Sort parameters alphabetically by key
3. Serialize to canonical JSON format
4. Calculate MD5 hash of serialized string
5. Use hash as part of cache key

Example:
Request: /api/documents?sort=created_at&limit=10&filter=active
Sorted: {"filter": "active", "limit": 10, "sort": "created_at"}
JSON: '{"filter":"active","limit":10,"sort":"created_at"}'
MD5: e4d909c290d0fb1ca068ffaddf22cbd0

Purpose: Same parameters → Same hash → Cache hit
```

#### 4.4.2.3 Cache TTL Strategy

| Data Category | TTL | Rationale | Invalidation Trigger |
|---------------|-----|-----------|----------------------|
| Static Configuration | 24 hours | Rarely changes | Manual cache clear on config update |
| Public Content | 1 hour | Infrequently updated | On content publish/update |
| User Profile | 15 minutes | Occasionally updated | On profile update, logout |
| User-Generated Content | 5 minutes | Frequently created/updated | On create/update/delete operations |
| Search Results | 5 minutes | Dynamic based on data changes | On relevant data changes |
| Real-Time Analytics | 30 seconds | Frequently changing | Time-based expiration only |
| Session Data | 15 minutes | Match JWT token lifetime | On logout, token refresh |
| LLM Responses | 1 hour | Expensive to regenerate | On model update or manual clear |
| No Cache | N/A | Highly sensitive or unique | N/A |

#### 4.4.2.4 Cache Invalidation Strategies

**Time-Based Expiration** (Primary):
```
Method: Set TTL when storing in Redis (SETEX command)
Behavior: Redis automatically deletes key when TTL expires
Advantage: Simple, no manual invalidation needed
Disadvantage: May serve slightly stale data until expiration

Implementation:
redis.setex(cache_key, ttl_seconds, json_data)
```

**Event-Based Invalidation** (Secondary):
```
Trigger: On write operations (create, update, delete)

Strategies:
1. Exact Key Deletion:
   - Know exact cache key to invalidate
   - redis.delete(cache_key)
   
2. Pattern-Based Deletion:
   - Invalidate multiple related keys
   - Pattern: api:documents:*  (all documents caches for all users)
   - redis.keys(pattern) → redis.delete(*keys)  [Use with caution in production]
   
3. Tag-Based Invalidation:
   - Maintain a set of cache keys per resource
   - On write: Iterate set and delete all keys
   - redis.smembers(f"cache_tags:{resource_id}") → delete all

Example:
On document update (document_id=123):
- Delete: api:documents:*  (all lists)
- Delete: api:documents/123:*  (specific document)
- Delete: api:search:*  (search results may include this document)
```

**Stale-While-Revalidate**:
```
Strategy: Serve stale cache while fetching fresh data in background

Implementation:
1. Check cache, if hit and not expired → Return immediately
2. If hit but near expiration → Return cache, trigger background refresh
3. Background job: Query DB, update cache with new TTL

Benefits:
- Always fast response (no waiting for DB)
- Cache always fresh (proactive refresh)
- Graceful degradation (stale cache if DB fails)

Challenge: Requires background job framework (Celery, RQ)
```

**Cache Stampede Prevention**:
```
Problem: Multiple concurrent requests for expired cache all hit DB simultaneously

Solution: Distributed Lock (Redis SETNX)
1. Request A: Cache miss, acquire lock (SETNX cache_key:lock 1 EX 10)
2. Request A: Lock acquired, query DB
3. Request B: Cache miss, try lock, fails (lock exists)
4. Request B: Wait or poll cache with short delay
5. Request A: Populates cache, releases lock
6. Request B: Cache hit (populated by Request A)

Alternative: Probabilistic Early Expiration
- Before TTL expires, probabilistically trigger refresh
- Reduces likelihood of multiple requests hitting expired cache
```

### 4.4.3 Error Handling and Recovery

The API implements comprehensive error handling to provide meaningful feedback, ensure system stability, and enable graceful degradation.

#### 4.4.3.1 Error Handling Flow

```mermaid
flowchart TD
    Start([Error Occurs]) --> ClassifyError{Error<br/>Type?}
    
    ClassifyError -->|Client Error| ClientError[Client Error<br/>4xx Status]
    ClassifyError -->|Server Error| ServerError[Server Error<br/>5xx Status]
    ClassifyError -->|External Service Error| ExternalError[External Service Error<br/>503 or Fallback]
    
    ClientError --> ClientType{Specific<br/>Client Error?}
    ClientType -->|Authentication| Handle401[401 Unauthorized<br/>Invalid/Missing Token]
    ClientType -->|Authorization| Handle403[403 Forbidden<br/>Insufficient Permissions]
    ClientType -->|Not Found| Handle404[404 Not Found<br/>Resource Does Not Exist]
    ClientType -->|Validation| Handle400[400 Bad Request<br/>Field-Specific Errors]
    ClientType -->|Conflict| Handle409[409 Conflict<br/>Duplicate/Constraint Violation]
    ClientType -->|Rate Limit| Handle429[429 Too Many Requests<br/>Retry-After Header]
    
    ServerError --> ServerType{Specific<br/>Server Error?}
    ServerType -->|Database Error| HandleDB[Database Error Handler]
    ServerType -->|Internal Logic| Handle500[500 Internal Server Error<br/>Generic Message]
    ServerType -->|Timeout| Handle504[504 Gateway Timeout<br/>Request Took Too Long]
    
    ExternalError --> ExternalType{Fallback<br/>Available?}
    ExternalType -->|Cache Available| ReturnCache[Return Cached Data<br/>Stale but Available]
    ExternalType -->|Default Available| ReturnDefault[Return Default/Static Data]
    ExternalType -->|No Fallback| Handle503[503 Service Unavailable<br/>Retry Later]
    
    Handle401 --> FormatError[Format Error Response<br/>JSON with Error Details]
    Handle403 --> FormatError
    Handle404 --> FormatError
    Handle400 --> FormatError
    Handle409 --> FormatError
    Handle429 --> FormatError
    HandleDB --> CheckDBType{Database<br/>Error Type?}
    Handle500 --> FormatError
    Handle504 --> FormatError
    ReturnCache --> FormatError
    ReturnDefault --> FormatError
    Handle503 --> FormatError
    
    CheckDBType -->|Connection Lost| RetryDB[Retry with<br/>Exponential Backoff]
    CheckDBType -->|Query Timeout| LogTimeout[Log Slow Query<br/>Return Timeout Error]
    CheckDBType -->|Constraint Violation| Handle409
    CheckDBType -->|Other DB Error| LogDBError[Log Detailed Error<br/>Return Generic Error]
    
    RetryDB --> RetrySuccess{Retry<br/>Successful?}
    RetrySuccess -->|Yes| ReturnData[Return Queried Data<br/>200 OK]
    RetrySuccess -->|No| CircuitBreaker[Open Circuit Breaker<br/>Fail Fast]
    
    CircuitBreaker --> Handle503
    LogTimeout --> Handle504
    LogDBError --> Handle500
    
    FormatError --> LogError[Log Error Event<br/>CloudWatch Logs]
    LogError --> CheckSeverity{Error<br/>Severity?}
    
    CheckSeverity -->|Critical| AlertOps[Alert Operations Team<br/>PagerDuty/Slack]
    CheckSeverity -->|Warning| LogWarning[Log Warning<br/>No Alert]
    CheckSeverity -->|Info| LogInfo[Log Info<br/>Metrics Only]
    
    AlertOps --> ReturnResponse[Return Error Response<br/>to Client]
    LogWarning --> ReturnResponse
    LogInfo --> ReturnResponse
    ReturnData --> ReturnResponse
    
    ReturnResponse --> End([End])
    
    style Handle401 fill:#ffcdd2
    style Handle403 fill:#ffcdd2
    style Handle404 fill:#fff9c4
    style Handle400 fill:#ffcdd2
    style Handle500 fill:#ef9a9a
    style AlertOps fill:#ff6f00
```

#### 4.4.3.2 Error Response Format

**Standard Error Response Structure**:
```json
{
  "error": {
    "code": "ERROR_CODE",
    "message": "Human-readable error message",
    "details": {
      "field": "Specific error details",
      "another_field": "More context"
    },
    "request_id": "550e8400-e29b-41d4-a716-446655440000",
    "timestamp": "2024-01-15T10:30:00Z",
    "documentation_url": "https://docs.api.example.com/errors/ERROR_CODE"
  }
}
```

**Error Code Categories**:
```
Authentication Errors (AUTH_xxx):
- AUTH_TOKEN_MISSING: Authorization header not provided
- AUTH_TOKEN_INVALID: JWT signature invalid or malformed
- AUTH_TOKEN_EXPIRED: JWT token expired
- AUTH_MFA_REQUIRED: Multi-factor authentication required

Authorization Errors (AUTHZ_xxx):
- AUTHZ_PERMISSION_DENIED: User lacks required permission
- AUTHZ_RESOURCE_FORBIDDEN: User cannot access specific resource
- AUTHZ_ADMIN_REQUIRED: Admin-only operation

Validation Errors (VALID_xxx):
- VALID_SCHEMA_ERROR: Request body doesn't match schema
- VALID_FIELD_REQUIRED: Required field missing
- VALID_FIELD_FORMAT: Field format invalid (e.g., email)
- VALID_FIELD_RANGE: Field value out of acceptable range

Resource Errors (RES_xxx):
- RES_NOT_FOUND: Requested resource doesn't exist
- RES_CONFLICT: Resource already exists (duplicate)
- RES_GONE: Resource was deleted and no longer available

Rate Limiting Errors (RATE_xxx):
- RATE_LIMIT_EXCEEDED: Too many requests from user/IP
- RATE_QUOTA_EXCEEDED: API quota exceeded for billing period

Server Errors (SERVER_xxx):
- SERVER_INTERNAL_ERROR: Unspecified internal error
- SERVER_DATABASE_ERROR: Database operation failed
- SERVER_TIMEOUT: Request processing timeout
- SERVER_UNAVAILABLE: Service temporarily unavailable

External Service Errors (EXT_xxx):
- EXT_AUTH0_ERROR: Auth0 service error
- EXT_OPENAI_ERROR: OpenAI API error
- EXT_S3_ERROR: S3 operation failed
```

**Example Error Responses**:

```json
// 400 Validation Error
{
  "error": {
    "code": "VALID_SCHEMA_ERROR",
    "message": "Request validation failed",
    "details": {
      "email": "Invalid email format",
      "age": "Must be at least 18",
      "username": "Required field missing"
    },
    "request_id": "req_abc123",
    "timestamp": "2024-01-15T10:30:00Z"
  }
}

// 401 Authentication Error
{
  "error": {
    "code": "AUTH_TOKEN_EXPIRED",
    "message": "JWT token has expired",
    "details": {
      "expired_at": "2024-01-15T10:00:00Z",
      "current_time": "2024-01-15T10:30:00Z"
    },
    "request_id": "req_def456",
    "timestamp": "2024-01-15T10:30:00Z"
  }
}

// 429 Rate Limit Error
{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded for this endpoint",
    "details": {
      "limit": 100,
      "window": "1 minute",
      "retry_after": 45
    },
    "request_id": "req_ghi789",
    "timestamp": "2024-01-15T10:30:00Z"
  }
}

// 500 Server Error (sanitized for client)
{
  "error": {
    "code": "SERVER_INTERNAL_ERROR",
    "message": "An unexpected error occurred. Please try again later.",
    "details": {},
    "request_id": "req_jkl012",
    "timestamp": "2024-01-15T10:30:00Z"
  }
}
```

#### 4.4.3.3 Retry Mechanisms

**Exponential Backoff Strategy**:
```
Purpose: Retry transient failures without overwhelming the system

Algorithm:
Attempt 1: Immediate (0s delay)
Attempt 2: 1s delay (2^0)
Attempt 3: 2s delay (2^1)
Attempt 4: 4s delay (2^2)
Attempt 5: 8s delay (2^3)
Max Attempts: 5
Max Delay: 16s

Implementation (Python):
import time
import random

def retry_with_backoff(func, max_retries=5, base_delay=1):
    for attempt in range(max_retries):
        try:
            return func()
        except RetryableException as e:
            if attempt == max_retries - 1:
                raise  # Final attempt failed
            delay = base_delay * (2 ** attempt)
            jitter = random.uniform(0, 0.1 * delay)  # Add jitter
            time.sleep(delay + jitter)
```

**Retry Decision Matrix**:

| Error Type | Retry? | Max Retries | Strategy | Client Action |
|------------|--------|-------------|----------|---------------|
| Network Timeout | Yes | 3 | Exponential backoff | Auto-retry or user prompt |
| Database Connection Lost | Yes | 3 | Exponential backoff | Return 503, client retries |
| Rate Limit (429) | Yes | 1 | Wait for Retry-After | Client waits, then retries |
| Server Error (500) | Maybe | 2 | Exponential backoff | User prompted to retry |
| Auth Error (401) | No | 0 | N/A | Redirect to login |
| Validation Error (400) | No | 0 | N/A | Display errors, user fixes |
| Not Found (404) | No | 0 | N/A | Display "not found" message |
| External Service Timeout | Yes | 2 | Exponential backoff | Fallback to cache or error |

**Idempotency for Safe Retries**:
```
Problem: Retrying write operations may cause duplicates (e.g., double-charge)

Solution: Idempotency Keys
1. Client generates unique idempotency key (UUID) for each request
2. Client includes key in header: Idempotency-Key: {uuid}
3. Server checks if request with this key was already processed
4. If yes: Return cached result of original request (no duplicate operation)
5. If no: Process request, cache result with idempotency key for 24 hours

Implementation:
@app.route('/api/v1/transactions', methods=['POST'])
@jwt_required()
def create_transaction():
    idempotency_key = request.headers.get('Idempotency-Key')
    if idempotency_key:
        cached_result = redis.get(f"idempotent:{idempotency_key}")
        if cached_result:
            return json.loads(cached_result), 200  # Return cached result
    
    # Process transaction
    result = process_transaction(request.json)
    
    # Cache result for 24 hours
    if idempotency_key:
        redis.setex(f"idempotent:{idempotency_key}", 86400, json.dumps(result))
    
    return result, 201
```

#### 4.4.3.4 Circuit Breaker Pattern

**Circuit Breaker States**:
```mermaid
stateDiagram-v2
    [*] --> Closed: Initial State
    
    Closed --> Open: Error Threshold Exceeded<br/>(e.g., 50% errors in 1 min)
    Closed --> Closed: Requests Succeed<br/>(Normal Operation)
    
    Open --> HalfOpen: Timeout Expires<br/>(e.g., after 30 seconds)
    Open --> Open: Requests Fail Fast<br/>(No Backend Calls)
    
    HalfOpen --> Closed: Test Requests Succeed<br/>(Recovery Confirmed)
    HalfOpen --> Open: Test Requests Fail<br/>(Still Unhealthy)
    
    note right of Closed
        State: CLOSED
        - Allow all requests
        - Monitor error rate
        - Count consecutive failures
    end note
    
    note right of Open
        State: OPEN
        - Reject requests immediately
        - Return fallback or error
        - Wait for timeout
    end note
    
    note right of HalfOpen
        State: HALF-OPEN
        - Allow limited test requests
        - Monitor success rate
        - Transition to Closed or Open
    end note
```

**Circuit Breaker Implementation Pattern**:
```
Purpose: Prevent cascading failures when external service (DB, API) is unhealthy

Configuration:
- Error Threshold: 50% of requests failing within 1-minute window
- Request Threshold: At least 20 requests in window before tripping
- Open Timeout: 30 seconds (how long to stay open before testing)
- Half-Open Requests: 3 test requests to determine recovery

Behavior:
1. Closed State (Normal):
   - All requests are allowed
   - Monitor error rate
   - If error threshold exceeded → Open

2. Open State (Failing Fast):
   - All requests are rejected immediately (no backend call)
   - Return cached response or default error
   - After timeout → Half-Open

3. Half-Open State (Testing Recovery):
   - Allow limited test requests (e.g., 3 requests)
   - If all succeed → Closed (recovered)
   - If any fail → Open (still unhealthy, extended timeout)

Benefits:
- Prevents overwhelming failing service (gives it time to recover)
- Fast failure (no waiting for timeouts in Open state)
- Automatic recovery detection (Half-Open state)
```

**Example Circuit Breaker for Database**:
```
Scenario: MongoDB connection becomes unstable

Without Circuit Breaker:
- Every API request attempts database connection
- Each request waits for connection timeout (e.g., 5 seconds)
- All requests fail after 5 seconds
- System is unresponsive
- Database is overwhelmed with connection attempts

With Circuit Breaker:
1. First 20 requests fail within 1 minute (50% error rate)
2. Circuit breaker trips to Open state
3. Next requests are rejected immediately (no DB call)
4. Clients receive 503 errors with cached data (if available)
5. After 30 seconds, circuit breaker enters Half-Open
6. 3 test requests are sent to database
7. If database recovered: Circuit closes, normal operation resumes
8. If still failing: Circuit reopens, wait another 30 seconds (exponential backoff)

Result:
- System remains responsive (fast failures)
- Database has time to recover (no more connection attempts)
- Automatic recovery when database is healthy again
```

## 4.5 AI/ML Processing Workflows (Planned)

### 4.5.1 Simple LLM Completion Flow

The planned simple LLM completion workflow handles straightforward text generation requests without conversation history or additional context retrieval.

#### 4.5.1.1 Simple Completion Flow Diagram

```mermaid
sequenceDiagram
    participant User
    participant Client
    participant API as Flask API
    participant Lang as LangChain<br/>Service
    participant OpenAI as OpenAI API<br/>(Optional)
    participant Cache as Redis<br/>Cache
    participant DB as MongoDB

    User->>Client: Submit Text Generation Request<br/>(e.g., "Summarize this text...")
    Client->>API: POST /api/v1/ai/completions<br/>Authorization: Bearer {JWT}<br/>Body: {prompt, model, max_tokens}
    
    API->>API: Validate JWT<br/>Check Permissions<br/>(require: ai:completions)
    API->>API: Validate Input<br/>(prompt length, model valid)
    API->>API: Check Rate Limit<br/>(AI requests: 10/min)
    
    alt Rate Limit Exceeded
        API->>Client: 429 Too Many Requests<br/>Retry-After: 60
    else Proceed
        API->>API: Generate Cache Key<br/>(model:prompt_hash)
        API->>Cache: Check for Cached Response<br/>GET cache_key
        
        alt Cache Hit (Common Prompt)
            Cache->>API: Return Cached Completion
            API->>DB: Log Cache Hit Event<br/>(for analytics)
            API->>Client: 200 OK<br/>{completion, cached: true}
        else Cache Miss
            API->>Lang: Invoke LangChain<br/>{prompt, model, params}
            
            Lang->>Lang: Load Prompt Template<br/>(if configured)
            Lang->>Lang: Format Prompt<br/>Apply Template Variables
            Lang->>Lang: Validate Prompt Length<br/>Check Token Count
            
            alt Prompt Too Long
                Lang->>API: Error: Prompt exceeds token limit
                API->>Client: 400 Bad Request<br/>Prompt too long
            else Prompt Valid
                Lang->>OpenAI: LLM API Call<br/>POST /v1/completions<br/>{model, prompt, max_tokens, temperature}
                
                OpenAI->>OpenAI: Process Request<br/>Generate Completion
                
                alt OpenAI Error
                    OpenAI->>Lang: Error Response<br/>(Rate limit, API error)
                    Lang->>API: Propagate Error
                    API->>Client: 503 Service Unavailable<br/>AI service temporarily unavailable
                else OpenAI Success
                    OpenAI->>Lang: Completion Response<br/>{text, tokens_used, model}
                    Lang->>Lang: Post-Process Response<br/>(trim, format)
                    Lang->>API: Return Completion<br/>{completion, metadata}
                    
                    API->>Cache: Store Completion<br/>SETEX cache_key 3600 response
                    API->>DB: Log AI Interaction<br/>(user, prompt, response, tokens, cost)
                    API->>DB: Update Usage Metrics<br/>(total tokens, API calls)
                    
                    API->>Client: 200 OK<br/>{completion, cached: false, tokens_used}
                end
            end
        end
    end
    
    Client->>User: Display AI Response
```

#### 4.5.1.2 Simple Completion Process Steps

**Stage 1: Request Validation and Rate Limiting**

```
Step 1: Authentication and Authorization
- Validate JWT token
- Check permission: ai:completions or equivalent
- Rate limit: 10 AI requests per minute per user (strict limit due to cost)

Step 2: Input Validation (Pydantic Schema)
- Required Fields:
  * prompt: string (1-4000 characters)
  * model: enum ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"] (if OpenAI)
- Optional Fields:
  * max_tokens: integer (default: 500, max: 2000)
  * temperature: float (0.0-2.0, default: 0.7)
  * top_p: float (0.0-1.0, default: 1.0)
  * stop_sequences: list of strings

Step 3: Cost Estimation (Optional)
- Calculate estimated tokens: prompt_tokens + max_tokens
- Check user quota: Ensure user has sufficient AI credits/quota
- If quota exceeded: Return 402 Payment Required or quota error
```

**Stage 2: Cache Check**

```
Step 1: Generate Cache Key
- Hash prompt (MD5 or SHA-256)
- Include model and key parameters (temperature, top_p)
- Format: ai:completion:{model}:{param_hash}:{prompt_hash}
- Purpose: Cache identical prompts with same parameters

Step 2: Redis Lookup
- GET cache_key
- TTL: 1 hour for completions (balance freshness and cost savings)

Step 3: Cache Hit Handling
- If found: Return cached response immediately
- Add metadata: {cached: true, cache_age: seconds}
- Log cache hit for analytics
- Skip LLM API call (cost savings)
```

**Stage 3: LangChain Processing**

```
Step 1: Prompt Template Application (if configured)
- Load prompt template from configuration or database
- Template example: "You are a helpful assistant. {prompt}"
- Substitute variables: User prompt, system instructions
- Benefit: Consistent prompt engineering across app

Step 2: Token Count Validation
- Count tokens using tiktoken (OpenAI tokenizer)
- Ensure: prompt_tokens + max_tokens <= model_limit
  * GPT-3.5-turbo: 4,096 tokens
  * GPT-4: 8,192 tokens
  * GPT-4-turbo: 128,000 tokens
- If exceeded: Return error or truncate prompt (with warning)

Step 3: LangChain LLM Invocation
- Initialize LLM wrapper: ChatOpenAI(model=model, temperature=temperature)
- Call LLM: llm.predict(prompt)
- LangChain handles: API call, error handling, retries
```

**Stage 4: OpenAI API Interaction**

```
Step 1: API Request
- Endpoint: https://api.openai.com/v1/chat/completions
- Headers:
  * Authorization: Bearer {OPENAI_API_KEY}
  * Content-Type: application/json
- Body:
  {
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "{prompt}"}],
    "max_tokens": 500,
    "temperature": 0.7
  }

Step 2: Response Handling
- Success Response:
  {
    "id": "chatcmpl-123",
    "object": "chat.completion",
    "created": 1677652288,
    "model": "gpt-3.5-turbo-0613",
    "choices": [{
      "index": 0,
      "message": {"role": "assistant", "content": "{completion_text}"},
      "finish_reason": "stop"
    }],
    "usage": {
      "prompt_tokens": 56,
      "completion_tokens": 120,
      "total_tokens": 176
    }
  }

Step 3: Extract Completion
- Text: choices[0].message.content
- Tokens Used: usage.total_tokens
- Finish Reason: "stop" (complete), "length" (truncated), "content_filter" (filtered)
```

**Stage 5: Response Caching and Logging**

```
Step 1: Cache Storage
- Store in Redis: SETEX cache_key 3600 response_json
- TTL: 1 hour (balance freshness and cost savings)
- Serialization: JSON format with metadata

Step 2: Database Logging
- Collection: ai_interactions
- Document Structure:
  {
    "user_id": "auth0|123456",
    "request_type": "completion",
    "model": "gpt-3.5-turbo",
    "prompt": "{user_prompt}",  // May be truncated for storage
    "response": "{completion_text}",  // May be truncated
    "tokens": {
      "prompt": 56,
      "completion": 120,
      "total": 176
    },
    "cost_usd": 0.000352,  // Calculated based on model pricing
    "cached": false,
    "timestamp": "2024-01-15T10:30:00Z",
    "duration_ms": 1250
  }

Step 3: Update Usage Metrics
- Increment user's AI usage counters
- Track total tokens consumed (for billing/quotas)
- Update cost tracking (for internal analytics)
```

**Stage 6: Client Response**

```
Response Format:
{
  "completion": "The AI-generated text response...",
  "metadata": {
    "model": "gpt-3.5-turbo",
    "tokens_used": 176,
    "finish_reason": "stop",
    "cached": false,
    "processing_time_ms": 1250
  }
}

Error Responses:
- 400: Invalid prompt or parameters
- 401: Authentication failed
- 403: Permission denied or quota exceeded
- 429: Rate limit exceeded
- 503: OpenAI API unavailable
```

### 4.5.2 Conversational AI Workflow

The planned conversational AI workflow maintains conversation history and context across multiple turns, enabling coherent multi-turn dialogues.

#### 4.5.2.1 Conversational AI Flow Diagram

```mermaid
sequenceDiagram
    participant User
    participant Client
    participant API as Flask API
    participant Lang as LangChain<br/>Service
    participant Memory as Conversation<br/>Memory (MongoDB)
    participant OpenAI as OpenAI API
    participant Cache as Redis

    Note over User,Cache: New Conversation Start
    
    User->>Client: Start New Conversation<br/>"Hello, I need help with..."
    Client->>API: POST /api/v1/ai/conversations<br/>{message, conversation_id: null}
    
    API->>API: Validate JWT<br/>Check ai:chat permission
    API->>DB: Create Conversation<br/>{user_id, conversation_id, created_at}
    DB->>API: Conversation Created<br/>conversation_id: conv_abc123
    
    API->>Lang: Process Message<br/>{message, conversation_id, user_id}
    Lang->>Memory: Load Conversation History<br/>(Empty for new conversation)
    Lang->>Lang: Build Messages Array<br/>[{role: user, content: message}]
    
    Lang->>OpenAI: Chat Completion Request<br/>{messages, model: gpt-4}
    OpenAI->>Lang: Assistant Response
    
    Lang->>Memory: Store Message Pair<br/>(User message + Assistant response)
    Memory->>DB: Insert Messages<br/>{conversation_id, messages[]}
    
    Lang->>API: Return Response<br/>{response, conversation_id}
    API->>Client: 201 Created<br/>{response, conversation_id: conv_abc123}
    Client->>User: Display Response
    
    Note over User,Cache: Conversation Continue
    
    User->>Client: Follow-up Message<br/>"Can you elaborate on..."
    Client->>API: POST /api/v1/ai/conversations<br/>{message, conversation_id: conv_abc123}
    
    API->>Lang: Process Message<br/>{message, conversation_id: conv_abc123}
    Lang->>Memory: Load Conversation History<br/>conversation_id: conv_abc123
    
    Memory->>DB: Query Messages<br/>find({conversation_id, limit: 10, sort: -created_at})
    DB->>Memory: Return Last 10 Messages<br/>[msg1, msg2, ..., msg10]
    
    Lang->>Lang: Build Context<br/>Messages: [system, history..., new_user_msg]
    Lang->>Lang: Token Count Check<br/>Ensure within context window
    
    alt Context Too Long
        Lang->>Lang: Summarize Old Messages<br/>Compress conversation history
        Lang->>Memory: Store Summary<br/>Update conversation metadata
    end
    
    Lang->>OpenAI: Chat Completion Request<br/>{messages: full_context}
    OpenAI->>Lang: Contextual Response
    
    Lang->>Memory: Append New Messages<br/>(User message + Assistant response)
    Memory->>DB: Insert Messages<br/>{conversation_id, messages[]}
    
    Lang->>API: Return Response<br/>{response, conversation_id}
    API->>Client: 200 OK<br/>{response, conversation_id: conv_abc123}
    Client->>User: Display Contextual Response
```

#### 4.5.2.2 Conversation Memory Management

**Conversation Data Model (MongoDB)**:
```
Collection: conversations

Document Structure:
{
  "_id": "conv_abc123",
  "user_id": "auth0|123456",
  "title": "Help with project planning",  // Auto-generated or user-set
  "created_at": "2024-01-15T10:00:00Z",
  "updated_at": "2024-01-15T10:30:00Z",
  "status": "active",  // active, archived, deleted
  "metadata": {
    "total_messages": 15,
    "total_tokens": 2500,
    "model": "gpt-4",
    "summary": "User asked about project planning best practices..."
  }
}

Collection: messages

Document Structure:
{
  "_id": "msg_xyz789",
  "conversation_id": "conv_abc123",
  "role": "user",  // user, assistant, system
  "content": "Can you help me plan a software project?",
  "tokens": 45,
  "created_at": "2024-01-15T10:00:05Z",
  "metadata": {
    "client_timestamp": "2024-01-15T10:00:04Z",
    "edited": false
  }
}
```

**Conversation History Loading Strategy**:
```
Step 1: Determine Context Window
- GPT-3.5-turbo: 4,096 tokens (limited history)
- GPT-4: 8,192 tokens (moderate history)
- GPT-4-turbo: 128,000 tokens (extensive history)

Step 2: Load Recent Messages
- Query: Last N messages from conversation (e.g., N=20 for GPT-4)
- Sort: Chronological order (oldest first)
- Purpose: Provide LLM with conversation context

Step 3: Token Budget Calculation
- Reserve tokens for system prompt: 100-500 tokens
- Reserve tokens for user's new message: Actual token count
- Reserve tokens for completion: max_tokens (e.g., 500)
- Available for history: context_window - reserved_tokens

Step 4: Fit History into Budget
- Calculate tokens for each historical message
- Include messages from newest to oldest until budget exhausted
- Truncate oldest messages if necessary
- Alternative: Summarize old messages to save tokens
```

**Context Window Management Strategies**:

**Strategy 1: Sliding Window** (Simple)
```
Approach: Keep only last N messages

Advantages:
- Simple to implement
- Predictable token usage
- No additional processing

Disadvantages:
- Loses long-term context
- May forget important early information

Implementation:
messages = db.messages.find(
    {"conversation_id": conv_id},
    sort=[("created_at", -1)],
    limit=20
).reverse()  # Chronological order
```

**Strategy 2: Summarization** (Advanced)
```
Approach: Summarize old messages, keep recent messages verbatim

Steps:
1. Divide conversation into chunks (e.g., every 10 messages)
2. Summarize older chunks with LLM
3. Store summaries in conversation metadata
4. Build context: [summary1, summary2, recent_messages]

Advantages:
- Maintains long-term context
- Efficient token usage
- Retains key information

Disadvantages:
- Additional LLM calls for summarization (cost)
- Potential information loss in summaries

Implementation:
if total_messages > 30:
    old_messages = messages[0:20]  # Messages 1-20
    recent_messages = messages[20:]  # Messages 21+
    
    # Summarize old messages (if not already summarized)
    if not conversation.metadata.get('summary'):
        summary = llm.summarize(old_messages)
        conversation.metadata['summary'] = summary
    
    context = [
        {"role": "system", "content": f"Previous context: {summary}"},
        *[{"role": msg.role, "content": msg.content} for msg in recent_messages]
    ]
```

**Strategy 3: Semantic Compression** (Experimental)
```
Approach: Use embeddings to identify and keep most relevant messages

Steps:
1. Convert all messages to embeddings (vector representations)
2. Calculate similarity between new user message and historical messages
3. Select top-k most relevant historical messages
4. Include recent messages + relevant historical messages

Advantages:
- Maintains relevant context even from early conversation
- Efficient use of context window

Disadvantages:
- Complex implementation
- Requires vector similarity computation
- May break conversation flow (non-sequential messages)
```

### 4.5.3 RAG-Based Semantic Search Workflow

The planned Retrieval-Augmented Generation (RAG) workflow enhances LLM responses by retrieving relevant information from a knowledge base before generating answers.

#### 4.5.3.1 RAG Workflow Diagram

```mermaid
flowchart TD
    Start([User Submits Query]) --> ClientReq[Client: POST /api/v1/ai/search<br/>query: What is the return policy?]
    ClientReq --> APIReceive[API: Receive Request<br/>Validate JWT & Permissions]
    
    APIReceive --> LangChainProc[LangChain: Process Query]
    LangChainProc --> CreateEmbed[Create Query Embedding<br/>OpenAI Embeddings API<br/>model: text-embedding-ada-002]
    
    CreateEmbed --> VectorSearch[Search Vector Store<br/>MongoDB Atlas Vector Search or Dedicated Vector DB]
    VectorSearch --> SearchQuery[Execute Similarity Search<br/>K-Nearest Neighbors K=5]
    
    SearchQuery --> RetrieveDocs[Retrieve Top-K Documents<br/>with Similarity Scores]
    RetrieveDocs --> FilterDocs{Filter by<br/>Threshold?}
    
    FilterDocs -->|Score < 0.7| NoRelevant[No Relevant Documents<br/>Return fallback response]
    FilterDocs -->|Score >= 0.7| RelevantDocs[Relevant Documents Found]
    
    RelevantDocs --> ExtractChunks[Extract Document Chunks<br/>Title, Content, Metadata]
    ExtractChunks --> BuildContext[Build Augmented Context<br/>Combine retrieved docs]
    
    BuildContext --> ConstructPrompt[Construct RAG Prompt:<br/>Context: docs<br/>Question: query<br/>Instructions: Answer based on context]
    
    ConstructPrompt --> TokenCheck{Context<br/>Token Count OK?}
    TokenCheck -->|Too Many| TruncateContext[Truncate Context<br/>Keep top-3 docs]
    TokenCheck -->|OK| CallLLM[Call LLM with Augmented Prompt]
    TruncateContext --> CallLLM
    
    CallLLM --> LLMGen[LLM: Generate Answer<br/>based on provided context]
    LLMGen --> ExtractAnswer[Extract Answer<br/>and Citations]
    
    ExtractAnswer --> FormatResponse["Format Response:<br/>answer: text<br/>sources: [doc_ids]"]
    
    NoRelevant --> FallbackResponse[Return: Unable to find<br/>relevant information]
    
    FormatResponse --> LogInteraction[Log RAG Interaction<br/>query, docs_used, response]
    FallbackResponse --> LogInteraction
    
    LogInteraction --> ReturnClient[Return to Client<br/>200 OK with answer & sources]
    ReturnClient --> DisplayUser[Client: Display Answer<br/>with Source Links]
    
    DisplayUser --> End([End])
    
    style CreateEmbed fill:#e1f5ff
    style VectorSearch fill:#e1f5ff
    style CallLLM fill:#c8e6c9
    style NoRelevant fill:#fff9c4
```

#### 4.5.3.2 RAG Process Stages

**Stage 1: Query Embedding Generation**

```
Purpose: Convert user query to vector representation for similarity search

Step 1: Receive User Query
- Input: Natural language question (e.g., "What is your return policy?")
- Validation: Check query length (1-500 words)

Step 2: Generate Query Embedding
- API: OpenAI Embeddings API
- Model: text-embedding-ada-002 (1536 dimensions)
- Endpoint: POST https://api.openai.com/v1/embeddings
- Request Body:
  {
    "model": "text-embedding-ada-002",
    "input": "What is your return policy?"
  }
- Response:
  {
    "data": [{
      "embedding": [0.002, -0.015, 0.032, ...],  // 1536 floats
      "index": 0
    }],
    "model": "text-embedding-ada-002",
    "usage": {"prompt_tokens": 7, "total_tokens": 7}
  }

Step 3: Extract Embedding Vector
- Vector: embedding_vector = response['data'][0]['embedding']
- Dimensions: 1536 floats (normalized vector)
- Purpose: Use for similarity comparison with document embeddings
```

**Stage 2: Vector Similarity Search**

**Option A: MongoDB Atlas Vector Search**

```
Setup:
1. Create Vector Search Index on documents collection
   {
     "name": "vector_index",
     "type": "vectorSearch",
     "definition": {
       "fields": [{
         "type": "vector",
         "path": "embedding",
         "numDimensions": 1536,
         "similarity": "cosine"
       }]
     }
   }

2. Document Structure in MongoDB:
   {
     "_id": "doc_123",
     "title": "Return Policy",
     "content": "Our return policy allows...",
     "embedding": [0.001, -0.012, 0.025, ...],  // 1536 dimensions
     "metadata": {
       "category": "policy",
       "last_updated": "2024-01-01",
       "url": "/policies/returns"
     }
   }

Query Execution:
pipeline = [
  {
    "$vectorSearch": {
      "index": "vector_index",
      "path": "embedding",
      "queryVector": query_embedding,  // User query embedding
      "numCandidates": 50,  // Number of candidates to consider
      "limit": 5,  // Top-K results to return
      "similarityThreshold": 0.7  // Minimum similarity score
    }
  },
  {
    "$project": {
      "title": 1,
      "content": 1,
      "metadata": 1,
      "score": {"$meta": "vectorSearchScore"}
    }
  }
]

results = db.documents.aggregate(pipeline)

Result Example:
[
  {
    "title": "Return Policy",
    "content": "Our return policy allows customers to return items within 30 days...",
    "metadata": {"category": "policy", "url": "/policies/returns"},
    "score": 0.92  // Cosine similarity score (0-1, higher is better)
  },
  {
    "title": "Refund Process",
    "content": "Refunds are processed within 5-7 business days...",
    "metadata": {"category": "policy", "url": "/policies/refunds"},
    "score": 0.85
  },
  ...
]
```

**Option B: Dedicated Vector Database (Pinecone, Weaviate, Qdrant)**

```
Example with Pinecone:

1. Initialize Pinecone Client:
   import pinecone
   pinecone.init(api_key=PINECONE_API_KEY, environment="us-west1-gcp")
   index = pinecone.Index("documents-index")

2. Query Vector Index:
   results = index.query(
     vector=query_embedding,  // 1536-dim vector
     top_k=5,
     include_metadata=True,
     filter={"category": "policy"}  // Optional metadata filter
   )

3. Result Format:
   {
     "matches": [
       {
         "id": "doc_123",
         "score": 0.92,
         "metadata": {
           "title": "Return Policy",
           "content": "Our return policy allows...",
           "url": "/policies/returns"
         }
       },
       ...
     ]
   }
```

**Stage 3: Context Augmentation**

# 5. System Architecture

**Architecture Status Notice**: The following describes the **planned system architecture** for the CheckSameRepoNoPrompt project, which is currently in pre-implementation phase. The repository contains only foundational documentation (`README.md`), with no source code or infrastructure implementations present. All architectural details documented in this section represent the intended design based on technical specifications and will serve as the blueprint for future development.

## 5.1 High-Level Architecture

### 5.1.1 System Overview

#### 5.1.1.1 Architecture Style and Rationale

The CheckSameRepoNoPrompt system is designed as a **cloud-native, microservices-oriented architecture** with multi-platform client applications. The architecture adopts a modern three-tier pattern that emphasizes scalability, maintainability, and platform flexibility:

**Architectural Pattern - Three-Tier Separation**:

1. **Presentation Layer**: Multi-platform client applications providing user interfaces across Web, Mobile (iOS Native, Android Native, React Native), and Desktop (Electron, macOS Native) platforms
2. **Application Layer**: RESTful API backend built with Flask 3.0+ and Python 3.11+, integrated with LangChain 0.1.0+ for AI/ML capabilities
3. **Data Layer**: NoSQL document database (MongoDB 7.0+), in-memory caching (Redis 7+), object storage (Amazon S3), and vector database for semantic search

**Core Architectural Style**: The system follows a **cloud-native, API-first approach** where all client applications consume a unified RESTful API, enabling consistent business logic enforcement and simplified maintenance. The backend API is designed as stateless microservices, facilitating horizontal scaling and resilience.

#### 5.1.1.2 Key Architectural Principles

The architecture is grounded in the following fundamental principles:

**1. Cloud-Native Design**
- Leverages AWS managed services (Amazon ECS Fargate, Application Load Balancer, S3, CloudWatch) to minimize operational overhead
- Containerized services using Docker 24+ enable consistent deployment across environments
- Infrastructure as Code (Terraform 1.6+) ensures reproducible, version-controlled infrastructure

**2. API-First Philosophy**
- Single RESTful API serves all client platforms, ensuring consistent business logic
- JSON-based request/response format with comprehensive OpenAPI documentation
- Versioned API endpoints (`/api/v1/`) support backward compatibility

**3. Stateless Service Architecture**
- Backend API maintains no session state, storing all session data in Redis or MongoDB
- Enables horizontal scaling without session affinity requirements
- JWT-based authentication eliminates server-side session management

**4. Managed Service Preference**
- Auth0 provides enterprise-grade authentication and authorization
- MongoDB Atlas offers managed database with automated backups and scaling
- AWS managed services reduce infrastructure management complexity

**5. Event-Driven Caching**
- Multi-layer caching strategy (Redis + CloudFront CDN) optimizes performance
- Cache invalidation triggered by data modification events maintains consistency
- Time-based expiration (TTL) handles stale data scenarios

**6. Security by Design**
- Authentication required at every layer with Auth0 OAuth 2.0/OIDC
- TLS encryption for all external communication
- Permission-Based Access Control (PBAC) enforces fine-grained authorization
- AWS Secrets Manager protects sensitive credentials

#### 5.1.1.3 System Boundaries and Major Interfaces

The system defines clear boundaries between internal components and external integrations:

**Internal System Boundary**:
- Client applications (Web, Mobile, Desktop)
- Flask REST API backend
- LangChain AI/ML service
- MongoDB database
- Redis cache
- Amazon S3 object storage
- AWS infrastructure (ECS, ALB, CloudWatch)

**External System Interfaces**:

| External System | Interface Type | Purpose | Protocol |
|----------------|----------------|---------|----------|
| Auth0 | Authentication Provider | User authentication, JWT issuance, MFA | HTTPS REST API, OIDC |
| OpenAI API | LLM Provider (Optional) | AI text generation, embeddings | HTTPS REST API |
| AWS Services | Cloud Infrastructure | Compute, storage, networking, monitoring | AWS SDK (Boto3) |
| MongoDB Atlas | Managed Database (Optional) | Database hosting, automated backups | MongoDB Wire Protocol |

**System Integration Points**:
- **Client-to-API**: HTTPS/REST with JWT authentication
- **API-to-Auth0**: OIDC token validation, JWKS retrieval
- **API-to-Database**: MongoDB driver (PyMongo) over TCP
- **API-to-Cache**: Redis protocol over TCP
- **API-to-Storage**: S3 API via Boto3 SDK
- **API-to-LLM**: HTTPS REST API calls through LangChain

```mermaid
graph TB
    subgraph "Client Layer"
        WebApp[Web Application<br/>React + TypeScript]
        MobileRN[Mobile Cross-Platform<br/>React Native]
        MobileIOS[iOS Native<br/>Swift]
        MobileAndroid[Android Native<br/>Kotlin]
        DesktopElectron[Desktop App<br/>Electron]
        DesktopMac[macOS Native<br/>Objective-C]
    end
    
    subgraph "External Services"
        Auth0[Auth0<br/>Authentication]
        OpenAI[OpenAI API<br/>LLM Provider]
    end
    
    subgraph "AWS Infrastructure"
        ALB[Application Load Balancer<br/>TLS Termination]
        
        subgraph "Application Layer"
            API[Flask REST API<br/>Python 3.11+]
            LangChain[LangChain Service<br/>AI/ML Orchestration]
        end
        
        subgraph "Data Layer"
            MongoDB[(MongoDB 7.0+<br/>Document Database)]
            Redis[(Redis 7+<br/>Cache)]
            S3[Amazon S3<br/>Object Storage]
            VectorDB[(Vector Database<br/>Embeddings)]
        end
        
        CloudWatch[CloudWatch<br/>Monitoring]
        ECS[ECS Fargate<br/>Container Orchestration]
    end
    
    WebApp -->|HTTPS + JWT| ALB
    MobileRN -->|HTTPS + JWT| ALB
    MobileIOS -->|HTTPS + JWT| ALB
    MobileAndroid -->|HTTPS + JWT| ALB
    DesktopElectron -->|HTTPS + JWT| ALB
    DesktopMac -->|HTTPS + JWT| ALB
    
    WebApp -.->|OAuth 2.0| Auth0
    MobileRN -.->|OAuth 2.0| Auth0
    MobileIOS -.->|OAuth 2.0| Auth0
    MobileAndroid -.->|OAuth 2.0| Auth0
    DesktopElectron -.->|OAuth 2.0| Auth0
    DesktopMac -.->|OAuth 2.0| Auth0
    
    ALB -->|Load Balanced| API
    API -->|JWT Validation| Auth0
    API -->|Query/Write| MongoDB
    API -->|Cache Operations| Redis
    API -->|File Operations| S3
    API -->|AI Requests| LangChain
    
    LangChain -->|LLM Calls| OpenAI
    LangChain -->|Memory Storage| MongoDB
    LangChain -->|Vector Search| VectorDB
    
    ECS -.->|Manages| API
    ECS -.->|Manages| LangChain
    API -.->|Logs/Metrics| CloudWatch
```

### 5.1.2 Core Components

#### 5.1.2.1 Component Responsibilities and Dependencies

The following table summarizes the primary components, their responsibilities, key dependencies, and integration points:

| Component Name | Primary Responsibility | Key Dependencies | Integration Points |
|----------------|------------------------|------------------|-------------------|
| **Web Application** | Browser-based UI for all devices | React 18.2+, Auth0 React SDK | Auth0, Flask API via HTTPS |
| **Mobile Apps** | Native mobile experience (iOS/Android) | React Native 0.72+, Native SDKs | Auth0, Flask API via HTTPS |
| **Desktop Apps** | Cross-platform desktop interface | Electron 28+, React | Auth0, Flask API via HTTPS |
| **Flask REST API** | Core business logic and orchestration | MongoDB, Redis, Auth0, AWS SDK | All clients, Auth0, databases |

| Component Name | Primary Responsibility | Key Dependencies | Integration Points |
|----------------|------------------------|------------------|-------------------|
| **LangChain Service** | AI/ML workflow orchestration | LangChain 0.1.0+, OpenAI SDK | Flask API, OpenAI, Vector DB |
| **Auth0** | Identity and access management | OAuth 2.0/OIDC standards | All clients, Flask API |
| **MongoDB** | Primary data persistence | MongoDB 7.0+ | Flask API, LangChain |
| **Redis Cache** | Performance optimization, rate limiting | Redis 7+ | Flask API |

| Component Name | Primary Responsibility | Key Dependencies | Integration Points |
|----------------|------------------------|------------------|-------------------|
| **Amazon S3** | Object storage for files and assets | AWS SDK (Boto3) | Flask API, CloudFront |
| **Application Load Balancer** | Traffic routing, TLS termination | AWS Certificate Manager | Clients, ECS tasks |
| **ECS Fargate** | Serverless container orchestration | Docker 24+, ECR | Flask API, LangChain |
| **CloudWatch** | Monitoring, logging, alerting | AWS CloudWatch SDK | All backend components |

#### 5.1.2.2 Critical Considerations

**Scalability Considerations**:
- **Horizontal Scaling**: Flask API and LangChain services scale via ECS auto-scaling based on CPU/memory metrics
- **Database Scaling**: MongoDB supports horizontal sharding for future data growth
- **Cache Scaling**: Redis can scale to Redis Cluster architecture if needed
- **CDN Scaling**: CloudFront automatically scales to handle global traffic

**Availability Considerations**:
- **High Availability**: ECS deploys services across multiple availability zones
- **Database Replication**: MongoDB 3-node replica set (Primary + 2 Secondaries) ensures failover
- **Load Balancer Health Checks**: ALB automatically routes traffic away from unhealthy instances
- **Graceful Degradation**: Cache fallback mechanisms maintain functionality during partial outages

**Security Considerations**:
- **Zero Trust Model**: Every request validated with JWT, no implicit trust
- **Secrets Management**: AWS Secrets Manager for credentials, no hardcoded secrets
- **Network Isolation**: VPC subnets isolate backend services from public internet
- **Encryption**: TLS 1.3 for data in transit, encryption at rest for S3 and databases

### 5.1.3 Data Flow Architecture

#### 5.1.3.1 Primary Data Flows

**Client-to-API Request Flow (Read Operations)**:

The standard data flow for read operations follows a carefully orchestrated path through multiple system layers:

1. **Authentication Phase**: Client application authenticates with Auth0 using OAuth 2.0 Authorization Code Flow with PKCE, receiving a JWT access token (15-minute lifetime) and refresh token (7-day lifetime)

2. **Request Initiation**: Client includes JWT in HTTP Authorization header (`Bearer {token}`) and sends HTTPS request to API endpoint

3. **Infrastructure Layer**: Request passes through Application Load Balancer, which performs TLS termination, health check validation, and load balancing across healthy ECS task instances

4. **JWT Validation**: Flask API validates JWT by:
   - Extracting JWT from Authorization header
   - Decoding header to identify signing key (kid)
   - Fetching Auth0 JWKS (public keys) - cached in Redis with 1-hour TTL
   - Verifying signature using RS256 algorithm
   - Validating claims: expiration (exp), issuer (iss), audience (aud)
   - Extracting user context: subject (sub = Auth0 user ID), permissions

5. **Rate Limiting**: API checks rate limits using Redis-backed counters, enforcing per-user quotas (e.g., 10 AI requests/minute)

6. **Request Validation**: API validates request payload using Pydantic schema validation to prevent injection attacks and ensure data integrity

7. **Authorization**: API checks permission-based access control, verifying JWT contains required permissions (e.g., `read:documents`)

8. **Cache Layer**: API generates cache key (`{namespace}:{endpoint}:{user_id}:{params_hash}`) and checks Redis cache first

9. **Database Query** (on cache miss): Query MongoDB using PyMongo driver, applying appropriate indexes

10. **Data Transformation**: Transform MongoDB documents to API response format (JSON serialization)

11. **Cache Population**: Store response in Redis with appropriate TTL (5 minutes for general responses, 1 hour for LLM responses)

12. **Response Delivery**: Return JSON response to client through ALB with appropriate HTTP status codes and headers

**Write Operation Data Flow**:

Write operations follow a similar authentication path but with additional steps for data integrity:

1. Follow authentication, rate limiting, validation, and authorization steps (steps 1-7 above)

2. **Write Operation Execution**: API executes INSERT, UPDATE, or DELETE operation in MongoDB with transaction support

3. **Cache Invalidation**: API invalidates related cache keys using pattern-based deletion (e.g., delete all keys matching `documents:{user_id}:*`)

4. **Audit Logging**: API logs operation details to CloudWatch Logs including user_id, operation type, affected resources, and timestamp

5. **Response Delivery**: Return success response (200 OK, 201 Created, 204 No Content) to client with operation details

```mermaid
sequenceDiagram
    participant Client
    participant Auth0
    participant ALB as Application Load Balancer
    participant API as Flask API
    participant Redis as Redis Cache
    participant MongoDB as MongoDB
    participant CloudWatch as CloudWatch Logs
    
    Note over Client,CloudWatch: Authentication Phase (First Time)
    Client->>Auth0: OAuth 2.0 Authorization Code Flow + PKCE
    Auth0->>Client: JWT Access Token (15 min) + Refresh Token (7 days)
    
    Note over Client,CloudWatch: Read Request Flow
    Client->>ALB: HTTPS GET /api/v1/documents<br/>Authorization: Bearer {JWT}
    ALB->>API: Forward request (TLS terminated)
    API->>Auth0: Validate JWT (fetch JWKS - cached)
    Auth0-->>API: JWT Valid + User Context
    API->>Redis: Check rate limit
    Redis-->>API: Rate limit OK
    API->>API: Validate request schema
    API->>API: Check permissions in JWT
    API->>Redis: GET cache key
    
    alt Cache Hit
        Redis-->>API: Cached response
        API->>Client: 200 OK + JSON response
    else Cache Miss
        Redis-->>API: Cache miss
        API->>MongoDB: Query documents
        MongoDB-->>API: Document results
        API->>Redis: SET cache key (TTL=5min)
        API->>CloudWatch: Log successful request
        API->>Client: 200 OK + JSON response
    end
    
    Note over Client,CloudWatch: Write Request Flow
    Client->>ALB: HTTPS POST /api/v1/documents<br/>Authorization: Bearer {JWT}
    ALB->>API: Forward request
    API->>Auth0: Validate JWT
    Auth0-->>API: JWT Valid + User Context
    API->>Redis: Check rate limit
    Redis-->>API: Rate limit OK
    API->>API: Validate payload schema
    API->>API: Check write permissions
    API->>MongoDB: INSERT document
    MongoDB-->>API: Insert success
    API->>Redis: DELETE pattern documents:{user_id}:*
    API->>CloudWatch: Log write operation
    API->>Client: 201 Created + JSON response
```

#### 5.1.3.2 AI/ML Processing Flow

AI and machine learning requests follow a specialized data flow optimized for LLM interactions:

**Simple Completion Flow**:
1. Client sends AI request to `/api/v1/ai/completions` with prompt and parameters
2. API validates AI-specific rate limits (10 requests/minute per user)
3. API checks Redis cache for identical prompt (1-hour TTL to reduce OpenAI costs)
4. On cache miss: LangChain orchestrates LLM call with prompt engineering
5. API calls OpenAI API (or alternative LLM provider) through LangChain abstraction
6. Response cached in Redis with prompt hash as key
7. API logs AI interaction to MongoDB: prompt, response, tokens used, cost, model
8. Return AI response to client with metadata (tokens_used, model, cost_estimate)

**Conversational AI Flow (Multi-Turn)**:
1. Client initiates conversation, API creates conversation record in MongoDB
2. Each message appended to conversation history in MongoDB `messages` collection
3. LangChain retrieves conversation context (last N messages within token window)
4. LangChain constructs prompt with conversation history as context
5. LLM generates response considering conversation history
6. Response appended to conversation history
7. Conversation memory pruned if token limit exceeded (keep recent messages)

**RAG (Retrieval-Augmented Generation) Flow**:
1. Client sends semantic search query to `/api/v1/ai/search`
2. API generates query embedding using OpenAI Embeddings API (text-embedding-ada-002)
3. API executes vector similarity search in Vector Database (MongoDB Atlas Vector Search or dedicated vector DB)
4. Top K relevant documents retrieved based on cosine similarity
5. LangChain constructs prompt with query + retrieved context documents
6. LLM generates response grounded in provided context
7. API returns response with source citations (document IDs, relevance scores)

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant Redis as Redis Cache
    participant LangChain
    participant MongoDB
    participant VectorDB as Vector Database
    participant OpenAI as OpenAI API
    
    Note over Client,OpenAI: RAG-Based Semantic Search Flow
    
    Client->>API: POST /api/v1/ai/search<br/>{"query": "user question"}
    API->>API: Validate JWT + Rate Limit (10/min)
    
    API->>Redis: Check cached RAG response
    Redis-->>API: Cache miss
    
    API->>LangChain: Semantic search request
    LangChain->>OpenAI: Generate query embedding
    OpenAI-->>LangChain: Embedding vector (1536 dims)
    
    LangChain->>VectorDB: Vector similarity search<br/>(top_k=5, cosine similarity)
    VectorDB-->>LangChain: Relevant documents + scores
    
    LangChain->>LangChain: Construct prompt:<br/>Query + Context Documents
    LangChain->>OpenAI: LLM completion with context
    OpenAI-->>LangChain: Generated response
    
    LangChain-->>API: Response + source citations
    
    API->>MongoDB: Log AI interaction:<br/>query, response, tokens, cost, sources
    API->>Redis: Cache response (TTL=1hr)
    
    API->>Client: 200 OK<br/>{"answer": "...", "sources": [...], "tokens_used": 500}
```

#### 5.1.3.3 File Upload Flow

File uploads utilize presigned S3 URLs to enable direct client-to-S3 uploads without proxying through the API:

1. **Presigned URL Request**: Client requests presigned S3 URL from API endpoint `/api/v1/files/upload-url`
2. **Authorization**: API validates JWT and checks file upload permissions
3. **URL Generation**: API generates presigned S3 PUT URL with 15-minute expiration using Boto3
4. **URL Response**: API returns presigned URL, file_id, and upload metadata to client
5. **Direct Upload**: Client uploads file directly to S3 using presigned URL (HTTPS PUT)
6. **Upload Notification**: Client notifies API of successful upload via `/api/v1/files/complete`
7. **Metadata Storage**: API stores file metadata in MongoDB (`files` collection): file_id, s3_key, user_id, filename, size, mime_type, created_at
8. **Response**: API returns file record to client

**Benefits of Presigned URL Pattern**:
- Reduces API bandwidth consumption (no file proxy)
- Improves upload performance (direct client-to-S3)
- Simplifies backend implementation
- Enables larger file uploads without API timeout concerns

#### 5.1.3.4 Integration Patterns and Protocols

The system employs standardized integration patterns for consistency and maintainability:

| Integration Type | Pattern | Protocol/Format | Example Use Case |
|-----------------|---------|-----------------|------------------|
| Client-to-API | RESTful Request/Response | HTTPS, JSON | All client application interactions |
| API-to-Database | Direct Driver Connection | MongoDB Wire Protocol | Data persistence operations |
| API-to-Cache | Cache-Aside | Redis Protocol | Performance optimization |
| API-to-Storage | Presigned URLs | HTTPS, S3 API | File upload/download operations |

| Integration Type | Pattern | Protocol/Format | Example Use Case |
|-----------------|---------|-----------------|------------------|
| API-to-Auth | Token Validation | HTTPS REST, OIDC | JWT signature verification |
| API-to-LLM | Request/Response | HTTPS REST, JSON | AI text generation |
| Monitoring | Event Streaming | CloudWatch API | Log aggregation, metrics |
| CI/CD | Pipeline Automation | GitHub Actions, AWS APIs | Automated deployments |

### 5.1.4 External Integration Points

#### 5.1.4.1 Third-Party Service Integration

The system integrates with external services to leverage specialized capabilities and reduce implementation complexity:

| System Name | Integration Type | Data Exchange Pattern | Protocol/Format |
|-------------|------------------|----------------------|-----------------|
| **Auth0** | Authentication Provider | JWT issuance, token validation | HTTPS REST, OAuth 2.0, OIDC |
| **OpenAI API** | LLM Provider (Optional) | Text completion, embeddings | HTTPS REST, JSON |
| **AWS ECS** | Container Orchestration | Task management, auto-scaling | AWS SDK (Boto3) |
| **AWS S3** | Object Storage | File upload/download | S3 API, Presigned URLs |

| System Name | Integration Type | Data Exchange Pattern | Protocol/Format |
|-------------|------------------|----------------------|-----------------|
| **MongoDB Atlas** | Managed Database (Optional) | Database queries, replication | MongoDB Wire Protocol, TLS |
| **Redis/ElastiCache** | Managed Cache (Optional) | Key-value operations | Redis Protocol |
| **CloudWatch** | Monitoring Service | Logs, metrics, alarms | CloudWatch API |
| **AWS Secrets Manager** | Secrets Storage | Credential retrieval | AWS SDK (Boto3) |

#### 5.1.4.2 Service Level Agreement Requirements

The architecture must accommodate SLAs from external providers:

**Auth0 SLAs** (Expected):
- Availability: 99.99% uptime
- Token Validation Latency: < 100ms p95
- Authentication Flow: < 2 seconds end-to-end

**AWS Service SLAs** (Standard):
- **ECS Fargate**: 99.99% availability
- **Application Load Balancer**: 99.99% availability
- **S3**: 99.99% availability, 99.999999999% durability
- **CloudWatch**: 99.9% availability

**OpenAI API SLAs** (Expected):
- Rate Limits: 3,500 requests/minute (tier-dependent)
- Response Time: < 5 seconds p95 for completions
- Availability: 99.9% uptime (no published SLA)

**MongoDB Atlas SLAs** (M10+ Clusters):
- Availability: 99.995% uptime
- Automatic Failover: < 10 seconds

**Dependency Risk Mitigation**:
- **Critical Dependencies**: Auth0, MongoDB - implement circuit breakers and graceful degradation
- **Optional Dependencies**: OpenAI - implement fallback mechanisms and error handling
- **Retry Strategies**: Exponential backoff with jitter for transient failures
- **Monitoring**: CloudWatch alarms for external service failures

---

## 5.2 Component Details

### 5.2.1 Client Layer Components

#### 5.2.1.1 Web Application (React + TypeScript)

**Purpose and Responsibilities**:
The web application serves as the primary browser-based user interface accessible across desktop and mobile devices. It provides a responsive, accessible interface for all system functionality.

**Technologies and Frameworks**:
- **Core Framework**: React 18.2+ with TypeScript 5.0+ for type-safe component development
- **Build Tool**: Vite 5.0+ for fast development builds and optimized production bundles
- **Styling**: TailwindCSS 3.4+ for utility-first, responsive design
- **State Management**: TanStack Query (React Query) for server state caching and synchronization
- **Routing**: React Router 6+ for client-side navigation and route protection
- **HTTP Client**: Axios for API communication with interceptors for authentication
- **Authentication SDK**: @auth0/auth0-react for OAuth 2.0 integration

**Key Interfaces and APIs**:

The web application interfaces with external systems through the following mechanisms:

- **Auth0 Integration**: Uses @auth0/auth0-react Auth0Provider wrapper with configured domain, client ID, and redirect URIs. Implements OAuth 2.0 Authorization Code Flow with PKCE for secure authentication
- **Flask API Integration**: Axios client configured with base URL, JWT token interceptors, and error handling. All API requests include Authorization header with Bearer token
- **Local Storage**: Securely stores non-sensitive application state (user preferences, UI settings) in browser localStorage. Sensitive tokens managed by Auth0 SDK in secure memory
- **CloudFront CDN**: Static assets served from CloudFront edge locations for optimized global delivery

**Data Persistence Requirements**:
- **LocalStorage**: Application preferences, theme settings, cached UI state (< 5MB total)
- **SessionStorage**: Temporary state during active session (cleared on tab close)
- **IndexedDB** (Future): Offline data caching for progressive web app features

**Scaling Considerations**:
- **CDN Distribution**: CloudFront automatically scales to handle traffic spikes globally
- **Static Asset Optimization**: Code splitting, lazy loading, and tree shaking reduce bundle size
- **Client-Side Caching**: TanStack Query caches API responses, reducing server load
- **Progressive Enhancement**: Core functionality works without JavaScript, enhanced with React

**Deployment Architecture**:
1. GitHub Actions builds production bundle (`npm run build`)
2. Static files (HTML, CSS, JS, images) uploaded to S3 bucket (`app-static-assets`)
3. CloudFront distribution configured with S3 as origin
4. Route 53 DNS points custom domain to CloudFront distribution
5. CloudFront invalidation triggered after deployment to clear old cache

#### 5.2.1.2 Mobile Applications (React Native + Native Code)

**Purpose and Responsibilities**:
Mobile applications provide native iOS and Android experiences, leveraging platform-specific features (biometric authentication, push notifications, camera) while sharing cross-platform UI code.

**Technologies and Frameworks**:

**Cross-Platform Layer** (React Native 0.72+):
- **UI Framework**: React Native for shared component library across iOS and Android
- **Navigation**: React Navigation 6+ for stack, tab, and drawer navigation patterns
- **State Management**: TanStack Query for API data, React Context for app state
- **HTTP Client**: Axios with React Native-specific configuration

**iOS Native Layer** (Swift 5.9+):
- **Purpose**: Platform-specific features requiring native implementation
- **Capabilities**: FaceID/TouchID, HealthKit integration, Handoff, Apple Pay
- **Bridge**: Swift modules exposed to React Native via Native Modules

**Android Native Layer** (Kotlin 1.9+):
- **Purpose**: Platform-specific features requiring native implementation
- **Capabilities**: Fingerprint authentication, Google Pay, Android-specific APIs
- **Bridge**: Kotlin modules exposed to React Native via Native Modules

**Key Interfaces and APIs**:
- **Auth0 Native SDKs**: Platform-specific authentication using ASWebAuthenticationSession (iOS) and Chrome Custom Tabs (Android) for secure OAuth flows
- **Biometric Authentication**: Face ID, Touch ID (iOS), Fingerprint (Android) for app unlock
- **Push Notifications**: Firebase Cloud Messaging for cross-platform notifications
- **Deep Linking**: Universal Links (iOS), App Links (Android) for external navigation

**Data Persistence Requirements**:
- **AsyncStorage**: Key-value storage for user preferences and lightweight data (< 6MB recommended)
- **Secure Storage**: Platform-specific secure storage for JWT tokens (iOS Keychain, Android Keystore)
- **SQLite** (Future): Local database for offline data synchronization
- **File System**: Local file caching for images and documents

**Scaling Considerations**:
- **App Store Distribution**: iOS App Store and Google Play Store handle global distribution
- **Client-Side Performance**: Optimize React Native bundle size, use Hermes JavaScript engine
- **API Request Optimization**: Batch requests, implement request deduplication
- **Offline Support** (Future): Queue operations when offline, sync when connection restored

#### 5.2.1.3 Desktop Application (Electron.js)

**Purpose and Responsibilities**:
The desktop application provides a cross-platform native application experience for Windows, macOS, and Linux, with deeper system integration than web browsers allow.

**Technologies and Frameworks**:
- **Core Framework**: Electron 28+ for cross-platform desktop application shell
- **Frontend**: React 18+ with TypeScript for renderer process UI
- **IPC**: Electron IPC (Inter-Process Communication) for main-renderer communication
- **Native Integrations**: Electron APIs for file system, notifications, menus, protocol handlers
- **Build Tools**: Electron Builder for platform-specific installers (DMG, EXE, AppImage)

**macOS Native Application** (Objective-C 2.0):
- **Purpose**: Native macOS application for users requiring pure native experience
- **Technologies**: AppKit, Cocoa frameworks, Swift/Objective-C interop
- **Features**: Native macOS UI, system integration, Handoff, iCloud sync

**Key Interfaces and APIs**:
- **Main Process**: Node.js environment with full system access (file system, networking, OS APIs)
- **Renderer Process**: Chromium-based web view running React application (sandboxed)
- **IPC Bridge**: Secure message passing between main and renderer processes
- **Auth0 Integration**: Adapted SPA flow with custom protocol handler for OAuth callbacks

**Data Persistence Requirements**:
- **electron-store**: Encrypted JSON storage for application settings and preferences
- **Native Storage**: Platform-specific secure storage (macOS Keychain, Windows Credential Manager)
- **Local Files**: User documents, cache, and temporary files in standard OS directories

**Scaling Considerations**:
- **Auto-Updates**: Electron auto-updater for seamless application updates
- **Memory Management**: Optimize Chromium memory usage for multiple windows
- **Distribution**: Direct download from website, alternative app stores (Microsoft Store, Snapcraft)

```mermaid
graph TB
    subgraph "Web Application Architecture"
        Browser[Browser]
        subgraph "React App"
            Auth0React["@auth0/auth0-react"]
            ReactRouter[React Router]
            TanStack[TanStack Query]
            AxiosWeb[Axios Client]
            Components[React Components]
        end
    end
    
    subgraph "Mobile Application Architecture"
        subgraph "React Native Layer"
            RNComponents[React Native Components]
            RNNav[React Navigation]
            RNQuery[TanStack Query]
            AxiosMobile[Axios Client]
        end
        
        subgraph "iOS Native Layer"
            SwiftModules[Swift Native Modules]
            Keychain[iOS Keychain]
            BiometricIOS["FaceID/TouchID"]
        end
        
        subgraph "Android Native Layer"
            KotlinModules[Kotlin Native Modules]
            Keystore[Android Keystore]
            BiometricAndroid[Fingerprint]
        end
    end
    
    subgraph "Desktop Application Architecture"
        subgraph "Electron Main Process"
            NodeRuntime[Node.js Runtime]
            FileSystem[File System Access]
            NativeAPIs[Native OS APIs]
        end
        
        subgraph "Electron Renderer Process"
            ChromiumEngine[Chromium Engine]
            ReactElectron[React UI]
            IPC[IPC Bridge]
        end
    end
    
    Browser --> Auth0React
    Browser --> ReactRouter
    ReactRouter --> Components
    Components --> TanStack
    TanStack --> AxiosWeb
    AxiosWeb -.->|HTTPS + JWT| API[Flask API]
    
    RNComponents --> RNNav
    RNComponents --> RNQuery
    RNQuery --> AxiosMobile
    AxiosMobile -.->|HTTPS + JWT| API
    
    RNComponents --> SwiftModules
    RNComponents --> KotlinModules
    SwiftModules --> Keychain
    SwiftModules --> BiometricIOS
    KotlinModules --> Keystore
    KotlinModules --> BiometricAndroid
    
    ChromiumEngine --> ReactElectron
    ReactElectron --> IPC
    IPC --> NodeRuntime
    NodeRuntime --> FileSystem
    NodeRuntime --> NativeAPIs
    ReactElectron -.->|HTTPS + JWT| API
```

### 5.2.2 Backend Layer Components

#### 5.2.2.1 Flask REST API (Core Backend Service)

**Purpose and Responsibilities**:
The Flask REST API serves as the central backend service responsible for business logic orchestration, data validation, authentication enforcement, and coordination between data storage, caching, and external services.

**Technologies and Frameworks**:
- **Web Framework**: Flask 3.0+ with Python 3.11+ for RESTful API development
- **WSGI Server**: Gunicorn with gevent workers for production deployment
- **Request Validation**: Pydantic 2.0+ for schema validation and data serialization
- **Database Driver**: PyMongo 4.6+ for MongoDB connectivity
- **Cache Client**: redis-py 5.0+ for Redis operations
- **AWS Integration**: Boto3 1.34+ for S3, Secrets Manager, and CloudWatch integration
- **Authentication**: python-jose for JWT validation, PyJWT for token operations
- **Rate Limiting**: Flask-Limiter with Redis backend for API throttling

**Key Interfaces and APIs**:

**RESTful Endpoints** (Planned Structure):

| Endpoint Category | Example Endpoints | Purpose |
|------------------|------------------|---------|
| Authentication | `/api/v1/auth/refresh`, `/api/v1/auth/logout` | Token management |
| User Management | `/api/v1/users/me`, `/api/v1/users/{id}` | User profiles, preferences |
| Documents | `/api/v1/documents`, `/api/v1/documents/{id}` | Document CRUD operations |
| AI Features | `/api/v1/ai/completions`, `/api/v1/ai/conversations`, `/api/v1/ai/search` | AI/ML interactions |

| Endpoint Category | Example Endpoints | Purpose |
|------------------|------------------|---------|
| File Operations | `/api/v1/files/upload-url`, `/api/v1/files/{id}` | File management |
| System | `/api/version`, `/health` | System information, health checks |

**API Middleware Stack**:
1. **CORS Middleware**: Configures allowed origins, methods, and headers
2. **Request ID Middleware**: Generates UUID for request tracing
3. **JWT Validation Middleware**: Validates and decodes JWT for protected routes
4. **Rate Limiting Middleware**: Enforces per-user rate limits using Redis
5. **Request Logging Middleware**: Logs incoming requests with structured format
6. **Error Handling Middleware**: Catches exceptions and formats error responses

**Data Persistence Requirements**:
- **MongoDB Collections** (Primary Database):
  - `users`: User profiles supplementing Auth0 (auth0_id, preferences, created_at)
  - `conversations`: AI conversation metadata (user_id, title, created_at, updated_at)
  - `messages`: Conversation history (conversation_id, role, content, tokens, created_at)
  - `documents`: User-uploaded document metadata (user_id, s3_key, filename, size, created_at)
  - `ai_interactions`: AI usage logging (user_id, type, prompt, response, tokens, cost)
  - `analytics`: Application events and metrics (event_type, user_id, metadata, timestamp)

- **Redis Cache Keys** (In-Memory Cache):
  - `jwks:auth0`: Auth0 public keys (TTL: 1 hour)
  - `ratelimit:{user_id}:{endpoint}`: Rate limit counters (TTL: varies)
  - `cache:{endpoint}:{user_id}:{params_hash}`: API response cache (TTL: 5-60 minutes)
  - `session:{session_id}`: Optional session data (TTL: 15 minutes)

**Scaling Considerations**:
- **Horizontal Scaling**: Stateless design enables running multiple API instances behind ALB
- **Auto-Scaling Policy**: ECS scales based on CPU utilization (target: 70%) and memory usage
- **Connection Pooling**: MongoDB connection pool (50 connections/instance), Redis connection pool (20 connections/instance)
- **Async Operations**: Celery task queue (future) for long-running background jobs
- **Request Optimization**: Database query optimization with proper indexes, cache-aside pattern

**API Request Processing Architecture**:

```mermaid
sequenceDiagram
    participant Client
    participant ALB
    participant Middleware as API Middleware Stack
    participant Handler as Route Handler
    participant Cache as Redis Cache
    participant DB as MongoDB
    participant Auth0
    
    Client->>ALB: HTTPS Request
    ALB->>Middleware: Forward to API
    
    Note over Middleware: 1. CORS Check
    Middleware->>Middleware: Validate origin
    
    Note over Middleware: 2. Generate Request ID
    Middleware->>Middleware: UUID generation
    
    Note over Middleware: 3. JWT Validation
    Middleware->>Cache: Check cached JWKS
    alt JWKS cached
        Cache-->>Middleware: Return JWKS
    else JWKS not cached
        Middleware->>Auth0: Fetch JWKS
        Auth0-->>Middleware: Public keys
        Middleware->>Cache: Cache JWKS (1hr)
    end
    Middleware->>Middleware: Verify JWT signature
    
    Note over Middleware: 4. Rate Limiting
    Middleware->>Cache: Check rate limit
    Cache-->>Middleware: Rate limit status
    
    alt Rate limit exceeded
        Middleware-->>Client: 429 Too Many Requests
    else Rate limit OK
        Note over Middleware: 5. Request Logging
        Middleware->>Middleware: Log request
        
        Middleware->>Handler: Forward to handler
        
        Note over Handler: 6. Business Logic
        Handler->>Cache: Check response cache
        
        alt Cache hit
            Cache-->>Handler: Cached response
        else Cache miss
            Handler->>DB: Query database
            DB-->>Handler: Data results
            Handler->>Handler: Transform data
            Handler->>Cache: Store in cache
        end
        
        Handler-->>Middleware: Response
        Middleware-->>ALB: HTTP Response
        ALB-->>Client: Return to client
    end
```

#### 5.2.2.2 LangChain AI/ML Service

**Purpose and Responsibilities**:
The LangChain service orchestrates AI/ML workflows, managing LLM interactions, conversation memory, vector search, and prompt engineering. It abstracts the complexity of working with various LLM providers and enables sophisticated AI features.

**Technologies and Frameworks**:
- **Orchestration Framework**: LangChain 0.1.0+ for chain composition and LLM abstraction
- **LLM Integration**: OpenAI SDK (optional), Anthropic SDK (optional), or open-source alternatives
- **Embeddings**: OpenAI Embeddings API (text-embedding-ada-002) for vector generation
- **Vector Search**: Integration with MongoDB Atlas Vector Search or dedicated vector database
- **Memory Management**: LangChain conversation memory with MongoDB backend
- **Prompt Templates**: LangChain PromptTemplates for reusable, parameterized prompts

**Key Interfaces and APIs**:

**AI Capabilities**:

| Capability | LangChain Chain Type | Input | Output |
|------------|---------------------|-------|--------|
| Simple Completions | LLMChain | User prompt + parameters | Generated text |
| Conversational AI | ConversationChain | Message + conversation history | Response with context |
| RAG Search | RetrievalQA | Query + vector store | Answer with source citations |
| Document Q&A | QAChain | Document + question | Extracted answer |

**Integration with Flask API**:
- LangChain service exposed as Python module imported by Flask route handlers
- Synchronous function calls for simple completions (< 5 seconds)
- Asynchronous task queue (Celery) for long-running operations (future enhancement)

**Data Persistence Requirements**:
- **Conversation Memory**: Store conversation history in MongoDB `messages` collection
- **Vector Embeddings**: Store document embeddings in vector database (1536-dimensional vectors)
- **AI Interaction Logs**: Log all LLM API calls to MongoDB `ai_interactions` collection for cost tracking and analytics
- **Prompt Templates**: Store reusable prompt templates in MongoDB `prompt_templates` collection

**Scaling Considerations**:
- **LLM Rate Limits**: Implement queue system to respect OpenAI rate limits (3,500 requests/minute)
- **Cost Optimization**: Aggressive caching strategy (1-hour TTL) reduces duplicate LLM calls
- **Token Management**: Monitor and enforce token limits per request (max 4,096 input tokens, 1,024 output tokens)
- **Provider Fallback**: Support multiple LLM providers with automatic failover
- **Batch Processing**: Batch embedding generation for multiple documents

**AI Processing Workflow**:

```mermaid
graph TB
    subgraph "Flask API Layer"
        APIEndpoint[API Endpoint Handler]
    end
    
    subgraph "LangChain Service"
        ChainOrchestrator[Chain Orchestrator]
        
        subgraph "Chain Types"
            SimpleChain[Simple Completion Chain]
            ConvChain[Conversation Chain]
            RAGChain[RAG Chain]
        end
        
        PromptEngine[Prompt Template Engine]
        MemoryManager[Memory Manager]
        EmbeddingGen[Embedding Generator]
    end
    
    subgraph "External LLM Providers"
        OpenAI[OpenAI API]
        Anthropic[Anthropic API - Optional]
    end
    
    subgraph "Data Stores"
        ConvMemory[(MongoDB<br/>Conversation Memory)]
        VectorStore[(Vector Database<br/>Embeddings)]
        CacheStore[(Redis<br/>Response Cache)]
    end
    
    APIEndpoint --> ChainOrchestrator
    ChainOrchestrator --> SimpleChain
    ChainOrchestrator --> ConvChain
    ChainOrchestrator --> RAGChain
    
    SimpleChain --> PromptEngine
    ConvChain --> PromptEngine
    ConvChain --> MemoryManager
    RAGChain --> PromptEngine
    RAGChain --> EmbeddingGen
    RAGChain --> VectorStore
    
    MemoryManager <--> ConvMemory
    EmbeddingGen --> VectorStore
    
    PromptEngine --> OpenAI
    PromptEngine --> Anthropic
    
    ChainOrchestrator --> CacheStore
    
    OpenAI -.-> |Generated Response| ChainOrchestrator
    Anthropic -.-> |Generated Response| ChainOrchestrator
    ChainOrchestrator -.-> APIEndpoint
```

### 5.2.3 Authentication & Authorization Component

#### 5.2.3.1 Auth0 Integration Architecture

**Purpose and Responsibilities**:
Auth0 serves as the centralized identity and access management platform, handling user authentication, JWT token issuance, multi-factor authentication, social login integrations, and permission management.

**Authentication Flow**: Authorization Code Flow with PKCE (Proof Key for Code Exchange)

**Flow Description**:
1. **Login Initiation**: User clicks login button, client generates code_verifier (random string) and code_challenge (SHA256 hash)
2. **Authorization Request**: Client redirects to Auth0 with code_challenge, client_id, redirect_uri, scope, and response_type=code
3. **User Authentication**: Auth0 presents login screen, user enters credentials (or uses social login)
4. **MFA Challenge** (if enabled): Auth0 prompts for second factor (SMS code, authenticator app TOTP)
5. **Authorization Code**: Auth0 redirects back to client with authorization code
6. **Token Exchange**: Client sends authorization code + code_verifier to Auth0 token endpoint
7. **Token Issuance**: Auth0 validates code_verifier matches code_challenge, issues JWT access token and refresh token
8. **Client Storage**: Client securely stores tokens (memory for web, secure storage for mobile)

**Token Types and Lifetimes**:

| Token Type | Format | Lifetime | Purpose | Storage Location |
|------------|--------|----------|---------|------------------|
| Access Token | JWT (RS256) | 15 minutes | API authorization | Memory (web), Keychain/Keystore (mobile) |
| Refresh Token | Opaque string | 7 days | Silent token renewal | Secure storage |
| ID Token | JWT (RS256) | 15 minutes | User profile information | Memory (web), Secure storage (mobile) |

**Platform-Specific SDK Integration**:

| Platform | SDK | Authentication Mechanism | Redirect Handling |
|----------|-----|-------------------------|-------------------|
| Web | @auth0/auth0-react | Auth0Provider wrapper | Browser redirect + callback route |
| React Native | react-native-auth0 | Platform-specific web views | Deep link + custom URL scheme |
| iOS Native | Auth0.swift | ASWebAuthenticationSession | Universal Links |
| Android Native | Auth0.Android | Chrome Custom Tabs | App Links |

**Features Utilized**:
- **OAuth 2.0/OIDC Compliance**: Standards-based authentication protocol
- **Social Login**: Google, Facebook, Apple, GitHub OAuth integration
- **Multi-Factor Authentication**: SMS, authenticator apps (TOTP), email codes
- **Role-Based Access Control**: Assign roles and permissions to users
- **User Management**: User registration, profile management, password reset
- **Branding Customization**: Custom login page, email templates, hosted pages
- **Security Features**: Breached password detection, bot detection, anomaly detection

```mermaid
stateDiagram-v2
    [*] --> Unauthenticated
    Unauthenticated --> InitiatingAuth: User clicks login
    
    InitiatingAuth --> Auth0Login: Generate PKCE challenge,<br/>redirect to Auth0
    
    Auth0Login --> CredentialEntry: Display login form
    
    CredentialEntry --> CredentialValidation: User submits credentials
    
    CredentialValidation --> MFARequired: Valid credentials<br/>+ MFA enabled
    CredentialValidation --> CredentialEntry: Invalid credentials
    CredentialValidation --> TokenIssuance: Valid credentials<br/>+ No MFA
    
    MFARequired --> MFAEntry: Prompt for MFA code
    
    MFAEntry --> MFAValidation: User submits code
    
    MFAValidation --> TokenIssuance: Valid MFA code
    MFAValidation --> MFAEntry: Invalid code (retry)
    
    TokenIssuance --> Authenticated: Issue JWT tokens,<br/>store securely
    
    Authenticated --> TokenExpired: Access token expires<br/>(after 15 minutes)
    Authenticated --> Unauthenticated: User logs out
    
    TokenExpired --> RefreshingToken: Auto-refresh using<br/>refresh token
    
    RefreshingToken --> Authenticated: Refresh successful,<br/>new access token
    RefreshingToken --> Unauthenticated: Refresh failed<br/>(expired refresh token)
```

#### 5.2.3.2 Backend JWT Validation Process

**JWT Validation Steps**:

The Flask API performs comprehensive JWT validation for every protected endpoint:

1. **Token Extraction**: Extract JWT from `Authorization: Bearer {token}` header
2. **Header Decoding**: Decode JWT header (without verification) to extract signing key ID (`kid`)
3. **JWKS Retrieval**: Fetch Auth0 JSON Web Key Set (JWKS) containing public keys
   - First check Redis cache: `GET jwks:auth0`
   - If not cached: HTTP GET `https://{auth0-domain}/.well-known/jwks.json`
   - Cache JWKS in Redis with 1-hour TTL
4. **Key Matching**: Find public key in JWKS matching JWT header `kid`
5. **Signature Verification**: Verify JWT signature using RS256 algorithm with public key
6. **Claims Validation**: Validate JWT claims:
   - `exp` (expiration): Ensure token not expired
   - `iss` (issuer): Verify issuer matches Auth0 domain
   - `aud` (audience): Verify audience matches API identifier
   - `sub` (subject): Extract Auth0 user ID
7. **Permission Extraction**: Extract permissions from JWT custom claims (`permissions` array)
8. **User Context**: Attach user context (user_id, permissions) to request object for authorization

**Authorization Model**: Permission-Based Access Control (PBAC)

**Permission Format**: `{action}:{resource}` (e.g., `read:documents`, `write:users`, `admin:system`)

**Authorization Enforcement**:
- **Endpoint-Level**: Decorator `@require_permissions(['read:documents'])` on route handlers
- **Resource-Level**: Check resource ownership or sharing (e.g., verify user_id matches document owner)
- **Administrative Access**: Admin permissions (`admin:*`) grant access to all resources

**Example Authorization Check**:
```python
# Pseudocode representation (not actual code)
# Decorator checks JWT permissions
@app.route('/api/v1/documents/<document_id>', methods=['GET'])
@require_auth  # Validates JWT
@require_permissions(['read:documents'])  # Checks permissions
def get_document(document_id):
    # Additional resource-level check
    document = db.documents.find_one({'_id': document_id})
    if document['user_id'] != request.user_id:
        return 403 Forbidden
    return document
```

### 5.2.4 Data Layer Components

#### 5.2.4.1 MongoDB (Primary Database)

**Purpose and Responsibilities**:
MongoDB serves as the primary database for all application data, providing flexible schema design, powerful querying capabilities, and horizontal scalability.

**Deployment Options**:
- **MongoDB Atlas** (Recommended): Fully managed database-as-a-service with automated backups, monitoring, and scaling
- **Self-Hosted on ECS**: MongoDB container deployed on ECS Fargate with persistent EBS volumes

**Data Models** (Planned Collections):

| Collection | Purpose | Key Fields | Indexes |
|------------|---------|------------|---------|
| `users` | User profiles, preferences | auth0_id (unique), email, preferences, created_at | auth0_id, email |
| `conversations` | AI conversation metadata | user_id, title, created_at, updated_at, model | user_id, created_at |
| `messages` | Conversation history | conversation_id, role, content, tokens, created_at | conversation_id, created_at |
| `documents` | Document metadata | user_id, s3_key, filename, size, mime_type, created_at | user_id, created_at, full-text search |

| Collection | Purpose | Key Fields | Indexes |
|------------|---------|------------|---------|
| `ai_interactions` | AI usage logging | user_id, type, prompt, response, tokens, cost, created_at | user_id, created_at, type |
| `analytics` | Event tracking | event_type, user_id, metadata, timestamp | event_type, user_id, timestamp |
| `files` | File metadata | file_id, user_id, s3_key, filename, size, created_at | file_id, user_id |

**High Availability Configuration**:
- **Replica Set**: 3-node configuration (1 Primary + 2 Secondaries) for automatic failover
- **Read Preference**: Primary for writes, SecondaryPreferred for read-heavy operations
- **Write Concern**: majority (wait for acknowledgment from majority of nodes)
- **Read Concern**: majority (read data acknowledged by majority of nodes)

**Backup Strategy**:
- **Automated Backups**: Daily full backups to Amazon S3 with 30-day retention
- **Point-in-Time Recovery**: Continuous backup enabling restore to any point in last 7 days (Atlas feature)
- **Backup Testing**: Quarterly restore drills to verify backup integrity
- **Cross-Region Replication**: Secondary backup region for disaster recovery (future)

**Scaling Strategy**:
- **Vertical Scaling**: Increase instance size (CPU, memory) for initial growth
- **Horizontal Scaling**: Sharding with appropriate shard key (user_id or tenant_id) for large datasets
- **Connection Pooling**: 50 connections per API instance, connection reuse

#### 5.2.4.2 Redis (Caching Layer)

**Purpose and Responsibilities**:
Redis provides in-memory caching for performance optimization, rate limiting enforcement, distributed locking, and temporary data storage.

**Deployment Options**:
- **Amazon ElastiCache for Redis** (Recommended): Fully managed Redis with automatic failover and scaling
- **Self-Hosted Redis Container**: Redis container on ECS Fargate (lower cost, more management)

**Use Cases and Data Structures**:

| Use Case | Data Structure | Key Pattern | TTL | Purpose |
|----------|----------------|-------------|-----|---------|
| API Response Cache | String (JSON) | `cache:{endpoint}:{user_id}:{hash}` | 5-60 min | Reduce database queries |
| JWKS Cache | String (JSON) | `jwks:auth0` | 1 hour | Optimize JWT validation |
| Rate Limiting | String (counter) | `ratelimit:{user_id}:{endpoint}` | 1 minute | Enforce API quotas |
| Distributed Lock | String (SET NX) | `lock:{resource_id}` | 30 sec | Prevent cache stampede |

**Cache Strategies**:

**Cache-Aside Pattern** (Primary Strategy):
1. Check if data exists in Redis cache
2. If cache hit: Return cached data
3. If cache miss: Query MongoDB, store result in Redis with TTL, return data

**TTL Strategy by Data Type**:

| Data Type | TTL | Rationale |
|-----------|-----|-----------|
| Static Configuration | 24 hours | Rarely changes |
| User Profile | 15 minutes | Matches JWT lifetime |
| API Responses (General) | 5 minutes | Balance freshness and performance |
| LLM Responses | 1 hour | Expensive to regenerate |

**Cache Invalidation**:
- **Time-Based**: Primary method using TTL expiration
- **Event-Based**: On write operations, delete related cache keys using pattern matching
- **Manual**: Admin endpoint to clear specific cache keys or patterns

**Cache Stampede Prevention**:
- **Distributed Locking**: Use Redis SETNX to acquire lock before database query
- **Probabilistic Early Expiration**: Refresh cache before TTL expires based on probability

**Scaling Strategy**:
- **Single Instance**: Sufficient for initial deployment (< 100,000 requests/day)
- **Redis Cluster**: Deploy Redis Cluster for horizontal scaling if needed
- **Read Replicas**: ElastiCache read replicas for read-heavy workloads

#### 5.2.4.3 Amazon S3 (Object Storage)

**Purpose and Responsibilities**:
Amazon S3 provides scalable, durable object storage for user-uploaded files, static assets, backups, and infrastructure state files.

**Bucket Strategy**:

| Bucket Name | Purpose | Access | Encryption | Versioning |
|-------------|---------|--------|------------|------------|
| `app-uploads-prod` | User-generated content | Private | SSE-S3 | Disabled |
| `app-static-assets` | Frontend static files | Public (via CloudFront) | SSE-S3 | Disabled |
| `app-backups` | Database backups, archives | Private | SSE-KMS | Enabled |
| `terraform-state` | Terraform state files | Private | SSE-S3 | Enabled |

**Security Configuration**:
- **Server-Side Encryption**: SSE-S3 (AES-256) for standard buckets, SSE-KMS for sensitive data
- **Bucket Policies**: Deny all public access except `app-static-assets` (via CloudFront only)
- **IAM Roles**: ECS tasks access S3 via IAM roles (no hardcoded credentials)
- **Presigned URLs**: Temporary upload/download URLs with 15-minute expiration
- **CORS Configuration**: Restrict cross-origin requests to known client domains

**Integration with Application**:
- **Boto3 SDK**: Python AWS SDK for S3 operations from Flask API
- **Presigned URL Pattern**: Client requests presigned URL from API, uploads directly to S3
- **CloudFront Integration**: Static assets served via CloudFront CDN for performance

**Lifecycle Policies**:
- **Backup Retention**: Transition old backups to Glacier after 90 days, delete after 1 year
- **Incomplete Multipart Uploads**: Delete incomplete uploads after 7 days
- **Old Versions**: Delete old object versions after 30 days (versioned buckets)

**Scaling Considerations**:
- **Unlimited Capacity**: S3 automatically scales storage capacity
- **Request Rates**: S3 supports 3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix
- **Prefix Strategy**: Use date-based prefixes for high-throughput scenarios (`uploads/2024/01/15/...`)

#### 5.2.4.4 Vector Database (To Be Determined)

**Purpose and Responsibilities**:
Vector database stores and queries high-dimensional embeddings for semantic search, powering RAG (Retrieval-Augmented Generation) features.

**Options Under Consideration**:

| Option | Type | Pros | Cons |
|--------|------|------|------|
| MongoDB Atlas Vector Search | Integrated | Same database, no additional service | Limited vector search features |
| Pinecone | Managed | High performance, fully managed | Additional cost, vendor lock-in |
| Weaviate | Self-Hosted | Open-source, feature-rich | Requires management |
| Qdrant | Self-Hosted | High performance, open-source | Operational overhead |

**Data Model**:
- **Vector Dimensions**: 1536 (OpenAI text-embedding-ada-002 model)
- **Similarity Metric**: Cosine similarity
- **Metadata**: Document ID, user_id, text content, created_at
- **Index Type**: HNSW (Hierarchical Navigable Small World) for fast approximate search

**Integration with LangChain**:
- LangChain provides native integration for all vector database options
- Abstraction layer enables switching providers without application code changes

**Scaling Strategy**:
- **Managed Options**: Automatic scaling (Pinecone, MongoDB Atlas)
- **Self-Hosted**: Vertical scaling initially, horizontal sharding for large datasets

### 5.2.5 Infrastructure Layer Components

#### 5.2.5.1 Amazon ECS Fargate (Serverless Compute)

**Purpose and Responsibilities**:
ECS Fargate provides serverless container orchestration, eliminating EC2 instance management while enabling auto-scaling, health monitoring, and blue-green deployments.

**Architecture**:
- **Cluster**: Single ECS cluster hosting all backend services
- **Services**: Separate ECS services for Flask API and LangChain (if separated)
- **Tasks**: Individual container instances running application code
- **Task Definitions**: Docker container configuration (image, CPU, memory, environment variables)

**Task Configuration** (Flask API):
- **Container Image**: `{account-id}.dkr.ecr.{region}.amazonaws.com/flask-api:latest`
- **CPU**: 0.5 vCPU (512 CPU units)
- **Memory**: 1GB
- **Environment Variables**: Loaded from AWS Secrets Manager
- **Health Check**: HTTP GET `/health` every 30 seconds
- **Logging**: CloudWatch Logs with structured JSON format

**Auto-Scaling Configuration**:
- **Target Tracking**: Scale based on average CPU utilization (target: 70%)
- **Scale-Out**: Add 1 task when CPU > 70% for 3 minutes
- **Scale-In**: Remove 1 task when CPU < 30% for 10 minutes
- **Min Tasks**: 2 (high availability)
- **Max Tasks**: 10 (cost control)

**Deployment Strategy**:
- **Type**: Rolling deployment
- **Minimum Healthy Percent**: 100% (no downtime)
- **Maximum Percent**: 200% (run old and new versions simultaneously)
- **Health Check Grace Period**: 60 seconds (allow container startup time)

**Networking**:
- **VPC**: Custom VPC with public and private subnets across 3 availability zones
- **Subnets**: Tasks deployed in private subnets, no direct internet access
- **NAT Gateway**: Private subnets route internet traffic through NAT Gateway
- **Security Groups**: Restrict inbound traffic to ALB only, allow outbound to MongoDB, Redis, S3

#### 5.2.5.2 Application Load Balancer (ALB)

**Purpose and Responsibilities**:
ALB distributes incoming HTTPS traffic across healthy ECS tasks, performs TLS termination, and enables path-based routing for future microservices.

**Configuration**:
- **Scheme**: Internet-facing (public)
- **Subnets**: Public subnets across 3 availability zones for high availability
- **Security Group**: Allow inbound HTTPS (443) from 0.0.0.0/0, allow outbound to ECS security group
- **Listeners**: HTTPS listener (port 443) forwarding to target group

**TLS Configuration**:
- **Certificate**: AWS Certificate Manager (ACM) certificate for custom domain
- **Protocol**: TLS 1.3 (with TLS 1.2 fallback)
- **Cipher Suites**: Modern cipher suite (AWS recommended policy)
- **HTTP to HTTPS Redirect**: Redirect HTTP (port 80) to HTTPS (port 443)

**Target Group Configuration**:
- **Type**: IP targets (Fargate tasks)
- **Protocol**: HTTP (port 5000 - internal Flask port)
- **Health Check**: HTTP GET `/health` every 30 seconds, 2 consecutive successes required
- **Deregistration Delay**: 30 seconds (allow in-flight requests to complete)

**Features**:
- **Sticky Sessions**: Disabled (stateless API)
- **Access Logs**: S3 bucket logging for request analysis
- **Connection Draining**: Gracefully close connections during task termination

#### 5.2.5.3 Terraform (Infrastructure as Code)

**Purpose and Responsibilities**:
Terraform enables version-controlled, reproducible infrastructure provisioning across all AWS resources.

**Terraform Module Structure**:

```
terraform/
├── modules/
│   ├── networking/       # VPC, subnets, security groups
│   ├── compute/          # ECS cluster, task definitions, services
│   ├── storage/          # S3 buckets, EBS volumes
│   ├── database/         # MongoDB container (if self-hosted)
│   ├── cache/            # Redis container or ElastiCache
│   ├── monitoring/       # CloudWatch alarms, dashboards
│   └── secrets/          # Secrets Manager configuration
├── environments/
│   ├── dev/              # Development environment
│   ├── staging/          # Staging environment
│   └── production/       # Production environment
└── main.tf               # Root module
```

**State Management**:
- **Backend**: S3 bucket with versioning enabled
- **State Locking**: DynamoDB table for concurrent access prevention
- **State Encryption**: Server-side encryption enabled

**Workflow**:
1. **Plan**: `terraform plan` generates execution plan
2. **Review**: Manual review of proposed changes
3. **Apply**: `terraform apply` provisions infrastructure
4. **CI/CD Integration**: GitHub Actions automates plan/apply for pull requests

#### 5.2.5.4 GitHub Actions (CI/CD Platform)

**Purpose and Responsibilities**:
GitHub Actions automates build, test, and deployment pipelines for backend services, frontend applications, and infrastructure changes.

**Workflow Categories**:

| Workflow | Trigger | Jobs | Deployment Target |
|----------|---------|------|-------------------|
| Backend CI/CD | Push to main/develop, PRs | Lint, test, build Docker image, push to ECR, deploy to ECS | ECS Fargate |
| Frontend CI/CD | Push to main/develop, PRs | Lint, test, build, deploy to S3, invalidate CloudFront | S3 + CloudFront |
| Mobile CI/CD | Push to main, tags | Build iOS/Android apps, run tests, upload artifacts | App Store, Play Store |
| Infrastructure CI/CD | Changes to terraform/, PRs | Terraform plan/apply, validate infrastructure | AWS (via Terraform) |

**Backend CI/CD Workflow Steps**:
1. **Checkout Code**: Clone repository
2. **Set Up Python**: Install Python 3.11+
3. **Install Dependencies**: `pip install -r requirements.txt`
4. **Lint**: Run Flake8 and Black code formatting check
5. **Unit Tests**: Run pytest with coverage report
6. **Build Docker Image**: `docker build -t flask-api:${GITHUB_SHA}`
7. **Push to ECR**: Authenticate and push image to Amazon ECR
8. **Deploy to ECS**: Update ECS task definition with new image, trigger service update
9. **Health Check**: Verify deployment health after rolling update

**Secrets Management**:
- **GitHub Secrets**: Store AWS credentials, Auth0 configuration, API keys
- **Environment Variables**: Inject secrets into workflows via GitHub environment secrets
- **Runtime Secrets**: ECS tasks fetch secrets from AWS Secrets Manager at runtime

```mermaid
graph LR
    subgraph "GitHub Repository"
        Code[Source Code]
        PR[Pull Request]
    end
    
    subgraph "GitHub Actions"
        Workflow[CI/CD Workflow]
        
        subgraph "Build Jobs"
            Lint[Code Linting]
            Test[Unit Tests]
            Build[Docker Build]
        end
        
        subgraph "Deploy Jobs"
            PushECR[Push to ECR]
            UpdateECS[Update ECS]
            HealthCheck[Health Check]
        end
    end
    
    subgraph "AWS Infrastructure"
        ECR[Amazon ECR<br/>Container Registry]
        ECS[Amazon ECS<br/>Fargate Service]
        ALB[Application Load Balancer]
    end
    
    Code --> Workflow
    PR --> Workflow
    
    Workflow --> Lint
    Lint --> Test
    Test --> Build
    
    Build --> PushECR
    PushECR --> ECR
    
    ECR --> UpdateECS
    UpdateECS --> ECS
    
    ECS --> HealthCheck
    HealthCheck --> ALB
    
    ALB -.->|Healthy| Workflow
```

---

## 5.3 Technical Decisions

### 5.3.1 Architecture Style Decisions

#### 5.3.1.1 Cloud-Native Architecture

**Decision**: Adopt cloud-native architecture leveraging AWS managed services

**Rationale**:
- **Operational Efficiency**: Managed services (ECS Fargate, RDS/Atlas, ElastiCache) eliminate infrastructure management overhead, allowing focus on application development
- **Elastic Scaling**: Cloud-native services automatically scale resources based on demand, handling traffic spikes without manual intervention
- **High Availability**: AWS multi-AZ deployments provide built-in redundancy and failover capabilities
- **Cost Optimization**: Pay-per-use pricing model aligns costs with actual usage, avoiding over-provisioning
- **Global Reach**: CloudFront CDN and multi-region capabilities enable low-latency access worldwide

**Tradeoffs**:

| Aspect | Benefits | Drawbacks |
|--------|----------|-----------|
| **Vendor Lock-In** | Deep AWS integration, optimized performance | Migration difficulty, AWS-specific dependencies |
| **Cost at Scale** | Low initial cost, no capital expenses | Potentially higher costs at very large scale |
| **Control** | Less infrastructure management burden | Limited low-level control, dependency on AWS |
| **Learning Curve** | Extensive AWS documentation and community | Team must learn AWS-specific services |

**Alternative Considered**: Self-Hosted Infrastructure (EC2, Self-Managed Databases)
- **Rejected Reason**: Higher operational overhead, manual scaling, requires dedicated DevOps team
- **When to Reconsider**: If strict data sovereignty requirements or cost optimization at very large scale become priorities

#### 5.3.1.2 Microservices-Oriented Architecture

**Decision**: Design system with microservices principles, starting with modular monolith

**Rationale**:
- **Modularity**: Clear separation between API layer, AI/ML service, and data layer enables independent development
- **Scalability**: Services scale independently based on demand (e.g., scale AI service separately from CRUD API)
- **Technology Flexibility**: Different services can use optimal technologies (Python for API, specialized AI frameworks)
- **Deployment Independence**: Services deploy independently, reducing deployment risk
- **Gradual Evolution**: Start with modular monolith, extract microservices as needed

**Implementation Approach**:
1. **Phase 1** (Current): Modular monolith with clear service boundaries within Flask application
2. **Phase 2** (Future): Extract AI/ML service into separate ECS service with dedicated scaling
3. **Phase 3** (If Needed): Extract additional services (e.g., file processing, analytics) as growth demands

**Tradeoffs**:

| Aspect | Benefits | Drawbacks |
|--------|----------|-----------|
| **Complexity** | Clear separation of concerns | Increased operational complexity |
| **Performance** | Optimized scaling per service | Network latency between services |
| **Development** | Team independence, parallel development | Requires strong API contracts, versioning |
| **Testing** | Isolated unit testing | Complex integration testing |

### 5.3.2 Communication Patterns

#### 5.3.2.1 RESTful HTTP API

**Decision**: Implement RESTful HTTP API with JSON payloads as primary communication protocol

**Rationale**:
- **Universal Support**: HTTP/REST supported by all client platforms (web, mobile, desktop) and programming languages
- **Simplicity**: Clear request/response semantics with standard HTTP methods (GET, POST, PUT, DELETE)
- **Caching**: Leverage HTTP caching headers and intermediary caching (CloudFront, browser cache)
- **Tooling Ecosystem**: Extensive tooling for testing (Postman, curl), documentation (Swagger/OpenAPI), monitoring
- **Statelessness**: REST enables stateless server design, critical for horizontal scaling

**API Design Principles**:
- **Resource-Oriented**: Endpoints represent resources (`/api/v1/documents`, `/api/v1/users`)
- **HTTP Methods**: Standard methods map to CRUD operations (GET=Read, POST=Create, PUT=Update, DELETE=Delete)
- **Status Codes**: Meaningful HTTP status codes (200 OK, 201 Created, 400 Bad Request, 401 Unauthorized, 404 Not Found, 500 Internal Server Error)
- **Versioning**: API version in URL path (`/api/v1/`) for backward compatibility
- **Pagination**: Cursor-based pagination for large result sets
- **Filtering**: Query parameters for filtering, sorting, and searching

**Tradeoffs**:

| Aspect | REST | GraphQL (Alternative) |
|--------|------|----------------------|
| **Simplicity** | Simple, well-understood | Complex, requires schema definition |
| **Flexibility** | Fixed endpoints, predictable | Flexible queries, client-controlled data |
| **Caching** | Standard HTTP caching | Complex caching strategies |
| **Over-fetching** | May return unnecessary data | Precise data fetching |
| **Tooling** | Mature ecosystem | Growing ecosystem |

**Decision Outcome**: REST chosen for simplicity and initial requirements. GraphQL considered for future adoption if complex data fetching patterns emerge.

#### 5.3.2.2 Synchronous vs. Asynchronous Communication

**Decision**: Primarily synchronous request/response, with asynchronous processing for long-running operations

**Synchronous Communication** (Primary):
- **Use Cases**: All client-facing API endpoints (CRUD operations, user authentication, simple AI requests)
- **Benefits**: Simple request/response flow, immediate feedback, easy error handling
- **Implementation**: Direct HTTP request to Flask API, response returned in same connection

**Asynchronous Communication** (Selective):
- **Use Cases**: Long-running operations (batch file processing, large report generation, expensive AI operations)
- **Benefits**: Non-blocking, prevents timeout issues, better resource utilization
- **Implementation**: Celery task queue with Redis broker (future enhancement)

**Decision Matrix**:

| Operation Type | Communication Pattern | Rationale |
|---------------|----------------------|-----------|
| User Authentication | Synchronous | Fast operation, immediate result required |
| Document CRUD | Synchronous | Quick database operations, real-time feedback |
| Simple AI Completion | Synchronous | Acceptable latency (< 5 seconds) |
| File Upload | Hybrid | Presigned URL (sync), S3 upload (async from backend perspective) |
| Batch Processing | Asynchronous | Long-running, background processing |

### 5.3.3 Data Storage Solutions

#### 5.3.3.1 MongoDB as Primary Database

**Decision**: Use MongoDB 7.0+ as the primary database for all application data

**Rationale**:

| Justification Category | Details |
|----------------------|---------|
| **Schema Flexibility** | Document model accommodates evolving data structures without migrations, critical for rapid development |
| **Developer Productivity** | JSON-like documents map naturally to Python dictionaries and JavaScript objects, reducing impedance mismatch |
| **Query Capabilities** | Powerful aggregation framework supports complex analytics and data transformations |
| **Horizontal Scalability** | Built-in sharding with automatic data distribution enables future growth |
| **AI Integration** | MongoDB Atlas Vector Search provides native vector similarity search for RAG features |
| **Operational Maturity** | Proven at scale, extensive tooling, managed Atlas offering reduces operational burden |

**Alternative Considered**: PostgreSQL (Relational Database)

| Aspect | MongoDB | PostgreSQL |
|--------|---------|-----------|
| **Schema** | Flexible, schema-less | Rigid, requires migrations |
| **Queries** | Rich aggregation framework | SQL, complex joins |
| **Scaling** | Horizontal sharding | Vertical scaling, complex sharding |
| **ACID** | Document-level ACID | Full ACID transactions |
| **Use Case Fit** | Document storage, flexible data | Relational data, complex transactions |

**Decision Outcome**: MongoDB selected for schema flexibility and alignment with document-oriented data (user profiles, conversations, messages). PostgreSQL reconsidered if complex transactional requirements emerge.

#### 5.3.3.2 Redis for Caching and Rate Limiting

**Decision**: Deploy Redis 7+ for caching, rate limiting, and temporary data storage

**Rationale**:
- **Performance**: In-memory storage provides sub-millisecond response times, dramatically reducing API latency
- **Versatility**: Supports multiple use cases (caching, rate limiting, session storage, distributed locking)
- **Simplicity**: Straightforward key-value model, easy integration with Flask via redis-py
- **Cost-Effectiveness**: Reduces MongoDB query load, prevents expensive LLM API calls through caching
- **Scalability**: Redis Cluster enables horizontal scaling if needed

**Use Case Breakdown**:

| Use Case | Redis Data Structure | Benefit |
|----------|---------------------|---------|
| API Response Caching | String (JSON serialized) | Reduce database queries, improve response time |
| Rate Limiting | String (counter) | Enforce API quotas, prevent abuse |
| JWKS Caching | String (JSON) | Optimize JWT validation, reduce Auth0 API calls |
| LLM Response Caching | String (JSON) | Reduce OpenAI costs, improve AI feature performance |
| Distributed Locking | String (SET NX) | Prevent cache stampede, ensure consistency |

#### 5.3.3.3 Amazon S3 for Object Storage

**Decision**: Use Amazon S3 for file storage and static asset delivery

**Rationale**:
- **Unlimited Scalability**: S3 automatically scales storage capacity without provisioning
- **Durability**: 99.999999999% (11 nines) durability through automatic cross-AZ replication
- **Cost Efficiency**: Pay-per-use model, significantly cheaper than database storage for large files
- **Direct Upload**: Presigned URLs enable client-to-S3 uploads without backend proxy, reducing API bandwidth
- **CDN Integration**: Native CloudFront integration for fast static asset delivery
- **Lifecycle Management**: Automatic transitions to cheaper storage tiers (Glacier) for backups

**Storage Strategy**:
- **User Uploads**: Store in S3, metadata in MongoDB (file_id, s3_key, size, mime_type)
- **Static Assets**: Frontend builds, images, CSS/JS files served via CloudFront
- **Backups**: Database backups, archived logs stored with lifecycle policies

### 5.3.4 Caching Strategy

#### 5.3.4.1 Multi-Layer Caching Architecture

**Decision**: Implement multi-layer caching with Redis and CloudFront CDN

**Caching Layers**:

| Layer | Technology | Scope | TTL Range |
|-------|-----------|-------|-----------|
| **Client Cache** | Browser cache | Individual user, device-specific | 0-1 hour |
| **CDN Cache** | CloudFront | Edge locations, global users | 0-1 year |
| **Application Cache** | Redis | Backend services, shared across users | 30 sec - 24 hours |
| **Database Cache** | MongoDB query cache | Database internals | Managed by MongoDB |

#### 5.3.4.2 Redis Cache Strategy

**Cache-Aside Pattern** (Primary Strategy):

**Flow**:
1. **Read Request**: Check Redis for cached data
2. **Cache Hit**: Return cached data immediately
3. **Cache Miss**: Query MongoDB, store result in Redis with TTL, return data
4. **Write Request**: Update MongoDB, invalidate related cache keys

**TTL Strategy**:

| Data Type | TTL | Invalidation Method | Rationale |
|-----------|-----|-------------------|-----------|
| Static Configuration | 24 hours | Time-based | Rarely changes, safe to cache long |
| User Profile | 15 minutes | Time + Event-based | Matches JWT lifetime, invalidate on update |
| API Responses | 5 minutes | Time + Event-based | Balance freshness and performance |
| LLM Responses | 1 hour | Time-based | Expensive to regenerate, acceptable staleness |
| JWKS (Auth0 Keys) | 1 hour | Time-based | Auth0 rotates keys infrequently |
| Rate Limit Counters | 1 minute | Time-based | Reset counter each minute |

**Cache Key Generation**:
- **Format**: `{namespace}:{endpoint}:{user_id}:{params_hash}`
- **Example**: `cache:documents:auth0|123:sha256(query_params)`
- **Benefits**: Unique per user and query, supports pattern-based deletion

**Cache Invalidation Strategies**:

```mermaid
graph TD
    WriteRequest[Write Request to API]
    
    WriteRequest --> UpdateDB[Update MongoDB]
    UpdateDB --> InvalidateCache{Determine Cache Keys to Invalidate}
    
    InvalidateCache --> PatternDelete[Pattern-Based Deletion]
    InvalidateCache --> SpecificDelete[Specific Key Deletion]
    
    PatternDelete --> Example1["DELETE cache:documents:user123:*<br/>(All user's document cache)"]
    
    SpecificDelete --> Example2["DELETE cache:documents:user123:doc456<br/>(Specific document cache)"]
    
    Example1 --> LogInvalidation[Log Cache Invalidation Event]
    Example2 --> LogInvalidation
    
    LogInvalidation --> ReturnResponse[Return Success Response to Client]
```

#### 5.3.4.3 Cache Stampede Prevention

**Problem**: When cached item expires, multiple concurrent requests query database simultaneously, causing load spike.

**Solution**: Distributed Locking with Redis

**Implementation**:
1. **Check Cache**: Attempt to read from cache
2. **Cache Miss**: Attempt to acquire lock using `SETNX lock:{key} 1 EX 30`
3. **Lock Acquired**: Query database, populate cache, release lock
4. **Lock Not Acquired**: Wait briefly, retry cache read (another request is populating)
5. **Timeout**: If lock held too long, force-refresh cache

**Alternative Approach**: Probabilistic Early Expiration
- Refresh cache before TTL expires based on probability (`random() < (current_time - cache_time) / TTL`)
- Avoids hard expiration cutoff, spreads refresh operations

#### 5.3.4.4 CloudFront CDN Caching

**Decision**: Use CloudFront for static asset caching at edge locations

**Cache Configuration**:

| Asset Type | TTL | Cache-Control Header | Rationale |
|-----------|-----|---------------------|-----------|
| Hashed Assets (JS, CSS) | 1 year | `max-age=31536000, immutable` | Filename changes on update, safe to cache permanently |
| Images | 1 week | `max-age=604800` | Rarely change, balance freshness and performance |
| HTML Files | 0 seconds | `no-cache` | Always check origin for updates |
| API Responses | N/A | Not cached via CDN | Dynamic content, user-specific |

**Cache Invalidation**:
- **Deployment Process**: Create CloudFront invalidation for `/*` after S3 deployment
- **Cost Consideration**: First 1,000 invalidation paths per month free, then $0.005 per path
- **Invalidation Pattern**: Use wildcard patterns (`/assets/*`) to minimize costs

### 5.3.5 Security Mechanisms

#### 5.3.5.1 Auth0 for Authentication

**Decision**: Use Auth0 as centralized identity and access management platform

**Justification**:

| Category | Benefit |
|----------|---------|
| **Security Compliance** | SOC 2 Type II certified, complies with GDPR, HIPAA, PCI DSS requirements |
| **Enterprise Features** | MFA, social login, breached password detection, anomaly detection out-of-box |
| **Multi-Platform Support** | Native SDKs for web, mobile (iOS, Android), and desktop with consistent API |
| **Maintenance** | Security patches, vulnerability fixes, compliance updates managed by Auth0 |
| **Scalability** | Proven to handle millions of authentications, automatic scaling |
| **Cost** | Free tier (up to 7,000 active users), transparent pricing scaling with MAU |

**Alternative Considered**: Self-Hosted Authentication (Keycloak, Auth0 OSS)

| Aspect | Auth0 (Managed) | Self-Hosted (Keycloak) |
|--------|----------------|----------------------|
| **Setup** | Minutes | Days/weeks |
| **Maintenance** | Managed by Auth0 | Team responsibility |
| **Security Updates** | Automatic | Manual |
| **Compliance** | Built-in certifications | Self-certification required |
| **Cost** | SaaS pricing | Infrastructure + operational costs |

**Decision Outcome**: Auth0 selected for rapid development, reduced security risk, and operational simplicity. Self-hosted reconsidered only if strict data sovereignty requirements emerge.

#### 5.3.5.2 JWT for API Authorization

**Decision**: Use JWT (JSON Web Tokens) with RS256 asymmetric signing for API authorization

**Rationale**:
- **Stateless**: No server-side session storage required, critical for horizontal scaling
- **Standard**: Industry-standard format (RFC 7519) with broad library support across languages
- **Performance**: No database lookup required for authorization, permissions embedded in token
- **Security**: RS256 asymmetric signing prevents token tampering, short lifetime (15 minutes) limits exposure

**JWT Structure**:

**Header**:
```json
{
  "alg": "RS256",
  "typ": "JWT",
  "kid": "key-id-from-auth0"
}
```

**Payload**:
```json
{
  "iss": "https://{auth0-domain}/",
  "sub": "auth0|123456",
  "aud": "https://api.example.com",
  "iat": 1640995200,
  "exp": 1640996100,
  "permissions": ["read:documents", "write:documents"]
}
```

**Signature**: RS256 signature using Auth0 private key

**Security Measures**:

| Measure | Implementation | Purpose |
|---------|---------------|---------|
| **Short Expiration** | 15-minute lifetime | Limit damage if token compromised |
| **Refresh Tokens** | 7-day refresh token for silent renewal | Balance security and UX |
| **Token Rotation** | New refresh token issued on each use | Detect token theft |
| **Signature Validation** | Verify RS256 signature against Auth0 public keys | Prevent tampering |
| **Claims Validation** | Check exp, iss, aud claims | Ensure token legitimacy |

#### 5.3.5.3 TLS/HTTPS Encryption

**Decision**: Enforce TLS 1.3 for all external communication

**Implementation**:
- **Client to ALB**: HTTPS only, HTTP redirects to HTTPS
- **ALB to Backend**: HTTP (internal VPC network, no internet exposure)
- **Backend to External Services**: HTTPS (Auth0, OpenAI, MongoDB Atlas)

**Certificate Management**:
- **Provider**: AWS Certificate Manager (ACM)
- **Issuance**: Free SSL/TLS certificates with automatic renewal
- **Domains**: Wildcard certificate for `*.example.com`
- **Validation**: DNS validation via Route 53

**TLS Configuration**:
- **Protocol**: TLS 1.3 preferred, TLS 1.2 fallback for compatibility
- **Cipher Suites**: AWS recommended policy (modern, secure ciphers only)
- **HSTS**: HTTP Strict Transport Security header enforces HTTPS

#### 5.3.5.4 Additional Security Mechanisms

**Rate Limiting**:
- **Implementation**: Flask-Limiter with Redis backend
- **Limits**: 
  - General API: 1000 requests/hour per user
  - AI endpoints: 10 requests/minute per user (cost control)
  - Authentication: 5 login attempts/minute per IP (brute force prevention)
- **Response**: 429 Too Many Requests with Retry-After header

**Input Validation**:
- **Framework**: Pydantic for request payload validation
- **Benefits**: Type checking, automatic validation, clear error messages
- **Protection**: Prevents injection attacks (SQL, NoSQL, XSS)

**CORS (Cross-Origin Resource Sharing)**:
- **Configuration**: Strict allowlist of known origins
- **Allowed Origins**: `https://app.example.com`, `https://www.example.com`
- **Allowed Methods**: GET, POST, PUT, DELETE
- **Credentials**: `Access-Control-Allow-Credentials: true` for JWT cookies

**Secrets Management**:
- **Service**: AWS Secrets Manager
- **Secrets Stored**: Database credentials, API keys (OpenAI, Auth0), encryption keys
- **Access**: ECS tasks fetch secrets at runtime via IAM roles
- **Rotation**: Automatic secret rotation where supported (database passwords)

**Container Security**:
- **Image Scanning**: AWS ECR scans Docker images for vulnerabilities
- **Base Images**: Use official, minimal base images (python:3.11-slim)
- **Updates**: Regular base image updates to patch vulnerabilities

---

## 5.4 Cross-Cutting Concerns

### 5.4.1 Monitoring and Observability

#### 5.4.1.1 Observability Strategy

The system implements a comprehensive observability strategy encompassing logs, metrics, and distributed tracing to ensure visibility into system behavior and rapid incident response.

**Observability Pillars**:

| Pillar | Technology | Purpose | Retention |
|--------|-----------|---------|-----------|
| **Logs** | CloudWatch Logs | Detailed event records, debugging | 30 days |
| **Metrics** | CloudWatch Metrics | Quantitative system measurements | 15 months |
| **Traces** | AWS X-Ray (optional) | Request flow across services | 30 days |
| **Alerts** | CloudWatch Alarms | Proactive issue notification | N/A (real-time) |

#### 5.4.1.2 CloudWatch Logs Implementation

**Log Groups**:

| Log Group | Source | Log Format | Purpose |
|-----------|--------|-----------|---------|
| `/ecs/flask-api` | Flask API containers | Structured JSON | Application logs, request/response |
| `/ecs/langchain` | LangChain service | Structured JSON | AI/ML operation logs |
| `/aws/lambda/*` | Lambda functions (future) | Structured JSON | Serverless function logs |
| `/aws/alb/access` | Application Load Balancer | Apache Combined | HTTP access logs |

**Structured Log Format** (JSON):
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456",
  "service": "api",
  "endpoint": "/api/v1/documents",
  "method": "GET",
  "status_code": 200,
  "duration_ms": 45,
  "cache_hit": true,
  "message": "Request processed successfully",
  "metadata": {
    "query_params": {"limit": 10},
    "response_size": 2048
  }
}
```

**Log Levels**:
- **DEBUG**: Verbose diagnostic information (development only)
- **INFO**: General informational messages (request/response, successful operations)
- **WARNING**: Warning conditions (cache miss, retry attempts, deprecated API usage)
- **ERROR**: Error conditions (failed API calls, validation errors, database errors)
- **CRITICAL**: Critical failures requiring immediate attention (service unavailable, data corruption)

#### 5.4.1.3 CloudWatch Metrics

**Infrastructure Metrics** (Automatic):

| Metric Category | Specific Metrics | Source | Alert Threshold |
|----------------|------------------|--------|----------------|
| ECS Service | CPU utilization, memory utilization, task count | ECS | CPU > 80% for 5 min |
| Application Load Balancer | Request count, target response time, HTTP error rates | ALB | 5xx errors > 5% |
| MongoDB | Connection count, query execution time | MongoDB exporter | Connections > 80% |
| Redis | CPU utilization, memory usage, evicted keys | ElastiCache | Memory > 90% |

**Application Metrics** (Custom):

| Metric | Type | Purpose | Alert Threshold |
|--------|------|---------|----------------|
| `api.request.count` | Counter | Total API requests | N/A (informational) |
| `api.request.duration` | Histogram | Request latency (p50, p95, p99) | p95 > 1000ms |
| `api.error.rate` | Gauge | Percentage of failed requests | > 5% |
| `ai.tokens.consumed` | Counter | LLM token usage for cost tracking | Budget threshold |
| `cache.hit.rate` | Gauge | Cache effectiveness | < 70% (cache tuning needed) |
| `auth.failed.attempts` | Counter | Failed authentication attempts | > 100/min (potential attack) |

**Metric Collection**:
- **Method**: CloudWatch PutMetricData API from Flask application
- **Frequency**: Real-time (on event) or batched (every 60 seconds)
- **Dimensions**: service, environment, endpoint, user_tier

#### 5.4.1.4 Alerting and Dashboards

**CloudWatch Alarms**:

| Alarm Name | Metric | Condition | Action |
|-----------|--------|-----------|--------|
| High Error Rate | `api.error.rate` | > 5% for 5 minutes | Email operations team, PagerDuty |
| API Latency Spike | `api.request.duration (p95)` | > 1000ms for 5 minutes | Email engineering team |
| ECS CPU High | `ECS CPU Utilization` | > 80% for 10 minutes | Auto-scale ECS tasks |
| Database Connection Pool Exhausted | `MongoDB connections` | > 80% of max | Email DBA team |

**CloudWatch Dashboards**:

| Dashboard | Widgets | Audience |
|-----------|---------|----------|
| **System Health** | API request rate, error rate, latency, ECS health | Operations team |
| **Business Metrics** | Active users, AI usage, revenue-generating events | Product/Business teams |
| **Cost Tracking** | LLM token costs, AWS service costs, cache savings | Finance/Engineering |
| **Security** | Failed auth attempts, rate limit hits, suspicious activity | Security team |

**Third-Party Monitoring** (Optional):

| Service | Purpose | Integration |
|---------|---------|-------------|
| DataDog | APM, distributed tracing, log aggregation | Agent on ECS tasks |
| Sentry | Error tracking, frontend/backend exception monitoring | SDK in applications |
| LogRocket | Session replay, frontend monitoring | JavaScript SDK |

#### 5.4.1.5 Distributed Tracing (Optional)

**AWS X-Ray Implementation**:
- **Purpose**: Trace requests across microservices (API → LangChain → OpenAI → MongoDB)
- **Instrumentation**: X-Ray SDK in Flask application and LangChain wrapper
- **Trace Data**: Request ID, service name, start/end time, errors, metadata
- **Analysis**: Identify bottlenecks, visualize service dependencies, debug latency issues

**Request ID Propagation**:
- **Generation**: UUID generated at ALB or API entry point
- **Propagation**: Included in all log entries, X-Ray traces, and downstream service calls
- **Header**: `X-Request-ID` passed to all microservices
- **Correlation**: Use Request ID to correlate logs across services

### 5.4.2 Logging and Tracing

#### 5.4.2.1 Structured Logging Standards

**Logging Framework**: Python `logging` module with JSON formatter

**Standard Fields**:

| Field | Type | Required | Purpose |
|-------|------|----------|---------|
| `timestamp` | ISO 8601 datetime | Yes | Event time |
| `level` | String (DEBUG/INFO/WARNING/ERROR/CRITICAL) | Yes | Log severity |
| `request_id` | UUID | Yes (for requests) | Request correlation |
| `user_id` | String | No | User context |
| `service` | String | Yes | Service name (api, langchain) |
| `message` | String | Yes | Human-readable message |

**PII (Personally Identifiable Information) Handling**:
- **Redaction**: Automatically redact sensitive fields (passwords, tokens, credit cards, SSNs)
- **Hashing**: Hash user_id and email for privacy while maintaining traceability
- **Compliance**: Ensure logging complies with GDPR, CCPA data privacy regulations
- **Configuration**: Environment variable controls PII logging level (none, hashed, full for development)

**Log Sampling**:
- **High-Traffic Endpoints**: Sample logs to reduce volume (e.g., 10% sampling for health checks)
- **Error Logs**: Always log errors at 100% rate
- **Sensitive Operations**: Always log security-related operations (auth, admin actions) at 100%

#### 5.4.2.2 Request Tracing Flow

**Trace Propagation**:

```mermaid
sequenceDiagram
    participant Client
    participant ALB
    participant API as Flask API
    participant LangChain
    participant MongoDB
    participant OpenAI
    
    Note over Client,OpenAI: Request Trace Flow with Request ID
    
    Client->>ALB: HTTP Request
    Note over ALB: Generate Request ID<br/>550e8400-e29b...
    ALB->>API: X-Request-ID: 550e8400...
    
    Note over API: Log: Request received<br/>request_id: 550e8400...
    
    API->>LangChain: AI request<br/>X-Request-ID: 550e8400...
    Note over LangChain: Log: AI processing started<br/>request_id: 550e8400...
    
    LangChain->>OpenAI: LLM API call
    Note over LangChain: Log: OpenAI call initiated<br/>request_id: 550e8400...
    
    LangChain->>MongoDB: Store conversation
    Note over LangChain: Log: Data persisted<br/>request_id: 550e8400...
    
    MongoDB-->>LangChain: Success
    OpenAI-->>LangChain: Response
    
    LangChain-->>API: AI result<br/>X-Request-ID: 550e8400...
    Note over API: Log: Response prepared<br/>request_id: 550e8400...<br/>duration_ms: 2450
    
    API-->>ALB: HTTP Response<br/>X-Request-ID: 550e8400...
    ALB-->>Client: Response
```

**Log Correlation Example**:
```bash
# Query CloudWatch Logs Insights for all logs related to request
fields @timestamp, level, service, message
| filter request_id = "550e8400-e29b-41d4-a716-446655440000"
| sort @timestamp asc
```

### 5.4.3 Error Handling

#### 5.4.3.1 Error Classification

**Client Errors (4xx)**: Caused by client mistakes, require client correction

| Status Code | Error Type | Meaning | Client Action |
|------------|-----------|---------|---------------|
| 400 | Bad Request | Invalid input, validation failure | Fix request payload, check API docs |
| 401 | Unauthorized | Missing/invalid authentication token | Login, refresh token |
| 403 | Forbidden | Insufficient permissions | Request access, upgrade plan |
| 404 | Not Found | Resource doesn't exist | Check resource ID, verify existence |
| 409 | Conflict | Resource already exists, constraint violation | Use different identifier, check state |
| 429 | Too Many Requests | Rate limit exceeded | Wait, implement backoff, upgrade tier |

**Server Errors (5xx)**: Caused by server issues, require investigation

| Status Code | Error Type | Meaning | Server Action |
|------------|-----------|---------|---------------|
| 500 | Internal Server Error | Unhandled exception, unexpected error | Log error, alert ops team, investigate |
| 503 | Service Unavailable | External service down, circuit breaker open | Check dependencies, failover if possible |
| 504 | Gateway Timeout | Request processing timeout | Optimize query, increase timeout, scale resources |

#### 5.4.3.2 Standardized Error Response Format

**Error Response Structure**:
```json
{
  "error": {
    "code": "VALIDATION_ERROR",
    "message": "Request validation failed",
    "details": {
      "field": "email",
      "issue": "Invalid email format"
    },
    "request_id": "550e8400-e29b-41d4-a716-446655440000",
    "timestamp": "2024-01-15T10:30:00Z",
    "documentation_url": "https://docs.example.com/errors/VALIDATION_ERROR"
  }
}
```

**Error Code Taxonomy**:

| Error Code | HTTP Status | Description |
|-----------|-------------|-------------|
| `VALIDATION_ERROR` | 400 | Request payload failed schema validation |
| `AUTHENTICATION_REQUIRED` | 401 | JWT missing or invalid |
| `INSUFFICIENT_PERMISSIONS` | 403 | User lacks required permissions |
| `RESOURCE_NOT_FOUND` | 404 | Requested resource doesn't exist |
| `RESOURCE_CONFLICT` | 409 | Resource constraint violation |
| `RATE_LIMIT_EXCEEDED` | 429 | API rate limit exceeded |
| `INTERNAL_ERROR` | 500 | Unexpected server error |
| `SERVICE_UNAVAILABLE` | 503 | External dependency unavailable |
| `REQUEST_TIMEOUT` | 504 | Request processing timeout |

#### 5.4.3.3 Error Handling Flow

```mermaid
graph TD
    ErrorOccurs[Error Occurs in Application]
    
    ErrorOccurs --> ClassifyError{Classify Error Type}
    
    ClassifyError --> ClientError[Client Error - 4xx]
    ClassifyError --> ServerError[Server Error - 5xx]
    ClassifyError --> ExternalError[External Service Error]
    
    ClientError --> SpecificClient{Specific Type}
    SpecificClient --> Auth401[401 Unauthorized]
    SpecificClient --> Forbidden403[403 Forbidden]
    SpecificClient --> NotFound404[404 Not Found]
    SpecificClient --> BadRequest400[400 Bad Request]
    SpecificClient --> Conflict409[409 Conflict]
    SpecificClient --> RateLimit429[429 Too Many Requests]
    
    ServerError --> SpecificServer{Specific Type}
    SpecificServer --> DatabaseError[Database Error]
    SpecificServer --> UnhandledException[Unhandled Exception]
    
    DatabaseError --> CheckType{Error Type}
    CheckType --> ConnectionLost[Connection Lost]
    CheckType --> QueryTimeout[Query Timeout]
    CheckType --> ConstraintViolation[Constraint Violation]
    
    ConnectionLost --> RetryBackoff[Retry with Exponential Backoff]
    QueryTimeout --> LogTimeout[Log Slow Query]
    QueryTimeout --> Return504[Return 504 Gateway Timeout]
    ConstraintViolation --> Return409[Return 409 Conflict]
    
    UnhandledException --> LogDetailedError[Log Detailed Stack Trace]
    LogDetailedError --> Return500[Return Generic 500 Error]
    
    ExternalError --> CheckFallback{Fallback Available?}
    CheckFallback --> CacheAvailable[Cached Data Available]
    CheckFallback --> DefaultAvailable[Default Data Available]
    CheckFallback --> NoFallback[No Fallback]
    
    CacheAvailable --> ReturnCached[Return Stale Cached Data]
    DefaultAvailable --> ReturnDefault[Return Default Response]
    NoFallback --> Return503[Return 503 Service Unavailable]
    
    Auth401 --> FormatError[Format Error Response]
    Forbidden403 --> FormatError
    NotFound404 --> FormatError
    BadRequest400 --> FormatError
    Conflict409 --> FormatError
    RateLimit429 --> FormatError
    Return500 --> FormatError
    Return503 --> FormatError
    Return504 --> FormatError
    Return409 --> FormatError
    ReturnCached --> FormatError
    ReturnDefault --> FormatError
    
    FormatError --> LogError[Log Error Event to CloudWatch]
    
    LogError --> CheckCritical{Critical Error?}
    CheckCritical --> AlertOps[Alert Operations Team<br/>PagerDuty/Slack]
    CheckCritical --> ReturnToClient[Return Formatted Error to Client]
    
    AlertOps --> ReturnToClient
```

#### 5.4.3.4 Retry Mechanisms

**Exponential Backoff Strategy**:
- **Use Case**: Transient failures (network timeout, connection lost, rate limit)
- **Algorithm**: Wait time = min(base_delay * 2^attempt + jitter, max_delay)
- **Configuration**: 
  - Base delay: 100ms
  - Max attempts: 3
  - Max delay: 5 seconds
  - Jitter: Random(0, 100ms) to prevent thundering herd

**Idempotency**:
- **Requirement**: Write operations must be idempotent to safely retry
- **Implementation**: 
  - Idempotency keys for POST requests
  - Natural idempotency for PUT/DELETE operations
  - Database constraints prevent duplicate inserts

**Circuit Breaker Pattern**:

```mermaid
stateDiagram-v2
    [*] --> Closed: Initial State
    
    Closed --> Closed: Requests succeed normally
    Closed --> Open: Error threshold exceeded<br/>(50% errors in 1-min window)
    
    Open --> Open: Requests fail fast<br/>(no backend calls)
    Open --> HalfOpen: Timeout expires<br/>(after 30 seconds)
    
    HalfOpen --> Closed: Test requests succeed<br/>(5 consecutive successes)
    HalfOpen --> Open: Test requests fail
    
    note right of Closed
        Normal operation
        Track success/failure rate
    end note
    
    note right of Open
        Prevent cascading failures
        Return cached data or error immediately
    end note
    
    note right of HalfOpen
        Test if service recovered
        Allow limited requests through
    end note
```

**Graceful Degradation**:

| Failure Scenario | Degradation Strategy | User Experience |
|-----------------|---------------------|-----------------|
| MongoDB Unavailable | Return cached data with warning | Stale data displayed with notice |
| Redis Unavailable | Direct MongoDB queries, disable caching | Slower response times |
| OpenAI API Down | Disable AI features, show error message | AI features temporarily unavailable |
| Auth0 Down | Use cached JWKS for JWT validation | Authentication continues with cached keys |

### 5.4.4 Authentication and Authorization Framework

#### 5.4.4.1 Multi-Platform Authentication Flow

**Web Application Authentication**:
1. User clicks login button
2. React app redirects to Auth0 Universal Login (`https://{auth0-domain}/authorize`)
3. Auth0 displays login form (or social login options)
4. User enters credentials (or authenticates with social provider)
5. Auth0 performs MFA challenge if enabled
6. Auth0 redirects to callback URL with authorization code
7. React app exchanges authorization code for tokens (Authorization Code Flow with PKCE)
8. Tokens stored in memory (Auth0 SDK manages token lifecycle)

**Mobile Application Authentication** (React Native):
1. User taps login button
2. App opens platform-specific web view (ASWebAuthenticationSession for iOS, Chrome Custom Tabs for Android)
3. Auth0 login page rendered in secure web view
4. User authenticates, Auth0 redirects to custom URL scheme (e.g., `com.example.app://callback`)
5. App intercepts deep link, extracts authorization code
6. App exchanges authorization code for tokens
7. Tokens stored in platform-specific secure storage (iOS Keychain, Android Keystore)

**Desktop Application Authentication** (Electron):
1. User clicks login button
2. Electron opens system default browser with Auth0 login URL
3. User authenticates in browser
4. Auth0 redirects to custom protocol handler (e.g., `myapp://callback`)
5. Electron app registered as protocol handler intercepts redirect
6. App extracts authorization code from URL
7. App exchanges code for tokens, stores in native secure storage

#### 5.4.4.2 JWT Token Lifecycle Management

**Token Issuance**:
- **Trigger**: Successful authentication with Auth0
- **Access Token**: Short-lived (15 minutes), used for API authorization
- **Refresh Token**: Long-lived (7 days), used to obtain new access tokens
- **ID Token**: Contains user profile information (name, email, picture)

**Token Storage**:

| Platform | Access Token Storage | Refresh Token Storage | Security Mechanism |
|----------|---------------------|----------------------|-------------------|
| Web | Memory (Auth0 SDK) | HTTP-only secure cookie (optional) | XSS protection |
| iOS | Memory (short-term) | iOS Keychain | Biometric protection available |
| Android | Memory (short-term) | Android Keystore | Biometric protection available |
| Desktop | Electron SafeStorage | OS-specific secure storage | OS-level encryption |

**Token Refresh Flow**:
1. Access token expires (after 15 minutes of use)
2. Client attempts API request, receives 401 Unauthorized
3. Client uses refresh token to request new access token from Auth0
4. Auth0 validates refresh token, issues new access token and refresh token
5. Client retries original API request with new access token

**Token Revocation**:
- **Logout**: Client calls Auth0 logout endpoint, invalidates refresh token
- **Security Event**: Admin can revoke tokens via Auth0 dashboard
- **Token Rotation**: Refresh token rotated on each use, previous token invalidated

#### 5.4.4.3 Authorization Model (PBAC)

**Permission-Based Access Control** (PBAC):
- **Permission Format**: `{action}:{resource}` (e.g., `read:documents`, `write:users`)
- **Permission Storage**: Stored in Auth0, included in JWT claims
- **Granularity**: Fine-grained permissions for specific resources and actions

**Common Permissions**:

| Permission | Resource | Action | Description |
|-----------|----------|--------|-------------|
| `read:documents` | documents | read | View document metadata and content |
| `write:documents` | documents | write | Create and update documents |
| `delete:documents` | documents | delete | Delete documents |
| `read:users` | users | read | View user profiles |
| `admin:system` | system | admin | Full administrative access |

**Authorization Enforcement**:

**Endpoint-Level Authorization**:
```python
# Pseudocode example (not actual implementation)
@app.route('/api/v1/documents', methods=['GET'])
@require_auth  # Validates JWT
@require_permissions(['read:documents'])  # Checks permissions
def list_documents():
    # Permission validated, proceed with business logic
    pass
```

**Resource-Level Authorization**:
```python
# Pseudocode example
@app.route('/api/v1/documents/<document_id>', methods=['GET'])
@require_auth
@require_permissions(['read:documents'])
def get_document(document_id):
    document = db.documents.find_one({'_id': document_id})
    
    # Check resource ownership or sharing
    if document['user_id'] != request.user_id:
        # Check if document is shared with user
        if request.user_id not in document.get('shared_with', []):
            return 403 Forbidden
    
    return document
```

**Role-Based Access Control (RBAC)** (Optional):
- **Roles**: Group permissions into roles (e.g., "Admin", "Editor", "Viewer")
- **Assignment**: Assign roles to users in Auth0
- **Inheritance**: Roles can inherit permissions from other roles
- **Use Case**: Simplify permission management for large user bases

### 5.4.5 Performance Requirements and SLAs

#### 5.4.5.1 API Response Time Targets

**Performance Targets** (Planned):

| Endpoint Category | p50 Latency | p95 Latency | p99 Latency | Target |
|------------------|-------------|-------------|-------------|--------|
| Simple CRUD (GET, POST) | < 100ms | < 300ms | < 500ms | 95% of requests |
| Complex Queries (Aggregations) | < 300ms | < 800ms | < 1200ms | 90% of requests |
| AI Completions (Simple) | < 2000ms | < 5000ms | < 8000ms | 90% of requests |
| AI Conversations (Multi-turn) | < 3000ms | < 6000ms | < 10000ms | 85% of requests |
| File Upload (Presigned URL) | < 500ms | < 1500ms | < 3000ms | 95% of requests |

**Latency Budget Breakdown** (Example: CRUD Operation):

| Component | Budget | Typical Actual | Notes |
|-----------|--------|---------------|-------|
| Network (Client to ALB) | 50ms | 20-100ms | Varies by geography |
| ALB Processing | 10ms | 2-5ms | TLS termination, routing |
| JWT Validation | 20ms | 5-10ms | JWKS cached in Redis |
| Business Logic | 20ms | 10-30ms | Depends on complexity |
| Database Query | 50ms | 20-100ms | With proper indexes |
| Response Serialization | 10ms | 5-15ms | JSON serialization |
| **Total** | **160ms** | **62-260ms** | Well within p95 target |

#### 5.4.5.2 Throughput and Scalability Targets

**Throughput Targets** (Planned):

| Metric | Target | Scaling Mechanism |
|--------|--------|-------------------|
| API Requests | 1,000 req/sec per instance | Horizontal scaling via ECS auto-scaling |
| Concurrent Users | 10,000 concurrent users | Add ECS tasks based on load |
| Database Queries | 5,000 queries/sec | MongoDB replica set, read replicas |
| Cache Operations | 50,000 ops/sec | Redis, upgrade to cluster if needed |
| File Uploads | 100 concurrent uploads | Direct S3 uploads, no backend bottleneck |

**Scalability Approach**:

| Resource | Scaling Method | Trigger | Action |
|----------|---------------|---------|--------|
| Flask API | Horizontal (ECS tasks) | CPU > 70% for 5 min | Add 1 task (max 10) |
| MongoDB | Vertical, then horizontal | Connections > 80% | Increase instance size, add sharding |
| Redis | Vertical, then clustering | Memory > 90% | Upgrade instance, Redis Cluster |
| S3 | Automatic | N/A | AWS handles automatically |

#### 5.4.5.3 Availability and Uptime SLAs

**Availability Targets** (Planned):

| Component | SLA Target | Monthly Downtime | Mechanism |
|-----------|------------|-----------------|-----------|
| Overall Application | 99.9% | 43.2 minutes | Multi-AZ deployment, auto-healing |
| Flask API | 99.95% | 21.6 minutes | ECS health checks, auto-restart |
| MongoDB | 99.95% | 21.6 minutes | Replica set auto-failover |
| Redis | 99.9% | 43.2 minutes | ElastiCache multi-AZ (optional) |
| S3 | 99.99% | 4.32 minutes | AWS standard SLA |
| Auth0 | 99.99% | 4.32 minutes | Auth0 enterprise SLA |

**High Availability Mechanisms**:
- **Multi-AZ Deployment**: ALB and ECS tasks deployed across 3 availability zones
- **Auto-Healing**: ECS automatically restarts failed tasks
- **Health Checks**: ALB performs continuous health checks, routes traffic to healthy instances only
- **Database Replication**: MongoDB replica set with automatic failover (< 10 seconds)
- **Backup and Restore**: Daily backups with 30-day retention, point-in-time recovery

**Maintenance Windows**:
- **Scheduled Maintenance**: Weekly 2-hour window (Tuesday 2:00 AM - 4:00 AM UTC)
- **Zero-Downtime Deployments**: Rolling deployments maintain 100% minimum healthy instances
- **Emergency Maintenance**: Rare, announced 24 hours in advance when possible

### 5.4.6 Disaster Recovery

#### 5.4.6.1 Backup Strategy

**MongoDB Backup**:
- **Frequency**: Automated daily backups at 2:00 AM UTC
- **Retention**: 30 days for daily backups, 1 year for monthly backups
- **Method**: MongoDB Atlas automated backups or mongodump to S3
- **Point-in-Time Recovery**: Continuous backup with ability to restore to any point in last 7 days (Atlas feature)
- **Backup Testing**: Quarterly restore drills to verify backup integrity

**S3 Versioning**:
- **Critical Buckets**: `app-backups`, `terraform-state` have versioning enabled
- **Retention**: Previous versions retained for 30 days, then deleted
- **Cross-Region Replication**: Replicate backups to secondary AWS region (future enhancement)

**Application State**:
- **Infrastructure as Code**: All infrastructure reproducible via Terraform
- **Configuration Management**: Secrets stored in AWS Secrets Manager with versioning
- **Container Images**: All Docker images tagged and stored in ECR with retention policy

#### 5.4.6.2 Recovery Objectives

**Recovery Time Objective (RTO)**: < 4 hours
- **Definition**: Maximum acceptable downtime after disaster
- **Target**: Full system recovery within 4 hours of incident detection

**Recovery Point Objective (RPO)**: < 1 hour
- **Definition**: Maximum acceptable data loss
- **Target**: Restore to within 1 hour of failure time using point-in-time recovery

**Recovery Scenarios**:

| Scenario | RTO | RPO | Recovery Procedure |
|----------|-----|-----|-------------------|
| Single ECS Task Failure | < 1 minute | 0 (no data loss) | ECS auto-restarts task |
| MongoDB Primary Failure | < 10 seconds | 0 (no data loss) | Replica set auto-failover |
| Availability Zone Failure | < 5 minutes | 0 (no data loss) | ALB routes to healthy AZ |
| Full Region Failure | < 4 hours | < 1 hour | Manual failover to secondary region |
| Data Corruption | < 4 hours | < 24 hours | Restore from daily backup |

#### 5.4.6.3 Disaster Recovery Procedures

**MongoDB Restore Procedure**:
1. **Identify Restore Point**: Determine timestamp to restore to
2. **Create New Instance**: Provision new MongoDB instance (avoid overwriting production)
3. **Restore Data**: Restore backup to new instance (mongorestore or Atlas restore)
4. **Verify Data Integrity**: Run data validation queries, check record counts
5. **Update Application Configuration**: Point application to new database instance
6. **Monitor**: Closely monitor application logs and metrics after restoration
7. **Post-Mortem**: Document incident, root cause, and preventive measures

**Infrastructure Recovery Procedure**:
1. **Assess Damage**: Determine scope of infrastructure failure
2. **Execute Terraform**: Run `terraform apply` to recreate infrastructure
3. **Deploy Application**: Run CI/CD pipeline to deploy latest application version
4. **Restore Database**: Follow MongoDB restore procedure if needed
5. **Validate Functionality**: Execute smoke tests, verify critical workflows
6. **Monitor**: Continuous monitoring for 24 hours post-recovery

**Incident Response Workflow**:
1. **Detection**: CloudWatch alarms trigger alerts to operations team
2. **Assessment**: Operations team assesses severity, determines if disaster recovery needed
3. **Notification**: Inform stakeholders (engineering, management, customers)
4. **Execution**: Follow disaster recovery procedures for specific scenario
5. **Communication**: Provide status updates every 30 minutes during recovery
6. **Verification**: Validate system functionality, performance, and data integrity
7. **Post-Mortem**: Conduct incident review within 48 hours, document lessons learned

#### 5.4.6.4 Failover and Redundancy

**Database Redundancy**:
- **MongoDB Replica Set**: 3-node configuration (1 Primary + 2 Secondaries)
- **Automatic Failover**: Secondary promoted to Primary within 10 seconds of failure
- **Read Scaling**: Read operations distributed across secondaries (SecondaryPreferred)

**Application Redundancy**:
- **Multi-Instance Deployment**: Minimum 2 ECS tasks running at all times
- **Multi-AZ Distribution**: Tasks spread across 3 availability zones
- **Load Balancing**: ALB distributes traffic across all healthy instances

**Infrastructure Redundancy**:
- **Multi-AZ ALB**: Load balancer nodes deployed across 3 availability zones
- **NAT Gateway**: Deploy NAT Gateway in each availability zone for redundancy (optional)
- **VPN/Direct Connect**: Redundant network connections for hybrid architectures (future)

**Backup Redundancy**:
- **Multi-Region Backups**: Replicate critical backups to secondary AWS region
- **S3 Cross-Region Replication**: Automatically replicate backup bucket to another region
- **Offline Backups**: Periodic offline backups stored securely (quarterly)

---

## 5.5 References

### 5.5.1 Technical Specification Sections Retrieved

The System Architecture section was developed by analyzing the following Technical Specification sections:

- `1.1 Executive Summary` - Project overview and current development stage
- `1.2 System Overview` - System context and pre-implementation status
- `2.2 Feature Catalog` - Feature catalog framework (pending population)
- `2.7 Assumptions and Constraints` - Project constraints and risk factors
- `3.1 Technology Stack Overview` - High-level technology architecture and stack diagram
- `3.2 Programming Languages` - Python 3.11+, TypeScript 5.0+, JavaScript, Swift 5.9+, Kotlin 1.9+, Objective-C 2.0
- `3.3 Frameworks & Libraries` - Flask 3.0+, LangChain 0.1.0+, React 18.2+, React Native 0.72+, Electron 28+, TailwindCSS 3.4+
- `3.4 Open Source Dependencies` - Comprehensive backend and frontend dependency catalog
- `3.5 Third-Party Services` - Auth0, AWS services (ECS, S3, ECR, ALB, CloudWatch, Route 53, CloudFront, Secrets Manager), OpenAI API
- `3.6 Databases & Storage` - MongoDB 7.0+, Redis 7+, Amazon S3, Vector Database (TBD)
- `3.7 Development & Deployment` - Docker 24+, Terraform 1.6+, GitHub Actions, AWS infrastructure
- `3.8 Technology Integration and Compatibility` - Integration matrix, security considerations, cross-platform concerns
- `4.1 Process Flow Overview and Project Context` - Workflow categories and process foundation
- `4.2 CI/CD Workflows` - Backend, frontend, mobile, and infrastructure pipeline specifications
- `4.3 Authentication and Authorization Flows` - Auth0 integration, JWT validation, multi-platform authentication, PBAC
- `4.4 API Request Processing Flows` - Standard request flow, caching strategy, error handling, retry mechanisms
- `4.5 AI/ML Processing Workflows` - LangChain orchestration, LLM completions, conversational AI, RAG-based search

### 5.5.2 Repository Files Examined

The following repository files were examined during architecture analysis:

- `README.md` (root) - Project title "CheckSameRepoNoPrompt" (single line, no additional documentation)
- Repository root directory - Contains only README.md, no source code or infrastructure files present

**Repository Status**: Pre-implementation phase with no code, configuration files, or infrastructure definitions. All architectural details represent planned architecture for future development.

### 5.5.3 Architecture Documentation Sources

All architectural information in this section is derived from:

1. **Planned Architecture** documented in Technical Specification sections 3.x (Technology Stack) and 4.x (Process Flows)
2. **Technology Documentation** from official sources (AWS documentation, Flask documentation, MongoDB documentation, Auth0 documentation, LangChain documentation)
3. **Industry Best Practices** for cloud-native architecture, microservices, security, and observability patterns

**Critical Note**: This System Architecture section describes the **intended design** for the CheckSameRepoNoPrompt project, which has not yet been implemented. The repository currently contains no source code, and all architectural decisions represent the planned approach for future development based on documented specifications.

# 6. SYSTEM COMPONENTS DESIGN

## 6.1 Core Services Architecture

#### SYSTEM ARCHITECTURE

## 6.1 Core Services Architecture

### 6.1.1 Architecture Overview and Implementation Status

#### 6.1.1.1 Architectural Approach

The CheckSameRepoNoPrompt system is architected as a **cloud-native, microservices-oriented platform** designed to deliver scalable, resilient AI-powered functionality across multiple client platforms. The architecture embraces modern distributed systems principles while maintaining operational simplicity through strategic use of AWS managed services and a phased implementation approach.

**Implementation Status**: This section documents the **planned architecture** for the CheckSameRepoNoPrompt system. As of the current state, the repository contains only project documentation with no source code implementation. All architectural details, service boundaries, and technical specifications described herein represent the designed target architecture based on comprehensive technical planning.

The architecture adopts a three-tier pattern optimized for cloud-native deployment:

1. **Presentation Layer**: Multi-platform client applications (Web, Mobile, Desktop) providing user interfaces
2. **Application Layer**: RESTful API backend with integrated AI/ML capabilities deployed as containerized services
3. **Data Layer**: Distributed data storage combining document database, in-memory cache, object storage, and vector database

#### 6.1.1.2 Core Architectural Principles

The services architecture is grounded in six fundamental principles that guide all design decisions:

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **Cloud-Native Design** | Leverage AWS managed services (ECS Fargate, ALB, S3, CloudWatch) | Minimize operational overhead, automatic scaling |
| **API-First Philosophy** | Single RESTful API serves all client platforms | Consistent business logic, simplified maintenance |
| **Stateless Services** | No server-side session state, JWT-based authentication | Enable horizontal scaling without session affinity |
| **Managed Service Preference** | Auth0, MongoDB Atlas, ElastiCache managed offerings | Reduce infrastructure complexity, focus on features |
| **Event-Driven Caching** | Multi-layer caching with TTL and event-based invalidation | Optimize performance, reduce costs |
| **Security by Design** | Authentication at every layer, TLS encryption, PBAC authorization | Comprehensive security posture |

### 6.1.2 Service Component Architecture

#### 6.1.2.1 Service Inventory and Boundaries

The system comprises five core service components, each with clearly defined responsibilities and integration points:

**Backend Application Services**:

| Service | Deployment | Primary Responsibility | Technology Stack |
|---------|-----------|----------------------|------------------|
| **Flask REST API** | ECS Fargate Container | Business logic orchestration, API gateway, authentication enforcement | Python 3.11+, Flask 3.0+, Gunicorn, PyMongo, redis-py, Boto3 |
| **LangChain AI/ML Service** | Integrated with Flask (Phase 1), Separate ECS Service (Phase 2) | AI workflow orchestration, LLM interaction, RAG processing | LangChain 0.1.0+, OpenAI SDK, Vector DB integration |

**External Managed Services**:

| Service | Provider | Primary Responsibility | Integration Method |
|---------|----------|----------------------|-------------------|
| **Auth0 Identity Platform** | Auth0 SaaS | User authentication, JWT issuance, MFA, social login | OAuth 2.0/OIDC, HTTPS REST API |
| **MongoDB Database** | MongoDB Atlas (recommended) or Self-Hosted | Primary data persistence, conversation storage, metadata | MongoDB Wire Protocol, PyMongo driver |
| **Redis Cache** | Amazon ElastiCache (recommended) or Self-Hosted | Performance caching, rate limiting, distributed locking | Redis Protocol, redis-py client |
| **Amazon S3 Storage** | AWS S3 | Object storage for files, static assets, backups | S3 API, Boto3 SDK, Presigned URLs |

#### 6.1.2.2 Flask REST API Service (Primary Backend)

**Service Boundaries and Responsibilities**:

The Flask REST API serves as the central orchestration layer, handling all client requests and coordinating between data stores, caching layers, and external services. This service enforces business rules, validates inputs, manages authentication state, and provides a unified interface for all client platforms.

**Core Responsibilities**:
- RESTful endpoint exposure with comprehensive API versioning
- JWT validation and permission-based access control enforcement
- Request schema validation using Pydantic models
- Rate limiting and quota enforcement via Redis
- Database and cache operation coordination
- External service integration (Auth0, AWS services)
- Structured logging and metrics emission for observability
- Error handling with standardized response formats

**API Endpoint Structure**:

| Category | Endpoints | HTTP Methods | Authentication |
|----------|-----------|--------------|----------------|
| Authentication | `/api/v1/auth/refresh`, `/api/v1/auth/logout` | POST | Required (refresh token) |
| User Management | `/api/v1/users/me`, `/api/v1/users/{id}` | GET, PUT, DELETE | Required |
| Documents | `/api/v1/documents`, `/api/v1/documents/{id}` | GET, POST, PUT, DELETE | Required |
| AI Features | `/api/v1/ai/completions`, `/api/v1/ai/conversations`, `/api/v1/ai/search` | POST, GET | Required |
| File Operations | `/api/v1/files/upload-url`, `/api/v1/files/{id}` | POST, GET, DELETE | Required |
| System | `/api/version`, `/health` | GET | Public |

**Middleware Processing Pipeline**:

The Flask API implements a comprehensive middleware stack that processes every request through six distinct layers:

1. **CORS Middleware**: Validates request origin against allowlist, configures appropriate CORS headers
2. **Request ID Middleware**: Generates unique UUID for distributed tracing and log correlation
3. **JWT Validation Middleware**: Extracts and validates JWT token, verifies signature against Auth0 JWKS
4. **Rate Limiting Middleware**: Enforces per-user API quotas using Redis-backed counters
5. **Request Logging Middleware**: Records structured JSON logs with request metadata and timing
6. **Error Handling Middleware**: Catches exceptions and formats standardized error responses

**Scaling Configuration**:
- Horizontal scaling via ECS auto-scaling (target: 70% CPU utilization)
- Minimum instances: 2 (high availability)
- Maximum instances: 10 (cost control)
- Connection pooling: 50 MongoDB connections, 20 Redis connections per instance

#### 6.1.2.3 LangChain AI/ML Service

**Service Boundaries and Responsibilities**:

The LangChain service specializes in orchestrating artificial intelligence and machine learning workflows, providing a layer of abstraction between the core API and various LLM providers. This service manages conversation memory, generates embeddings, executes vector searches, and coordinates Retrieval-Augmented Generation workflows.

**Core Responsibilities**:
- LLM interaction management through LangChain abstractions
- Conversation memory storage and retrieval from MongoDB
- Vector embedding generation for semantic search capabilities
- RAG workflow orchestration with context document retrieval
- Prompt engineering and template management
- AI interaction logging for cost tracking and analytics
- Token usage monitoring and optimization

**AI Capability Matrix**:

| Capability | Chain Type | Input Requirements | Output Format | Use Case |
|-----------|-----------|-------------------|---------------|----------|
| Simple Completions | LLMChain | User prompt, model parameters | Generated text response | Basic text generation |
| Conversational AI | ConversationChain | Message, conversation history | Contextual response | Multi-turn dialogues |
| Semantic Search (RAG) | RetrievalQA | Query, vector store reference | Answer with source citations | Knowledge base queries |
| Document Q&A | QAChain | Document content, question | Extracted answer | Document interrogation |

**Evolution Strategy**:
- **Phase 1** (Initial): Modular monolith with service boundaries within Flask application
- **Phase 2** (Future): Extract to separate ECS service with dedicated resource allocation
- **Phase 3** (If Needed): Additional microservices extraction for specialized AI capabilities

**Scaling Configuration**:
- Initial: Scales with Flask API instances
- Phase 2: Independent horizontal scaling based on AI request volume
- Rate limiting: 10 AI requests per minute per user (cost control)
- Response caching: 1-hour TTL for identical prompts to reduce OpenAI costs

#### 6.1.2.4 Auth0 Identity Platform (External)

**Service Boundaries and Responsibilities**:

Auth0 provides enterprise-grade identity and access management as an external SaaS platform, handling all user authentication workflows, JWT token lifecycle management, and multi-factor authentication enforcement. The system integrates Auth0 across all client platforms using platform-specific SDKs and OAuth 2.0 standards.

**Core Responsibilities**:
- User authentication via multiple methods (credentials, social login, SSO)
- JWT access token and refresh token issuance
- Multi-factor authentication challenge and verification
- User profile management and metadata storage
- Permission-based access control configuration
- Security features (breached password detection, anomaly detection)

**Token Management Strategy**:

| Token Type | Format | Lifetime | Storage Location | Purpose |
|-----------|--------|----------|------------------|---------|
| Access Token | JWT (RS256 signed) | 15 minutes | Memory (web), Keychain/Keystore (mobile) | API authorization |
| Refresh Token | Opaque string | 7 days | Secure storage only | Silent token renewal |
| ID Token | JWT (RS256 signed) | 15 minutes | Memory or secure storage | User profile information |

**Authentication Flow Pattern**:

Auth0 implements the Authorization Code Flow with PKCE (Proof Key for Code Exchange), providing protection against authorization code interception attacks. This flow consists of eight distinct steps from login initiation through token storage.

#### 6.1.2.5 Data Layer Services

**MongoDB (Primary Database)**:

MongoDB serves as the primary persistence layer for all application data, providing flexible document storage with powerful querying and aggregation capabilities.

**Planned Collections**:

| Collection | Purpose | Key Indexes | Estimated Size |
|-----------|---------|-------------|----------------|
| `users` | User profiles and preferences | auth0_id (unique), email | 100KB per user |
| `conversations` | AI conversation metadata | user_id, created_at | 10KB per conversation |
| `messages` | Conversation message history | conversation_id, created_at | 5KB per message |
| `documents` | Document metadata and references | user_id, created_at, full-text | 50KB per document |
| `ai_interactions` | AI usage logging and analytics | user_id, created_at, type | 20KB per interaction |
| `analytics` | System event tracking | event_type, user_id, timestamp | 5KB per event |
| `files` | File metadata and S3 references | file_id, user_id | 2KB per file |

**High Availability Configuration**:
- 3-node replica set architecture (1 Primary + 2 Secondary nodes)
- Automatic failover with secondary promotion within 10 seconds
- Write Concern: majority (wait for acknowledgment from majority of nodes)
- Read Concern: majority for consistency-critical operations
- Read Preference: SecondaryPreferred for read-heavy operations

**Redis (Caching Layer)**:

Redis provides in-memory caching and data structures for performance optimization, rate limiting, and distributed coordination.

**Cache Use Cases**:

| Use Case | Data Structure | Key Pattern | TTL | Purpose |
|----------|---------------|-------------|-----|---------|
| API Response Cache | String (JSON) | `cache:{endpoint}:{user_id}:{hash}` | 5-60 min | Reduce database query load |
| JWKS Cache | String (JSON) | `jwks:auth0` | 1 hour | Optimize JWT validation performance |
| Rate Limiting | String (counter) | `ratelimit:{user_id}:{endpoint}` | 1 minute | Enforce API usage quotas |
| LLM Response Cache | String (JSON) | `llm:{prompt_hash}` | 1 hour | Reduce OpenAI API costs |
| Distributed Lock | String (SET NX) | `lock:{resource_id}` | 30 seconds | Prevent cache stampede |

**Amazon S3 (Object Storage)**:

S3 provides scalable object storage for user-generated content, static assets, and backup archives.

**Bucket Strategy**:

| Bucket | Purpose | Access Pattern | Encryption | Lifecycle |
|--------|---------|---------------|------------|-----------|
| `app-uploads-prod` | User-generated files | Private (presigned URLs) | SSE-S3 | Retain indefinitely |
| `app-static-assets` | Frontend static files | Public via CloudFront | SSE-S3 | Retain indefinitely |
| `app-backups` | Database backups | Private | SSE-KMS | Glacier after 90 days |
| `terraform-state` | IaC state files | Private | SSE-S3 | Versioning enabled |

### 6.1.3 Inter-Service Communication Architecture

#### 6.1.3.1 Communication Patterns and Protocols

The system employs a hybrid communication strategy optimizing for simplicity, performance, and reliability across different interaction types.

**Primary Pattern: Synchronous RESTful HTTP/JSON**

All client-to-server and most internal service communications utilize synchronous HTTP requests with JSON payloads. This pattern provides universal compatibility, leverages standard HTTP caching infrastructure, and enables straightforward error handling.

**Communication Decision Matrix**:

| Interaction Type | Pattern | Protocol | Rationale |
|-----------------|---------|----------|-----------|
| Client to API | Synchronous HTTP | HTTPS + JSON | Real-time feedback required |
| API to MongoDB | Direct Driver | MongoDB Wire Protocol | Low-latency requirement |
| API to Redis | Direct Client | Redis Protocol | Sub-millisecond operations |
| API to S3 | Presigned URLs | HTTPS (direct client upload) | Bypass API for large files |
| API to Auth0 | Synchronous HTTP | HTTPS + OIDC | Token validation workflow |
| API to LangChain | Function Call | Python module import | In-process communication |
| API to OpenAI | Synchronous HTTP | HTTPS + JSON | LLM completion requests |

**Future Asynchronous Communication** (Phase 2):

For long-running operations exceeding acceptable synchronous timeouts, the architecture plans Celery task queue implementation with Redis broker support. Use cases include batch file processing, large report generation, and expensive multi-step AI operations.

#### 6.1.3.2 Request Flow Architecture

**Standard API Request Flow**:

```mermaid
sequenceDiagram
    participant Client
    participant ALB as Application Load Balancer
    participant API as Flask API Service
    participant Redis as Redis Cache
    participant Auth0
    participant MongoDB
    participant CloudWatch as CloudWatch Logs

    Note over Client,CloudWatch: Complete API Request Flow

    Client->>ALB: HTTPS Request<br/>Authorization: Bearer {JWT}
    ALB->>API: Route to healthy ECS task<br/>(TLS terminated)
    
    rect rgb(240, 248, 255)
        Note over API: Middleware Processing Pipeline
        API->>API: 1. CORS Validation
        API->>API: 2. Generate Request ID (UUID)
        
        API->>Redis: 3. Check JWKS cache
        alt JWKS Cached
            Redis-->>API: Cached public keys
        else JWKS Not Cached
            API->>Auth0: Fetch JWKS
            Auth0-->>API: Public keys
            API->>Redis: Cache JWKS (1hr TTL)
        end
        
        API->>API: 4. Verify JWT signature
        API->>API: 5. Validate JWT claims
        
        API->>Redis: 6. Check rate limit
        Redis-->>API: Rate limit status
        
        alt Rate Limit Exceeded
            API-->>Client: 429 Too Many Requests
        end
        
        API->>API: 7. Validate request schema
        API->>API: 8. Check permissions
    end
    
    rect rgb(255, 250, 240)
        Note over API,MongoDB: Business Logic Execution
        API->>Redis: Check response cache
        
        alt Cache Hit
            Redis-->>API: Cached response
            API->>CloudWatch: Log cache hit
        else Cache Miss
            API->>MongoDB: Execute query
            MongoDB-->>API: Query results
            API->>API: Transform data
            API->>Redis: Store in cache (TTL)
            API->>CloudWatch: Log cache miss
        end
    end
    
    API->>CloudWatch: Log request completion
    API-->>ALB: HTTP Response
    ALB-->>Client: Return response
```

**AI/ML Processing Flow**:

For AI-powered features utilizing LangChain and LLM providers, the request flow includes additional steps for embedding generation, vector search, and prompt engineering.

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant Redis as Redis Cache
    participant LangChain
    participant VectorDB as Vector Database
    participant OpenAI as OpenAI API
    participant MongoDB

    Note over Client,MongoDB: RAG-Based Semantic Search Flow

    Client->>API: POST /api/v1/ai/search<br/>{query: "user question"}
    
    rect rgb(240, 248, 255)
        Note over API: Authentication & Validation
        API->>API: Validate JWT + Check permissions
        API->>Redis: Check AI rate limit (10/min)
        Redis-->>API: Rate limit OK
    end
    
    rect rgb(255, 250, 240)
        Note over API,OpenAI: AI Processing Pipeline
        API->>Redis: Check cached RAG response
        Redis-->>API: Cache miss
        
        API->>LangChain: Initiate semantic search
        
        LangChain->>OpenAI: Generate query embedding<br/>(text-embedding-ada-002)
        OpenAI-->>LangChain: 1536-dim vector
        
        LangChain->>VectorDB: Vector similarity search<br/>(cosine, top_k=5)
        VectorDB-->>LangChain: Relevant documents + scores
        
        LangChain->>LangChain: Construct prompt:<br/>Query + Context Documents
        
        LangChain->>OpenAI: LLM completion with context<br/>(gpt-4-turbo)
        OpenAI-->>LangChain: Generated answer
        
        LangChain-->>API: Response + source citations
    end
    
    rect rgb(250, 255, 240)
        Note over API,MongoDB: Logging & Caching
        API->>MongoDB: Log AI interaction:<br/>(prompt, response, tokens, cost)
        API->>Redis: Cache response (1hr TTL)
        API->>CloudWatch: Emit custom metrics
    end
    
    API-->>Client: 200 OK<br/>{answer, sources, tokens_used}
```

#### 6.1.3.3 File Upload Architecture

The system implements a presigned URL pattern for file uploads, enabling direct client-to-S3 transfers that bypass the API layer for improved performance and reduced backend load.

**File Upload Flow**:

1. **Presigned URL Request**: Client requests upload URL from `/api/v1/files/upload-url` with filename and content type
2. **Authorization Check**: API validates JWT and verifies file upload permissions
3. **URL Generation**: API generates presigned S3 PUT URL with 15-minute expiration using Boto3
4. **Metadata Creation**: API creates file record in MongoDB with pending status
5. **URL Response**: API returns presigned URL, file_id, and upload parameters
6. **Direct Upload**: Client uploads file directly to S3 using presigned URL (bypasses API)
7. **Upload Confirmation**: Client notifies API via `/api/v1/files/complete` endpoint
8. **Metadata Update**: API updates file status to complete in MongoDB

**Benefits**:
- Eliminates API bandwidth bottleneck for large file transfers
- Reduces backend infrastructure costs by offloading traffic to S3
- Improves upload performance with direct S3 connectivity
- Prevents API timeout issues for large file uploads

### 6.1.4 Service Discovery and Load Balancing

#### 6.1.4.1 Application Load Balancer Configuration

The Application Load Balancer serves as the single entry point for all client traffic, providing intelligent traffic distribution, TLS termination, and health-based routing across ECS Fargate tasks.

**ALB Architecture**:
- **Deployment Scope**: Internet-facing load balancer deployed across 3 availability zones
- **Listener Configuration**: HTTPS listener on port 443 with HTTP-to-HTTPS redirect on port 80
- **TLS Termination**: TLS 1.3 with TLS 1.2 fallback, AWS Certificate Manager certificate
- **Target Type**: IP-based targeting for ECS Fargate tasks
- **Path-Based Routing**: Single target group initially, supports future microservices routing

**Load Balancing Strategy**:

| Aspect | Configuration | Purpose |
|--------|--------------|---------|
| **Algorithm** | Round-robin | Distribute traffic evenly across healthy targets |
| **Cross-Zone** | Enabled | Balance traffic across all availability zones |
| **Sticky Sessions** | Disabled | Stateless API design requires no session affinity |
| **Connection Draining** | 30 seconds | Allow in-flight requests to complete during deployments |
| **Idle Timeout** | 60 seconds | Balance connection reuse and resource utilization |

**Health Check Configuration**:

| Parameter | Value | Purpose |
|-----------|-------|---------|
| Protocol | HTTP | Standard HTTP health check |
| Path | `/health` | Dedicated health endpoint |
| Interval | 30 seconds | Frequency of health checks |
| Timeout | 5 seconds | Maximum wait time for response |
| Healthy Threshold | 2 consecutive successes | Marks target as healthy |
| Unhealthy Threshold | 2 consecutive failures | Removes target from rotation |

#### 6.1.4.2 ECS Service Discovery

Amazon ECS Fargate provides serverless container orchestration with automatic service registration and health-aware task management.

**Service Configuration**:
- **Desired Task Count**: 2 (minimum for high availability)
- **Task Definition**: CPU: 0.5 vCPU, Memory: 1GB, Health check: `/health` endpoint
- **Network Mode**: awsvpc (each task receives dedicated ENI)
- **Subnet Placement**: Private subnets across 3 availability zones
- **Security Groups**: Restrict inbound to ALB only, allow outbound to dependencies

**Dynamic Task Registration**:

```mermaid
graph TB
    subgraph "ECS Fargate Cluster"
        Service[ECS Service<br/>Desired Count: 2-10]
        
        subgraph "Availability Zone 1"
            Task1[ECS Task 1<br/>IP: 10.0.1.10]
        end
        
        subgraph "Availability Zone 2"
            Task2[ECS Task 2<br/>IP: 10.0.2.10]
        end
        
        subgraph "Availability Zone 3"
            Task3[ECS Task 3<br/>IP: 10.0.3.10]
        end
    end
    
    Service -.->|Manages| Task1
    Service -.->|Manages| Task2
    Service -.->|Manages| Task3
    
    subgraph "Application Load Balancer"
        ALB[ALB<br/>Multi-AZ]
        TargetGroup[Target Group<br/>Health Checks]
    end
    
    ALB --> TargetGroup
    
    Task1 -->|Auto-Register<br/>IP Target| TargetGroup
    Task2 -->|Auto-Register<br/>IP Target| TargetGroup
    Task3 -->|Auto-Register<br/>IP Target| TargetGroup
    
    TargetGroup -.->|Health Check<br/>HTTP GET /health| Task1
    TargetGroup -.->|Health Check<br/>HTTP GET /health| Task2
    TargetGroup -.->|Health Check<br/>HTTP GET /health| Task3
    
    subgraph "External Traffic"
        Client[Clients<br/>Web, Mobile, Desktop]
    end
    
    Client -->|HTTPS| ALB
    
    CloudWatch[CloudWatch<br/>Logs & Metrics]
    Task1 -.->|Telemetry| CloudWatch
    Task2 -.->|Telemetry| CloudWatch
    Task3 -.->|Telemetry| CloudWatch
```

**Auto-Healing Mechanisms**:
- **Health Check Failure**: ECS automatically stops and replaces unhealthy tasks
- **Task Crash**: Immediate task restart with exponential backoff
- **Deployment Failure**: Automatic rollback after health check failures
- **Maximum Restart Attempts**: 10 attempts before alerting operations team

### 6.1.5 Scalability Architecture

#### 6.1.5.1 Horizontal Scaling Strategy

The architecture prioritizes horizontal scaling for application services, enabling linear capacity growth by adding identical service instances rather than increasing individual instance resources.

**ECS Auto-Scaling Configuration**:

```mermaid
graph LR
    subgraph "Scaling Triggers"
        CPU[CPU Utilization<br/>Target: 70%]
        Memory[Memory Utilization<br/>Target: 80%]
        Requests[Request Count<br/>Threshold: 1000/min]
    end
    
    subgraph "CloudWatch Alarms"
        ScaleOut[Scale Out Alarm<br/>Threshold Exceeded<br/>Duration: 3 minutes]
        ScaleIn[Scale In Alarm<br/>Below Target<br/>Duration: 10 minutes]
    end
    
    subgraph "Auto-Scaling Actions"
        AddTask[Add 1 ECS Task<br/>Max: 10 tasks]
        RemoveTask[Remove 1 ECS Task<br/>Min: 2 tasks]
    end
    
    CPU --> ScaleOut
    Memory --> ScaleOut
    Requests --> ScaleOut
    
    CPU --> ScaleIn
    Memory --> ScaleIn
    
    ScaleOut --> AddTask
    ScaleIn --> RemoveTask
    
    AddTask -.->|Update| CurrentCapacity[Current Task Count]
    RemoveTask -.->|Update| CurrentCapacity
    
    style ScaleOut fill:#ffcccc
    style ScaleIn fill:#ccffcc
```

**Scaling Parameters**:

| Metric | Scale Out Threshold | Scale In Threshold | Cooldown | Action |
|--------|--------------------|--------------------|----------|--------|
| **CPU Utilization** | > 70% for 3 minutes | < 30% for 10 minutes | 3 minutes | Add/remove 1 task |
| **Memory Utilization** | > 80% for 3 minutes | < 40% for 10 minutes | 3 minutes | Add/remove 1 task |
| **Request Count** | > 1000 req/min per task | N/A | 5 minutes | Add 1 task |

**Capacity Limits**:
- **Minimum Tasks**: 2 (ensures high availability during single task failure)
- **Maximum Tasks**: 10 (cost control and reasonable capacity ceiling)
- **Task Resources**: 0.5 vCPU, 1GB RAM per task
- **Maximum Capacity**: 10,000 requests/minute (10 tasks × 1,000 req/min)

#### 6.1.5.2 Vertical Scaling Strategy

Vertical scaling applies to data layer components where increasing individual instance resources provides better performance than horizontal distribution.

**Database Vertical Scaling Path**:

| Growth Stage | Instance Type | CPU | Memory | Connections | Monthly Cost (Est.) |
|-------------|---------------|-----|--------|-------------|---------------------|
| **Initial** | M10 (Atlas) / t3.medium | 2 vCPU | 4GB | 500 | $60 |
| **Growth** | M20 (Atlas) / t3.large | 2 vCPU | 8GB | 1,500 | $160 |
| **Scale** | M30 (Atlas) / m5.xlarge | 4 vCPU | 16GB | 3,000 | $480 |
| **Enterprise** | M40 (Atlas) / m5.2xlarge | 8 vCPU | 32GB | 6,000 | $960 |

**Horizontal Sharding Trigger**: When single-instance vertical scaling reaches practical limits (M40/M50 tier), implement MongoDB sharding with appropriate shard key (user_id recommended).

**Cache Vertical Scaling Path**:

| Growth Stage | Instance Type | Memory | Max Connections | Throughput | Monthly Cost (Est.) |
|-------------|---------------|--------|----------------|------------|---------------------|
| **Initial** | cache.t3.micro | 0.5GB | 1,000 | 5K ops/sec | $12 |
| **Growth** | cache.t3.small | 1.4GB | 2,500 | 15K ops/sec | $25 |
| **Scale** | cache.m5.large | 6.4GB | 10,000 | 50K ops/sec | $90 |
| **Enterprise** | cache.r5.xlarge | 26GB | 40,000 | 100K ops/sec | $200 |

**Redis Cluster Trigger**: When single-node Redis memory exceeds 25GB or operations exceed 100K ops/sec, migrate to Redis Cluster for horizontal scaling.

#### 6.1.5.3 Resource Allocation Strategy

**Connection Pooling Configuration**:

| Resource | Pool Size per Task | Reuse Strategy | Timeout | Rationale |
|----------|-------------------|----------------|---------|-----------|
| **MongoDB Connections** | 50 | Persistent pool | 30s idle timeout | Balance connection overhead vs availability |
| **Redis Connections** | 20 | Persistent pool | 60s idle timeout | Lower pool size for lightweight operations |
| **HTTP Client (Auth0, OpenAI)** | 10 | Session reuse | 30s timeout | Reuse TLS connections for external APIs |

**Task Resource Allocation**:

The ECS task resource allocation balances memory requirements for application code, connection pools, caching, and request buffering:

```mermaid
pie title ECS Task Memory Allocation (1GB Total)
    "Application Runtime" : 400
    "Connection Pools" : 150
    "Request Buffering" : 100
    "Caching Layer" : 200
    "OS & Overhead" : 150
```

#### 6.1.5.4 Performance Optimization Techniques

**Multi-Layer Caching Strategy**:

The architecture implements four caching layers working in concert to minimize latency and reduce load on origin services:

| Layer | Technology | Scope | TTL Range | Cache Hit Rate Target |
|-------|-----------|-------|-----------|----------------------|
| **Client Cache** | Browser Cache | Per-user, device-local | 0-1 hour | 40% (repeat requests) |
| **CDN Cache** | CloudFront | Edge locations, global | 0-1 year | 80% (static assets) |
| **Application Cache** | Redis | Backend services, shared | 30s-24h | 70% (API responses) |
| **Database Cache** | MongoDB | Query results, internal | Auto-managed | 60% (hot data) |

**Cache-Aside Pattern Implementation**:

```mermaid
flowchart TD
    Start[API Request Received] --> CheckCache{Check Redis Cache}
    
    CheckCache -->|Cache Hit| ReturnCached[Return Cached Response]
    CheckCache -->|Cache Miss| AcquireLock{Acquire Distributed Lock}
    
    AcquireLock -->|Lock Acquired| QueryDB[Query MongoDB]
    AcquireLock -->|Lock Held by Another| WaitRetry[Wait 50ms, Retry Cache Check]
    
    WaitRetry --> CheckCache
    
    QueryDB --> Transform[Transform Data to API Format]
    Transform --> StoreCache[Store in Redis with TTL]
    StoreCache --> ReleaseLock[Release Lock]
    ReleaseLock --> ReturnData[Return Response]
    
    ReturnCached --> LogMetrics[Log Cache Hit Metric]
    ReturnData --> LogMiss[Log Cache Miss Metric]
    
    LogMetrics --> End[End]
    LogMiss --> End
    
    style CheckCache fill:#ffffcc
    style AcquireLock fill:#ffcccc
    style ReturnCached fill:#ccffcc
```

**Database Query Optimization**:

| Optimization Technique | Implementation | Impact |
|----------------------|----------------|---------|
| **Index Strategy** | Compound indexes on frequently queried fields | 10-100x query speedup |
| **Aggregation Pipeline** | Use MongoDB aggregation for complex transformations | Reduce application logic complexity |
| **Read Preference** | SecondaryPreferred for read-heavy operations | Distribute read load across replicas |
| **Projection** | Return only required fields | Reduce network transfer, faster serialization |
| **Connection Pooling** | 50 connections per instance | Eliminate connection establishment overhead |

#### 6.1.5.5 Capacity Planning Guidelines

**Throughput Capacity Targets**:

| Metric | Target Capacity | Current Provisioning | Scaling Trigger |
|--------|----------------|---------------------|-----------------|
| **API Requests** | 1,000 req/sec per task | 2,000 req/sec (2 tasks) | Add tasks at 70% CPU |
| **Concurrent Users** | 10,000 concurrent | Calculated from req/sec | Monitor active connections |
| **Database Queries** | 5,000 queries/sec | M10: 500 queries/sec | Upgrade instance tier |
| **Cache Operations** | 50,000 ops/sec | t3.small: 15K ops/sec | Upgrade cache instance |
| **File Uploads** | 100 concurrent | S3: unlimited | No bottleneck |

**Performance Targets by Endpoint Category**:

| Endpoint Category | p50 Latency | p95 Latency | p99 Latency | Capacity Planning Factor |
|------------------|-------------|-------------|-------------|------------------------|
| **Simple CRUD** | < 100ms | < 300ms | < 500ms | 100 req/sec per task |
| **Complex Queries** | < 300ms | < 800ms | < 1200ms | 50 req/sec per task |
| **AI Completions** | < 2000ms | < 5000ms | < 8000ms | 10 req/sec per task |
| **File Upload URLs** | < 500ms | < 1500ms | < 3000ms | 200 req/sec per task |

**Growth Projection Model**:

```mermaid
graph LR
    subgraph "Month 1-3: Initial"
        Users1[100-500 Users]
        Tasks1[2 ECS Tasks]
        DB1[M10 MongoDB]
        Cache1[t3.micro Redis]
    end
    
    subgraph "Month 4-6: Growth"
        Users2[500-2000 Users]
        Tasks2[3-5 ECS Tasks]
        DB2[M20 MongoDB]
        Cache2[t3.small Redis]
    end
    
    subgraph "Month 7-12: Scale"
        Users3[2000-10000 Users]
        Tasks3[5-8 ECS Tasks]
        DB3[M30 MongoDB]
        Cache3[m5.large Redis]
    end
    
    subgraph "Year 2+: Enterprise"
        Users4[10000+ Users]
        Tasks4[8-10 ECS Tasks]
        DB4[M40+ MongoDB<br/>Consider Sharding]
        Cache4[r5.xlarge Redis<br/>Consider Cluster]
    end
    
    Users1 --> Users2
    Users2 --> Users3
    Users3 --> Users4
    
    Tasks1 --> Tasks2
    Tasks2 --> Tasks3
    Tasks3 --> Tasks4
    
    DB1 --> DB2
    DB2 --> DB3
    DB3 --> DB4
    
    Cache1 --> Cache2
    Cache2 --> Cache3
    Cache3 --> Cache4
```

### 6.1.6 Resilience and Fault Tolerance

#### 6.1.6.1 Circuit Breaker Pattern

The circuit breaker pattern protects the system from cascading failures when external dependencies experience degraded performance or outages. The implementation follows a three-state model with automatic recovery testing.

**Circuit Breaker State Machine**:

```mermaid
stateDiagram-v2
    [*] --> Closed: System Initialization
    
    Closed --> Closed: Requests Succeed<br/>(Track Success Rate)
    Closed --> Open: Error Threshold Exceeded<br/>(50% errors in 60-second window)
    
    Open --> Open: Requests Fail Fast<br/>(Return cached data or error)
    Open --> HalfOpen: Recovery Timeout<br/>(30 seconds elapsed)
    
    HalfOpen --> Closed: Test Requests Succeed<br/>(5 consecutive successful requests)
    HalfOpen --> Open: Test Requests Fail<br/>(Any failure during test period)
    
    note right of Closed
        CLOSED STATE
        - Normal operation mode
        - All requests pass through
        - Track error rate continuously
        - Error window: 60 seconds
        - Threshold: 50% failure rate
    end note
    
    note right of Open
        OPEN STATE
        - Circuit breaker active
        - Fail requests immediately
        - Return cached/fallback data
        - Prevent resource exhaustion
        - Duration: 30 seconds
    end note
    
    note right of HalfOpen
        HALF-OPEN STATE
        - Testing recovery
        - Allow limited requests
        - Require 5 consecutive successes
        - Single failure returns to OPEN
    end note
```

**Circuit Breaker Configuration by Service**:

| External Service | Error Threshold | Open Duration | Test Requests | Fallback Strategy |
|-----------------|----------------|---------------|---------------|------------------|
| **OpenAI API** | 50% errors in 60s | 30 seconds | 5 consecutive | Return cached response or disable AI features |
| **MongoDB** | 50% errors in 60s | 30 seconds | 5 consecutive | Return stale cached data with warning |
| **Redis** | 50% errors in 60s | 30 seconds | 5 consecutive | Direct MongoDB queries, disable caching |
| **Auth0 JWKS** | 50% errors in 60s | 30 seconds | 5 consecutive | Use cached JWKS (extend TTL temporarily) |

#### 6.1.6.2 Retry Mechanisms

The system implements intelligent retry strategies with exponential backoff and jitter to handle transient failures without overwhelming failing services.

**Exponential Backoff Algorithm**:

```
Wait Time = min(base_delay × 2^attempt + random_jitter, max_delay)

Where:
- base_delay: 100ms
- attempt: 0, 1, 2 (max 3 attempts)
- random_jitter: Random(0, 100ms)
- max_delay: 5 seconds
```

**Retry Attempt Timeline**:

| Attempt | Base Wait | Jitter Range | Total Wait Range | Cumulative Max |
|---------|-----------|--------------|------------------|----------------|
| 1st retry | 100ms | 0-100ms | 100-200ms | 200ms |
| 2nd retry | 200ms | 0-100ms | 200-300ms | 500ms |
| 3rd retry | 400ms | 0-100ms | 400-500ms | 1000ms |
| Final failure | - | - | - | Total: ~1 second |

**Retry Decision Matrix**:

| Error Type | Retry | Max Attempts | Rationale |
|-----------|-------|--------------|-----------|
| **Network Timeout** | Yes | 3 | Transient network issue, likely to succeed |
| **Connection Refused** | Yes | 3 | Service may be restarting |
| **Rate Limit (429)** | Yes | 3 | Wait for quota reset |
| **Server Error (5xx)** | Yes | 2 | Service may recover quickly |
| **Authentication Error (401)** | No | 0 | Invalid credentials, retry won't help |
| **Authorization Error (403)** | No | 0 | Insufficient permissions, retry won't help |
| **Not Found (404)** | No | 0 | Resource doesn't exist, retry won't help |
| **Validation Error (400)** | No | 0 | Client error, retry without fix won't help |

**Idempotency Requirements**:

To safely retry operations, the system implements idempotency guarantees:

- **POST Requests**: Include `Idempotency-Key` header (UUID) to prevent duplicate resource creation
- **PUT/DELETE Requests**: Naturally idempotent (same operation repeated yields same result)
- **Database Operations**: Use upsert operations and unique constraints to prevent duplicates
- **External API Calls**: Track request IDs and deduplicate within time window

#### 6.1.6.3 Graceful Degradation Strategy

When external dependencies fail, the system implements graceful degradation to maintain partial functionality rather than complete outage.

**Degradation Response Matrix**:

| Failure Scenario | System Response | User Experience | Data Freshness |
|-----------------|----------------|----------------|----------------|
| **MongoDB Unavailable** | Return cached data from Redis with warning banner | Read-only mode with stale data | Last cached: 5-60 minutes |
| **Redis Unavailable** | Direct MongoDB queries, disable rate limiting | Slower response times, potential overload | Real-time data |
| **OpenAI API Down** | Disable AI features, show maintenance notice | AI features temporarily unavailable | N/A |
| **Auth0 Down** | Use cached JWKS for validation, disable new logins | Existing sessions continue, new logins fail | Cached keys: 1 hour |
| **S3 Unavailable** | Block uploads, serve cached files | Upload disabled, downloads from cache | Recent files only |

**Degradation Level Classification**:

```mermaid
graph TD
    Normal[Normal Operation<br/>All Services Available]
    
    Normal --> Level1{Primary DB Slow}
    Normal --> Level2{Cache Unavailable}
    Normal --> Level3{AI Service Down}
    Normal --> Level4{Multiple Failures}
    
    Level1 --> Degraded1[Level 1: Degraded<br/>Slower responses<br/>All features available]
    
    Level2 --> Degraded2[Level 2: Degraded<br/>Direct DB queries<br/>Higher latency]
    
    Level3 --> Degraded3[Level 3: Partial<br/>Core features only<br/>AI features disabled]
    
    Level4 --> Degraded4[Level 4: Critical<br/>Read-only mode<br/>Maintenance banner]
    
    style Normal fill:#ccffcc
    style Degraded1 fill:#ffffcc
    style Degraded2 fill:#ffeecc
    style Degraded3 fill:#ffddcc
    style Degraded4 fill:#ffcccc
```

#### 6.1.6.4 Fault Tolerance Mechanisms

**Multi-Availability Zone Deployment**:

The architecture distributes all critical components across three AWS availability zones to ensure tolerance of zone-level failures.

```mermaid
graph TB
    subgraph "Availability Zone 1"
        ALB1[ALB Node]
        ECS1[ECS Task]
        NAT1[NAT Gateway]
    end
    
    subgraph "Availability Zone 2"
        ALB2[ALB Node]
        ECS2[ECS Task]
        NAT2[NAT Gateway]
    end
    
    subgraph "Availability Zone 3"
        ALB3[ALB Node]
        ECS3[ECS Task]
        NAT3[NAT Gateway]
    end
    
    Internet[Internet Traffic] --> ALB1
    Internet --> ALB2
    Internet --> ALB3
    
    ALB1 --> ECS1
    ALB1 --> ECS2
    ALB1 --> ECS3
    
    ALB2 --> ECS1
    ALB2 --> ECS2
    ALB2 --> ECS3
    
    ALB3 --> ECS1
    ALB3 --> ECS2
    ALB3 --> ECS3
    
    ECS1 --> NAT1
    ECS2 --> NAT2
    ECS3 --> NAT3
    
    subgraph "Data Layer - Multi-AZ"
        MongoDB[(MongoDB Replica Set<br/>Primary + 2 Secondaries<br/>Distributed across AZs)]
        Redis[(Redis<br/>Multi-AZ if ElastiCache)]
        S3[(S3<br/>Automatic Cross-AZ<br/>Replication)]
    end
    
    ECS1 -.-> MongoDB
    ECS2 -.-> MongoDB
    ECS3 -.-> MongoDB
    
    ECS1 -.-> Redis
    ECS2 -.-> Redis
    ECS3 -.-> Redis
    
    NAT1 -.-> MongoDB
    NAT2 -.-> MongoDB
    NAT3 -.-> MongoDB
```

**Failure Impact Analysis**:

| Failure Type | Components Affected | Automatic Recovery | Recovery Time | Data Loss |
|-------------|--------------------|--------------------|---------------|-----------|
| **Single ECS Task Failure** | 1 task (50% capacity with 2 tasks) | ECS restarts task automatically | < 1 minute | None |
| **Availability Zone Failure** | ALB node, ECS tasks, NAT Gateway in zone | ALB routes to healthy zones | < 5 minutes | None |
| **MongoDB Primary Failure** | Write operations temporarily blocked | Replica set promotes secondary | < 10 seconds | None (acknowledged writes) |
| **Redis Failure** | Cache layer, rate limiting | Direct DB queries, degraded performance | Immediate | Cache data only |
| **ALB Failure** | All incoming traffic | AWS replaces ALB (very rare) | 5-15 minutes | None |

**Auto-Healing Configuration**:

| Component | Health Check | Failure Detection | Healing Action | Timeout |
|-----------|-------------|------------------|----------------|---------|
| **ECS Tasks** | HTTP GET /health every 30s | 2 consecutive failures | Stop and replace task | 60 seconds |
| **ALB Targets** | HTTP GET /health every 30s | 2 consecutive failures | Remove from rotation | 60 seconds |
| **MongoDB Replica** | Replica set heartbeat | 10 seconds no response | Promote secondary to primary | 10 seconds |

### 6.1.7 Disaster Recovery Architecture

#### 6.1.7.1 Backup Strategy

**MongoDB Backup Configuration**:

| Backup Type | Frequency | Retention | Method | Storage Location |
|------------|-----------|-----------|--------|-----------------|
| **Full Backup** | Daily at 2:00 AM UTC | 30 days (daily), 1 year (monthly) | MongoDB Atlas automated or mongodump | S3 bucket: `app-backups` |
| **Point-in-Time** | Continuous (Atlas) | 7 days | Oplog-based continuous backup | MongoDB Atlas internal |
| **Incremental** | Every 6 hours | 7 days | Changed documents only | S3 bucket: `app-backups` |

**S3 Versioning and Lifecycle**:

```mermaid
graph LR
    subgraph "S3 Backup Lifecycle"
        Upload[New Backup Uploaded]
        S3Standard[S3 Standard Storage<br/>First 30 Days]
        S3IA[S3 Infrequent Access<br/>Days 31-90]
        Glacier[S3 Glacier<br/>Days 91-365]
        Delete[Automatic Deletion<br/>After 1 Year]
    end
    
    Upload --> S3Standard
    S3Standard -->|30 days| S3IA
    S3IA -->|60 days| Glacier
    Glacier -->|275 days| Delete
    
    subgraph "Cost Optimization"
        Cost1["Standard: $0.023/GB/month<br/>High availability"]
        Cost2["IA: $0.0125/GB/month<br/>Lower cost, occasional access"]
        Cost3["Glacier: $0.004/GB/month<br/>Archival, rare access"]
    end
    
    S3Standard -.-> Cost1
    S3IA -.-> Cost2
    Glacier -.-> Cost3
```

**Infrastructure as Code Backup**:

All infrastructure is defined in Terraform configuration files stored in Git with state files versioned in S3, enabling complete infrastructure recreation from code.

| Asset | Backup Method | Storage | Restoration Time |
|-------|--------------|---------|------------------|
| **Terraform State** | S3 with versioning | `terraform-state` bucket | < 5 minutes |
| **Terraform Code** | Git repository | GitHub | < 5 minutes |
| **Docker Images** | ECR with lifecycle policy | Amazon ECR | < 10 minutes |
| **Application Code** | Git repository | GitHub | < 5 minutes |
| **Secrets** | AWS Secrets Manager | AWS managed | < 1 minute |

#### 6.1.7.2 Recovery Objectives

**RTO (Recovery Time Objective) and RPO (Recovery Point Objective) Targets**:

| Scenario | RTO | RPO | Recovery Procedure | Complexity |
|----------|-----|-----|-------------------|------------|
| **Single ECS Task Failure** | < 1 minute | 0 (no data loss) | Automatic ECS task restart | Low |
| **MongoDB Primary Failure** | < 10 seconds | 0 (no data loss) | Automatic replica set failover | Low |
| **Availability Zone Failure** | < 5 minutes | 0 (no data loss) | ALB routes to healthy AZ | Low |
| **Region-Wide Failure** | < 4 hours | < 1 hour | Manual failover to secondary region | High |
| **Database Corruption** | < 4 hours | < 24 hours | Restore from daily backup | Medium |
| **Complete Infrastructure Loss** | < 8 hours | < 24 hours | Rebuild via Terraform + restore data | High |

**Recovery Priority Matrix**:

```mermaid
graph TD
    Incident[Incident Detected]
    
    Incident --> Assess{Assess Severity}
    
    Assess -->|P0: Critical Outage| P0[Priority 0<br/>RTO: < 1 hour<br/>Complete system down]
    Assess -->|P1: Major Degradation| P1[Priority 1<br/>RTO: < 4 hours<br/>Core features impacted]
    Assess -->|P2: Minor Degradation| P2[Priority 2<br/>RTO: < 24 hours<br/>Non-critical features]
    Assess -->|P3: Monitoring Alert| P3[Priority 3<br/>RTO: < 1 week<br/>No user impact]
    
    P0 --> Team0[All-hands response<br/>24/7 attention<br/>Executive updates]
    P1 --> Team1[Ops team + Engineers<br/>Regular updates<br/>Stakeholder comm]
    P2 --> Team2[Ops team<br/>Normal hours<br/>Status page update]
    P3 --> Team3[Individual engineer<br/>Normal hours<br/>Internal tracking]
    
    style P0 fill:#ff0000,color:#ffffff
    style P1 fill:#ff9900
    style P2 fill:#ffff00
    style P3 fill:#cccccc
```

#### 6.1.7.3 Disaster Recovery Procedures

**MongoDB Restore Procedure**:

1. **Incident Detection**: CloudWatch alarm triggers for database connectivity issues or data corruption
2. **Impact Assessment**: Determine scope (corrupted collections, missing data, complete failure)
3. **Identify Restore Point**: Determine target timestamp for restoration (last known good state)
4. **Provision New Instance**: Create new MongoDB instance to avoid overwriting production
5. **Restore Data**: 
   - Atlas: Use point-in-time restore feature to target timestamp
   - Self-Hosted: Download backup from S3, execute `mongorestore` command
6. **Verify Data Integrity**: Run validation queries, check record counts, verify critical data
7. **DNS/Configuration Cutover**: Update application configuration to point to restored database
8. **Monitor Performance**: Close monitoring for 24 hours post-recovery
9. **Post-Mortem**: Document incident, root cause, timeline, and preventive measures

**Infrastructure Disaster Recovery**:

```mermaid
flowchart TD
    Start[Disaster Detected] --> Stop[Stop Application Traffic<br/>Update DNS/Status Page]
    
    Stop --> Assess{Infrastructure<br/>Salvageable?}
    
    Assess -->|Yes: Partial Failure| Repair[Repair Failed Components<br/>Replace Tasks/Services]
    Assess -->|No: Complete Loss| Rebuild[Full Infrastructure Rebuild]
    
    Rebuild --> TF1[Clone Terraform Repository]
    TF1 --> TF2[terraform init<br/>Load S3 state]
    TF2 --> TF3[terraform plan<br/>Review changes]
    TF3 --> TF4[terraform apply<br/>Provision infrastructure]
    
    TF4 --> Deploy1[Build Docker Images<br/>Push to ECR]
    Deploy1 --> Deploy2[Deploy ECS Services<br/>Run health checks]
    
    Repair --> RestoreDB{Database<br/>Restore Needed?}
    Deploy2 --> RestoreDB
    
    RestoreDB -->|Yes| DB1[Restore MongoDB Backup]
    RestoreDB -->|No| Verify[Verify System Health]
    
    DB1 --> DB2[Verify Data Integrity]
    DB2 --> Verify
    
    Verify --> Smoke[Run Smoke Tests<br/>Critical User Journeys]
    Smoke --> Monitor[Enable Monitoring<br/>Resume Traffic]
    Monitor --> Postmortem[Schedule Post-Mortem<br/>Document Lessons Learned]
    
    style Start fill:#ffcccc
    style Postmortem fill:#ccffcc
```

#### 6.1.7.4 Data Redundancy and Failover

**MongoDB Replica Set Failover**:

The MongoDB replica set provides automatic failover with zero data loss for acknowledged writes:

```mermaid
sequenceDiagram
    participant App as Application
    participant Primary as MongoDB Primary
    participant Secondary1 as MongoDB Secondary 1
    participant Secondary2 as MongoDB Secondary 2
    
    Note over Primary,Secondary2: Normal Operation
    App->>Primary: Write Request (write concern: majority)
    Primary->>Secondary1: Replicate data
    Primary->>Secondary2: Replicate data
    Secondary1-->>Primary: Acknowledge
    Secondary2-->>Primary: Acknowledge
    Primary-->>App: Write Confirmed
    
    Note over Primary,Secondary2: Primary Failure Event
    rect rgb(255, 200, 200)
        Primary-xSecondary1: Heartbeat timeout
        Primary-xSecondary2: Heartbeat timeout
        Secondary1->>Secondary2: Initiate election
        Secondary2->>Secondary1: Vote for S1
        Secondary1->>Secondary1: Elected as new Primary
    end
    
    Note over Primary,Secondary2: Failover Complete (< 10 seconds)
    App->>Secondary1: Write Request<br/>(now Primary)
    Secondary1->>Secondary2: Replicate data
    Secondary2-->>Secondary1: Acknowledge
    Secondary1-->>App: Write Confirmed
    
    Note over Primary,Secondary2: Recovery
    Primary->>Secondary1: Rejoins as Secondary
    Secondary1->>Primary: Sync missed operations
```

**Failover Characteristics**:
- **Detection Time**: 10 seconds (replica set heartbeat interval)
- **Election Time**: < 5 seconds (raft consensus protocol)
- **Total Failover**: < 10 seconds (detection + election)
- **Data Loss**: None (for writes with majority write concern)
- **Application Impact**: Brief connection error, automatic reconnection

**Application-Level Failover**:

| Component | Primary | Secondary | Failover Trigger | Switchover Time |
|-----------|---------|-----------|------------------|-----------------|
| **ALB** | Active ALB | AWS manages replacement | Health check failure | Automatic, < 1 minute |
| **ECS Tasks** | Running tasks | Standby capacity | Task failure | Automatic, < 1 minute |
| **MongoDB** | Primary node | 2 Secondary nodes | Primary heartbeat timeout | Automatic, < 10 seconds |
| **Redis** | Primary node | Replica (if ElastiCache Multi-AZ) | Node failure | Automatic, < 30 seconds |

### 6.1.8 Security and Observability Integration

#### 6.1.8.1 Monitoring Architecture

**CloudWatch Integration**:

The services architecture integrates comprehensive monitoring through Amazon CloudWatch, capturing logs, metrics, and traces from all components.

**Log Aggregation Strategy**:

| Log Source | Log Group | Format | Retention | Query Pattern |
|-----------|-----------|--------|-----------|---------------|
| **Flask API** | `/ecs/flask-api` | Structured JSON | 30 days | Filter by request_id, user_id, endpoint |
| **LangChain Service** | `/ecs/langchain` | Structured JSON | 30 days | Filter by request_id, prompt_hash, tokens |
| **ALB Access Logs** | `/aws/alb/access` | Apache Combined | 30 days | Filter by client_ip, status_code, latency |
| **Application Errors** | `/ecs/flask-api` (level=ERROR) | Structured JSON | 90 days | Filter by error_type, stack_trace |

**Structured Log Format**:
```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456",
  "service": "api",
  "endpoint": "/api/v1/documents",
  "method": "GET",
  "status_code": 200,
  "duration_ms": 45,
  "cache_hit": true,
  "message": "Request processed successfully"
}
```

**Custom Application Metrics**:

| Metric | Type | Dimensions | Alert Threshold | Business Value |
|--------|------|-----------|----------------|----------------|
| `api.request.count` | Counter | service, endpoint, status | N/A | Traffic analysis |
| `api.request.duration` | Histogram | service, endpoint | p95 > 1000ms | Performance SLA |
| `api.error.rate` | Gauge | service, error_type | > 5% | Reliability SLA |
| `ai.tokens.consumed` | Counter | user_id, model | Budget threshold | Cost control |
| `cache.hit.rate` | Gauge | cache_layer | < 70% | Cache efficiency |
| `auth.failed.attempts` | Counter | ip_address | > 100/min | Security threat |

#### 6.1.8.2 Distributed Tracing

**Request ID Propagation Flow**:

```mermaid
sequenceDiagram
    participant Client
    participant ALB
    participant API
    participant LangChain
    participant MongoDB
    participant OpenAI
    
    Note over Client,OpenAI: Request ID Lifecycle
    
    Client->>ALB: HTTP Request
    Note over ALB: Generate UUID<br/>550e8400-e29b...
    ALB->>API: X-Request-ID: 550e8400...
    
    Note over API: Log: [550e8400] Request received
    
    API->>LangChain: AI request with request_id
    Note over LangChain: Log: [550e8400] AI processing
    
    LangChain->>MongoDB: Store with request_id
    Note over MongoDB: Log: [550e8400] Data persisted
    
    LangChain->>OpenAI: External call
    Note over OpenAI: No request_id<br/>(external service)
    OpenAI-->>LangChain: Response
    
    Note over LangChain: Log: [550e8400] OpenAI complete
    
    LangChain-->>API: Response with request_id
    Note over API: Log: [550e8400] Total: 2450ms
    
    API-->>ALB: Response with X-Request-ID
    ALB-->>Client: Response header includes request_id
```

**Log Correlation Example**:

Using CloudWatch Logs Insights to trace complete request lifecycle:
```
fields @timestamp, level, service, message, duration_ms
| filter request_id = "550e8400-e29b-41d4-a716-446655440000"
| sort @timestamp asc
| display @timestamp, service, message, duration_ms
```

#### 6.1.8.3 Security Monitoring

**Security Event Tracking**:

| Event Type | Log Level | Alert Threshold | Response Action |
|-----------|-----------|----------------|-----------------|
| **Failed Authentication** | WARNING | > 5 attempts/min per IP | Rate limit IP, potential ban |
| **Invalid JWT** | WARNING | > 10/min per endpoint | Investigate token source |
| **Permission Denied** | INFO | > 50/min per user | Review user permissions |
| **Rate Limit Exceeded** | WARNING | > 100/min across users | Check for DDoS attack |
| **Unusual AI Usage** | INFO | > 100 requests/hour per user | Monitor for abuse |

### 6.1.9 References

This section was compiled from the following sources within the technical specification and repository:

**Technical Specification Sections**:
- `5.1 High-Level Architecture` - Overall system architecture, service boundaries, and data flows
- `5.2 Component Details` - Detailed specifications for Flask API, LangChain service, Auth0, MongoDB, Redis, S3, ECS, and ALB components
- `5.3 Technical Decisions` - Architectural rationale including cloud-native approach, microservices orientation, communication patterns, and technology selection
- `5.4 Cross-Cutting Concerns` - Monitoring and observability strategy, error handling, authentication framework, performance targets, and disaster recovery procedures

**Repository Files Examined**:
- `README.md` - Project title documentation (only file in repository, no implementation code)

**Key Findings**:
- **Implementation Status**: Repository contains only README.md with project title "CheckSameRepoNoPrompt"
- **Architecture Status**: All service components, communication patterns, and infrastructure configurations represent planned architecture
- **Deployment Model**: Cloud-native AWS deployment with ECS Fargate, Application Load Balancer, and managed data services
- **Service Pattern**: Microservices-oriented with initial modular monolith, phased extraction strategy
- **Scalability Approach**: Horizontal scaling for application services (2-10 ECS tasks), vertical scaling for data layer
- **Resilience Implementation**: Circuit breaker pattern, exponential backoff retry, graceful degradation, multi-AZ deployment
- **Recovery Targets**: RTO < 4 hours, RPO < 1 hour for critical scenarios

---

**Last Updated**: 2024-01-15  
**Architecture Version**: 1.0 (Planned)  
**Next Review**: Upon implementation commencement

## 6.2 Database Design

### 6.2.1 Overview and Implementation Status

**Current Implementation Status**: This repository contains **only a README.md file** with the project title "CheckSameRepoNoPrompt". No database implementation code exists yet. All database design information documented in this section represents **planned architecture** as specified in the technical specification.

**Database Architecture Philosophy**: The system employs a cloud-native, multi-database architecture optimized for scalability, performance, and developer productivity. This approach leverages MongoDB for flexible document storage, Redis for high-performance caching, Amazon S3 for durable object storage, and a to-be-determined vector database for AI/ML embeddings.

### 6.2.2 Database Technology Stack

| Database Type | Technology | Version | Purpose | Deployment |
|--------------|------------|---------|---------|------------|
| Primary Database | MongoDB | 7.0+ | Document storage, application data | MongoDB Atlas (AWS) or Self-hosted ECS |
| Caching Layer | Redis | 7+ | In-memory cache, session storage | Amazon ElastiCache or Self-hosted ECS |
| Object Storage | Amazon S3 | N/A | File uploads, static assets, backups | AWS Managed |
| Vector Database | TBD | TBD | AI embeddings, semantic search | TBD |

---

### 6.2.3 Schema Design

#### 6.2.3.1 MongoDB Primary Database Architecture

**Deployment Strategy**:
- **Recommended Approach**: MongoDB Atlas (Managed Database-as-a-Service on AWS)
- **Alternative Approach**: Self-Hosted MongoDB on AWS ECS Fargate with persistent EBS volumes

**Selection Rationale**:
- **Schema Flexibility**: Document model accommodates evolving data structures without complex migrations
- **Developer Productivity**: JSON-like documents map naturally to application objects, reducing impedance mismatch
- **Horizontal Scalability**: Built-in sharding capability for distributed data storage as dataset grows
- **Rich Query Language**: Powerful aggregation framework enables complex analytical queries
- **Python Integration**: Excellent support through PyMongo 4.6+ (synchronous) and Motor 3.3+ (async) drivers
- **ACID Transactions**: Multi-document transaction support ensures data consistency for critical operations

#### 6.2.3.2 Entity-Relationship Design

#### Collection: `users`

**Purpose**: Store user profiles, preferences, and metadata supplementing Auth0 identity management.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439011"),
  "auth0_id": "auth0|123456789",
  "email": "user@example.com",
  "preferences": {
    "theme": "dark",
    "language": "en",
    "notifications_enabled": true
  },
  "created_at": ISODate("2024-01-15T10:30:00Z"),
  "updated_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: MongoDB ObjectId (primary key, auto-generated)
- `auth0_id`: String, unique identifier from Auth0 identity provider (indexed, unique constraint)
- `email`: String, user email address (indexed for lookup)
- `preferences`: Object, flexible JSON structure for user-specific settings
- `created_at`: DateTime, account creation timestamp
- `updated_at`: DateTime, last modification timestamp

**Indexes**:
- `auth0_id`: Unique index (ensures one MongoDB record per Auth0 user)
- `email`: Single field index (enables efficient email-based queries)

**Estimated Document Size**: ~100 KB per user

**Relationships**:
- **One-to-Many** with `conversations`: A user owns multiple AI conversations
- **One-to-Many** with `documents`: A user uploads multiple documents
- **One-to-Many** with `files`: A user uploads multiple files
- **One-to-Many** with `ai_interactions`: A user generates multiple AI interactions
- **One-to-Many** with `analytics`: A user triggers multiple analytics events

---

#### Collection: `conversations`

**Purpose**: Store AI conversation metadata, tracking user interactions with the LLM.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439012"),
  "user_id": "auth0|123456789",
  "title": "Project Planning Discussion",
  "model": "gpt-4-turbo",
  "created_at": ISODate("2024-01-15T10:30:00Z"),
  "updated_at": ISODate("2024-01-15T11:45:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `user_id`: String, references `users.auth0_id` (indexed, foreign key relationship)
- `title`: String, conversation title (user-defined or auto-generated)
- `model`: String, LLM model identifier (e.g., "gpt-4-turbo", "gpt-3.5-turbo")
- `created_at`: DateTime, conversation initiation timestamp (indexed for chronological queries)
- `updated_at`: DateTime, last message timestamp

**Indexes**:
- `user_id`: Single field index (efficient user conversation retrieval)
- `created_at`: Single field index (chronological sorting)
- `{user_id: 1, created_at: -1}`: Compound index (optimized for paginated user conversation lists)

**Estimated Document Size**: ~10 KB per conversation

**Relationships**:
- **Many-to-One** with `users`: Many conversations belong to one user
- **One-to-Many** with `messages`: One conversation contains multiple messages

---

#### Collection: `messages`

**Purpose**: Store individual messages within AI conversations, maintaining complete conversation history.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439013"),
  "conversation_id": ObjectId("507f1f77bcf86cd799439012"),
  "role": "user",
  "content": "What are the best practices for database indexing?",
  "tokens": 12,
  "created_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `conversation_id`: ObjectId, references `conversations._id` (indexed, foreign key relationship)
- `role`: String, enum: "user" (human), "assistant" (AI), "system" (system prompt)
- `content`: String, message text content
- `tokens`: Integer, token count for cost tracking and context window management
- `created_at`: DateTime, message creation timestamp (indexed for chronological retrieval)

**Indexes**:
- `conversation_id`: Single field index (efficient message retrieval for conversation)
- `created_at`: Single field index (chronological sorting)
- `{conversation_id: 1, created_at: 1}`: Compound index (optimized chronological message retrieval per conversation)

**Estimated Document Size**: ~5 KB per message

**Relationships**:
- **Many-to-One** with `conversations`: Many messages belong to one conversation

---

#### Collection: `documents`

**Purpose**: Store metadata for user-uploaded documents, with actual file content stored in Amazon S3.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439014"),
  "user_id": "auth0|123456789",
  "s3_key": "uploads/2024/01/15/507f1f77bcf86cd799439014-document.pdf",
  "filename": "quarterly-report-q4-2023.pdf",
  "size": 2048576,
  "mime_type": "application/pdf",
  "created_at": ISODate("2024-01-15T10:30:00Z"),
  "metadata": {
    "tags": ["finance", "quarterly"],
    "description": "Q4 2023 Financial Report"
  }
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `user_id`: String, references `users.auth0_id` (indexed)
- `s3_key`: String, Amazon S3 object key for file retrieval
- `filename`: String, original filename (full-text search indexed)
- `size`: Integer, file size in bytes
- `mime_type`: String, file MIME type (e.g., "application/pdf", "image/jpeg")
- `created_at`: DateTime, upload timestamp (indexed)
- `metadata`: Object, flexible custom metadata (tags, description, etc.)

**Indexes**:
- `user_id`: Single field index (user document retrieval)
- `created_at`: Single field index (chronological sorting)
- `{user_id: 1, created_at: -1}`: Compound index (paginated user document lists)
- Full-text search index on `filename` and `metadata` fields (enables search functionality)

**Estimated Document Size**: ~50 KB per document

**Relationships**:
- **Many-to-One** with `users`: Many documents belong to one user
- **One-to-One** with S3 object: Each document metadata record references one S3 object

---

#### Collection: `ai_interactions`

**Purpose**: Log all AI/ML API interactions for cost tracking, usage analytics, and debugging.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439015"),
  "user_id": "auth0|123456789",
  "type": "completion",
  "prompt": "Summarize the following document...",
  "response": "This document discusses...",
  "tokens": 450,
  "cost": 0.0135,
  "model": "gpt-4-turbo",
  "created_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `user_id`: String, references `users.auth0_id` (indexed)
- `type`: String, enum: "completion", "conversation", "search" (indexed for filtering)
- `prompt`: String, user input/prompt sent to LLM
- `response`: String, LLM-generated response
- `tokens`: Integer, total tokens consumed (prompt + completion)
- `cost`: Decimal, estimated cost in USD based on model pricing
- `model`: String, LLM model identifier
- `created_at`: DateTime, interaction timestamp (indexed)

**Indexes**:
- `user_id`: Single field index (user usage tracking)
- `created_at`: Single field index (time-series queries)
- `type`: Single field index (filter by interaction type)
- `{user_id: 1, created_at: -1, type: 1}`: Compound index (user analytics queries)

**Estimated Document Size**: ~20 KB per interaction

**Relationships**:
- **Many-to-One** with `users`: Many AI interactions belong to one user

---

#### Collection: `analytics`

**Purpose**: Track application events, user behavior, and system metrics for product analytics.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439016"),
  "event_type": "document_uploaded",
  "user_id": "auth0|123456789",
  "metadata": {
    "file_size": 2048576,
    "mime_type": "application/pdf",
    "source": "web_app"
  },
  "timestamp": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `event_type`: String, event category identifier (indexed)
- `user_id`: String, references `users.auth0_id` (indexed)
- `metadata`: Object, event-specific contextual data
- `timestamp`: DateTime, event occurrence time (indexed)

**Indexes**:
- `event_type`: Single field index (filter events by type)
- `user_id`: Single field index (user behavior tracking)
- `timestamp`: Single field index (time-series analysis)
- `{event_type: 1, timestamp: -1}`: Compound index (event analytics queries)

**Estimated Document Size**: ~5 KB per event

**Relationships**:
- **Many-to-One** with `users`: Many analytics events belong to one user

---

#### Collection: `files`

**Purpose**: Track file upload status and metadata during presigned URL upload workflow.

**Schema Structure**:
```json
{
  "file_id": "uuid-v4-550e8400-e29b-41d4",
  "user_id": "auth0|123456789",
  "s3_key": "uploads/2024/01/15/uuid-v4-550e8400-e29b-41d4.pdf",
  "filename": "document.pdf",
  "size": 2048576,
  "status": "complete",
  "created_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `file_id`: String, UUID v4 unique identifier (unique index, primary key alternative)
- `user_id`: String, references `users.auth0_id` (indexed)
- `s3_key`: String, S3 object key
- `filename`: String, original filename
- `size`: Integer, file size in bytes
- `status`: String, enum: "pending" (upload initiated), "complete" (upload finished), "failed" (upload error)
- `created_at`: DateTime, record creation timestamp

**Indexes**:
- `file_id`: Unique index (primary identifier for file operations)
- `user_id`: Single field index (user file retrieval)
- `{user_id: 1, created_at: -1}`: Compound index (user file lists)

**Estimated Document Size**: ~2 KB per file

**Relationships**:
- **Many-to-One** with `users`: Many files belong to one user
- **One-to-One** with S3 object: Each file record references one S3 object

---

#### 6.2.3.3 Entity-Relationship Diagram

```mermaid
erDiagram
    USERS ||--o{ CONVERSATIONS : "owns"
    USERS ||--o{ DOCUMENTS : "uploads"
    USERS ||--o{ FILES : "uploads"
    USERS ||--o{ AI_INTERACTIONS : "generates"
    USERS ||--o{ ANALYTICS : "triggers"
    
    CONVERSATIONS ||--o{ MESSAGES : "contains"
    
    USERS {
        ObjectId _id PK
        string auth0_id UK "Unique, Indexed"
        string email "Indexed"
        object preferences
        datetime created_at
        datetime updated_at
    }
    
    CONVERSATIONS {
        ObjectId _id PK
        string user_id FK "Indexed, ref: users.auth0_id"
        string title
        string model "LLM model identifier"
        datetime created_at "Indexed"
        datetime updated_at
    }
    
    MESSAGES {
        ObjectId _id PK
        ObjectId conversation_id FK "Indexed, ref: conversations._id"
        string role "Enum: user, assistant, system"
        string content
        integer tokens
        datetime created_at "Indexed"
    }
    
    DOCUMENTS {
        ObjectId _id PK
        string user_id FK "Indexed, ref: users.auth0_id"
        string s3_key "S3 object key"
        string filename "Full-text indexed"
        integer size "Bytes"
        string mime_type
        object metadata "Custom tags, description"
        datetime created_at "Indexed"
    }
    
    AI_INTERACTIONS {
        ObjectId _id PK
        string user_id FK "Indexed, ref: users.auth0_id"
        string type "Indexed, Enum: completion, conversation, search"
        string prompt
        string response
        integer tokens
        decimal cost "USD"
        string model
        datetime created_at "Indexed"
    }
    
    ANALYTICS {
        ObjectId _id PK
        string event_type "Indexed"
        string user_id FK "Indexed, ref: users.auth0_id"
        object metadata "Event-specific data"
        datetime timestamp "Indexed"
    }
    
    FILES {
        string file_id PK "UUID v4, Unique, Indexed"
        string user_id FK "Indexed, ref: users.auth0_id"
        string s3_key "S3 object key"
        string filename
        integer size "Bytes"
        string status "Enum: pending, complete, failed"
        datetime created_at
    }
```

#### 6.2.3.4 Indexing Strategy

**Indexing Philosophy**: Indexes are created based on query patterns, prioritizing frequently executed queries while balancing write performance overhead. All indexes are created with appropriate direction (ascending/descending) to optimize sort operations.

#### Index Categories

**Primary Indexes** (Unique Constraints):

| Collection | Field | Type | Purpose |
|-----------|-------|------|---------|
| `users` | `auth0_id` | Unique | Ensure one MongoDB record per Auth0 user |
| `files` | `file_id` | Unique | Primary identifier for file operations |

**Single Field Indexes** (Lookup and Filter):

| Collection | Field | Purpose | Query Pattern |
|-----------|-------|---------|---------------|
| `users` | `email` | Email-based user lookup | `db.users.find({email: "user@example.com"})` |
| `conversations` | `user_id` | User conversation retrieval | `db.conversations.find({user_id: "auth0\|123"})` |
| `conversations` | `created_at` | Chronological sorting | `db.conversations.find().sort({created_at: -1})` |
| `messages` | `conversation_id` | Message retrieval for conversation | `db.messages.find({conversation_id: ObjectId})` |
| `messages` | `created_at` | Chronological message ordering | `db.messages.find().sort({created_at: 1})` |
| `documents` | `user_id` | User document retrieval | `db.documents.find({user_id: "auth0\|123"})` |
| `documents` | `created_at` | Chronological sorting | `db.documents.find().sort({created_at: -1})` |
| `ai_interactions` | `user_id` | User AI usage tracking | `db.ai_interactions.find({user_id: "auth0\|123"})` |
| `ai_interactions` | `created_at` | Time-series analysis | `db.ai_interactions.find().sort({created_at: -1})` |
| `ai_interactions` | `type` | Filter by interaction type | `db.ai_interactions.find({type: "completion"})` |
| `analytics` | `event_type` | Event type filtering | `db.analytics.find({event_type: "document_uploaded"})` |
| `analytics` | `user_id` | User behavior tracking | `db.analytics.find({user_id: "auth0\|123"})` |
| `analytics` | `timestamp` | Time-series analysis | `db.analytics.find().sort({timestamp: -1})` |
| `files` | `user_id` | User file retrieval | `db.files.find({user_id: "auth0\|123"})` |

**Compound Indexes** (Multi-Field Queries):

| Collection | Fields | Purpose | Query Pattern |
|-----------|--------|---------|---------------|
| `conversations` | `{user_id: 1, created_at: -1}` | Paginated user conversation lists | User-specific conversations sorted by recency |
| `messages` | `{conversation_id: 1, created_at: 1}` | Chronological message retrieval | Messages for specific conversation in order |
| `documents` | `{user_id: 1, created_at: -1}` | Paginated user document lists | User-specific documents sorted by recency |
| `ai_interactions` | `{user_id: 1, created_at: -1, type: 1}` | User AI analytics queries | User-specific AI interactions by type and time |
| `analytics` | `{event_type: 1, timestamp: -1}` | Event analytics queries | Events by type sorted by recency |
| `files` | `{user_id: 1, created_at: -1}` | User file lists | User-specific files sorted by recency |

**Text Indexes** (Full-Text Search):

| Collection | Fields | Purpose |
|-----------|--------|---------|
| `documents` | `filename`, `metadata` | Enable keyword search on document names and custom metadata |

#### Index Performance Targets

| Metric | Target | Rationale |
|--------|--------|-----------|
| Query Execution Time (Indexed) | < 50ms | Ensure responsive user experience |
| Index Size Overhead | < 10% of total data size | Balance query performance with storage costs |
| Index Build Time | Background creation only | Avoid blocking database operations |

#### Index Maintenance Strategy

**Monitoring**:
- Utilize MongoDB profiler to log slow queries (> 100ms execution time)
- Analyze query execution plans using `explain()` to verify index usage
- Track index size growth relative to data size

**Optimization**:
- Review index usage statistics monthly
- Remove unused indexes identified by zero `accesses` count in `db.collection.aggregate([{$indexStats: {}}])`
- Create new indexes based on slow query analysis

**Reindexing**:
- Schedule reindex operations during maintenance windows (Tuesday 2:00 AM - 4:00 AM UTC)
- Use background index builds (`{background: true}`) to minimize impact on operations

---

#### 6.2.3.5 Partitioning Approach

**Current Strategy**: Single MongoDB instance or replica set without sharding (sufficient for initial deployment).

**Sharding Not Required Initially Because**:
- Dataset expected to remain under 500GB in first year
- Single replica set can handle anticipated query load (< 5,000 queries/second)
- Vertical scaling (upgrading instance size) sufficient for growth

**Future Horizontal Sharding Triggers**:

| Trigger Condition | Current Capacity | Action |
|------------------|------------------|--------|
| Dataset size exceeds 1TB | Single instance practical limit | Enable sharding |
| Read/write throughput exceeds 5,000 ops/sec | Single instance saturation | Enable sharding |
| Vertical scaling reaches practical limits | M40/M50 tier in MongoDB Atlas | Transition to sharding |
| Multi-tenancy requirements emerge | Single tenant architecture | Shard by tenant_id |

#### Recommended Shard Key Selection

**Primary Shard Key**: `user_id` or `tenant_id`

**Rationale**:
- **Query Targeting**: Most queries filter by `user_id`, enabling efficient routing to specific shards
- **Data Isolation**: User data naturally partitioned across shards for security and compliance
- **Scalability**: High cardinality field supports balanced distribution across shards
- **Multi-Tenancy**: Facilitates future tenant-level data isolation

**Alternative Shard Keys**:

| Shard Key | Pros | Cons | Use Case |
|-----------|------|------|----------|
| Hashed `_id` | Even distribution | Loses query targeting | No dominant query pattern |
| `created_at` | Time-based partitioning | Hot shard problem | Archival-focused workloads |
| Compound `{user_id, created_at}` | Combines targeting and chronology | Increased complexity | Complex query patterns |

**Sharding Considerations**:
- Avoid low-cardinality shard keys (e.g., `status` with only 3 values)
- Monitor shard distribution balance using MongoDB balancer
- Plan for zone sharding if geographic data residency required (GDPR compliance)

---

#### 6.2.3.6 Replication Configuration

#### MongoDB Replica Set Architecture

**Configuration**: 3-node replica set for high availability and read scalability.

**Node Roles**:

| Node | Role | Responsibilities | Deployment |
|------|------|-----------------|------------|
| **Primary** | Read/Write | Handles all write operations, primary source for reads | AWS Availability Zone 1 |
| **Secondary 1** | Read-Only Replica | Replicates from Primary, serves read queries | AWS Availability Zone 2 |
| **Secondary 2** | Read-Only Replica | Replicates from Primary, serves read queries | AWS Availability Zone 3 |

**Multi-AZ Deployment Benefits**:
- **High Availability**: Automatic failover if Primary fails
- **Disaster Recovery**: Data replicated across physically separate data centers
- **Reduced Latency**: Secondaries distributed geographically for read-heavy workloads
- **Maintenance Windows**: Perform rolling upgrades without downtime

#### Replication Mechanism

**Oplog-Based Replication**:
- Primary node records all write operations in operations log (oplog)
- Secondary nodes continuously pull oplog entries and apply them locally
- Asynchronous replication with eventual consistency (typically < 1 second lag)

**Replication Flow**:
```
Write Operation → Primary Node → Oplog → Secondary Nodes (async) → Data Synchronized
```

#### Write Concern Configuration

**Write Concern**: `majority`

**Behavior**:
- Application write operations wait for acknowledgment from a majority of replica set members (2 out of 3 nodes)
- Ensures write durability (data survives Primary failure)
- Prevents rollback scenarios during failover

**Trade-offs**:
- **Benefit**: Strong durability guarantee, no data loss on failover
- **Cost**: Slightly higher write latency (~5-10ms overhead for network round-trip to Secondary)

**Configuration Example**:
```python
# Pseudocode representation (not actual implementation)
result = db.documents.insert_one(
    document,
    write_concern=WriteConcern(w='majority', wtimeout=5000)
)
```

#### Read Concern Configuration

**Read Concern**: `majority`

**Use Cases**: Consistency-critical operations requiring latest committed data.

**Behavior**:
- Application reads data that has been acknowledged by a majority of replica set members
- Guarantees no rollback of read data during failover
- Essential for financial transactions, audit logs, compliance-critical operations

**Configuration Example**:
```python
# Pseudocode representation
document = db.documents.find_one(
    {'_id': document_id},
    read_concern=ReadConcern('majority')
)
```

#### Read Preference Strategy

**Read Preference Modes**:

| Mode | Use Case | Target Nodes | Rationale |
|------|----------|--------------|-----------|
| **primary** | Write operations, consistency-critical reads | Primary only | Guaranteed latest data |
| **secondaryPreferred** | Read-heavy analytics, reporting | Secondary (fallback: Primary) | Offload read traffic from Primary |
| **nearest** | Geographic distribution (future) | Node with lowest network latency | Minimize read latency for global users |

**Query Routing Strategy**:

| Query Type | Read Preference | Example Query |
|-----------|----------------|---------------|
| User profile reads | `primary` | `db.users.find_one({auth0_id: user_id})` |
| Conversation history | `secondaryPreferred` | `db.messages.find({conversation_id: conv_id})` |
| Analytics queries | `secondaryPreferred` | `db.analytics.aggregate([...])` |
| Document retrieval | `secondaryPreferred` | `db.documents.find({user_id: user_id})` |
| All write operations | `primary` (always) | `db.documents.insert_one(...)` |

**Read Distribution Benefits**:
- Offload 40% of read traffic to Secondary nodes
- Improve write throughput on Primary (reduced read contention)
- Scale read capacity horizontally by adding Secondary nodes

#### Replication Lag Monitoring

**Target Replication Lag**: < 1 second under normal conditions

**Monitoring Metrics**:

| Metric | Alert Threshold | Action |
|--------|----------------|--------|
| Replication lag | > 5 seconds | Investigate network issues, check Secondary resource utilization |
| Oplog window | < 1 hour | Increase oplog size to prevent Secondary falling behind |
| Heartbeat failures | > 3 consecutive failures | Check network connectivity, node health |

**Replication Lag Causes**:
- Network latency or packet loss between nodes
- Heavy write load exceeding Secondary replication capacity
- Secondary node resource constraints (CPU, disk I/O, memory)

#### Automatic Failover Process

**Failure Detection**:
- Replica set members exchange heartbeats every 2 seconds
- **Failure Detection Time**: 10 seconds (5 consecutive missed heartbeats)

**Election Process**:
- Remaining replica set members initiate election using Raft consensus protocol
- **Election Time**: < 5 seconds (typically 2-3 seconds)
- Secondary with highest priority and most up-to-date oplog elected as new Primary

**Total Failover Time**: < 15 seconds from Primary failure to new Primary elected

**Data Loss Guarantee**:
- **Zero data loss** for writes with `majority` write concern
- Uncommitted writes (without majority acknowledgment) may be rolled back

**Application Impact**:
- Brief connection errors (~10-15 seconds) as clients detect new Primary
- PyMongo and Motor drivers automatically reconnect to new Primary
- Implement automatic retry logic in application code for transient connection errors

**Failover Diagram**:

```mermaid
sequenceDiagram
    participant App as Application
    participant P as Primary Node
    participant S1 as Secondary 1
    participant S2 as Secondary 2
    
    Note over P,S2: Normal Operation
    App->>P: Write Request
    P->>S1: Oplog Replication
    P->>S2: Oplog Replication
    P-->>App: Write Acknowledged (majority)
    
    Note over P: Primary Failure Occurs
    P-xApp: Connection Lost
    
    Note over S1,S2: 10 seconds: Heartbeat Timeout
    S1->>S2: Initiate Election
    
    Note over S1,S2: < 5 seconds: Raft Election
    Note over S1: S1 Elected as New Primary
    
    App->>S1: Retry Write Request
    Note over S1: Now Primary
    S1->>S2: Oplog Replication
    S1-->>App: Write Acknowledged
    
    Note over App,S2: Total Downtime: < 15 seconds
```

---

#### 6.2.3.7 Backup Architecture

#### Automated Backup Strategy

**Backup Types and Schedules**:

| Backup Type | Frequency | Method | Storage Location | Retention Policy |
|------------|-----------|--------|------------------|------------------|
| **Full Backup** | Daily at 2:00 AM UTC | MongoDB Atlas automated or mongodump | S3 bucket: `app-backups` | 30 days (daily), 1 year (monthly) |
| **Point-in-Time Backup** | Continuous (oplog-based) | MongoDB Atlas continuous backup | MongoDB Atlas internal | 7 days rolling window |
| **Incremental Backup** | Every 6 hours | Changed documents only | S3 bucket: `app-backups` | 7 days |

#### Backup Lifecycle Management

**S3 Storage Class Transition**:

```mermaid
graph LR
    A[Day 1-30<br/>S3 Standard<br/>$0.023/GB/month] -->|After 30 days| B[Day 31-90<br/>S3 Infrequent Access<br/>$0.0125/GB/month]
    B -->|After 90 days| C[Day 91-365<br/>S3 Glacier<br/>$0.004/GB/month]
    C -->|After 1 year| D[Delete<br/>Except Monthly Backups]
    
    style A fill:#4CAF50
    style B fill:#8BC34A
    style C fill:#2196F3
    style D fill:#FF9800
```

**Lifecycle Rules**:
- **Day 1-30**: S3 Standard (high-frequency access)
- **Day 31-90**: S3 Standard-IA (reduced access, lower cost)
- **Day 91-365**: S3 Glacier (long-term archival, lowest cost)
- **After 1 Year**: Automatic deletion (except first-of-month backups retained indefinitely)

#### MongoDB Atlas Automated Backup Features

**Continuous Backup** (Recommended for Production):
- **Mechanism**: Continuous oplog backup every few seconds
- **Point-in-Time Recovery**: Restore to any second within 7-day window
- **Granularity**: 1-second precision for recovery point selection
- **Use Case**: Recover from data corruption, accidental deletion, application bugs

**Snapshot Backup** (Alternative):
- **Mechanism**: Full database snapshots at scheduled intervals
- **Frequency**: Configurable (hourly, daily, weekly)
- **Retention**: Customizable retention policies
- **Restoration**: Restore entire database to snapshot point

#### Backup Testing and Validation

**Quarterly Restore Drills**:

| Test Type | Frequency | Procedure | Success Criteria |
|-----------|-----------|-----------|------------------|
| **Full Restore** | Quarterly | Restore production backup to test environment | Database fully accessible, data integrity verified |
| **Point-in-Time Restore** | Quarterly | Restore to specific timestamp (e.g., 24 hours ago) | Data matches expected state at target time |
| **Partial Restore** | Quarterly | Restore single collection | Collection data complete, indexes intact |

**Validation Procedures**:
1. **Record Count Verification**: Compare document counts across all collections
2. **Data Integrity Checks**: Verify referential integrity (foreign key relationships)
3. **Index Validation**: Confirm all indexes recreated correctly
4. **Application Testing**: Execute critical application workflows against restored database
5. **Performance Testing**: Verify query performance matches production
6. **Documentation Update**: Document restore procedure with actual timings

**Restore Time Objectives**:
- **Full Database Restore**: < 2 hours (for 100GB database)
- **Single Collection Restore**: < 30 minutes
- **Point-in-Time Restore**: < 1 hour (MongoDB Atlas)

#### Cross-Region Disaster Recovery (Future Enhancement)

**Future Implementation**:
- **Secondary Backup Region**: Replicate backups to geographically distant AWS region (e.g., us-east-1 → us-west-2)
- **S3 Cross-Region Replication**: Asynchronous replication of `app-backups` bucket
- **Manual Failover**: Documented procedure for regional outage recovery
- **RPO**: < 1 hour (time since last backup replication)
- **RTO**: < 4 hours (time to restore and redirect traffic)

---

### 6.2.4 Data Management

#### 6.2.4.1 Migration Procedures

**Current Status**: No database migrations exist yet (no implementation code). This section documents the planned migration strategy for future development.

#### Planned Migration Framework

**Migration Tool Options**:
- **Custom Python Scripts**: Purpose-built migration scripts using PyMongo
- **MongoDB Migration Tools**: Community tools like `mongomigrate` or `migrate-mongo`
- **Application-Level Migrations**: Integrated into Flask application startup

**Migration Structure**:
```
migrations/
├── 001_create_users_collection.py
├── 002_add_preferences_field.py
├── 003_create_conversations_indexes.py
└── README.md
```

**Migration Script Template**:
```python
# Pseudocode representation (not actual implementation)
class Migration:
    def up(self, db):
        """Apply forward migration"""
        db.users.update_many(
            {},
            {'$set': {'preferences': {'theme': 'light', 'language': 'en'}}}
        )
    
    def down(self, db):
        """Rollback migration"""
        db.users.update_many(
            {},
            {'$unset': {'preferences': ''}}
        )
```

#### Migration Types

**Schema Migrations** (Add/Remove Fields):
```python
# Example: Add new field to existing documents
db.documents.update_many(
    {'tags': {'$exists': False}},  # Only documents without tags
    {'$set': {'tags': []}}
)
```

**Data Transformation Migrations**:
```python
# Example: Transform existing data format
for doc in db.documents.find({'old_format_field': {'$exists': True}}):
    new_value = transform(doc['old_format_field'])
    db.documents.update_one(
        {'_id': doc['_id']},
        {'$set': {'new_format_field': new_value}, '$unset': {'old_format_field': ''}}
    )
```

**Index Migrations**:
```python
# Example: Create new compound index
db.conversations.create_index([('user_id', 1), ('created_at', -1)], background=True)
```

#### Migration Execution Workflow

1. **Development Phase**:
   - Develop migration script with `up()` and `down()` methods
   - Test migration on local development database
   - Verify data integrity after migration
   - Test rollback procedure

2. **Staging Environment**:
   - Apply migration to staging database
   - Run full application test suite
   - Validate data consistency
   - Measure migration execution time
   - Verify rollback procedure

3. **Production Deployment**:
   - Schedule migration during maintenance window (Tuesday 2:00 AM - 4:00 AM UTC)
   - Create pre-migration full backup
   - Execute migration with monitoring
   - Validate migration success
   - Monitor application logs and metrics

4. **Post-Migration**:
   - Verify data integrity using validation queries
   - Monitor performance metrics for anomalies
   - Document migration execution time and issues encountered

#### Migration Version Tracking

**Migrations Collection**:
```json
{
  "_id": ObjectId("..."),
  "migration_id": "001_create_users_collection",
  "applied_at": ISODate("2024-01-15T02:05:00Z"),
  "execution_time_ms": 2340,
  "status": "completed"
}
```

**Migration Status**:
- `completed`: Migration applied successfully
- `failed`: Migration encountered error, rolled back
- `partial`: Migration partially completed, manual intervention required

---

#### 6.2.4.2 Versioning Strategy

**Current Approach**: Document versioning **not implemented initially** to reduce complexity.

#### Future Versioning Implementation

**Use Cases Requiring Versioning**:
- Audit trail for document changes (regulatory compliance)
- Collaborative editing with conflict resolution
- Undo/redo functionality for user actions
- Historical analysis of data changes

**Versioning Approach**: Embedded version field with separate history collection.

**Main Document** (Current Version):
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439014"),
  "user_id": "auth0|123456789",
  "title": "Project Proposal",
  "content": "Updated project proposal content...",
  "version": 3,
  "updated_at": ISODate("2024-01-15T10:30:00Z")
}
```

**History Collection** (Version History):
```json
{
  "_id": ObjectId("..."),
  "document_id": ObjectId("507f1f77bcf86cd799439014"),
  "version": 2,
  "content": "Previous project proposal content...",
  "changed_by": "auth0|123456789",
  "changed_at": ISODate("2024-01-14T15:20:00Z"),
  "change_type": "update"
}
```

**Versioning Operations**:

| Operation | Main Document | History Collection |
|-----------|---------------|-------------------|
| **Create** | Insert v1 | No history entry |
| **Update** | Update to v2, store old version in history | Insert v1 history entry |
| **Retrieve Version** | Query history collection by version number | Return specific version |
| **List Versions** | Query history collection by document_id | Return all versions |

**Version Retention Policy**:
- **Recent Versions**: Keep last 30 days of versions online (MongoDB)
- **Archival**: Move older versions to S3 cold storage
- **Compliance**: Retain versions for 7 years in S3 Glacier (audit requirements)

---

#### 6.2.4.3 Archival Policies

#### Data Retention Rules by Data Type

| Data Type | Active Retention | Archival Trigger | Archival Storage | Deletion Policy |
|-----------|-----------------|------------------|------------------|-----------------|
| **User Profiles** | Indefinite | N/A | N/A | Delete on account closure + 30 days |
| **Conversations** | Indefinite (user-controlled) | 1 year inactive | S3 Standard-IA | User can delete anytime |
| **Messages** | Indefinite (user-controlled) | 1 year inactive | S3 Standard-IA | Deleted with parent conversation |
| **AI Interactions** | 6 months online | 6 months age | S3 Standard-IA | Automatic deletion after 2 years |
| **Analytics Events** | 3 months online | 3 months age | S3 Standard-IA | Automatic deletion after 1 year |
| **Audit Logs** | 90 days online | 90 days age | S3 Glacier | Automatic deletion after 7 years |
| **Document Metadata** | Indefinite | N/A | N/A | User can delete anytime |

#### Archival Process Workflow

**Automated Archival Pipeline**:

```mermaid
flowchart TD
    A[Daily Cron Job<br/>2:00 AM UTC] --> B{Identify Documents<br/>Meeting Archival Criteria}
    
    B --> C[Query MongoDB:<br/>created_at < 6 months]
    
    C --> D[Export Documents<br/>to Parquet/JSON]
    
    D --> E[Upload to S3<br/>Bucket: app-archives]
    
    E --> F{Verify Successful<br/>S3 Upload}
    
    F -->|Success| G[Delete from MongoDB]
    F -->|Failed| H[Log Error,<br/>Retry Next Day]
    
    G --> I[Update Archive Metadata<br/>in archives_index Collection]
    
    I --> J[Send Archive Summary<br/>to Operations Team]
    
    H --> J
```

**Archival Execution Steps**:

1. **Identification**: Query MongoDB for documents exceeding retention period
   ```python
   # Pseudocode
   cutoff_date = datetime.now() - timedelta(days=180)
   docs_to_archive = db.ai_interactions.find({'created_at': {'$lt': cutoff_date}})
   ```

2. **Export**: Convert documents to archival format (Parquet for analytics, JSON for general data)
   ```python
   # Pseudocode
   df = pd.DataFrame(list(docs_to_archive))
   df.to_parquet('ai_interactions_2024_q1.parquet', compression='gzip')
   ```

3. **Upload**: Transfer to S3 with appropriate storage class
   ```python
   # Pseudocode
   s3_client.upload_file(
       'ai_interactions_2024_q1.parquet',
       'app-archives',
       'ai_interactions/2024/q1/data.parquet',
       ExtraArgs={'StorageClass': 'STANDARD_IA'}
   )
   ```

4. **Verification**: Confirm successful S3 upload and data integrity
   ```python
   # Pseudocode
   s3_object = s3_client.head_object(Bucket='app-archives', Key='...')
   assert s3_object['ContentLength'] == local_file_size
   ```

5. **Deletion**: Remove archived documents from MongoDB
   ```python
   # Pseudocode
   db.ai_interactions.delete_many({'_id': {'$in': archived_doc_ids}})
   ```

6. **Metadata Update**: Store archive location reference
   ```json
   {
     "_id": ObjectId("..."),
     "collection": "ai_interactions",
     "period": "2024-Q1",
     "document_count": 125000,
     "s3_key": "ai_interactions/2024/q1/data.parquet",
     "archived_at": ISODate("2024-07-15T02:30:00Z")
   }
   ```

#### Archive Retrieval Process

**Use Cases for Archive Retrieval**:
- Compliance audit requests
- User requests for historical data
- Legal discovery requests
- Long-term trend analysis

**Retrieval Procedure**:
1. Query `archives_index` collection to locate archive file
2. Download archive file from S3
3. Load data into temporary analysis environment
4. Extract requested data
5. Optionally restore to MongoDB if frequent access needed

---

#### 6.2.4.4 Data Storage and Retrieval Mechanisms

#### MongoDB Connection Management

**Driver Selection**:

| Driver | Type | Use Case | Version |
|--------|------|----------|---------|
| **PyMongo** | Synchronous | Traditional Flask views, batch jobs | 4.6+ |
| **Motor** | Asynchronous | FastAPI async endpoints, high concurrency | 3.3+ |

**Connection String Management**:
```python
# Pseudocode representation (not actual implementation)
# Connection string retrieved from AWS Secrets Manager
secret = secrets_client.get_secret_value(SecretId='prod/mongodb/connection')
connection_string = json.loads(secret['SecretString'])['MONGODB_URI']

client = MongoClient(
    connection_string,
    maxPoolSize=50,
    minPoolSize=10,
    serverSelectionTimeoutMS=5000
)
```

**Connection Pooling Configuration**:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `maxPoolSize` | 50 connections per API instance | Balance concurrency with MongoDB connection limits |
| `minPoolSize` | 10 connections | Maintain ready connections, reduce latency |
| `maxIdleTimeMS` | 30000 (30 seconds) | Close idle connections to free resources |
| `serverSelectionTimeoutMS` | 5000 (5 seconds) | Fail fast on connection issues |
| `socketTimeoutMS` | 30000 (30 seconds) | Timeout for individual operations |

#### Query Patterns and Best Practices

**Single Document Retrieval**:
```python
# Pseudocode: Fetch single document by ID with user authorization
document = db.documents.find_one({
    '_id': ObjectId(document_id),
    'user_id': user_id  # Ensure user owns document
})

if not document:
    raise NotFoundError("Document not found or access denied")
```

**Paginated List Queries**:
```python
# Pseudocode: Paginated user documents sorted by recency
page = 1
limit = 20
skip = (page - 1) * limit

documents = db.documents.find({'user_id': user_id}) \
    .sort('created_at', -1) \
    .skip(skip) \
    .limit(limit)

total_count = db.documents.count_documents({'user_id': user_id})

return {
    'documents': list(documents),
    'page': page,
    'limit': limit,
    'total': total_count,
    'has_more': skip + limit < total_count
}
```

**Aggregation Pipeline Queries**:
```python
# Pseudocode: User AI usage analytics
pipeline = [
    # Stage 1: Filter by user and date range
    {
        '$match': {
            'user_id': user_id,
            'created_at': {'$gte': start_date, '$lte': end_date}
        }
    },
    # Stage 2: Group by interaction type, sum tokens
    {
        '$group': {
            '_id': '$type',
            'total_interactions': {'$sum': 1},
            'total_tokens': {'$sum': '$tokens'},
            'total_cost': {'$sum': '$cost'}
        }
    },
    # Stage 3: Sort by cost descending
    {
        '$sort': {'total_cost': -1}
    }
]

results = list(db.ai_interactions.aggregate(pipeline))
```

**Bulk Write Operations**:
```python
# Pseudocode: Batch insert multiple documents
from pymongo import InsertOne

operations = [InsertOne(doc) for doc in documents_list]

result = db.documents.bulk_write(
    operations,
    ordered=False,  # Continue on error
    write_concern=WriteConcern(w='majority')
)

print(f"Inserted: {result.inserted_count}, Errors: {len(result.write_errors)}")
```

#### Write Operations with Error Handling

**Insert with Write Concern**:
```python
# Pseudocode: Insert document with majority write concern
from pymongo.write_concern import WriteConcern

result = db.documents.insert_one(
    document,
    write_concern=WriteConcern(w='majority', wtimeout=5000)
)

document_id = result.inserted_id
```

**Update with Optimistic Locking**:
```python
# Pseudocode: Update document with version check (prevent concurrent updates)
result = db.documents.update_one(
    {'_id': document_id, 'version': current_version},
    {
        '$set': {'content': new_content, 'updated_at': datetime.utcnow()},
        '$inc': {'version': 1}
    }
)

if result.matched_count == 0:
    raise ConflictError("Document was modified by another user")
```

**Delete with Cascade**:
```python
# Pseudocode: Delete conversation and all messages (cascade delete)
# Start transaction for atomicity
with client.start_session() as session:
    with session.start_transaction():
        # Delete all messages
        db.messages.delete_many({'conversation_id': conversation_id}, session=session)
        
        # Delete conversation
        result = db.conversations.delete_one({'_id': conversation_id}, session=session)
        
        if result.deleted_count == 0:
            raise NotFoundError("Conversation not found")
```

---

#### 6.2.4.5 Caching Policies

**Comprehensive caching strategy covered in Section 6.2.5 Performance Optimization → 6.2.5.2 Caching Strategy**

---

### 6.2.5 Compliance Considerations

#### 6.2.5.1 Data Retention Rules

**Regulatory Framework**: System designed for compliance with GDPR (General Data Protection Regulation) and CCPA (California Consumer Privacy Act).

#### Active User Data Retention

| Data Category | Retention While Active | Inactive User Policy | Rationale |
|---------------|----------------------|---------------------|-----------|
| **User Profiles** | Indefinite | Retain 2 years after last login | Support account recovery, maintain service continuity |
| **Conversations** | Indefinite (user-controlled) | Retain 2 years after last access | User may return, conversations have long-term value |
| **Documents** | Indefinite (user-controlled) | Retain 2 years after last access | User data ownership principle |
| **AI Interactions** | 2 years online | Archive after 6 months | Cost tracking, compliance audit trail |
| **Analytics Events** | 1 year online | Archive after 3 months | Product analytics, trend analysis |

#### Account Deletion and Right to be Forgotten

**User-Initiated Deletion** (GDPR Article 17):

1. **Grace Period**: 30-day soft delete (account can be restored)
   ```json
   {
     "_id": ObjectId("..."),
     "auth0_id": "auth0|123",
     "status": "pending_deletion",
     "deletion_requested_at": ISODate("2024-01-15T10:30:00Z"),
     "deletion_scheduled_for": ISODate("2024-02-14T10:30:00Z")
   }
   ```

2. **Permanent Deletion** (After 30 days):
   - Delete user profile from `users` collection
   - Delete all conversations and messages
   - Delete all documents metadata (S3 objects deleted)
   - Delete all files metadata (S3 objects deleted)
   - **Anonymize** user_id in analytics and AI interactions (cannot delete aggregated data)
   ```python
   # Pseudocode: Anonymize user_id in historical data
   anonymized_id = hashlib.sha256(user_id.encode()).hexdigest()
   db.analytics.update_many(
       {'user_id': user_id},
       {'$set': {'user_id': anonymized_id}}
   )
   ```

3. **Deletion Certificate**: Generate compliance record
   ```json
   {
     "_id": ObjectId("..."),
     "original_user_id": "REDACTED",
     "deletion_requested_at": ISODate("2024-01-15T10:30:00Z"),
     "deletion_completed_at": ISODate("2024-02-14T10:35:00Z"),
     "data_categories_deleted": [
       "user_profile", "conversations", "messages", "documents", "files"
     ],
     "data_categories_anonymized": ["analytics", "ai_interactions"],
     "deletion_confirmed_by": "automated_process"
   }
   ```

**Exception: Anonymized Aggregated Data**:
- Aggregated analytics cannot be deleted (statistical data, no PII)
- User_id replaced with irreversible cryptographic hash
- Ensures compliance while maintaining business intelligence

#### Audit Log Retention

**Compliance Requirement**: Retain audit logs for 7 years (varies by jurisdiction and industry).

**Audit Log Lifecycle**:
- **Day 1-90**: MongoDB `audit_logs` collection (hot storage, searchable)
- **Day 91-365**: S3 Standard-IA (warm storage, infrequent access)
- **Year 2-7**: S3 Glacier (cold storage, archival)
- **After 7 Years**: Automatic deletion

**Audit Log Access Control**:
- Restricted to compliance team and authorized auditors
- All audit log accesses logged in separate audit trail
- Annual review of access patterns

---

#### 6.2.5.2 Backup and Fault Tolerance Policies

#### Backup Compliance Requirements

**Data Protection Standards**:

| Requirement | Implementation | Compliance Standard |
|-------------|---------------|---------------------|
| **Daily Backups** | Automated daily at 2:00 AM UTC | SOC 2, ISO 27001 |
| **Retention Period** | 30 days online, 1 year archived | GDPR Article 32 (Security) |
| **Backup Testing** | Quarterly restore validation | SOC 2 CC7.4 |
| **Encryption at Rest** | AES-256 encryption | GDPR Article 32, CCPA |
| **Geographic Redundancy** | Cross-region backup (future) | Business continuity requirements |

#### Fault Tolerance Architecture

**High Availability Targets**:

| Component | Availability SLA | Mechanism | RTO | RPO |
|-----------|-----------------|-----------|-----|-----|
| **MongoDB** | 99.95% | 3-node replica set, auto-failover | < 10 seconds | 0 (majority write concern) |
| **Application** | 99.9% | Multi-AZ ECS deployment, auto-scaling | < 5 minutes | 0 (stateless) |
| **S3 Object Storage** | 99.99% | AWS managed redundancy | 0 (AWS SLA) | 0 (durable storage) |
| **Full System** | 99.9% | Combined fault tolerance | < 4 hours | < 1 hour |

**Disaster Scenarios and Recovery**:

| Scenario | Impact | Recovery Procedure | Estimated Downtime |
|----------|--------|-------------------|-------------------|
| **ECS Task Failure** | Single instance down | Automatic task restart | < 1 minute |
| **Availability Zone Failure** | 33% capacity reduction | ALB routes to healthy AZs | 0 (transparent failover) |
| **MongoDB Primary Failure** | Brief connection errors | Replica set auto-elects new Primary | < 15 seconds |
| **Region Failure** | Full service outage | Manual failover to secondary region | < 4 hours (future) |
| **Data Corruption** | Partial data loss | Restore from point-in-time backup | < 2 hours |

---

#### 6.2.5.3 Privacy Controls

#### Data Encryption

**Encryption at Rest**:

| Component | Encryption Method | Key Management | Standard Compliance |
|-----------|------------------|----------------|---------------------|
| **MongoDB** | WiredTiger storage engine encryption | AWS KMS or MongoDB encrypted storage engine | AES-256, FIPS 140-2 |
| **S3 Buckets** | Server-Side Encryption (SSE-S3) | AWS-managed keys | AES-256 |
| **S3 Backups** | Server-Side Encryption (SSE-KMS) | Customer-managed KMS keys | AES-256, audit trail |
| **Redis (Optional)** | ElastiCache encryption at rest | AWS-managed keys | AES-256 |

**Encryption in Transit**:

| Connection Type | Protocol | Certificate Management |
|----------------|----------|------------------------|
| **Client → ALB** | TLS 1.3 | AWS Certificate Manager (ACM) |
| **ALB → ECS** | HTTP (internal VPC) | Private network isolation |
| **ECS → MongoDB** | TLS 1.3 (MongoDB Wire Protocol over TLS) | MongoDB Atlas certificates or self-signed |
| **ECS → Redis** | TLS 1.3 (optional) | ElastiCache in-transit encryption |
| **ECS → S3** | HTTPS (TLS 1.3) | AWS managed |

#### PII (Personally Identifiable Information) Handling

**PII Classification**:

| Data Field | PII Category | Storage Location | Protection Measure |
|-----------|-------------|------------------|-------------------|
| `email` | Direct PII | MongoDB `users` collection | Encrypted at rest, access logged |
| `name` | Direct PII | Auth0 ID token (not stored) | Transient, not persisted |
| `auth0_id` | Pseudonymous identifier | MongoDB (all collections) | Pseudonymization |
| `ip_address` | Indirect PII | Audit logs | Encrypted at rest, 90-day retention |
| `user_id` (analytics) | Pseudonymous | Anonymized hash | One-way hash, irreversible |

**PII Protection Measures**:

**Logging Redaction**:
```python
# Pseudocode: Automatic PII redaction in logs
import logging

class PIIFilter(logging.Filter):
    def filter(self, record):
        record.msg = redact_sensitive_fields(
            record.msg,
            fields=['password', 'token', 'email', 'ssn', 'credit_card']
        )
        return True

logger.addFilter(PIIFilter())
```

**Field-Level Encryption** (Future Enhancement):
```python
# Pseudocode: Encrypt sensitive PII fields before storage
from cryptography.fernet import Fernet

encrypted_email = cipher.encrypt(email.encode())
db.users.update_one(
    {'_id': user_id},
    {'$set': {'email_encrypted': encrypted_email}}
)
```

**Access Audit Trail**:
```python
# Pseudocode: Log all PII accesses
db.audit_logs.insert_one({
    'timestamp': datetime.utcnow(),
    'user_id': admin_user_id,
    'action': 'READ_PII',
    'resource_type': 'users',
    'resource_id': user_id,
    'fields_accessed': ['email', 'name'],
    'ip_address': request.remote_addr,
    'justification': 'Customer support ticket #12345'
})
```

#### Data Anonymization for Analytics

**Anonymization Techniques**:

| Technique | Use Case | Reversibility | GDPR Compliance |
|-----------|----------|---------------|-----------------|
| **Hashing** | User analytics (user_id → hash) | Irreversible (SHA-256) | Fully anonymized |
| **Pseudonymization** | Internal analytics (auth0_id) | Reversible with key | Pseudonymous (still PII) |
| **Aggregation** | Statistical analysis | N/A (no individual data) | Fully anonymized |
| **Differential Privacy** | Research datasets (future) | N/A (statistical noise added) | Fully anonymized |

**Anonymization Example**:
```python
# Pseudocode: Anonymize user_id for research dataset export
import hashlib

def anonymize_user_id(user_id):
    """Irreversibly anonymize user_id"""
    salt = os.environ['ANONYMIZATION_SALT']
    return hashlib.sha256(f"{user_id}{salt}".encode()).hexdigest()

research_data = db.analytics.find({})
for record in research_data:
    record['user_id'] = anonymize_user_id(record['user_id'])
    export_to_csv(record)
```

---

#### 6.2.5.4 Audit Mechanisms

#### Comprehensive Audit Logging

**Audit Log Scope**: All data access, modifications, and deletions logged for compliance and security.

**Audit Log Schema** (`audit_logs` collection):
```json
{
  "_id": ObjectId("..."),
  "timestamp": ISODate("2024-01-15T10:30:00Z"),
  "user_id": "auth0|123456789",
  "action": "UPDATE",
  "resource_type": "documents",
  "resource_id": "507f1f77bcf86cd799439014",
  "ip_address": "203.0.113.45",
  "user_agent": "Mozilla/5.0...",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "changes": {
    "before": {"title": "Old Title"},
    "after": {"title": "New Title"}
  },
  "status": "success"
}
```

**Logged Actions**:

| Action Type | Examples | Retention |
|------------|----------|-----------|
| **CREATE** | New document, new user | 7 years |
| **READ** | View PII, access sensitive data | 7 years |
| **UPDATE** | Modify document, change settings | 7 years |
| **DELETE** | Delete document, delete account | 7 years |
| **AUTH** | Login, logout, token refresh | 1 year |
| **ADMIN** | Admin actions, permission changes | 7 years |

#### Audit Query Capabilities

**Common Audit Queries**:

**View all actions by user**:
```python
# Pseudocode
audit_trail = db.audit_logs.find(
    {'user_id': 'auth0|123456789'}
).sort('timestamp', -1).limit(100)
```

**View all accesses to specific resource**:
```python
# Pseudocode
access_log = db.audit_logs.find({
    'resource_type': 'documents',
    'resource_id': '507f1f77bcf86cd799439014',
    'action': 'READ'
}).sort('timestamp', -1)
```

**Compliance report (all PII accesses in last 90 days)**:
```python
# Pseudocode
from datetime import datetime, timedelta

ninety_days_ago = datetime.utcnow() - timedelta(days=90)

pii_accesses = db.audit_logs.find({
    'timestamp': {'$gte': ninety_days_ago},
    'resource_type': 'users',
    'action': 'READ'
}).sort('timestamp', -1)
```

#### Audit Trail Integrity

**Immutability**:
- Audit logs are **append-only** (no updates or deletes allowed)
- Write permissions restricted to audit logging service
- Read permissions restricted to compliance team and auditors

**Cryptographic Signatures** (Future Enhancement):
```python
# Pseudocode: Sign audit log entries for tamper detection
import hmac
import hashlib

def sign_audit_entry(entry, secret_key):
    """Generate HMAC signature for audit entry"""
    entry_json = json.dumps(entry, sort_keys=True)
    signature = hmac.new(
        secret_key.encode(),
        entry_json.encode(),
        hashlib.sha256
    ).hexdigest()
    entry['signature'] = signature
    return entry
```

**Regular Audit Log Exports**:
- **Frequency**: Weekly export to immutable S3 bucket
- **S3 Object Lock**: Enable WORM (Write Once Read Many) mode
- **Retention**: 7 years in S3 Glacier with compliance mode
- **Verification**: Monthly audit log integrity checks

---

#### 6.2.5.5 Access Controls

#### Database Access Control (RBAC)

**MongoDB User Roles**:

| Role Name | Permissions | Purpose | Assigned To |
|-----------|------------|---------|-------------|
| **application** | Read/write on application collections | Normal application operations | ECS tasks (via IAM role) |
| **backup** | Read-only on all collections | Backup job operations | Backup service |
| **analytics** | Read-only on non-PII fields | Business intelligence queries | Analytics service |
| **admin** | Full database access | Emergency operations, migrations | Database administrators |
| **auditor** | Read-only on audit_logs | Compliance auditing | Compliance team |

**MongoDB Authentication**:
- **Mechanism**: SCRAM-SHA-256 (Salted Challenge Response Authentication Mechanism)
- **Credential Storage**: AWS Secrets Manager (rotated quarterly)
- **Connection String Format**: `mongodb://username:password@host:port/database?authSource=admin`

**Application Role Permissions** (Detailed):
```javascript
// Pseudocode: MongoDB role definition
db.createRole({
  role: "application",
  privileges: [
    {
      resource: { db: "app_db", collection: "users" },
      actions: ["find", "insert", "update", "remove"]
    },
    {
      resource: { db: "app_db", collection: "conversations" },
      actions: ["find", "insert", "update", "remove"]
    },
    // ... other collections
  ],
  roles: []
})
```

#### Application-Level Access Control

**Permission-Based Access Control (PBAC)**:

**JWT Token Claims**:
```json
{
  "sub": "auth0|123456789",
  "permissions": [
    "read:documents",
    "write:documents",
    "delete:documents",
    "read:users"
  ],
  "aud": "https://api.example.com",
  "iss": "https://example.auth0.com/",
  "exp": 1705320600
}
```

**Permission Enforcement**:
```python
# Pseudocode: Endpoint-level permission check
@app.route('/api/v1/documents', methods=['POST'])
@require_auth  # JWT validation
@require_permissions(['write:documents'])  # Permission check
def create_document():
    # User has write:documents permission, proceed
    document = create_document_in_db(request.json)
    return jsonify(document), 201
```

**Resource-Level Authorization**:
```python
# Pseudocode: Verify resource ownership
@app.route('/api/v1/documents/<document_id>', methods=['GET'])
@require_auth
@require_permissions(['read:documents'])
def get_document(document_id):
    document = db.documents.find_one({'_id': ObjectId(document_id)})
    
    # Verify user owns document or document is shared with user
    if document['user_id'] != request.user_id:
        if request.user_id not in document.get('shared_with', []):
            return jsonify({'error': 'Forbidden'}), 403
    
    return jsonify(document), 200
```

**Administrative Access**:
```python
# Pseudocode: Admin permission grants full access
if 'admin:system' in request.user_permissions:
    # Bypass resource ownership checks
    document = db.documents.find_one({'_id': ObjectId(document_id)})
    return jsonify(document), 200
```

#### Network Security

**VPC Isolation**:
- **MongoDB Deployment**: Private subnets only (no public internet access)
- **ECS Tasks**: Private subnets with NAT Gateway for outbound internet
- **ALB**: Public subnets (internet-facing)

**Security Groups**:

| Component | Inbound Rules | Outbound Rules |
|-----------|--------------|----------------|
| **ALB** | Port 443 (HTTPS) from 0.0.0.0/0 | Port 5000 to ECS security group |
| **ECS Tasks** | Port 5000 from ALB security group | All ports to MongoDB, Redis, S3, internet |
| **MongoDB** | Port 27017 from ECS security group | None (no outbound required) |
| **Redis** | Port 6379 from ECS security group | None |

**IP Allowlisting** (MongoDB Atlas):
- If using MongoDB Atlas, configure IP allowlist
- Add NAT Gateway Elastic IP addresses
- No public internet access (0.0.0.0/0 blocked)

---

### 6.2.6 Performance Optimization

#### 6.2.6.1 Query Optimization Patterns

#### Index Usage Verification

**Query Execution Plan Analysis**:
```python
# Pseudocode: Analyze query performance with explain()
explain_result = db.documents.find({
    'user_id': 'auth0|123456789',
    'created_at': {'$gte': start_date}
}).sort('created_at', -1).explain('executionStats')

#### Key metrics to review:
#### - executionTimeMillis: Query execution time
#### - totalKeysExamined: Number of index keys scanned
#### - totalDocsExamined: Number of documents scanned
#### - executionStages: Index usage details

#### Optimal: totalKeysExamined ≈ totalDocsExamined (index covers query)
```

**Query Optimization Checklist**:

| Optimization | Implementation | Impact |
|-------------|----------------|--------|
| **Use Indexes** | Verify `explain()` shows index usage | 10-100x faster queries |
| **Projection** | Return only required fields (`find({}, {title: 1, _id: 1})`) | Reduce network transfer by 50-80% |
| **Limit Results** | Always paginate large result sets | Prevent memory exhaustion |
| **Avoid Collection Scans** | Ensure queries use indexes | 100x+ performance improvement |
| **Compound Index Order** | Match query filter order | Enable index covering |

#### Query Optimization Techniques

**Projection (Field Selection)**:
```python
# BAD: Return entire document (100KB each)
documents = db.documents.find({'user_id': user_id})

#### GOOD: Return only required fields (5KB each)
documents = db.documents.find(
    {'user_id': user_id},
    {'_id': 1, 'title': 1, 'created_at': 1}  # Projection
)
#### Impact: 95% reduction in network transfer
```

**Limit and Skip (Pagination)**:
```python
# BAD: Fetch all documents (potential OOM error)
documents = list(db.documents.find({'user_id': user_id}))

#### GOOD: Paginate results (safe memory usage)
documents = db.documents.find({'user_id': user_id}) \
    .sort('created_at', -1) \
    .skip((page - 1) * limit) \
    .limit(limit)
```

**Aggregation Pipeline (Push Transformations to Database)**:
```python
# BAD: Fetch all data, process in Python
all_interactions = list(db.ai_interactions.find({'user_id': user_id}))
total_tokens = sum(doc['tokens'] for doc in all_interactions)

#### GOOD: Use aggregation pipeline (database-side processing)
pipeline = [
    {'$match': {'user_id': user_id}},
    {'$group': {'_id': None, 'total_tokens': {'$sum': '$tokens'}}}
]
result = list(db.ai_interactions.aggregate(pipeline))[0]
total_tokens = result['total_tokens']
#### Impact: 10-100x faster for large datasets
```

**Index Hints (Force Specific Index)**:
```python
# Force MongoDB to use specific compound index
documents = db.documents.find({'user_id': user_id, 'status': 'active'}) \
    .hint([('user_id', 1), ('created_at', -1)]) \
    .sort('created_at', -1)
```

#### Query Performance Monitoring

**MongoDB Profiler**:
```python
# Enable profiling for slow queries (> 100ms)
db.set_profiling_level(1, slow_ms=100)

#### Query slow operations
slow_queries = db.system.profile.find({
    'millis': {'$gt': 100}
}).sort('ts', -1).limit(20)

for query in slow_queries:
    print(f"Slow query: {query['ns']}, Time: {query['millis']}ms")
    print(f"Query: {query['command']}")
```

**Query Performance Targets**:

| Query Type | Target Latency | Alert Threshold |
|-----------|---------------|-----------------|
| **Indexed Single Document Lookup** | < 10ms | > 50ms |
| **Indexed List Query** (paginated) | < 50ms | > 100ms |
| **Aggregation Query** | < 300ms | > 1000ms |
| **Full Collection Scan** | Avoid entirely | Alert immediately |

---

#### 6.2.6.2 Caching Strategy

#### Multi-Layer Caching Architecture

```mermaid
graph TB
    Client[Client Application]
    
    subgraph "Caching Layers"
        L1[Layer 1: Client Cache<br/>Browser/App Memory]
        L2[Layer 2: CDN Cache<br/>CloudFront]
        L3[Layer 3: Application Cache<br/>Redis]
        L4[Layer 4: Database Cache<br/>MongoDB WiredTiger]
    end
    
    Database[(MongoDB Database)]
    
    Client -->|1. Request| L1
    L1 -->|Cache Miss| L2
    L2 -->|Cache Miss| L3
    L3 -->|Cache Miss| L4
    L4 -->|Cache Miss| Database
    
    Database -.->|Data| L4
    L4 -.->|Data + Cache| L3
    L3 -.->|Data + Cache| L2
    L2 -.->|Data + Cache| L1
    L1 -.->|Data| Client
    
    style L1 fill:#E8F5E9
    style L2 fill:#FFF9C4
    style L3 fill:#FFE0B2
    style L4 fill:#F3E5F5
    style Database fill:#E3F2FD
```

**Layer Comparison**:

| Layer | Technology | Scope | TTL Range | Target Hit Rate | Purpose |
|-------|-----------|-------|-----------|-----------------|---------|
| **Layer 1** | Browser Cache, App Memory | Per-user, device-local | 0 - 1 hour | 40% | Reduce API calls, instant UI updates |
| **Layer 2** | CloudFront CDN | Edge locations, global | 0 - 1 year | 80% (static assets) | Reduce latency, offload origin |
| **Layer 3** | Redis | Backend services, shared | 30s - 24h | 70% | Reduce database load, share across instances |
| **Layer 4** | MongoDB WiredTiger | Database internal | Auto-managed | 60% | Optimize disk I/O, speed up queries |

#### Redis Cache Implementation (Layer 3)

**Use Cases and Data Structures**:

| Use Case | Redis Data Structure | Key Pattern | TTL | Purpose |
|----------|---------------------|-------------|-----|---------|
| **API Response Cache** | String (JSON) | `cache:{endpoint}:{user_id}:{params_hash}` | 5-60 min | Cache expensive database queries |
| **JWKS Cache** | String (JSON) | `jwks:auth0` | 1 hour | Cache Auth0 public keys for JWT validation |
| **Rate Limiting** | String (counter) | `ratelimit:{user_id}:{endpoint}` | 1 minute | Track API request counts per user |
| **LLM Response Cache** | String (JSON) | `llm:{prompt_hash}` | 1 hour | Cache identical LLM prompts (expensive) |
| **Distributed Lock** | String (SET NX EX) | `lock:{resource_id}` | 30 seconds | Prevent cache stampede |
| **Session Storage** | Hash | `session:{session_id}` | 15 minutes | Store temporary session data |

#### Cache-Aside Pattern (Primary Strategy)

```mermaid
flowchart TD
    Start[API Request] --> CheckCache{Check Redis<br/>Cache}
    
    CheckCache -->|Cache Hit| CacheHit[Return Cached Data]
    CheckCache -->|Cache Miss| CacheMiss[Cache Miss]
    
    CacheMiss --> AcquireLock{Try Acquire<br/>Distributed Lock}
    
    AcquireLock -->|Lock Acquired| QueryDB[Query MongoDB]
    AcquireLock -->|Lock Held by Other| WaitRetry[Wait 50ms,<br/>Retry Check Cache]
    
    WaitRetry --> CheckCache
    
    QueryDB --> Transform[Transform Data]
    Transform --> StoreCache[Store in Redis<br/>with TTL]
    StoreCache --> ReleaseLock[Release Lock]
    ReleaseLock --> Return[Return Data to Client]
    
    CacheHit --> LogHit[Log Cache Hit Metric]
    Return --> LogMiss[Log Cache Miss Metric]
    
    LogHit --> End[End]
    LogMiss --> End
    
    style CacheHit fill:#C8E6C9
    style CacheMiss fill:#FFCCBC
    style AcquireLock fill:#FFF9C4
    style QueryDB fill:#BBDEFB
```

**Implementation Pseudocode**:
```python
# Pseudocode: Cache-aside pattern implementation
def get_documents(user_id, page, limit):
    # Generate cache key
    cache_key = f"cache:documents:{user_id}:page{page}:limit{limit}"
    
    # 1. Check cache
    cached_data = redis_client.get(cache_key)
    if cached_data:
        metrics.increment('cache.hit', tags=['endpoint:documents'])
        return json.loads(cached_data)
    
    # 2. Cache miss - acquire lock to prevent stampede
    lock_key = f"lock:documents:{user_id}"
    lock_acquired = redis_client.set(lock_key, '1', nx=True, ex=30)
    
    if not lock_acquired:
        # Another process is fetching data, wait and retry
        time.sleep(0.05)  # 50ms
        return get_documents(user_id, page, limit)  # Retry
    
    try:
        # 3. Query database
        documents = db.documents.find({'user_id': user_id}) \
            .sort('created_at', -1) \
            .skip((page - 1) * limit) \
            .limit(limit)
        
        result = list(documents)
        
        # 4. Store in cache
        redis_client.setex(
            cache_key,
            300,  # 5 minutes TTL
            json.dumps(result, default=str)
        )
        
        metrics.increment('cache.miss', tags=['endpoint:documents'])
        return result
        
    finally:
        # 5. Release lock
        redis_client.delete(lock_key)
```

#### Cache Invalidation Strategies

**Time-Based Expiration (TTL)** - Primary Method:

| Data Type | TTL | Rationale |
|-----------|-----|-----------|
| **Static Configuration** | 24 hours | Rarely changes, safe to cache long |
| **User Profile** | 15 minutes | Matches JWT token lifetime, consistency |
| **API Responses (General)** | 5 minutes | Balance freshness and performance |
| **API Responses (Real-Time)** | 30 seconds | Near real-time data (e.g., active users) |
| **LLM Responses** | 1 hour | Expensive to regenerate, acceptable staleness |
| **JWKS Keys** | 1 hour | Auth0 rotates keys infrequently |

**Event-Based Invalidation** - On Write Operations:
```python
# Pseudocode: Invalidate related cache keys on document creation
def create_document(user_id, document_data):
    # 1. Insert document into MongoDB
    result = db.documents.insert_one(document_data)
    
    # 2. Invalidate all document list cache keys for this user
    pattern = f"cache:documents:{user_id}:*"
    for key in redis_client.scan_iter(match=pattern):
        redis_client.delete(key)
    
    # 3. Optionally invalidate user statistics cache
    redis_client.delete(f"cache:user_stats:{user_id}")
    
    return result
```

**Probabilistic Early Expiration** - Refresh Before TTL Expiry:
```python
# Pseudocode: Refresh cache probabilistically before expiration
import random

def get_cached_data(cache_key, fetch_function, ttl=300):
    cached_data, remaining_ttl = redis_client.get_with_ttl(cache_key)
    
    if cached_data:
        # Probabilistically refresh cache before expiration
        # Higher probability as TTL approaches expiration
        refresh_probability = 1 - (remaining_ttl / ttl)
        
        if random.random() < refresh_probability:
            # Asynchronously refresh cache in background
            background_task(refresh_cache, cache_key, fetch_function, ttl)
        
        return cached_data
    
    # Cache miss, fetch and store
    data = fetch_function()
    redis_client.setex(cache_key, ttl, data)
    return data
```

**Manual Invalidation** - Administrative Override:
```python
# Pseudocode: Admin endpoint to clear specific cache patterns
@app.route('/admin/cache/clear', methods=['POST'])
@require_admin_permission
def clear_cache():
    pattern = request.json.get('pattern')  # e.g., "cache:documents:*"
    
    deleted_count = 0
    for key in redis_client.scan_iter(match=pattern):
        redis_client.delete(key)
        deleted_count += 1
    
    return {'deleted_keys': deleted_count}, 200
```

#### Cache Performance Monitoring

**Key Metrics**:

| Metric | Target | Alert Threshold | Action |
|--------|--------|----------------|--------|
| **Cache Hit Rate** | > 70% | < 60% | Review TTLs, cache key strategies |
| **Cache Memory Usage** | < 80% | > 90% | Scale Redis instance or evict data |
| **Evicted Keys** | < 1% of total | > 5% | Increase memory or reduce TTLs |
| **Average Response Time** | < 10ms | > 50ms | Check network latency, Redis load |

**Monitoring Implementation**:
```python
# Pseudocode: Cache metrics collection
class CacheMetrics:
    def record_hit(self, endpoint):
        metrics.increment('cache.hit', tags=[f'endpoint:{endpoint}'])
    
    def record_miss(self, endpoint):
        metrics.increment('cache.miss', tags=[f'endpoint:{endpoint}'])
    
    def calculate_hit_rate(self, endpoint):
        hits = metrics.count('cache.hit', tags=[f'endpoint:{endpoint}'])
        misses = metrics.count('cache.miss', tags=[f'endpoint:{endpoint}'])
        total = hits + misses
        return (hits / total * 100) if total > 0 else 0

#### CloudWatch custom metric
cloudwatch.put_metric_data(
    Namespace='Application/Cache',
    MetricData=[
        {
            'MetricName': 'CacheHitRate',
            'Value': hit_rate,
            'Unit': 'Percent'
        }
    ]
)
```

---

#### 6.2.6.3 Connection Pooling

#### MongoDB Connection Pool Configuration

**PyMongo Connection Pool**:
```python
# Pseudocode: MongoDB connection pool configuration
from pymongo import MongoClient

client = MongoClient(
    connection_string,
    maxPoolSize=50,        # Maximum connections per instance
    minPoolSize=10,        # Minimum idle connections maintained
    maxIdleTimeMS=30000,   # Close idle connections after 30 seconds
    waitQueueTimeoutMS=5000,  # Max wait time for available connection
    serverSelectionTimeoutMS=5000,  # Max time to select server
    socketTimeoutMS=30000  # Socket operation timeout
)
```

**Connection Pool Parameters**:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `maxPoolSize` | 50 connections per API instance | Balance concurrency with MongoDB connection limits (MongoDB Atlas M10 tier supports ~1,000 connections) |
| `minPoolSize` | 10 connections | Maintain ready connections, reduce latency for burst traffic |
| `maxIdleTimeMS` | 30,000ms (30 seconds) | Close idle connections to free resources |
| `waitQueueTimeoutMS` | 5,000ms (5 seconds) | Fail fast if pool exhausted |
| `serverSelectionTimeoutMS` | 5,000ms (5 seconds) | Fail fast on connection issues (replica set election, network problems) |

**Connection Pool Sizing Calculation**:
```
Ideal Pool Size = (Number of API Instances) × (Connections per Instance)

Example:
- 5 ECS tasks (API instances)
- 50 connections per task
- Total: 250 concurrent MongoDB connections

MongoDB Atlas M10 tier limit: 1,000 connections
Headroom: 75% available for scaling
```

#### Redis Connection Pool Configuration

**redis-py Connection Pool**:
```python
# Pseudocode: Redis connection pool configuration
import redis

pool = redis.ConnectionPool(
    host='redis.example.com',
    port=6379,
    db=0,
    max_connections=20,  # Maximum connections per instance
    socket_timeout=5,    # Socket operation timeout (seconds)
    socket_connect_timeout=5,  # Connection establishment timeout
    retry_on_timeout=True,  # Retry on timeout
    health_check_interval=30  # Health check frequency (seconds)
)

redis_client = redis.Redis(connection_pool=pool)
```

**Connection Pool Parameters**:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `max_connections` | 20 connections per API instance | Redis single-threaded, fewer connections needed than MongoDB |
| `socket_timeout` | 5 seconds | Fail fast on unresponsive Redis |
| `health_check_interval` | 30 seconds | Periodic connection health checks |

#### Connection Pool Benefits

| Benefit | Impact | Quantification |
|---------|--------|----------------|
| **Eliminate Connection Overhead** | Reduce latency | 50-100ms saved per request (no connection establishment) |
| **Improve Database Throughput** | Higher QPS | 10-20% throughput increase (reduced connection churn) |
| **Reduce Database Load** | Fewer authentication/authorization operations | 90% reduction in connection establishment operations |
| **Enable Burst Traffic Handling** | Pre-warmed connections ready | Handle 5x traffic spike without connection delays |

#### Connection Pool Monitoring

**Key Metrics**:

| Metric | Target | Alert Threshold | Action |
|--------|--------|----------------|--------|
| **Active Connections** | 30-70% of max | > 90% | Increase pool size or scale instances |
| **Connection Wait Time** | < 10ms | > 100ms | Pool exhausted, increase size |
| **Connection Errors** | 0 | > 1% of requests | Check network, database health |
| **Idle Connections** | 10-20% of max | < 5% or > 50% | Adjust minPoolSize |

---

#### 6.2.6.4 Read/Write Splitting

#### MongoDB Read Preference Strategy

**Read Preference Configuration**:

| Query Type | Read Preference | Target Nodes | Rationale |
|-----------|----------------|--------------|-----------|
| **All Writes** | `primary` | Primary only (required) | MongoDB writes always go to Primary |
| **Consistency-Critical Reads** | `primary` | Primary only | Latest data guaranteed (e.g., user profile after update) |
| **Analytics Queries** | `secondaryPreferred` | Secondary (fallback: Primary) | Offload read traffic from Primary |
| **Reporting Workloads** | `secondaryPreferred` | Secondary (fallback: Primary) | Acceptable eventual consistency |
| **Document Retrieval** | `secondaryPreferred` | Secondary (fallback: Primary) | User documents (non-critical staleness) |

**Implementation**:
```python
# Pseudocode: Read preference configuration
from pymongo import ReadPreference

#### Write operation (always Primary)
db.documents.insert_one(document)

#### Consistency-critical read (Primary)
user = db.users.find_one(
    {'auth0_id': user_id},
    read_preference=ReadPreference.PRIMARY
)

#### Analytics read (Secondary preferred)
messages = db.messages.find(
    {'conversation_id': conversation_id},
    read_preference=ReadPreference.SECONDARY_PREFERRED
).sort('created_at', 1)
```

#### Read Distribution and Benefits

**Traffic Distribution**:

```mermaid
pie title Read Traffic Distribution
    "Primary (Writes + Critical Reads)" : 60
    "Secondary 1 (Analytics Reads)" : 20
    "Secondary 2 (Analytics Reads)" : 20
```

**Performance Benefits**:

| Benefit | Impact | Quantification |
|---------|--------|----------------|
| **Offload Read Traffic** | Reduce Primary load | 40% of read traffic redirected to Secondaries |
| **Improve Write Throughput** | Reduce contention | 20-30% write throughput increase on Primary |
| **Scale Read Capacity** | Horizontal scaling | Add Secondary nodes to scale reads |
| **High Availability** | Continued reads during Primary failover | Read operations from Secondaries during election |

#### Replication Lag Considerations

**Acceptable Replication Lag**:

| Use Case | Max Acceptable Lag | Action if Exceeded |
|----------|-------------------|-------------------|
| **User Document Retrieval** | < 5 seconds | Acceptable for non-critical data |
| **Analytics Queries** | < 30 seconds | Large lag acceptable for historical analysis |
| **Real-Time Dashboards** | < 1 second | Fall back to Primary if lag > 1s |

**Replication Lag Monitoring**:
```python
# Pseudocode: Check replication lag before read
from pymongo import MongoClient

client = MongoClient(connection_string)
repl_status = client.admin.command('replSetGetStatus')

for member in repl_status['members']:
    if member['stateStr'] == 'SECONDARY':
        lag = member['optimeDate'] - repl_status['date']
        if lag.total_seconds() > 5:
            # Fall back to Primary
            read_preference = ReadPreference.PRIMARY
        else:
            read_preference = ReadPreference.SECONDARY_PREFERRED
```

---

#### 6.2.6.5 Batch Processing Approach

#### Bulk Write Operations

**PyMongo Bulk Write API**:
```python
# Pseudocode: Batch insert 1,000 documents
from pymongo import InsertOne, UpdateOne, DeleteOne

operations = []

#### Build bulk operations
for document in documents_list:
    operations.append(InsertOne(document))

#### Execute bulk write
result = db.documents.bulk_write(
    operations,
    ordered=False,  # Continue on error, don't stop at first failure
    write_concern=WriteConcern(w='majority')
)

print(f"Inserted: {result.inserted_count}")
print(f"Errors: {len(result.write_errors)}")
```

**Batch Write Benefits**:

| Benefit | Single Writes | Bulk Write (1,000 docs) | Improvement |
|---------|--------------|------------------------|-------------|
| **Network Round Trips** | 1,000 round trips | 1 round trip | 1000x reduction |
| **Execution Time** | 10,000ms | 500ms | 20x faster |
| **Connection Overhead** | High (per-operation) | Amortized | 95% reduction |

**Optimal Batch Size**: 1,000 documents per bulk operation (balance memory usage and performance).

#### Batch Query Operations

**Single Query with `$in` Operator**:
```python
# BAD: 100 individual queries (100 network round trips)
documents = []
for doc_id in document_ids:
    doc = db.documents.find_one({'_id': ObjectId(doc_id)})
    documents.append(doc)

#### GOOD: Single query with $in (1 network round trip)
documents = list(db.documents.find({
    '_id': {'$in': [ObjectId(doc_id) for doc_id in document_ids]}
}))
#### Impact: 100x faster (100 queries → 1 query)
```

**Batch Update Operations**:
```python
# Pseudocode: Update multiple documents in single operation
result = db.documents.update_many(
    {'user_id': user_id, 'status': 'pending'},
    {'$set': {'status': 'processed', 'processed_at': datetime.utcnow()}}
)

print(f"Updated {result.modified_count} documents")
```

#### Background Job Batching

**Archival Job** (Batch Process Old Data):
```python
# Pseudocode: Archive old documents in batches
def archive_old_documents():
    cutoff_date = datetime.utcnow() - timedelta(days=365)
    batch_size = 1000
    
    while True:
        # Fetch batch of old documents
        old_documents = list(db.documents.find({
            'created_at': {'$lt': cutoff_date}
        }).limit(batch_size))
        
        if not old_documents:
            break  # No more documents to archive
        
        # Export to S3
        export_to_s3(old_documents)
        
        # Delete from MongoDB
        doc_ids = [doc['_id'] for doc in old_documents]
        db.documents.delete_many({'_id': {'$in': doc_ids}})
        
        print(f"Archived and deleted {len(doc_ids)} documents")
```

**Analytics Job** (Batch Aggregation):
```python
# Pseudocode: Generate daily analytics report
def generate_daily_analytics():
    yesterday = datetime.utcnow() - timedelta(days=1)
    
    # Single aggregation pipeline (efficient batch processing)
    pipeline = [
        {'$match': {'timestamp': {'$gte': yesterday}}},
        {'$group': {
            '_id': '$event_type',
            'count': {'$sum': 1},
            'unique_users': {'$addToSet': '$user_id'}
        }},
        {'$sort': {'count': -1}}
    ]
    
    results = list(db.analytics.aggregate(pipeline))
    
    # Store aggregated results
    db.daily_reports.insert_one({
        'date': yesterday,
        'metrics': results,
        'generated_at': datetime.utcnow()
    })
```

#### Streaming Large Result Sets

**MongoDB Cursors for Large Datasets**:
```python
# Pseudocode: Stream results instead of loading all in memory
def export_all_documents():
    # BAD: Load all documents in memory (OOM risk)
    # documents = list(db.documents.find())  # DON'T DO THIS
    
    # GOOD: Use cursor to stream results
    cursor = db.documents.find().batch_size(500)
    
    for document in cursor:
        # Process one document at a time
        export_to_csv(document)
        
        # Memory usage: Constant (only ~500 docs in memory at once)
```

**Batch Size Configuration**:
- **Small Batches** (100-500): Lower memory usage, more network round trips
- **Large Batches** (1,000-5,000): Higher memory usage, fewer network round trips
- **Default**: 500 documents per cursor batch (good balance)

---

### 6.2.7 Vector Database Design (To Be Determined)

#### 6.2.7.1 Vector Database Requirement

**Purpose**: Store and query high-dimensional vector embeddings for AI-powered features:
- Semantic search across user documents
- Document similarity and recommendations
- Retrieval-Augmented Generation (RAG) for contextual AI responses
- Conversation context retrieval

**Embedding Specifications**:
- **Model**: OpenAI text-embedding-ada-002
- **Dimensions**: 1536 (fixed)
- **Similarity Metric**: Cosine similarity
- **Expected Volume**: Millions of vectors at scale

#### 6.2.7.2 Vector Database Options Under Consideration

| Option | Type | Pros | Cons | LangChain Support | Estimated Cost |
|--------|------|------|------|-------------------|----------------|
| **MongoDB Atlas Vector Search** | Integrated | Same database, no new service, unified data model | Limited advanced vector search features | Native | Included in Atlas |
| **Pinecone** | Managed SaaS | High performance, fully managed, purpose-built | Additional cost, vendor lock-in | Excellent | $70/month (Starter) |
| **Weaviate** | Self-Hosted or Managed | Feature-rich, ML model integration, open-source | Requires management (self-hosted) | Excellent | Free (self-hosted) |
| **Qdrant** | Self-Hosted or Managed | High performance, optimized for LangChain, Rust-based | Operational overhead (self-hosted) | Excellent | Free (self-hosted) |

#### 6.2.7.3 Selection Criteria

| Criterion | Weight | MongoDB Atlas | Pinecone | Weaviate | Qdrant |
|-----------|--------|--------------|----------|----------|--------|
| **Scale of Operations** (QPS) | High | Medium | High | High | High |
| **Cost** | High | Low | High | Low (self-hosted) | Low (self-hosted) |
| **Integration Complexity** | Medium | Low | Low | Medium | Medium |
| **Query Performance** | High | Medium | High | High | High |
| **Operational Overhead** | High | None | None | High (self-hosted) | High (self-hosted) |
| **LangChain Support** | Medium | Good | Excellent | Excellent | Excellent |

**Decision Timeline**: To be finalized during implementation phase based on actual usage patterns and budget constraints.

#### 6.2.7.4 Planned Vector Data Model

**Vector Document Structure** (Conceptual):
```json
{
  "vector_id": "uuid-v4-550e8400-e29b",
  "document_id": "507f1f77bcf86cd799439014",
  "user_id": "auth0|123456789",
  "embedding": [0.123, -0.456, 0.789, ...],  // 1536 dimensions
  "text_content": "This is the original text chunk that was embedded...",
  "metadata": {
    "chunk_index": 0,
    "total_chunks": 5,
    "source": "quarterly-report-q4-2023.pdf",
    "page_number": 3
  },
  "created_at": "2024-01-15T10:30:00Z"
}
```

**Key Fields**:
- `vector_id`: Unique identifier for vector
- `document_id`: References MongoDB `documents` collection
- `user_id`: User ownership (for access control)
- `embedding`: 1536-dimensional vector array
- `text_content`: Original text (for context retrieval)
- `metadata`: Contextual information (source, location, etc.)

#### 6.2.7.5 Vector Search Query Flow

```mermaid
sequenceDiagram
    participant User
    participant API as Flask API
    participant Embeddings as OpenAI Embeddings API
    participant VectorDB as Vector Database
    participant MongoDB
    participant LLM as OpenAI LLM
    
    User->>API: Semantic Search Query<br/>"Find documents about Q4 revenue"
    
    API->>Embeddings: Generate Query Embedding
    Embeddings-->>API: [0.123, -0.456, ...] (1536-dim)
    
    API->>VectorDB: Vector Similarity Search<br/>top_k=5, similarity=cosine
    VectorDB-->>API: Top 5 Similar Vectors<br/>with scores
    
    API->>MongoDB: Fetch Document Metadata<br/>for vector IDs
    MongoDB-->>API: Document metadata
    
    Note over API: Construct RAG Prompt
    
    API->>LLM: Prompt: "Based on context:<br/>[retrieved text chunks]<br/>Answer: ..."
    LLM-->>API: Generated Response<br/>with context
    
    API-->>User: Response + Source Citations
```

#### 6.2.7.6 Vector Indexing Strategy

**Index Type**: HNSW (Hierarchical Navigable Small World)
- **Algorithm**: Approximate nearest neighbor search
- **Trade-off**: Slight accuracy loss for massive speed gain

**HNSW Parameters**:

| Parameter | Value | Impact |
|-----------|-------|--------|
| `M` | 16 | Number of connections per layer (higher = better accuracy, slower build) |
| `ef_construction` | 200 | Index build quality (higher = better accuracy, slower build) |
| `ef_search` | 100 | Query time accuracy (higher = better accuracy, slower query) |

**Performance Targets**:

| Metric | Target | Scale |
|--------|--------|-------|
| **Vector Search Latency** | < 100ms | top_k=5 queries |
| **Index Build Time** | < 5 minutes | 1 million vectors |
| **Query Throughput** | > 100 QPS | Concurrent queries |

#### 6.2.7.7 Vector Database Scaling Strategy

**Initial Deployment**: Single node (up to 10 million vectors)

**Growth Strategy**:
- **Phase 1** (0-1M vectors): Single node, vertical scaling
- **Phase 2** (1M-10M vectors): Optimize index parameters, increase instance size
- **Phase 3** (10M+ vectors): Horizontal sharding by user_id or collection_id

**Sharding Approach** (Future):
- Shard by `user_id` to isolate tenant data
- Each shard handles subset of users
- Query routing based on user context

---

### 6.2.8 Object Storage (Amazon S3)

#### 6.2.8.1 S3 Bucket Strategy and Organization

**Bucket Architecture**:

| Bucket Name | Purpose | Access Pattern | Encryption | Versioning | Lifecycle Policy |
|-------------|---------|---------------|------------|------------|------------------|
| `app-uploads-prod` | User-generated content (documents, media) | Private (presigned URLs) | SSE-S3 | Disabled | Retain indefinitely |
| `app-uploads-staging` | Staging environment uploads | Private (presigned URLs) | SSE-S3 | Disabled | Delete after 30 days |
| `app-static-assets` | Frontend static files (HTML, CSS, JS, images) | Public via CloudFront CDN | SSE-S3 | Disabled | Retain indefinitely |
| `app-backups` | Database backups, archives | Private | SSE-KMS | Enabled | Glacier after 90 days |
| `app-archives` | Archived data (old conversations, analytics) | Private | SSE-S3 | Disabled | Retain per retention policy |
| `app-logs` | Application and infrastructure log archives | Private | SSE-S3 | Disabled | Delete after 1 year |
| `terraform-state` | Terraform state files | Private | SSE-S3 | Enabled | Retain all versions |

#### 6.2.8.2 File Upload Architecture (Presigned URLs)

**Presigned URL Upload Flow**:

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant MongoDB
    participant S3 as Amazon S3
    
    Client->>API: POST /api/v1/files/upload-url<br/>{filename, size, mime_type}
    
    Note over API: Validate JWT,<br/>Check permissions
    
    API->>API: Generate unique file_id<br/>(UUID v4)
    
    API->>S3: Generate Presigned PUT URL<br/>(15-minute expiration)
    S3-->>API: Presigned URL
    
    API->>MongoDB: Insert file record<br/>{file_id, status: "pending"}
    MongoDB-->>API: Success
    
    API-->>Client: {upload_url, file_id}
    
    Note over Client: Direct Upload to S3
    Client->>S3: PUT file data<br/>(bypass API)
    S3-->>Client: 200 OK
    
    Client->>API: POST /api/v1/files/complete<br/>{file_id}
    
    API->>MongoDB: Update file status<br/>{file_id, status: "complete"}
    
    API-->>Client: {file_id, status: "complete"}
```

**Presigned URL Benefits**:

| Benefit | Traditional Upload | Presigned URL | Improvement |
|---------|------------------|---------------|-------------|
| **API Bandwidth** | 100 MB/request through API | 0 MB (direct to S3) | Eliminate API bottleneck |
| **Upload Performance** | Limited by API instance | Direct S3 (high throughput) | 5-10x faster |
| **API Timeout Risk** | Timeout for large files | No timeout (direct S3) | Support multi-GB files |
| **Infrastructure Cost** | High (data transfer through API) | Low (no API data transfer) | 80% cost reduction |

**Presigned URL Generation**:
```python
# Pseudocode: Generate presigned URL for file upload
import boto3
from datetime import timedelta

s3_client = boto3.client('s3')

def generate_upload_url(file_id, filename, mime_type):
    s3_key = f"uploads/{datetime.utcnow().year}/{datetime.utcnow().month}/{file_id}-{filename}"
    
    presigned_url = s3_client.generate_presigned_url(
        'put_object',
        Params={
            'Bucket': 'app-uploads-prod',
            'Key': s3_key,
            'ContentType': mime_type
        },
        ExpiresIn=900  # 15 minutes
    )
    
    return presigned_url, s3_key
```

#### 6.2.8.3 S3 Security Configuration

**Server-Side Encryption**:

| Bucket | Encryption Type | Key Management | Purpose |
|--------|---------------|---------------|---------|
| `app-uploads-*` | SSE-S3 | AWS-managed keys | User files (standard encryption) |
| `app-static-assets` | SSE-S3 | AWS-managed keys | Public static assets |
| `app-backups` | SSE-KMS | Customer-managed KMS keys | Sensitive backups (audit trail of access) |
| `app-archives` | SSE-S3 | AWS-managed keys | Archived data |
| `terraform-state` | SSE-S3 | AWS-managed keys | Infrastructure state |

**Bucket Access Policies**:

**Private Buckets** (Default Deny):
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::app-uploads-prod",
        "arn:aws:s3:::app-uploads-prod/*"
      ],
      "Condition": {
        "Bool": {
          "aws:SecureTransport": "false"
        }
      }
    }
  ]
}
```

**Public Bucket via CloudFront** (`app-static-assets`):
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "cloudfront.amazonaws.com"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::app-static-assets/*",
      "Condition": {
        "StringEquals": {
          "AWS:SourceArn": "arn:aws:cloudfront::account-id:distribution/distribution-id"
        }
      }
    }
  ]
}
```

**IAM Role for ECS Tasks**:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::app-uploads-prod/*",
        "arn:aws:s3:::app-backups/*"
      ]
    }
  ]
}
```

**CORS Configuration** (for client-side uploads):
```json
[
  {
    "AllowedOrigins": ["https://app.example.com"],
    "AllowedMethods": ["GET", "PUT", "POST"],
    "AllowedHeaders": ["*"],
    "MaxAgeSeconds": 3600
  }
]
```

#### 6.2.8.4 S3 Lifecycle Management

**Backup Bucket Lifecycle** (`app-backups`):

```mermaid
graph LR
    A[Upload to S3 Standard] -->|After 30 days| B[Transition to S3 Standard-IA]
    B -->|After 90 days| C[Transition to S3 Glacier]
    C -->|After 1 year| D[Delete Daily Backups<br/>Retain Monthly]
    
    style A fill:#4CAF50
    style B fill:#8BC34A
    style C fill:#2196F3
    style D fill:#FF9800
```

**Lifecycle Policy Configuration**:
```json
{
  "Rules": [
    {
      "Id": "TransitionToGlacier",
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        }
      ],
      "Expiration": {
        "Days": 365
      }
    },
    {
      "Id": "DeleteIncompleteUploads",
      "Status": "Enabled",
      "AbortIncompleteMultipartUpload": {
        "DaysAfterInitiation": 7
      }
    }
  ]
}
```

**Storage Cost Optimization**:

| Storage Class | Use Case | Cost per GB/Month | Retrieval Cost |
|--------------|----------|-------------------|---------------|
| **S3 Standard** | Active data (< 30 days) | $0.023 | None |
| **S3 Standard-IA** | Infrequent access (30-90 days) | $0.0125 | $0.01/GB |
| **S3 Glacier** | Long-term archival (> 90 days) | $0.004 | $0.03/GB + time |
| **S3 Glacier Deep Archive** | Compliance archival (> 1 year) | $0.00099 | $0.02/GB + 12 hours |

---

### 6.2.9 Data Flow Architecture

```mermaid
flowchart TB
    Client[Client Application<br/>Web/Mobile/Desktop]
    
    subgraph "Application Layer"
        ALB[Application Load Balancer]
        API[Flask REST API<br/>ECS Fargate]
        LangChain[LangChain AI Service]
    end
    
    subgraph "Caching Layer"
        Redis[(Redis Cache<br/>ElastiCache)]
        CacheOps["• API Response Cache<br/>• JWKS Cache<br/>• Rate Limit Counters<br/>• LLM Response Cache<br/>• Distributed Locks"]
    end
    
    subgraph "Primary Database"
        MongoDB[(MongoDB 7.0+<br/>3-Node Replica Set)]
        Collections["• users<br/>• conversations<br/>• messages<br/>• documents<br/>• ai_interactions<br/>• analytics<br/>• files"]
    end
    
    subgraph "Vector Database (TBD)"
        VectorDB[(Vector Database<br/>Pinecone/Weaviate/Qdrant)]
        Embeddings["• Document Embeddings<br/>• Semantic Search<br/>• RAG Context Retrieval"]
    end
    
    subgraph "Object Storage"
        S3[(Amazon S3)]
        Buckets["• app-uploads-prod<br/>• app-static-assets<br/>• app-backups<br/>• app-archives"]
    end
    
    subgraph "External Services"
        Auth0[Auth0 Identity Provider]
        OpenAI[OpenAI API<br/>LLM + Embeddings]
    end
    
    Client -->|1. HTTPS + JWT| ALB
    ALB -->|2. Load Balance| API
    
    API -->|3. Validate JWT| Auth0
    Auth0 -.->|JWKS| API
    
    API -->|4. Check Cache| Redis
    Redis -->|Cache Operations| CacheOps
    
    API -->|5. Query/Write| MongoDB
    MongoDB -->|Collections| Collections
    
    API -->|6. AI Requests| LangChain
    LangChain -->|Generate Embeddings| OpenAI
    LangChain -->|Vector Search| VectorDB
    VectorDB -->|Similar Vectors| Embeddings
    LangChain -->|LLM Completion| OpenAI
    
    API -->|7. File Operations| S3
    S3 -->|Buckets| Buckets
    
    MongoDB -.->|8. Daily Backups| S3
    MongoDB -.->|9. Oplog Replication| MongoDB
    
    API -->|10. Cache Response| Redis
    API -->|11. Return Response| ALB
    ALB -->|12. HTTPS| Client
    
    style Redis fill:#FFE6E6
    style MongoDB fill:#E6F3FF
    style VectorDB fill:#E6FFE6
    style S3 fill:#FFF9E6
    style Auth0 fill:#F3E5F5
    style OpenAI fill:#FFF3E0
```

---

### 6.2.10 Replication Architecture Diagram

```mermaid
graph TB
    subgraph "MongoDB Replica Set - Multi-AZ Deployment"
        subgraph "Availability Zone 1 (us-east-1a)"
            Primary[(MongoDB Primary<br/>Read/Write<br/>Oplog Source)]
        end
        
        subgraph "Availability Zone 2 (us-east-1b)"
            Secondary1[(MongoDB Secondary 1<br/>Read-Only<br/>Oplog Consumer)]
        end
        
        subgraph "Availability Zone 3 (us-east-1c)"
            Secondary2[(MongoDB Secondary 2<br/>Read-Only<br/>Oplog Consumer)]
        end
    end
    
    subgraph "Application Layer - Multi-AZ"
        API1[API Instance 1<br/>ECS Task - AZ1]
        API2[API Instance 2<br/>ECS Task - AZ2]
        API3[API Instance 3<br/>ECS Task - AZ3]
    end
    
    subgraph "Load Balancer"
        ALB[Application Load Balancer<br/>Multi-AZ Distribution]
    end
    
    Client[Clients<br/>Web/Mobile/Desktop] -->|HTTPS| ALB
    ALB -->|Load Balance| API1
    ALB -->|Load Balance| API2
    ALB -->|Load Balance| API3
    
    API1 -->|Writes<br/>w: majority| Primary
    API2 -->|Writes<br/>w: majority| Primary
    API3 -->|Writes<br/>w: majority| Primary
    
    API1 -.->|Reads<br/>SecondaryPreferred| Secondary1
    API2 -.->|Reads<br/>SecondaryPreferred| Secondary2
    API3 -.->|Reads<br/>SecondaryPreferred| Secondary1
    
    Primary ==>|Oplog Replication<br/>Asynchronous| Secondary1
    Primary ==>|Oplog Replication<br/>Asynchronous| Secondary2
    
    Secondary1 -.->|Heartbeat<br/>Every 2 seconds| Primary
    Secondary2 -.->|Heartbeat<br/>Every 2 seconds| Primary
    
    subgraph "Write Concern Configuration"
        WriteNote["Write Concern: majority<br/>Waits for 2/3 nodes<br/>Ensures zero data loss"]
    end
    
    subgraph "Read Preference Strategy"
        ReadNote["Read Preference:<br/>• Primary: Writes + Critical Reads<br/>• SecondaryPreferred: Analytics<br/>• Distribution: 60/20/20"]
    end
    
    subgraph "Failover Behavior"
        FailNote["Automatic Failover:<br/>1. Heartbeat timeout: 10 seconds<br/>2. Raft election: < 5 seconds<br/>3. Secondary promoted to Primary<br/>4. Total downtime: < 15 seconds"]
    end
    
    style Primary fill:#4CAF50,stroke:#2E7D32,stroke-width:3px
    style Secondary1 fill:#8BC34A,stroke:#558B2F,stroke-width:2px
    style Secondary2 fill:#8BC34A,stroke:#558B2F,stroke-width:2px
    style WriteNote fill:#E1F5FE,stroke:#0277BD
    style ReadNote fill:#F3E5F5,stroke:#6A1B9A
    style FailNote fill:#FFE0B2,stroke:#E65100
```

---

### 6.2.11 References

#### 6.2.11.1 Repository Files Examined

- **`README.md`**: Project title documentation (no database implementation code found)

#### 6.2.11.2 Repository Folders Explored

- **Root Directory** (`/`): Contains only README.md file; no source code, database configuration, or implementation files

#### 6.2.11.3 Technical Specification Sections Referenced

- **Section 3.1 - Technology Stack Overview**: Overall architecture and technology approach
- **Section 3.6 - Databases & Storage**: Comprehensive database, caching, and storage architecture specifications
- **Section 5.1 - High-Level Architecture**: System architecture overview, data flow patterns
- **Section 5.2 - Component Details**: Detailed component specifications including data models, indexes, and interfaces
- **Section 5.4 - Cross-Cutting Concerns**: Monitoring, error handling, authentication, performance requirements, disaster recovery procedures
- **Section 6.1 - Core Services Architecture**: Service-level architecture with database integration details

#### 6.2.11.4 Key Findings Summary

**Implementation Status**: 
- Repository contains **only README.md** with project title "CheckSameRepoNoPrompt"
- **No database implementation code exists** (no Python files, configuration files, or infrastructure code)
- All database design represents **planned architecture** documented in technical specification

**Database Design Scope**:
- **Primary Database**: MongoDB 7.0+ (NoSQL document database)
- **Caching Layer**: Redis 7+ (likely Amazon ElastiCache)
- **Object Storage**: Amazon S3 with defined bucket strategy
- **Vector Database**: To be determined (Pinecone, Weaviate, Qdrant, or MongoDB Atlas Vector Search)

**Collections Documented**: 7 primary MongoDB collections
- `users` (user profiles, preferences)
- `conversations` (AI conversation metadata)
- `messages` (conversation history)
- `documents` (document metadata, S3 references)
- `ai_interactions` (AI usage logging, cost tracking)
- `analytics` (application event tracking)
- `files` (file upload status, metadata)

**Architecture Highlights**:
- **High Availability**: 3-node MongoDB replica set with automatic failover (< 15 seconds)
- **Backup Strategy**: Daily automated backups, 30-day retention, point-in-time recovery
- **Performance Targets**: < 50ms for indexed queries, < 300ms for aggregations
- **Compliance**: GDPR/CCPA considerations, 7-year audit log retention
- **Caching**: Multi-layer caching (client, CDN, Redis, MongoDB) targeting 70% cache hit rate
- **Scalability**: Horizontal scaling via sharding (future), vertical scaling initially

**Total Research Depth**: 11 comprehensive searches across repository and technical specification sections

---

**Document Metadata**:
- **Section**: 6.2 Database Design
- **Version**: 1.0 (Planned Architecture)
- **Date**: January 2024
- **Status**: Pre-Implementation (Design Phase)
- **Implementation Code**: None (repository contains only README.md)

## 6.3 Integration Architecture

#### Implementation Status Notice

**Current Repository State**: The CheckSameRepoNoPrompt repository is in **pre-implementation phase**, containing only a README.md file with the project title. No source code, configuration files, or infrastructure implementations exist at this time.

**Documentation Scope**: This section documents the **planned integration architecture** based on comprehensive technical specifications. All integration patterns, API designs, and external system interfaces described herein represent the intended architecture that will be implemented during the development phase.

---

### 6.3.1 Integration Architecture Overview

The CheckSameRepoNoPrompt system implements a **cloud-native, API-first integration architecture** designed to support multi-platform client applications, external service integrations, and scalable AI/ML capabilities. The architecture emphasizes standards-based protocols, secure authentication, and resilient communication patterns.

#### 6.3.1.1 Integration Philosophy

The system's integration architecture adheres to the following core principles:

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **API-First Design** | Single RESTful API serves all platforms | Consistent business logic, simplified maintenance |
| **Standards-Based Protocols** | OAuth 2.0, OIDC, HTTPS, JSON | Interoperability, industry best practices |
| **Stateless Communication** | JWT tokens, no server-side sessions | Horizontal scalability, simplified infrastructure |
| **Secure by Default** | Authentication at every layer, TLS encryption | Comprehensive security posture |

#### 6.3.1.2 Integration Layers

```mermaid
graph TB
    subgraph "Client Layer"
        WebApp[Web Application<br/>React + TypeScript]
        MobileApps[Mobile Applications<br/>React Native, iOS, Android]
        DesktopApps[Desktop Applications<br/>Electron, macOS Native]
    end
    
    subgraph "API Gateway Layer"
        ALB[Application Load Balancer<br/>TLS Termination, Routing]
        RateLimit[Rate Limiting<br/>Redis-Based]
    end
    
    subgraph "Application Integration Layer"
        FlaskAPI[Flask REST API<br/>Business Logic Orchestration]
        AuthMiddleware[Authentication Middleware<br/>JWT Validation]
        AuthZMiddleware[Authorization Middleware<br/>Permission Checks]
    end
    
    subgraph "Service Integration Layer"
        LangChain[LangChain AI Service<br/>AI/ML Orchestration]
        CacheLayer[Redis Cache<br/>Response Caching]
        DatabaseLayer[MongoDB<br/>Data Persistence]
    end
    
    subgraph "External Service Integration"
        Auth0[Auth0<br/>Identity Provider]
        OpenAI[OpenAI API<br/>LLM Provider]
        AWS[AWS Services<br/>S3, CloudWatch, Secrets Manager]
    end
    
    WebApp -->|HTTPS + JWT| ALB
    MobileApps -->|HTTPS + JWT| ALB
    DesktopApps -->|HTTPS + JWT| ALB
    
    ALB --> RateLimit
    RateLimit --> FlaskAPI
    
    FlaskAPI --> AuthMiddleware
    AuthMiddleware -->|JWT Validation| Auth0
    AuthMiddleware --> AuthZMiddleware
    AuthZMiddleware --> CacheLayer
    
    CacheLayer -->|Cache Miss| DatabaseLayer
    FlaskAPI --> LangChain
    LangChain -->|LLM Calls| OpenAI
    LangChain -->|Vector Search| DatabaseLayer
    
    FlaskAPI -->|File Operations| AWS
    FlaskAPI -->|Logging| AWS
    FlaskAPI -->|Secrets| AWS
    
    style FlaskAPI fill:#4CAF50
    style Auth0 fill:#F3E5F5
    style OpenAI fill:#FFF3E0
    style AWS fill:#E3F2FD
```

---

### 6.3.2 API Design

#### 6.3.2.1 Protocol Specifications

**RESTful API Architecture**:

| Aspect | Specification | Rationale |
|--------|--------------|-----------|
| **Protocol** | HTTPS (TLS 1.3 with TLS 1.2 fallback) | Security, encryption in transit |
| **Data Format** | JSON (request/response bodies) | Universal compatibility, human-readable |
| **API Style** | RESTful with resource-based URLs | Industry standard, predictable patterns |
| **Versioning** | URI path versioning (`/api/v1/`) | Backward compatibility, clear version identification |

**HTTP Methods and Semantics**:

| Method | Usage | Idempotent | Safe |
|--------|-------|------------|------|
| **GET** | Retrieve resources | Yes | Yes |
| **POST** | Create resources | No | No |
| **PUT** | Update resources (full replacement) | Yes | No |
| **DELETE** | Remove resources | Yes | No |

**API Endpoint Structure**:

```
Base URL: https://api.example.com
Pattern: /api/{version}/{resource}/{id}/{sub-resource}

Examples:
- GET    /api/v1/documents              - List documents
- GET    /api/v1/documents/{id}         - Get specific document
- POST   /api/v1/documents              - Create document
- PUT    /api/v1/documents/{id}         - Update document
- DELETE /api/v1/documents/{id}         - Delete document
- POST   /api/v1/ai/completions         - AI text completion
- POST   /api/v1/ai/conversations       - Start/continue conversation
- POST   /api/v1/files/upload-url       - Get presigned upload URL
```

#### 6.3.2.2 Authentication Methods

**Auth0 OAuth 2.0 / OpenID Connect Integration**:

The system implements **Authorization Code Flow with PKCE** (Proof Key for Code Exchange) for all client platforms:

```mermaid
sequenceDiagram
    participant User
    participant Client as Client Application
    participant Auth0
    participant API as Flask API Backend
    
    User->>Client: Click "Login"
    Client->>Client: Generate code_verifier<br/>Generate code_challenge
    Client->>Auth0: Authorization Request<br/>response_type=code<br/>code_challenge={hash}
    Auth0->>User: Display Login Page
    User->>Auth0: Enter Credentials + MFA
    Auth0->>Client: Authorization Code<br/>(via callback URL)
    Client->>Auth0: Token Request<br/>grant_type=authorization_code<br/>code_verifier={original}
    Auth0->>Client: Access Token (JWT)<br/>Refresh Token<br/>ID Token
    Client->>API: API Request<br/>Authorization: Bearer {JWT}
    API->>Auth0: Validate JWT<br/>(fetch JWKS, verify signature)
    Auth0-->>API: JWT Valid + User Context
    API->>Client: Protected Resource
```

**JWT Token Structure**:

```json
{
  "header": {
    "alg": "RS256",
    "typ": "JWT",
    "kid": "key-identifier"
  },
  "payload": {
    "iss": "https://your-tenant.auth0.com/",
    "sub": "auth0|123456789",
    "aud": "your-api-identifier",
    "iat": 1672531200,
    "exp": 1672532100,
    "azp": "your-client-id",
    "scope": "openid profile email",
    "permissions": ["read:documents", "write:documents"]
  },
  "signature": "..."
}
```

**Token Lifecycle Management**:

| Token Type | Lifetime | Storage | Purpose |
|-----------|----------|---------|---------|
| **Access Token** | 15 minutes | Memory (web), Keychain/Keystore (mobile) | API authorization |
| **Refresh Token** | 7 days | Secure storage only | Silent token renewal |
| **ID Token** | 15 minutes | Memory or secure storage | User profile information |

#### 6.3.2.3 Authorization Framework

**Permission-Based Access Control (PBAC)**:

**Permission Naming Convention**: `{action}:{resource}`

| Permission | Description | Example Endpoint |
|-----------|-------------|------------------|
| `read:documents` | View document metadata and content | `GET /api/v1/documents` |
| `write:documents` | Create and update documents | `POST /api/v1/documents` |
| `delete:documents` | Delete documents | `DELETE /api/v1/documents/{id}` |
| `ai:completions` | Access AI text generation | `POST /api/v1/ai/completions` |

**Authorization Enforcement Pattern**:

```python
# Pseudocode: Multi-level authorization
@app.route('/api/v1/documents/<document_id>', methods=['GET'])
@require_auth  # Layer 1: Validate JWT
@require_permissions(['read:documents'])  # Layer 2: Check permissions
def get_document(document_id):
    document = db.documents.find_one({'_id': document_id})
    
    # Layer 3: Resource-level authorization
    if document['user_id'] != request.user_id:
        if request.user_id not in document.get('shared_with', []):
            # Layer 4: Admin override
            if 'admin:system' not in request.permissions:
                return {'error': 'Forbidden'}, 403
    
    return document, 200
```

#### 6.3.2.4 Rate Limiting Strategy

**Redis-Based Distributed Rate Limiting**:

| Endpoint Category | Rate Limit | Window | Rationale |
|------------------|------------|--------|-----------|
| **General API** | 100 requests/minute | 60 seconds | Prevent abuse, fair usage |
| **Write Operations** | 20 requests/minute | 60 seconds | Protect database from write floods |
| **AI/LLM Endpoints** | 10 requests/minute | 60 seconds | Cost control (expensive operations) |
| **File Uploads** | 20 uploads/minute | 60 seconds | Prevent storage abuse |

**Rate Limit Implementation**:

```python
# Pseudocode: Token bucket algorithm with Redis
def check_rate_limit(user_id, endpoint_category):
    key = f"ratelimit:{user_id}:{endpoint_category}"
    current = redis.incr(key)
    
    if current == 1:
        # First request in window, set expiration
        redis.expire(key, 60)  # 60-second window
    
    limit = get_limit_for_category(endpoint_category)
    
    if current > limit:
        remaining_ttl = redis.ttl(key)
        raise RateLimitExceeded(
            retry_after=remaining_ttl,
            limit=limit,
            current=current
        )
    
    return {
        'limit': limit,
        'remaining': limit - current,
        'reset_at': time.time() + remaining_ttl
    }
```

**Rate Limit Response Headers**:

```
HTTP/1.1 429 Too Many Requests
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1705320600
Retry-After: 45

{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded for this endpoint",
    "details": {
      "limit": 100,
      "window": "1 minute",
      "retry_after": 45
    }
  }
}
```

#### 6.3.2.5 API Versioning Approach

**URI Path Versioning Strategy**:

```
Current Version: /api/v1/*
Future Versions: /api/v2/*, /api/v3/*, etc.

Versioning Rules:
- Breaking changes require new version (v2, v3)
- Non-breaking changes deployed to existing version
- Each version maintained for minimum 12 months after replacement
- Deprecation notices provided 6 months in advance
```

**Version Lifecycle**:

| Stage | Status | Example | Support Level |
|-------|--------|---------|---------------|
| **Current** | Active, recommended | `/api/v1/` | Full support, new features |
| **Deprecated** | Active, discouraged | `/api/v0/` (hypothetical) | Bug fixes only, 6-month notice |
| **Sunset** | Removed | N/A | No support, returns 410 Gone |

**Backward Compatibility Guidelines**:

**Non-Breaking Changes** (Same version):
- Adding new optional fields to requests
- Adding new fields to responses
- Adding new endpoints
- Adding new HTTP methods to existing endpoints

**Breaking Changes** (New version required):
- Removing or renaming fields
- Changing field types
- Changing authentication methods
- Modifying error response formats

#### 6.3.2.6 API Documentation Standards

**OpenAPI (Swagger) Specification** (Planned):

```yaml
# Example OpenAPI 3.0 specification snippet
openapi: 3.0.0
info:
  title: CheckSameRepoNoPrompt API
  version: 1.0.0
  description: RESTful API for AI-powered document management

servers:
  - url: https://api.example.com/api/v1
    description: Production server

paths:
  /documents:
    get:
      summary: List documents
      security:
        - BearerAuth: [read:documents]
      parameters:
        - name: limit
          in: query
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Document'

components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
```

**Documentation Features**:
- Interactive API explorer (Swagger UI)
- Code examples in multiple languages
- Authentication flow documentation
- Rate limiting details
- Error code reference
- Webhooks documentation (future)

---

### 6.3.3 Message Processing

#### 6.3.3.1 Event Processing Patterns

**CloudWatch Logs for Event Streaming**:

The system implements **structured logging** to CloudWatch Logs for event processing and analysis:

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456",
  "service": "api",
  "event_type": "document_created",
  "endpoint": "/api/v1/documents",
  "method": "POST",
  "status_code": 201,
  "duration_ms": 145,
  "metadata": {
    "document_id": "507f1f77bcf86cd799439014",
    "file_size": 2048576,
    "mime_type": "application/pdf"
  }
}
```

**Event Types Logged**:

| Event Category | Event Types | Purpose |
|---------------|-------------|---------|
| **User Actions** | `user_login`, `user_logout`, `document_created`, `document_updated` | User behavior analytics |
| **System Events** | `api_request`, `cache_hit`, `cache_miss`, `rate_limit_exceeded` | Performance monitoring |
| **Security Events** | `auth_failed`, `permission_denied`, `suspicious_activity` | Security monitoring |
| **AI Events** | `ai_completion`, `ai_conversation`, `ai_search` | Cost tracking, usage analytics |

#### 6.3.3.2 Cache-Based Message Pattern

**Redis as Lightweight Message Layer**:

The system uses Redis for **cache-aside pattern** and **pub/sub messaging** (planned future):

**Cache Invalidation Event Pattern** (Current):

```python
# Pseudocode: Event-based cache invalidation
def update_document(document_id, updates):
    # 1. Update database
    result = db.documents.update_one(
        {'_id': document_id},
        {'$set': updates}
    )
    
    # 2. Publish cache invalidation event
    invalidate_cache_keys([
        f"cache:documents:{user_id}:*",  # All user document lists
        f"cache:documents:{document_id}:*",  # Specific document caches
        f"cache:search:*"  # Search result caches
    ])
    
    # 3. Emit CloudWatch event
    emit_event('document_updated', {
        'document_id': document_id,
        'user_id': user_id,
        'fields_updated': updates.keys()
    })
    
    return result
```

**Pub/Sub Messaging** (Future Enhancement):

```python
# Pseudocode: Redis Pub/Sub for real-time updates
# Publisher (API):
redis.publish('document:updates', json.dumps({
    'event': 'document_created',
    'document_id': document_id,
    'user_id': user_id,
    'timestamp': datetime.utcnow().isoformat()
}))

#### Subscriber (WebSocket service, future):
pubsub = redis.pubsub()
pubsub.subscribe('document:updates')

for message in pubsub.listen():
    if message['type'] == 'message':
        event_data = json.loads(message['data'])
        notify_connected_clients(event_data)
```

#### 6.3.3.3 Asynchronous Processing (Future)

**Celery Task Queue** (Planned for Long-Running Operations):

```python
# Pseudocode: Celery tasks for async processing
from celery import Celery

app = Celery('tasks', broker='redis://localhost:6379/0')

@app.task
def process_large_document(document_id):
    """Async document processing (OCR, indexing, embedding generation)"""
    document = db.documents.find_one({'_id': document_id})
    
    # 1. Extract text (OCR if PDF/image)
    text_content = extract_text(document)
    
    # 2. Generate embeddings for semantic search
    embeddings = generate_embeddings(text_content)
    
    # 3. Store in vector database
    store_embeddings(document_id, embeddings)
    
    # 4. Update document status
    db.documents.update_one(
        {'_id': document_id},
        {'$set': {'processing_status': 'complete'}}
    )
    
    return {'status': 'complete', 'document_id': document_id}

#### Enqueue task from API:
task = process_large_document.delay(document_id)
return {'task_id': task.id, 'status': 'processing'}
```

**Use Cases for Async Processing**:
- Large file processing (OCR, conversion)
- Batch operations (bulk updates, exports)
- Scheduled tasks (data archival, cleanup)
- Email notifications
- Report generation

#### 6.3.3.4 Error Handling and Retry Strategy

**Circuit Breaker Pattern for External Services**:

```mermaid
stateDiagram-v2
    [*] --> Closed
    
    Closed --> Closed: Requests succeed
    Closed --> Open: 50% errors in 60s window
    
    Open --> Open: Fail fast (no backend calls)
    Open --> HalfOpen: After 30 seconds
    
    HalfOpen --> Closed: 5 successful test requests
    HalfOpen --> Open: Any test request fails
    
    note right of Closed
        CLOSED: Normal operation
        All requests pass through
        Monitor error rate
    end note
    
    note right of Open
        OPEN: Circuit breaker active
        Return cached/fallback data
        Prevent cascading failures
    end note
    
    note right of HalfOpen
        HALF-OPEN: Testing recovery
        Allow limited requests
        Determine if service healthy
    end note
```

**Exponential Backoff Retry Algorithm**:

```python
# Pseudocode: Retry with exponential backoff
import time
import random

def retry_with_backoff(func, max_retries=3, base_delay=0.1):
    """
    Retry function with exponential backoff and jitter
    
    Wait times:
    - Attempt 1: 0.1s + jitter (0-0.1s) = 0.1-0.2s
    - Attempt 2: 0.2s + jitter = 0.2-0.3s
    - Attempt 3: 0.4s + jitter = 0.4-0.5s
    """
    for attempt in range(max_retries):
        try:
            return func()
        except RetryableException as e:
            if attempt == max_retries - 1:
                raise  # Final attempt failed, propagate error
            
            # Calculate exponential backoff with jitter
            delay = base_delay * (2 ** attempt)
            jitter = random.uniform(0, base_delay)
            total_delay = min(delay + jitter, 5.0)  # Max 5 seconds
            
            time.sleep(total_delay)
```

**Retry Decision Matrix**:

| Error Type | Retry | Max Attempts | Idempotency Required |
|-----------|-------|--------------|---------------------|
| Network timeout | Yes | 3 | Yes |
| Connection refused | Yes | 3 | Yes |
| Rate limit (429) | Yes | 2 | Yes |
| Server error (5xx) | Yes | 2 | Yes |

---

### 6.3.4 External Systems Integration

#### 6.3.4.1 Auth0 Identity Platform Integration

**Integration Architecture**:

```mermaid
graph TB
    subgraph "Client Applications"
        WebApp[Web App - React]
        MobileApp[Mobile Apps - RN/Native]
        DesktopApp[Desktop - Electron]
    end
    
    subgraph "Auth0 Platform"
        UniversalLogin[Universal Login Page]
        TokenEndpoint[Token Endpoint]
        JWKS[JWKS Endpoint<br/>Public Keys]
        UserManagement[User Management API]
    end
    
    subgraph "Backend Services"
        FlaskAPI[Flask API]
        AuthMiddleware[Auth Middleware]
        RedisCache[Redis<br/>JWKS Cache]
    end
    
    WebApp -->|1. Redirect to login| UniversalLogin
    MobileApp -->|1. OAuth 2.0 + PKCE| UniversalLogin
    DesktopApp -->|1. OAuth 2.0 + PKCE| UniversalLogin
    
    UniversalLogin -->|2. Auth code| WebApp
    UniversalLogin -->|2. Auth code| MobileApp
    UniversalLogin -->|2. Auth code| DesktopApp
    
    WebApp -->|3. Exchange code| TokenEndpoint
    MobileApp -->|3. Exchange code| TokenEndpoint
    DesktopApp -->|3. Exchange code| TokenEndpoint
    
    TokenEndpoint -->|4. JWT tokens| WebApp
    TokenEndpoint -->|4. JWT tokens| MobileApp
    TokenEndpoint -->|4. JWT tokens| DesktopApp
    
    WebApp -->|5. API request + JWT| FlaskAPI
    MobileApp -->|5. API request + JWT| FlaskAPI
    DesktopApp -->|5. API request + JWT| FlaskAPI
    
    FlaskAPI --> AuthMiddleware
    AuthMiddleware -->|6. Check cache| RedisCache
    RedisCache -->|Cache miss| JWKS
    JWKS -->|Public keys| AuthMiddleware
    AuthMiddleware -->|Cache keys| RedisCache
    
    AuthMiddleware -->|7. JWT valid| FlaskAPI
```

**Integration Details**:

| Integration Point | Protocol | Data Exchange | Purpose |
|------------------|----------|---------------|---------|
| **User Authentication** | OAuth 2.0 + PKCE | Authorization code, tokens | Secure user login across platforms |
| **Token Validation** | HTTPS REST | JWT verification via JWKS | Validate API requests |
| **User Profile Management** | Auth0 Management API | User metadata CRUD | Sync user data |
| **MFA Enforcement** | Auth0 MFA API | Challenge/response | Additional security layer |

**JWKS Caching Strategy**:

```python
# Pseudocode: JWKS caching for performance
def get_jwks():
    """Fetch Auth0 public keys with Redis caching"""
    cache_key = "jwks:auth0"
    
    # Check cache first
    cached_jwks = redis.get(cache_key)
    if cached_jwks:
        return json.loads(cached_jwks)
    
    # Cache miss: fetch from Auth0
    response = requests.get(
        f"https://{AUTH0_DOMAIN}/.well-known/jwks.json"
    )
    jwks = response.json()
    
    # Cache for 1 hour
    redis.setex(cache_key, 3600, json.dumps(jwks))
    
    return jwks
```

#### 6.3.4.2 OpenAI API Integration (Optional)

**LangChain Abstraction Layer**:

```mermaid
sequenceDiagram
    participant API as Flask API
    participant Lang as LangChain Service
    participant Cache as Redis Cache
    participant OpenAI as OpenAI API
    participant MongoDB
    
    API->>Lang: AI Completion Request<br/>{prompt, model}
    Lang->>Cache: Check prompt cache
    
    alt Cache Hit
        Cache-->>Lang: Cached response
        Lang-->>API: Return cached result
    else Cache Miss
        Lang->>Lang: Build prompt with template
        Lang->>OpenAI: POST /v1/chat/completions<br/>{messages, model, max_tokens}
        OpenAI-->>Lang: Completion response<br/>{text, tokens_used}
        Lang->>Cache: Store response (TTL: 1 hour)
        Lang->>MongoDB: Log interaction<br/>(cost tracking)
        Lang-->>API: Return completion
    end
```

**Integration Configuration**:

| Aspect | Specification | Value |
|--------|--------------|-------|
| **API Endpoint** | Base URL | `https://api.openai.com/v1` |
| **Authentication** | API Key | Stored in AWS Secrets Manager |
| **Models Supported** | LLM models | gpt-3.5-turbo, gpt-4, gpt-4-turbo |
| **Embeddings Model** | Vector embeddings | text-embedding-ada-002 (1536 dimensions) |

**API Request Example**:

```python
# Pseudocode: OpenAI API integration via LangChain
from langchain.llms import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

#### Initialize LLM with configuration
llm = ChatOpenAI(
    model="gpt-4-turbo",
    temperature=0.7,
    max_tokens=500,
    openai_api_key=get_secret("openai_api_key"),
    timeout=30,
    max_retries=2
)

#### Build prompt from template
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant."),
    ("user", "{user_input}")
])

#### Execute LLM call
response = llm.predict(
    prompt_template.format(user_input=user_query)
)

#### Log for cost tracking
log_ai_interaction(
    user_id=user_id,
    model="gpt-4-turbo",
    prompt=user_query,
    response=response,
    tokens_used=calculate_tokens(user_query, response),
    cost_usd=calculate_cost(tokens_used, "gpt-4-turbo")
)
```

#### 6.3.4.3 AWS Services Integration

**AWS Services Architecture**:

```mermaid
graph TB
    subgraph "Application Services"
        FlaskAPI[Flask API<br/>ECS Fargate]
        LangChain[LangChain Service<br/>ECS Fargate]
    end
    
    subgraph "AWS Infrastructure Services"
        ECS[Amazon ECS<br/>Container Orchestration]
        ALB[Application Load Balancer<br/>TLS Termination]
        S3[Amazon S3<br/>Object Storage]
        CloudWatch[CloudWatch<br/>Logs & Metrics]
        SecretsManager[Secrets Manager<br/>Credential Storage]
        ECR[Elastic Container Registry<br/>Docker Images]
    end
    
    subgraph "External Clients"
        Clients[Web/Mobile/Desktop<br/>Clients]
    end
    
    Clients -->|HTTPS| ALB
    ALB -->|Route| FlaskAPI
    
    ECS -.->|Orchestrate| FlaskAPI
    ECS -.->|Orchestrate| LangChain
    
    FlaskAPI -->|Read/Write| S3
    FlaskAPI -->|Logs| CloudWatch
    FlaskAPI -->|Fetch secrets| SecretsManager
    
    LangChain -->|Logs| CloudWatch
    LangChain -->|Fetch secrets| SecretsManager
    
    ECS -->|Pull images| ECR
    
    style FlaskAPI fill:#4CAF50
    style S3 fill:#FFF9E6
    style CloudWatch fill:#E3F2FD
    style SecretsManager fill:#F3E5F5
```

**AWS Service Integrations**:

| Service | Integration Method | Purpose | Data Exchange Pattern |
|---------|-------------------|---------|----------------------|
| **ECS Fargate** | AWS SDK (Boto3), Task Definitions | Container orchestration | ECS API calls for deployment |
| **S3** | Boto3 SDK, Presigned URLs | File storage | Direct client uploads, API downloads |
| **CloudWatch Logs** | CloudWatch Logs SDK | Centralized logging | Structured JSON logs |
| **Secrets Manager** | Boto3 SDK | Secure credential storage | Secret retrieval at runtime |

**S3 Presigned URL Pattern**:

```python
# Pseudocode: Generate presigned URL for file upload
import boto3
from datetime import timedelta

s3_client = boto3.client('s3')

def generate_upload_url(filename, mime_type, user_id):
    """Generate presigned URL for direct client upload"""
    file_id = str(uuid.uuid4())
    s3_key = f"uploads/{datetime.now().year}/{datetime.now().month}/{file_id}-{filename}"
    
    # Generate presigned PUT URL (15-minute expiration)
    presigned_url = s3_client.generate_presigned_url(
        'put_object',
        Params={
            'Bucket': 'app-uploads-prod',
            'Key': s3_key,
            'ContentType': mime_type
        },
        ExpiresIn=900  # 15 minutes
    )
    
    # Store file metadata in MongoDB
    db.files.insert_one({
        'file_id': file_id,
        'user_id': user_id,
        's3_key': s3_key,
        'filename': filename,
        'status': 'pending',
        'created_at': datetime.utcnow()
    })
    
    return {
        'upload_url': presigned_url,
        'file_id': file_id,
        's3_key': s3_key
    }
```

#### 6.3.4.4 MongoDB Integration

**Connection and Query Pattern**:

```python
# Pseudocode: MongoDB connection with replica set
from pymongo import MongoClient, ReadPreference, WriteConcern

#### Initialize connection with configuration
client = MongoClient(
    connection_string,
    maxPoolSize=50,  # Connection pool
    minPoolSize=10,
    serverSelectionTimeoutMS=5000,
    connectTimeoutMS=10000
)

db = client['app_database']

#### Write with majority write concern (durability)
db.documents.insert_one(
    document,
    write_concern=WriteConcern(w='majority', wtimeout=5000)
)

#### Read from secondary (offload primary)
documents = db.documents.find(
    {'user_id': user_id},
    read_preference=ReadPreference.SECONDARY_PREFERRED
).sort('created_at', -1).limit(20)
```

**Integration Patterns**:

| Pattern | Use Case | Implementation |
|---------|----------|----------------|
| **Direct Driver Connection** | All database operations | PyMongo with connection pooling |
| **Replica Set Failover** | High availability | Automatic promotion on primary failure (< 10s) |
| **Read Scaling** | Distribute read load | SecondaryPreferred read preference |
| **Transaction Support** | Multi-document atomicity | MongoDB multi-document transactions |

---

### 6.3.5 Integration Flow Diagrams

#### 6.3.5.1 Complete API Request Flow

```mermaid
sequenceDiagram
    participant Client
    participant ALB as Application Load Balancer
    participant API as Flask API
    participant Auth0
    participant Redis as Redis Cache
    participant MongoDB
    participant CloudWatch
    
    Client->>ALB: HTTPS Request<br/>Authorization: Bearer {JWT}
    ALB->>ALB: TLS Termination<br/>Health Check Routing
    ALB->>API: Forward to Healthy Instance
    
    API->>CloudWatch: Log Request (request_id, endpoint, user)
    
    rect rgb(240, 248, 255)
        Note over API: Authentication & Authorization
        API->>Redis: Check JWKS Cache
        alt JWKS Cached
            Redis-->>API: Cached Public Keys
        else JWKS Not Cached
            API->>Auth0: Fetch JWKS
            Auth0-->>API: Public Keys
            API->>Redis: Cache JWKS (1hr TTL)
        end
        
        API->>API: Verify JWT Signature<br/>Validate Claims (exp, iss, aud)
        API->>API: Extract User Context<br/>(user_id, permissions)
        
        API->>Redis: Check Rate Limit
        Redis-->>API: Rate Limit OK
        
        API->>API: Validate Request Schema<br/>(Pydantic)
        API->>API: Check Permissions<br/>(PBAC)
    end
    
    rect rgb(255, 250, 240)
        Note over API,MongoDB: Business Logic Execution
        API->>API: Generate Cache Key
        API->>Redis: Check Response Cache
        
        alt Cache Hit
            Redis-->>API: Cached Response
            API->>CloudWatch: Log Cache Hit
        else Cache Miss
            Redis-->>API: Cache Miss
            API->>MongoDB: Execute Query
            MongoDB-->>API: Query Results
            API->>API: Transform Data to API Format
            API->>Redis: Store in Cache (TTL)
            API->>CloudWatch: Log Cache Miss
        end
    end
    
    API->>CloudWatch: Log Response (status, duration)
    API-->>ALB: HTTP Response
    ALB-->>Client: HTTPS Response
```

#### 6.3.5.2 AI/ML Processing Flow

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant Redis
    participant LangChain
    participant OpenAI
    participant VectorDB as Vector Database
    participant MongoDB
    
    Client->>API: POST /api/v1/ai/search<br/>{query: "Find documents about X"}
    
    API->>API: Validate JWT<br/>Check ai:search permission
    API->>Redis: Check AI rate limit (10/min)
    Redis-->>API: Rate limit OK
    
    API->>Redis: Check cached RAG response
    Redis-->>API: Cache miss
    
    API->>LangChain: Semantic search request
    
    rect rgb(255, 250, 240)
        Note over LangChain,VectorDB: RAG Pipeline
        LangChain->>OpenAI: Generate query embedding<br/>text-embedding-ada-002
        OpenAI-->>LangChain: 1536-dim vector
        
        LangChain->>VectorDB: Vector similarity search<br/>(cosine, top_k=5)
        VectorDB-->>LangChain: Top 5 relevant documents
        
        LangChain->>LangChain: Construct prompt:<br/>Context: [retrieved docs]<br/>Question: [user query]
        
        LangChain->>OpenAI: LLM completion<br/>gpt-4-turbo
        OpenAI-->>LangChain: Generated answer
    end
    
    LangChain-->>API: Response + source citations
    
    API->>MongoDB: Log AI interaction<br/>(prompt, response, tokens, cost)
    API->>Redis: Cache response (1hr TTL)
    API->>Client: 200 OK<br/>{answer, sources, tokens_used}
```

#### 6.3.5.3 File Upload Flow (Presigned URL)

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant MongoDB
    participant S3 as Amazon S3
    
    Note over Client,S3: Phase 1: Request Upload URL
    Client->>API: POST /api/v1/files/upload-url<br/>{filename, size, mime_type}
    API->>API: Validate JWT<br/>Check permissions
    API->>API: Generate file_id (UUID)
    API->>S3: Generate presigned PUT URL<br/>(15-min expiration)
    S3-->>API: Presigned URL
    API->>MongoDB: Create file record<br/>{file_id, status: pending}
    API->>Client: {upload_url, file_id}
    
    Note over Client,S3: Phase 2: Direct Upload to S3
    Client->>S3: PUT file data<br/>(using presigned URL)
    S3-->>Client: 200 OK
    
    Note over Client,S3: Phase 3: Confirm Upload
    Client->>API: POST /api/v1/files/complete<br/>{file_id}
    API->>MongoDB: Update file status<br/>{file_id, status: complete}
    API->>Client: {file_id, status: complete}
```

---

### 6.3.6 Integration Diagrams

#### 6.3.6.1 System Integration Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        WebClient[Web Application<br/>React + TypeScript]
        MobileClient[Mobile Applications<br/>iOS, Android, React Native]
        DesktopClient[Desktop Applications<br/>Electron, macOS Native]
    end
    
    subgraph "API Gateway & Load Balancing"
        ALB[Application Load Balancer<br/>- TLS Termination<br/>- Health Checks<br/>- Multi-AZ Distribution]
    end
    
    subgraph "Application Services - ECS Fargate"
        FlaskAPI[Flask REST API<br/>- Business Logic<br/>- Authentication Middleware<br/>- Rate Limiting<br/>- Request Validation]
        LangChainSvc[LangChain AI Service<br/>- LLM Orchestration<br/>- RAG Processing<br/>- Prompt Engineering]
    end
    
    subgraph "Data Layer"
        MongoDB[(MongoDB Replica Set<br/>- Primary + 2 Secondaries<br/>- Auto-failover<br/>- Read Scaling)]
        Redis[(Redis Cache<br/>- API Response Cache<br/>- Rate Limit Counters<br/>- JWKS Cache)]
        S3[(Amazon S3<br/>- User File Storage<br/>- Backups<br/>- Static Assets)]
        VectorDB[(Vector Database<br/>- Document Embeddings<br/>- Semantic Search<br/>- 1536-dim vectors)]
    end
    
    subgraph "External Services"
        Auth0Cloud[Auth0<br/>- User Authentication<br/>- JWT Issuance<br/>- MFA<br/>- User Management]
        OpenAICloud[OpenAI API<br/>- GPT-4 Turbo<br/>- GPT-3.5 Turbo<br/>- text-embedding-ada-002]
        AWSServices[AWS Services<br/>- CloudWatch Logs/Metrics<br/>- Secrets Manager<br/>- ECR<br/>- Certificate Manager]
    end
    
    WebClient -->|1. HTTPS + JWT| ALB
    MobileClient -->|1. HTTPS + JWT| ALB
    DesktopClient -->|1. HTTPS + JWT| ALB
    
    ALB -->|2. Load Balance| FlaskAPI
    
    WebClient -.->|OAuth 2.0 Login| Auth0Cloud
    MobileClient -.->|OAuth 2.0 Login| Auth0Cloud
    DesktopClient -.->|OAuth 2.0 Login| Auth0Cloud
    
    FlaskAPI -->|3. JWT Validation| Auth0Cloud
    FlaskAPI <-->|4. Cache Ops| Redis
    FlaskAPI <-->|5. Data CRUD| MongoDB
    FlaskAPI -->|6. File Ops| S3
    FlaskAPI -->|7. AI Requests| LangChainSvc
    
    LangChainSvc -->|8. LLM Calls| OpenAICloud
    LangChainSvc -->|9. Embeddings| OpenAICloud
    LangChainSvc <-->|10. Vector Search| VectorDB
    LangChainSvc <-->|11. Memory Storage| MongoDB
    
    FlaskAPI -.->|Logs/Metrics| AWSServices
    LangChainSvc -.->|Logs/Metrics| AWSServices
    FlaskAPI -.->|Fetch Secrets| AWSServices
    
    style FlaskAPI fill:#4CAF50
    style LangChainSvc fill:#66BB6A
    style MongoDB fill:#E3F2FD
    style Redis fill:#FFE6E6
    style S3 fill:#FFF9E6
    style VectorDB fill:#E8F5E9
    style Auth0Cloud fill:#F3E5F5
    style OpenAICloud fill:#FFF3E0
    style AWSServices fill:#E1F5FE
```

#### 6.3.6.2 Authentication Integration Flow

```mermaid
flowchart TD
    Start([User Initiates Login]) --> PlatformCheck{Platform?}
    
    PlatformCheck -->|Web| WebFlow[Web Browser Flow]
    PlatformCheck -->|Mobile| MobileFlow[Mobile Native Flow]
    PlatformCheck -->|Desktop| DesktopFlow[Desktop App Flow]
    
    WebFlow --> Auth0Universal[Auth0 Universal Login<br/>HTTPS Redirect]
    MobileFlow --> Auth0Mobile[Auth0 via ASWebAuthenticationSession iOS<br/>or Chrome Custom Tabs Android]
    DesktopFlow --> Auth0Desktop[Auth0 via System Browser<br/>Custom Protocol Handler]
    
    Auth0Universal --> UserAuth[User Authenticates<br/>Credentials + MFA]
    Auth0Mobile --> UserAuth
    Auth0Desktop --> UserAuth
    
    UserAuth --> Auth0Issue[Auth0 Issues Tokens:<br/>- Access Token JWT 15min<br/>- Refresh Token 7 days<br/>- ID Token]
    
    Auth0Issue --> StoreTokens{Store Tokens}
    StoreTokens -->|Web| WebStore[Browser Memory<br/>Auth0 SDK]
    StoreTokens -->|Mobile| MobileStore[iOS Keychain<br/>Android Keystore]
    StoreTokens -->|Desktop| DesktopStore[Electron SafeStorage]
    
    WebStore --> APIRequest[Make API Request<br/>Authorization: Bearer JWT]
    MobileStore --> APIRequest
    DesktopStore --> APIRequest
    
    APIRequest --> ValidateJWT[API Validates JWT:<br/>1. Check JWKS Cache Redis<br/>2. Verify Signature RS256<br/>3. Validate Claims]
    
    ValidateJWT --> JWTValid{JWT Valid?}
    JWTValid -->|No| Return401[Return 401 Unauthorized]
    JWTValid -->|Yes| ExtractContext[Extract User Context:<br/>user_id, permissions]
    
    ExtractContext --> CheckPerms{Has Required<br/>Permissions?}
    CheckPerms -->|No| Return403[Return 403 Forbidden]
    CheckPerms -->|Yes| ProcessRequest[Process API Request]
    
    ProcessRequest --> Success[Return 200 OK + Data]
    
    Return401 --> End([End])
    Return403 --> End
    Success --> End
    
    style UserAuth fill:#FFF3E0
    style Auth0Issue fill:#F3E5F5
    style ValidateJWT fill:#E3F2FD
    style ProcessRequest fill:#C8E6C9
```

---

### 6.3.7 References

#### Technical Specification Sections Referenced
- `1.2 System Overview` - Project context, implementation status
- `3.1 Technology Stack Overview` - Overall technology approach and architecture
- `3.5 Third-Party Services` - Auth0, AWS, OpenAI integration details
- `4.3 Authentication and Authorization Flows (Planned)` - OAuth 2.0, JWT, PBAC specifications
- `4.4 API Request Processing Flows (Planned)` - Request handling, caching, error handling patterns
- `4.5 AI/ML Processing Workflows (Planned)` - LLM integration, RAG workflows, embedding generation
- `5.1 High-Level Architecture` - System architecture, data flows, component interactions
- `5.4 Cross-Cutting Concerns` - Monitoring, logging, error handling, performance requirements
- `6.1 Core Services Architecture` - Service specifications, communication patterns, scalability
- `6.2 Database Design` - Data models, integration patterns, replication architecture

#### Repository Files Examined
- `README.md` (root) - Project title documentation; repository in pre-implementation phase with no source code

#### Implementation Status
**Pre-Implementation Phase**: All integration architecture patterns, API designs, and external system interfaces documented in this section represent planned design specifications. The repository currently contains only a README.md file with no implemented code, configuration files, or infrastructure.

## 6.4 Security Architecture

### 6.4.1 Security Architecture Overview

#### 6.4.1.1 Implementation Status

**Current Repository State**: The CheckSameRepoNoPrompt repository is in **pre-implementation phase**, containing only a README.md file with the project title. No security implementation code, authentication modules, or security configuration files exist at this time.

**Documentation Scope**: This section documents the **planned security architecture** based on comprehensive technical specifications. All security frameworks, authentication flows, and data protection mechanisms described herein represent the intended security posture that will be implemented during the development phase.

#### 6.4.1.2 Security Design Philosophy

The CheckSameRepoNoPrompt system implements a **defense-in-depth security architecture** designed to protect user data, prevent unauthorized access, and ensure regulatory compliance. The security framework adheres to industry best practices and established standards including OAuth 2.0, OpenID Connect, and enterprise encryption protocols.

**Core Security Principles**:

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **Zero Trust Architecture** | Authentication and authorization at every layer | No implicit trust, continuous verification |
| **Defense in Depth** | Multiple security layers (network, transport, application, data) | Redundant protection, failure resilience |
| **Security by Design** | Security integrated from architecture phase | Proactive rather than reactive security |
| **Least Privilege Access** | Permission-based access control, minimal grants | Reduced attack surface, limited breach impact |

**Security Layers**:

```mermaid
graph TB
    subgraph "Security Layer Architecture"
        subgraph "Layer 1: Network Security"
            VPC[VPC Isolation<br/>Private Subnets]
            SG[Security Groups<br/>Port Restrictions]
            TLS[TLS 1.3 Encryption<br/>Certificate Management]
        end
        
        subgraph "Layer 2: Authentication"
            Auth0[Auth0 Identity Provider<br/>OAuth 2.0 + OIDC]
            MFA[Multi-Factor Authentication<br/>SMS, TOTP, Email]
            JWT[JWT Token Management<br/>RS256 Signatures]
        end
        
        subgraph "Layer 3: Authorization"
            PBAC[Permission-Based Access Control<br/>action:resource format]
            ResourceAuth[Resource-Level Authorization<br/>Ownership Validation]
            AdminOverride[Administrative Override<br/>admin:system permission]
        end
        
        subgraph "Layer 4: Application Security"
            RateLimit[Rate Limiting<br/>Redis Token Bucket]
            InputVal[Input Validation<br/>Pydantic Schemas]
            CORS[CORS Configuration<br/>Origin Restrictions]
        end
        
        subgraph "Layer 5: Data Protection"
            EncryptRest[Encryption at Rest<br/>AES-256]
            EncryptTransit[Encryption in Transit<br/>TLS 1.3]
            Audit[Audit Logging<br/>Immutable Append-Only]
        end
    end
    
    Client[Client Applications] -->|HTTPS| VPC
    VPC --> SG
    SG --> TLS
    TLS --> Auth0
    Auth0 --> MFA
    MFA --> JWT
    JWT --> PBAC
    PBAC --> ResourceAuth
    ResourceAuth --> AdminOverride
    AdminOverride --> RateLimit
    RateLimit --> InputVal
    InputVal --> CORS
    CORS --> EncryptRest
    EncryptRest --> EncryptTransit
    EncryptTransit --> Audit
    Audit --> Protected[Protected Resources]
    
    style Layer1 fill:#FFEBEE
    style Layer2 fill:#F3E5F5
    style Layer3 fill:#E8EAF6
    style Layer4 fill:#E0F2F1
    style Layer5 fill:#FFF9C4
    style Protected fill:#C8E6C9
```

---

### 6.4.2 Authentication Framework

#### 6.4.2.1 Identity Management

**Auth0 Enterprise Identity Platform**:

The system delegates all identity management to Auth0, a cloud-based identity-as-a-service provider that implements OAuth 2.0 and OpenID Connect standards. This approach provides enterprise-grade authentication with minimal operational overhead.

**Auth0 Configuration**:

| Component | Specification | Purpose |
|-----------|---------------|---------|
| **Authentication Protocol** | OAuth 2.0 with OIDC | Industry-standard secure authentication |
| **Authorization Flow** | Authorization Code Flow with PKCE | Mitigate authorization code interception |
| **User Database** | Auth0 managed | Centralized identity store with profile metadata |
| **Social Identity Providers** | Google, Facebook, Apple, GitHub | Simplified user onboarding |

**User Identity Structure**:

```json
{
  "user_id": "auth0|123456789",
  "email": "user@example.com",
  "email_verified": true,
  "name": "John Doe",
  "picture": "https://gravatar.com/avatar/...",
  "identities": [
    {
      "provider": "auth0",
      "user_id": "123456789",
      "connection": "Username-Password-Authentication",
      "isSocial": false
    }
  ],
  "created_at": "2024-01-15T10:30:00.000Z",
  "updated_at": "2024-01-20T14:45:00.000Z",
  "last_login": "2024-01-20T14:45:00.000Z",
  "logins_count": 42,
  "app_metadata": {
    "roles": ["user", "editor"],
    "tenant_id": "company-123"
  },
  "user_metadata": {
    "preferences": {
      "theme": "dark",
      "language": "en"
    }
  }
}
```

**Identity Synchronization**:

Auth0 serves as the source of truth for authentication, while MongoDB stores supplementary user data for application-specific features:

- **Auth0 Store**: Authentication credentials, email verification, MFA settings, login history
- **MongoDB Store**: User preferences, application settings, subscription tier, usage statistics

**User Lifecycle Management**:

| Event | Auth0 Action | MongoDB Action | Security Implication |
|-------|-------------|----------------|---------------------|
| **User Registration** | Create Auth0 user, send verification email | Create user profile on first login | Email verification prevents fake accounts |
| **Email Verification** | Mark email_verified=true | No action required | Enable full account access |
| **Password Reset** | Auth0 password reset flow | No action required | User-initiated, secure reset link |
| **Account Deletion** | Disable Auth0 user (soft delete) | 30-day grace period, then permanent deletion | GDPR Article 17 compliance |

#### 6.4.2.2 Multi-Factor Authentication (MFA)

**MFA Implementation**:

Auth0 provides built-in multi-factor authentication with multiple verification methods:

| MFA Method | Delivery Mechanism | Security Level | User Experience |
|-----------|-------------------|----------------|-----------------|
| **SMS OTP** | Text message to registered phone | Medium (vulnerable to SIM swap) | High friction, universal support |
| **TOTP Authenticator** | Time-based codes (Google Authenticator, Authy) | High (offline generation) | Medium friction, requires app |
| **Email OTP** | Code sent to verified email | Low (email compromise risk) | High friction, fallback option |
| **Push Notifications** | Auth0 Guardian app approval | High (biometric optional) | Low friction, best UX |

**MFA Enforcement Policies**:

```
Global MFA Policy: Optional (user-configurable)
Admin Users: Required MFA (TOTP or Push)
High-Risk Actions: Step-up authentication (additional MFA challenge)
New Device Login: Optional MFA prompt
```

**MFA Authentication Flow**:

The following diagram illustrates the complete authentication workflow including MFA challenges:

```mermaid
sequenceDiagram
    participant User
    participant Client as Client Application<br/>(Web/Mobile/Desktop)
    participant Auth0 as Auth0<br/>Identity Provider
    participant API as Backend API<br/>(Flask)
    participant DB as MongoDB<br/>Database

    Note over User,DB: Initial Application Access
    
    User->>Client: Launch Application
    Client->>Client: Check Local Storage<br/>for JWT Token
    
    alt Token Exists and Valid
        Client->>API: API Request<br/>(Authorization: Bearer {JWT})
        API->>API: Validate JWT Signature<br/>Check Expiration
        API->>DB: Query User Data
        DB->>API: Return User Profile
        API->>Client: Return Protected Resource
        Client->>User: Display Application
    else Token Expired or Invalid
        Client->>Client: Attempt Token Refresh
        Client->>Auth0: Refresh Token Request<br/>(grant_type=refresh_token)
        
        alt Refresh Token Valid
            Auth0->>Auth0: Validate Refresh Token
            Auth0->>Client: New Access Token<br/>+ Refresh Token
            Client->>Client: Store New Tokens
            Client->>User: Continue to Application
        else Refresh Token Invalid
            Client->>User: Redirect to Login
        end
    else No Token Present
        Client->>User: Redirect to Login
    end
    
    Note over User,DB: Login Flow
    
    User->>Client: Click "Login" Button
    Client->>Auth0: Redirect to Universal Login<br/>(response_type=code, scope=openid profile email)
    Auth0->>User: Display Login Page
    
    User->>Auth0: Enter Credentials<br/>(Email/Password or Social)
    Auth0->>Auth0: Validate Credentials
    
    alt Credentials Invalid
        Auth0->>User: Display Error<br/>"Invalid credentials"
        User->>Auth0: Retry Login
    else MFA Enabled
        Auth0->>User: Prompt for MFA Code<br/>(SMS/Authenticator App)
        User->>Auth0: Provide MFA Code
        Auth0->>Auth0: Validate MFA Code
        
        alt MFA Invalid
            Auth0->>User: Display Error<br/>"Invalid MFA code"
            User->>Auth0: Retry MFA
        end
    end
    
    Auth0->>Client: Authorization Code<br/>(via Callback URL)
    Client->>Auth0: Exchange Code for Tokens<br/>(grant_type=authorization_code)
    Auth0->>Auth0: Validate Authorization Code
    Auth0->>Client: Access Token (JWT)<br/>+ Refresh Token<br/>+ ID Token
    
    Client->>Client: Validate ID Token<br/>Extract User Info
    Client->>Client: Store Tokens Securely<br/>(Keychain/Keystore/Secure Storage)
    
    Client->>API: Create/Update User Profile<br/>(Authorization: Bearer {JWT})
    API->>API: Validate JWT<br/>Extract Auth0 User ID
    API->>DB: Upsert User Document<br/>(auth0_id, email, name, metadata)
    DB->>API: Confirm User Stored
    API->>Client: Return User Profile
    
    Client->>User: Redirect to Main Application
    User->>Client: Interact with Application
```

**MFA Recovery Mechanisms**:

| Scenario | Recovery Method | Security Control |
|----------|----------------|------------------|
| **Lost MFA Device** | Recovery codes (generated at MFA setup) | User must securely store 10 one-time codes |
| **Lost Recovery Codes** | Identity verification via email | Requires email access + account details |
| **Locked Account** | Admin manual unlock | Audit logged, requires justification |

#### 6.4.2.3 Session Management

**Stateless JWT-Based Sessions**:

The system implements **stateless authentication** using JSON Web Tokens (JWT), eliminating the need for server-side session storage. This architecture provides horizontal scalability and simplified infrastructure management.

**Token Types and Lifecycle**:

| Token Type | Purpose | Lifetime | Storage Location | Security Features |
|-----------|---------|----------|------------------|-------------------|
| **Access Token** | API authorization | 15 minutes | Memory (web), Keychain (iOS), Keystore (Android) | Short-lived, RS256 signed, expires automatically |
| **Refresh Token** | Silent renewal | 7 days | Secure storage only (never exposed to JavaScript) | Long-lived, one-time use, rotation enabled |
| **ID Token** | User profile | 15 minutes | Memory or secure storage | OpenID Connect standard, profile claims |

**JWT Access Token Structure**:

```json
{
  "header": {
    "alg": "RS256",
    "typ": "JWT",
    "kid": "key-identifier-abc123"
  },
  "payload": {
    "iss": "https://your-tenant.auth0.com/",
    "sub": "auth0|123456789",
    "aud": "your-api-identifier",
    "iat": 1672531200,
    "exp": 1672532100,
    "azp": "your-client-id",
    "scope": "openid profile email",
    "permissions": [
      "read:documents",
      "write:documents",
      "ai:completions"
    ]
  },
  "signature": "RS256_signature_bytes..."
}
```

**Session Security Controls**:

| Control | Implementation | Threat Mitigated |
|---------|----------------|------------------|
| **Short Token Lifetime** | 15-minute expiration | Limits window for token theft exploitation |
| **Refresh Token Rotation** | New refresh token issued on each use | Prevents refresh token replay attacks |
| **Token Binding** | IP address tracking (optional) | Detects token theft and cross-device usage |
| **Secure Storage** | Platform-specific secure storage | Prevents token extraction from device |

**Token Refresh Flow**:

```
1. Client detects Access Token approaching expiration (< 5 minutes remaining)
2. Client sends Refresh Token to Auth0 token endpoint
3. Auth0 validates Refresh Token (not revoked, not expired)
4. Auth0 issues new Access Token + new Refresh Token (rotation)
5. Client replaces old tokens with new tokens
6. Old Refresh Token becomes invalid (one-time use)
```

**Session Termination**:

| Termination Type | Trigger | Effect |
|-----------------|---------|--------|
| **User Logout** | User clicks logout button | Tokens cleared from local storage, Auth0 session terminated |
| **Token Expiration** | Access Token expires (15 min) | Automatic refresh attempt, or redirect to login |
| **Refresh Token Expiration** | Refresh Token expires (7 days) | User must re-authenticate via Auth0 |
| **Administrative Revocation** | Admin revokes user session | All tokens invalidated immediately via Auth0 Management API |

#### 6.4.2.4 Token Handling and Validation

**JWT Validation Process**:

Every API request requires a valid JWT token in the Authorization header. The backend performs comprehensive validation to ensure token authenticity and integrity:

```mermaid
flowchart TD
    Start([API Request Received]) --> ExtractHeader[Extract Authorization Header]
    ExtractHeader --> HeaderExists{Header<br/>Present?}
    
    HeaderExists -->|No| Return401Missing[Return 401 Unauthorized<br/>Error: Missing Authorization header]
    HeaderExists -->|Yes| ParseHeader["Parse Header<br/>Format: Bearer {token}"]
    
    ParseHeader --> FormatValid{Format<br/>Valid?}
    FormatValid -->|No| Return401Format[Return 401 Unauthorized<br/>Error: Invalid Authorization format]
    FormatValid -->|Yes| ExtractToken[Extract JWT Token<br/>from Bearer scheme]
    
    ExtractToken --> DecodeToken[Decode JWT<br/>Extract Header, Payload, Signature]
    DecodeToken --> CheckAlgorithm{Algorithm<br/>is RS256?}
    
    CheckAlgorithm -->|No| Return401Algo[Return 401 Unauthorized<br/>Error: Unsupported algorithm]
    CheckAlgorithm -->|Yes| FetchJWKS[Fetch Auth0 JWKS<br/>Public Key Set]
    
    FetchJWKS --> JWKSSuccess{JWKS<br/>Retrieved?}
    JWKSSuccess -->|No| Return503[Return 503 Service Unavailable<br/>Error: Cannot verify token]
    JWKSSuccess -->|Yes| SelectKey[Select Public Key<br/>by kid from JWT header]
    
    SelectKey --> VerifySignature[Verify JWT Signature<br/>with Public Key]
    VerifySignature --> SignatureValid{Signature<br/>Valid?}
    
    SignatureValid -->|No| Return401Sig[Return 401 Unauthorized<br/>Error: Invalid token signature]
    SignatureValid -->|Yes| CheckExpiration[Check Expiration<br/>exp claim vs. current time]
    
    CheckExpiration --> NotExpired{Token Not<br/>Expired?}
    NotExpired -->|No| Return401Exp[Return 401 Unauthorized<br/>Error: Token expired]
    NotExpired -->|Yes| CheckIssuer[Verify Issuer<br/>iss claim matches Auth0 domain]
    
    CheckIssuer --> IssuerValid{Issuer<br/>Valid?}
    IssuerValid -->|No| Return401Iss[Return 401 Unauthorized<br/>Error: Invalid issuer]
    IssuerValid -->|Yes| CheckAudience[Verify Audience<br/>aud claim matches API identifier]
    
    CheckAudience --> AudienceValid{Audience<br/>Valid?}
    AudienceValid -->|No| Return401Aud[Return 401 Unauthorized<br/>Error: Invalid audience]
    AudienceValid -->|Yes| ExtractClaims[Extract User Claims<br/>sub, permissions, scope]
    
    ExtractClaims --> StoreContext[Store User Context<br/>in Request Object]
    StoreContext --> ProceedRequest[✅ Proceed to<br/>Business Logic]
    
    Return401Missing --> End([End Request])
    Return401Format --> End
    Return401Algo --> End
    Return503 --> End
    Return401Sig --> End
    Return401Exp --> End
    Return401Iss --> End
    Return401Aud --> End
    ProceedRequest --> End
    
    style ProceedRequest fill:#c8e6c9
    style Return401Missing fill:#ffcdd2
    style Return401Format fill:#ffcdd2
    style Return401Algo fill:#ffcdd2
    style Return503 fill:#ffecb3
    style Return401Sig fill:#ffcdd2
    style Return401Exp fill:#ffcdd2
    style Return401Iss fill:#ffcdd2
    style Return401Aud fill:#ffcdd2
```

**JWT Validation Steps**:

1. **Header Extraction**: Parse `Authorization: Bearer {token}` header format
2. **Algorithm Verification**: Ensure JWT uses RS256 (RSA signature with SHA-256)
3. **JWKS Retrieval**: Fetch Auth0 JSON Web Key Set containing public keys for signature verification
4. **Signature Verification**: Use public key matching `kid` (Key ID) from JWT header to verify cryptographic signature
5. **Claims Validation**:
   - `exp` (Expiration): Token must not be expired
   - `iss` (Issuer): Must match Auth0 tenant domain
   - `aud` (Audience): Must match API identifier configured in Auth0
6. **User Context Extraction**: Extract `sub` (subject/user_id) and `permissions` array for authorization

**JWKS Caching Strategy**:

To minimize latency and reduce external dependencies, Auth0 public keys are cached in Redis:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| **Cache Key** | `jwks:auth0` | Single key for all Auth0 public keys |
| **TTL (Time to Live)** | 3600 seconds (1 hour) | Balance freshness with performance |
| **Cache Miss Behavior** | Fetch from Auth0 `/.well-known/jwks.json` | Fallback to source of truth |
| **Key Rotation Handling** | Automatic cache invalidation | Auth0 notifies of key changes |

**JWT Validation Performance Targets**:

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Validation Latency** | < 20ms | Minimize overhead on API requests |
| **JWKS Cache Hit Rate** | > 95% | Reduce Auth0 API calls |
| **Validation Success Rate** | > 99.9% | High reliability requirement |

#### 6.4.2.5 Password Policies

**Password Security Delegation**:

All password policies are enforced by Auth0, eliminating the need for custom password handling in the application. This approach reduces security risk and ensures consistent enforcement across all authentication methods.

**Auth0 Password Policy Configuration**:

| Policy Component | Specification | Enforcement |
|-----------------|---------------|-------------|
| **Minimum Length** | 8 characters | Auth0 validates on registration and password change |
| **Complexity Requirements** | At least 3 of: lowercase, uppercase, number, symbol | Auth0 password strength meter |
| **Password History** | Prevent reuse of last 5 passwords | Auth0 stores password hashes securely |
| **Breached Password Detection** | Integration with HaveIBeenPwned database | Auto-reject compromised passwords |
| **Account Lockout** | 10 failed attempts = 30-minute lockout | Brute force protection |

**Password Reset Flow**:

```
1. User clicks "Forgot Password" link
2. User enters email address
3. Auth0 sends secure reset link (expires in 24 hours)
4. User clicks link, redirected to Auth0 password reset page
5. User enters new password (validated against policies)
6. Auth0 updates password hash
7. User redirected to login page with success message
8. All existing sessions invalidated (security measure)
```

**Security Enhancements**:

- **Rate Limiting**: Password reset requests limited to 3 per hour per email
- **Email Verification**: Reset links only sent to verified email addresses
- **Geographic Validation**: Suspicious location triggers additional verification
- **Notification**: User receives email notification of password change

---

### 6.4.3 Authorization System

#### 6.4.3.1 Permission-Based Access Control (PBAC)

**Authorization Framework**:

The system implements **Permission-Based Access Control (PBAC)**, a fine-grained authorization model where each operation requires specific permissions embedded in the JWT token. This approach provides flexibility and scalability compared to traditional role-based models.

**Permission Naming Convention**:

```
Format: {action}:{resource}

Examples:
- read:documents      → View document metadata and content
- write:documents     → Create and update documents
- delete:documents    → Delete documents
- read:users          → View user profiles
- write:users         → Update user profiles (own profile only)
- ai:completions      → Access AI text generation endpoints
- ai:conversations    → Start and manage AI conversations
- admin:system        → Full administrative access (overrides all checks)
```

**Standard Permission Catalog**:

| Permission | HTTP Methods | Endpoints | Resource Scope |
|-----------|-------------|-----------|----------------|
| `read:documents` | GET | `/api/v1/documents`, `/api/v1/documents/{id}` | User's own documents + shared documents |
| `write:documents` | POST, PUT | `/api/v1/documents`, `/api/v1/documents/{id}` | User's own documents |
| `delete:documents` | DELETE | `/api/v1/documents/{id}` | User's own documents |
| `ai:completions` | POST | `/api/v1/ai/completions` | AI text generation (rate limited) |

**Authorization Decision Flow**:

```mermaid
flowchart TD
    Start([Authenticated Request]) --> ExtractPerms[Extract Permissions<br/>from JWT Claims]
    ExtractPerms --> RouteReq{What<br/>Operation?}
    
    RouteReq -->|Read Operation| CheckRead[Check Read Permission]
    RouteReq -->|Write Operation| CheckWrite[Check Write Permission]
    RouteReq -->|Delete Operation| CheckDelete[Check Delete Permission]
    RouteReq -->|Admin Operation| CheckAdmin[Check Admin Permission]
    
    CheckRead --> HasReadPerm{Has read:resource<br/>Permission?}
    HasReadPerm -->|No| Return403Read[Return 403 Forbidden<br/>Insufficient permissions]
    HasReadPerm -->|Yes| ResourceLevel[Resource-Level Check]
    
    CheckWrite --> HasWritePerm{Has write:resource<br/>Permission?}
    HasWritePerm -->|No| Return403Write[Return 403 Forbidden<br/>Insufficient permissions]
    HasWritePerm -->|Yes| ResourceLevel
    
    CheckDelete --> HasDeletePerm{Has delete:resource<br/>Permission?}
    HasDeletePerm -->|No| Return403Delete[Return 403 Forbidden<br/>Insufficient permissions]
    HasDeletePerm -->|Yes| ResourceLevel
    
    CheckAdmin --> HasAdminPerm{Has admin<br/>Permission?}
    HasAdminPerm -->|No| Return403Admin[Return 403 Forbidden<br/>Admin access required]
    HasAdminPerm -->|Yes| ExecuteOp[Execute Admin Operation]
    
    ResourceLevel --> FetchResource[Fetch Resource<br/>from Database]
    FetchResource --> ResourceExists{Resource<br/>Exists?}
    
    ResourceExists -->|No| Return404[Return 404 Not Found<br/>Resource does not exist]
    ResourceExists -->|Yes| CheckOwnership{User Owns<br/>Resource?}
    
    CheckOwnership -->|No| CheckShared{Resource<br/>Shared with User?}
    CheckOwnership -->|Yes| ExecuteOp
    
    CheckShared -->|No| Return403Owner[Return 403 Forbidden<br/>Access denied to resource]
    CheckShared -->|Yes| ExecuteOp
    
    ExecuteOp --> LogAccess[Log Access Event<br/>Audit Trail]
    LogAccess --> Success[✅ Operation Successful<br/>Return Result]
    
    Return403Read --> End([End Request])
    Return403Write --> End
    Return403Delete --> End
    Return403Admin --> End
    Return404 --> End
    Return403Owner --> End
    Success --> End
    
    style ExecuteOp fill:#e8f5e9
    style Success fill:#c8e6c9
    style Return403Read fill:#ffcdd2
    style Return403Write fill:#ffcdd2
    style Return403Delete fill:#ffcdd2
    style Return403Admin fill:#ffcdd2
    style Return403Owner fill:#ffcdd2
    style Return404 fill:#fff9c4
```

**Permission Enforcement Layers**:

1. **Endpoint-Level**: Validate user has required permission for endpoint (e.g., `write:documents` for document creation)
2. **Resource-Level**: Verify user owns or has access to specific resource (e.g., document belongs to user or is shared)
3. **Administrative Override**: `admin:system` permission bypasses resource-level checks for operational purposes

#### 6.4.3.2 Role-Based Access Control (RBAC)

**Role Definitions**:

While the system uses permission-based authorization, Auth0 implements roles as convenient permission bundles. Users are assigned one or more roles, and the JWT token contains all permissions from assigned roles.

| Role Name | Assigned Permissions | Typical User Type | Use Case |
|-----------|---------------------|-------------------|----------|
| **Viewer** | `read:documents`, `ai:completions` | Read-only user, guest | View documents, use AI features, no modifications |
| **User** | `read:documents`, `write:documents`, `ai:completions`, `ai:conversations` | Standard user | Full document management, AI interactions |
| **Admin** | All permissions including `admin:system` | System administrator | Full system access, user management, configuration |

**Role Assignment Methods**:

- **Auth0 Dashboard**: Administrators assign roles via Auth0 Management Console
- **Auth0 Management API**: Programmatic role assignment for automation and bulk operations
- **Rule-Based Assignment**: Auth0 Rules automatically assign roles based on user attributes (e.g., email domain)

#### 6.4.3.3 Resource Authorization

**Multi-Layer Resource Protection**:

Even with valid endpoint permissions, users must prove ownership or explicit sharing access to resources:

**Ownership Validation Pattern**:

```
1. Extract user_id from JWT token (sub claim)
2. Fetch resource from database by resource_id
3. Compare resource.owner_id with JWT user_id
4. If match → Grant access
5. If mismatch → Check resource.shared_with array
6. If user_id in shared_with → Grant access
7. Otherwise → Return 403 Forbidden
```

**Resource Sharing Model**:

```json
{
  "_id": "507f1f77bcf86cd799439014",
  "user_id": "auth0|123456789",
  "title": "Project Proposal",
  "owner_id": "auth0|123456789",
  "shared_with": [
    {
      "user_id": "auth0|987654321",
      "permission": "read",
      "shared_at": "2024-01-15T10:30:00Z"
    },
    {
      "user_id": "auth0|555666777",
      "permission": "write",
      "shared_at": "2024-01-16T14:00:00Z"
    }
  ],
  "visibility": "private"
}
```

#### 6.4.3.4 Policy Enforcement Points

**Security Enforcement Architecture**:

```
Client Request
    ↓
[1] ALB (Application Load Balancer)
    - TLS termination
    - Rate limiting (infrastructure level)
    - Health check routing
    ↓
[2] API Middleware Layer
    - JWT validation
    - User context extraction
    - Request logging
    ↓
[3] Authorization Middleware
    - Permission checks (PBAC)
    - Rate limiting (user-specific)
    - Input validation
    ↓
[4] Business Logic Layer
    - Resource ownership validation
    - Admin override checks
    - Data transformation
    ↓
[5] Data Access Layer
    - MongoDB RBAC (application user permissions)
    - Query execution
    - Response formatting
```

**Enforcement Point Responsibilities**:

| Layer | Enforcement Type | Rejections Logged |
|-------|-----------------|-------------------|
| **ALB** | Network-level rate limiting, TLS enforcement | Yes (CloudWatch) |
| **API Middleware** | JWT signature and expiration validation | Yes (Application logs + CloudWatch) |
| **Authorization Middleware** | Permission validation, user rate limiting | Yes (Audit logs) |
| **Business Logic** | Resource ownership, sharing rules | Yes (Audit logs) |
| **Data Access** | MongoDB role-based access, query validation | Yes (Database logs) |

#### 6.4.3.5 Audit Logging

**Comprehensive Audit Trail**:

All authorization decisions and resource access attempts are logged for compliance, security monitoring, and incident investigation.

**Audit Log Schema**:

```json
{
  "_id": "ObjectId('...')",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456789",
  "action": "UPDATE",
  "resource_type": "documents",
  "resource_id": "507f1f77bcf86cd799439014",
  "endpoint": "/api/v1/documents/507f1f77bcf86cd799439014",
  "method": "PUT",
  "ip_address": "203.0.113.45",
  "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)...",
  "status": "success",
  "permissions_checked": ["write:documents"],
  "authorization_decision": "granted",
  "changes": {
    "before": {"title": "Old Title"},
    "after": {"title": "New Title"}
  }
}
```

**Logged Security Events**:

| Event Category | Example Events | Retention Period |
|---------------|----------------|------------------|
| **Authentication** | Login success/failure, MFA challenges, token refresh | 1 year |
| **Authorization** | Permission denied, resource access granted/denied | 7 years |
| **Data Modification** | CREATE, UPDATE, DELETE operations with change tracking | 7 years |
| **Administrative** | Role assignments, permission changes, user deletions | Permanent |

**Audit Log Security Controls**:

- **Immutability**: Append-only storage, no updates or deletions permitted
- **Integrity**: Cryptographic signatures planned for tamper detection
- **Access Control**: Restricted to compliance team and authorized auditors
- **Retention**: 7-year retention for compliance (SOC 2, GDPR, CCPA)

---

### 6.4.4 Data Protection

#### 6.4.4.1 Encryption Standards

**Encryption at Rest**:

All persistent data is encrypted using AES-256 encryption, meeting industry standards for data protection:

| Component | Encryption Method | Key Management | Algorithm |
|-----------|------------------|----------------|-----------|
| **MongoDB** | WiredTiger storage engine encryption | AWS KMS or MongoDB encrypted storage engine | AES-256-GCM |
| **S3 Buckets (User Uploads)** | Server-Side Encryption (SSE-S3) | AWS-managed keys | AES-256 |
| **S3 Buckets (Backups)** | Server-Side Encryption (SSE-KMS) | Customer-managed AWS KMS keys | AES-256 |
| **Redis Cache** | ElastiCache encryption at rest (optional) | AWS-managed keys | AES-256 |

**Encryption in Transit**:

All network communication is encrypted using TLS (Transport Layer Security):

| Connection Path | Protocol | Certificate Management | Cipher Suites |
|----------------|----------|------------------------|---------------|
| **Client → ALB** | TLS 1.3 (TLS 1.2 fallback) | AWS Certificate Manager (ACM) | ECDHE-RSA-AES256-GCM-SHA384, ECDHE-RSA-AES128-GCM-SHA256 |
| **ALB → ECS Tasks** | HTTP (internal VPC) | Private network isolation (no encryption needed) | N/A (isolated VPC) |
| **ECS → MongoDB** | TLS 1.3 (MongoDB Wire Protocol) | MongoDB Atlas managed certificates | MongoDB default TLS configuration |
| **ECS → Redis** | TLS 1.3 (optional) | ElastiCache in-transit encryption | Redis default TLS configuration |
| **ECS → S3** | HTTPS (TLS 1.3) | AWS managed | AWS S3 TLS configuration |

**TLS Configuration Best Practices**:

- **TLS 1.3 Preferred**: Use latest protocol version for maximum security
- **TLS 1.2 Fallback**: Support older clients while maintaining strong security
- **Cipher Suite Selection**: Forward secrecy (ECDHE), authenticated encryption (GCM)
- **Certificate Validation**: Strict certificate verification, no self-signed certificates in production
- **HSTS Header**: `Strict-Transport-Security: max-age=31536000; includeSubDomains` forces HTTPS

#### 6.4.4.2 Key Management

**AWS Key Management Service (KMS)**:

Customer-managed keys provide enhanced security and auditability for sensitive data:

| Key Purpose | Key Type | Rotation Policy | Access Control |
|------------|----------|----------------|----------------|
| **S3 Backup Encryption** | Customer-managed KMS key | Automatic annual rotation | IAM policy: backup service only |
| **Secrets Encryption** | AWS Secrets Manager managed key | Automatic 90-day rotation | IAM policy: ECS task role |
| **Future PII Encryption** | Customer-managed KMS key (planned) | Automatic annual rotation | IAM policy: application service |

**KMS Security Benefits**:

- **Audit Trail**: CloudTrail logs every key usage event (who, when, what)
- **Fine-Grained Access**: IAM policies control which services can use keys
- **Key Rotation**: Automatic rotation without decrypting data
- **Cross-Region Replication**: Multi-region keys for disaster recovery

**Auth0 JWKS (JSON Web Key Set) Management**:

Auth0 manages JWT signing keys with automatic rotation:

| Aspect | Implementation | Security Benefit |
|--------|----------------|------------------|
| **Key Algorithm** | RS256 (RSA 2048-bit) | Asymmetric cryptography, public key distribution |
| **Key Rotation** | Auth0 automatic rotation (configurable) | Limits exposure window for compromised keys |
| **Key Distribution** | JWKS endpoint: `https://{tenant}.auth0.com/.well-known/jwks.json` | Public keys accessible for token validation |
| **Key Caching** | Redis cache (1-hour TTL) | Performance optimization without security trade-off |

#### 6.4.4.3 Data Masking Rules

**PII (Personally Identifiable Information) Classification**:

| Data Field | PII Category | Storage Location | Protection Measure |
|-----------|-------------|------------------|-------------------|
| `email` | Direct PII | MongoDB `users.email` | Encrypted at rest, access logged, GDPR protected |
| `name` | Direct PII | Auth0 ID token (transient) | Not stored in MongoDB, Auth0-managed |
| `auth0_id` | Pseudonymous identifier | MongoDB (all collections) | Pseudonymization strategy, foreign key |
| `ip_address` | Indirect PII | Audit logs, analytics | Encrypted at rest, 90-day retention, anonymized for analytics |
| `user_agent` | Indirect PII | Audit logs | Encrypted at rest, 90-day retention |

**Logging Redaction**:

Application logs automatically redact sensitive fields to prevent accidental PII exposure:

```
Redacted Fields: password, token, api_key, secret, credit_card, ssn, email (in certain contexts)

Example:
❌ BAD LOG:  "User login: email=user@example.com, password=secretpass123"
✅ GOOD LOG: "User login: email=***REDACTED***, password=***REDACTED***"
```

**Database-Level Masking (Future Enhancement)**:

Planned field-level encryption for highly sensitive PII:

```
Sensitive Fields: Social Security Numbers, Credit Card Numbers, Healthcare Data
Encryption Method: Application-level encryption before database storage
Key Management: AWS KMS customer-managed keys
Access: Decrypt only when explicitly authorized and logged
```

#### 6.4.4.4 Secure Communication

**HTTPS Enforcement**:

All client-to-API communication occurs exclusively over HTTPS with strict security configurations:

| Configuration | Value | Purpose |
|--------------|-------|---------|
| **HTTPS Redirect** | HTTP → HTTPS automatic redirect at ALB | Prevent unencrypted traffic |
| **HSTS Header** | `max-age=31536000; includeSubDomains; preload` | Enforce HTTPS for 1 year, include all subdomains |
| **Certificate Provider** | AWS Certificate Manager (ACM) | Free, automatic renewal, AWS-managed |
| **Certificate Validation** | Domain validation (DV) | Prove domain ownership |

**Internal Network Security**:

Backend services communicate within a private VPC with additional security layers:

```mermaid
graph TB
    subgraph "Public Subnet"
        ALB[Application Load Balancer<br/>Public IP<br/>Ports: 443 HTTPS]
    end
    
    subgraph "Private Subnet A"
        ECS1[ECS Task 1<br/>No Public IP<br/>Port 5000]
        MongoDB1[MongoDB Primary<br/>No Public IP<br/>Port 27017]
    end
    
    subgraph "Private Subnet B"
        ECS2[ECS Task 2<br/>No Public IP<br/>Port 5000]
        MongoDB2[MongoDB Secondary 1<br/>No Public IP<br/>Port 27017]
    end
    
    subgraph "Private Subnet C"
        ECS3[ECS Task 3<br/>No Public IP<br/>Port 5000]
        MongoDB3[MongoDB Secondary 2<br/>No Public IP<br/>Port 27017]
    end
    
    subgraph "NAT Gateway"
        NAT[NAT Gateway<br/>Outbound Internet<br/>For ECS → External APIs]
    end
    
    Internet[Internet] -->|HTTPS 443| ALB
    ALB -->|HTTP 5000| ECS1
    ALB -->|HTTP 5000| ECS2
    ALB -->|HTTP 5000| ECS3
    
    ECS1 -->|MongoDB Protocol TLS| MongoDB1
    ECS2 -->|MongoDB Protocol TLS| MongoDB2
    ECS3 -->|MongoDB Protocol TLS| MongoDB3
    
    MongoDB1 -.->|Replication TLS| MongoDB2
    MongoDB1 -.->|Replication TLS| MongoDB3
    
    ECS1 -.->|External API Calls| NAT
    ECS2 -.->|External API Calls| NAT
    ECS3 -.->|External API Calls| NAT
    NAT -.->|HTTPS| Internet
    
    style ALB fill:#FFCDD2
    style ECS1 fill:#C8E6C9
    style ECS2 fill:#C8E6C9
    style ECS3 fill:#C8E6C9
    style MongoDB1 fill:#BBDEFB
    style MongoDB2 fill:#BBDEFB
    style MongoDB3 fill:#BBDEFB
    style NAT fill:#FFF9C4
```

**Security Group Configuration**:

| Component | Inbound Rules | Outbound Rules | Security Rationale |
|-----------|--------------|----------------|-------------------|
| **ALB** | Port 443 from 0.0.0.0/0 (internet) | Port 5000 to ECS security group | Accept public HTTPS, route to backend |
| **ECS Tasks** | Port 5000 from ALB security group only | All ports to MongoDB, Redis, S3, internet | Isolated backend, controlled access |
| **MongoDB** | Port 27017 from ECS security group only | None required | Database isolation, ECS-only access |
| **Redis** | Port 6379 from ECS security group only | None required | Cache isolation, ECS-only access |

#### 6.4.4.5 Compliance Controls

**Regulatory Framework**:

The system is designed to comply with major data protection regulations:

| Regulation | Applicability | Key Requirements | Implementation Status |
|-----------|---------------|------------------|----------------------|
| **GDPR** (EU) | All EU users | Data protection, right to be forgotten, consent | Planned compliance |
| **CCPA** (California) | California residents | Data disclosure, deletion rights, opt-out | Planned compliance |
| **SOC 2 Type II** | SaaS products | Security, availability, confidentiality | Architecture aligned |

**GDPR Article 17: Right to Be Forgotten**:

User-initiated account deletion process with 30-day grace period:

```
Day 0: User requests account deletion
    ↓
    - Account marked as "pending_deletion"
    - User receives confirmation email
    - 30-day grace period begins (user can cancel)
    ↓
Day 30: Automatic permanent deletion
    ↓
    - Delete user profile from MongoDB users collection
    - Delete all conversations and messages
    - Delete all document metadata (S3 objects deleted)
    - Delete all file metadata (S3 objects deleted)
    - Anonymize user_id in analytics (irreversible hash)
    - Anonymize user_id in AI interactions (cost tracking preserved)
    ↓
Day 30+: Deletion certificate generated
    ↓
    - Audit log entry: data categories deleted/anonymized
    - Compliance record retained for 7 years
```

**Data Retention Policies**:

| Data Type | Active Retention | Archival Trigger | Archival Storage | Final Deletion |
|-----------|-----------------|------------------|------------------|----------------|
| **User Profiles** | Indefinite | N/A | N/A | Account closure + 30 days |
| **Conversations** | Indefinite (user-controlled) | 1 year inactive | S3 Standard-IA | User deletion or account closure |
| **AI Interactions** | 6 months online | 6 months age | S3 Standard-IA | Automatic after 2 years |
| **Analytics Events** | 3 months online | 3 months age | S3 Standard-IA | Automatic after 1 year |
| **Audit Logs** | 90 days online | 90 days age | S3 Glacier | Automatic after 7 years |

**Data Anonymization for Analytics**:

Irreversible anonymization technique for deleted users:

```
Method: One-way cryptographic hash (SHA-256 with salt)
Input: auth0_id + secret_salt
Output: Anonymous user identifier

Example:
Original: auth0|123456789
Salt: randomly_generated_secret_per_environment
Hash: sha256(auth0|123456789 + salt)
Result: a3f5b8c2d9e1f7a4b6c8d0e2f4a6b8c0d2e4f6a8b0c2d4e6f8a0b2c4d6e8f0a2

Properties:
✓ Irreversible: Cannot derive original user_id from hash
✓ Consistent: Same user_id always produces same hash
✓ Privacy-preserving: Maintains analytics integrity without PII
✓ GDPR-compliant: Fully anonymized data, no longer personal data
```

---

### 6.4.5 Security Monitoring and Incident Response

#### 6.4.5.1 Security Event Tracking

**CloudWatch Security Monitoring**:

Comprehensive security event logging with automated alerting for suspicious patterns:

| Event Type | Log Level | Alert Threshold | Automated Response |
|-----------|-----------|----------------|-------------------|
| **Failed Authentication** | WARNING | > 5 attempts/min from single IP | IP rate limit increase, potential temporary ban |
| **Invalid JWT Token** | WARNING | > 10/min for single endpoint | Investigate token source, possible compromised credentials |
| **Permission Denied** | INFO | > 50/min for single user | Review user permissions, investigate potential attack |
| **Rate Limit Exceeded** | WARNING | > 100/min across all users | DDoS detection, enable stricter rate limiting |
| **Unusual AI Usage** | INFO | > 100 requests/hour per user | Cost abuse monitoring, potential account investigation |
| **Admin Actions** | AUDIT | Every occurrence | Audit log, notification to security team |

**Security Metrics Dashboard**:

```
Real-Time Monitoring Metrics:
- Authentication success/failure rate (target: > 99% success)
- JWT validation latency (target: < 20ms)
- Permission denial rate by endpoint (baseline: < 1%)
- Rate limit hits per hour (baseline: < 10)
- Audit log write throughput (monitor for data loss)
```

#### 6.4.5.2 Circuit Breaker for Auth0

**Resilient Authentication**:

Circuit breaker pattern protects the system from Auth0 service degradation:

| Circuit State | Behavior | Transition Trigger |
|--------------|----------|-------------------|
| **CLOSED** (Normal) | All JWT validation requests to Auth0 | Error rate < 10% |
| **OPEN** (Failure) | Use cached JWKS, extend cache TTL to 4 hours, fail new authentications gracefully | Error rate > 50% in 60-second window |
| **HALF-OPEN** (Testing) | Allow 5 test requests to Auth0 | After 30 seconds in OPEN state |

**Fallback Strategy**:

```
Auth0 Unavailable:
1. Use cached JWKS public keys (extend TTL from 1 hour to 4 hours)
2. Continue validating existing tokens with cached keys
3. Reject new authentication attempts with 503 Service Unavailable
4. Display user-friendly error: "Authentication service temporarily unavailable"
5. Monitor Auth0 status page for incident updates
6. Automatically recover when Auth0 returns to healthy state
```

---

### 6.4.6 Security Architecture Diagrams

#### 6.4.6.1 Security Zone Architecture

```mermaid
graph TB
    subgraph "Internet Zone - Untrusted"
        Internet[Public Internet<br/>Clients, Attackers]
    end
    
    subgraph "Public Zone - DMZ"
        CloudFront[CloudFront CDN<br/>Static Assets<br/>DDoS Protection]
        ALB[Application Load Balancer<br/>TLS Termination<br/>WAF Integration<br/>Ports: 443 HTTPS]
    end
    
    subgraph "Application Zone - Private Subnet"
        subgraph "ECS Fargate Tasks"
            API1[API Instance 1<br/>JWT Validation<br/>Business Logic]
            API2[API Instance 2<br/>JWT Validation<br/>Business Logic]
            API3[API Instance 3<br/>JWT Validation<br/>Business Logic]
        end
        
        AppSG[Security Group: ECS<br/>Inbound: ALB only<br/>Outbound: Data zone + internet]
    end
    
    subgraph "Data Zone - Private Subnet"
        subgraph "Databases"
            MongoDB[(MongoDB Replica Set<br/>3 Nodes<br/>Port 27017<br/>TLS Encrypted)]
            Redis[(Redis Cache<br/>Port 6379<br/>TLS Optional)]
        end
        
        DataSG[Security Group: Databases<br/>Inbound: ECS only<br/>Outbound: None]
    end
    
    subgraph "Storage Zone - AWS Managed"
        S3[(Amazon S3<br/>Encrypted Buckets<br/>Private Access<br/>Presigned URLs)]
    end
    
    subgraph "External Services Zone"
        Auth0[Auth0<br/>Identity Provider<br/>User Authentication]
        OpenAI[OpenAI API<br/>LLM Services<br/>Embeddings]
    end
    
    subgraph "Management Zone"
        NAT[NAT Gateway<br/>Outbound Internet<br/>For ECS Tasks]
        Bastion[Bastion Host future<br/>SSH Access<br/>Operational Management]
    end
    
    Internet -->|HTTPS 443| CloudFront
    Internet -->|HTTPS 443| ALB
    CloudFront -->|CDN Origin| S3
    
    ALB -->|HTTP 5000<br/>Internal VPC| API1
    ALB -->|HTTP 5000<br/>Internal VPC| API2
    ALB -->|HTTP 5000<br/>Internal VPC| API3
    
    API1 -->|MongoDB Protocol<br/>TLS 27017| MongoDB
    API2 -->|MongoDB Protocol<br/>TLS 27017| MongoDB
    API3 -->|MongoDB Protocol<br/>TLS 27017| MongoDB
    
    API1 -->|Redis Protocol<br/>6379| Redis
    API2 -->|Redis Protocol<br/>6379| Redis
    API3 -->|Redis Protocol<br/>6379| Redis
    
    API1 -->|HTTPS<br/>Presigned URLs| S3
    API2 -->|HTTPS<br/>Presigned URLs| S3
    API3 -->|HTTPS<br/>Presigned URLs| S3
    
    API1 -.->|HTTPS<br/>via NAT| Auth0
    API2 -.->|HTTPS<br/>via NAT| Auth0
    API3 -.->|HTTPS<br/>via NAT| Auth0
    
    API1 -.->|HTTPS<br/>via NAT| OpenAI
    API2 -.->|HTTPS<br/>via NAT| OpenAI
    API3 -.->|HTTPS<br/>via NAT| OpenAI
    
    AppSG -.->|Egress Control| NAT
    NAT -.->|Internet Gateway| Internet
    
    style Internet fill:#FFCDD2,stroke:#C62828,stroke-width:3px
    style CloudFront fill:#E1F5FE,stroke:#0277BD,stroke-width:2px
    style ALB fill:#FFF9C4,stroke:#F57F17,stroke-width:2px
    style API1 fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px
    style API2 fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px
    style API3 fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px
    style MongoDB fill:#BBDEFB,stroke:#1565C0,stroke-width:2px
    style Redis fill:#FFE0B2,stroke:#E65100,stroke-width:2px
    style S3 fill:#F3E5F5,stroke:#6A1B9A,stroke-width:2px
    style Auth0 fill:#FCE4EC,stroke:#C2185B,stroke-width:2px
    style OpenAI fill:#FFF3E0,stroke:#EF6C00,stroke-width:2px
    style NAT fill:#E0F2F1,stroke:#00695C,stroke-width:2px
```

**Security Zone Descriptions**:

| Zone | Trust Level | Components | Security Controls |
|------|------------|------------|------------------|
| **Internet Zone** | Untrusted | Public clients, potential attackers | DDoS protection (CloudFront, AWS Shield), WAF rules |
| **Public Zone (DMZ)** | Limited trust | ALB, CloudFront | TLS termination, rate limiting, health checks |
| **Application Zone** | Trusted (authenticated) | ECS Fargate tasks | JWT validation, PBAC, input validation, isolated VPC |
| **Data Zone** | Highly trusted | MongoDB, Redis | No public access, security groups, encryption at rest |
| **Storage Zone** | Highly trusted | Amazon S3 | Private buckets, presigned URLs, server-side encryption |
| **External Services** | Third-party trust | Auth0, OpenAI | TLS connections, API key authentication, circuit breakers |
| **Management Zone** | Operational trust | NAT Gateway, Bastion (future) | Outbound internet only, operational access controls |

---

### 6.4.7 Security Control Matrices

#### 6.4.7.1 Access Control Matrix

| User Role | read:documents | write:documents | delete:documents | ai:completions | ai:conversations | admin:system |
|-----------|----------------|-----------------|------------------|----------------|------------------|--------------|
| **Viewer** | ✓ | ✗ | ✗ | ✓ | ✗ | ✗ |
| **User** | ✓ | ✓ | ✗ | ✓ | ✓ | ✗ |
| **Admin** | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |

**Permission Inheritance**: Admin role inherits all permissions from lower roles plus administrative capabilities.

#### 6.4.7.2 Security Control Implementation Matrix

| Security Control | Implementation | Status | Compliance Standard |
|------------------|----------------|--------|---------------------|
| **Authentication** | Auth0 OAuth 2.0 + OIDC | Planned | SOC 2 CC6.1, ISO 27001 A.9 |
| **Multi-Factor Authentication** | Auth0 MFA (SMS, TOTP, Push) | Planned | NIST 800-63B AAL2 |
| **Authorization** | JWT PBAC with resource checks | Planned | SOC 2 CC6.2 |
| **Encryption at Rest** | AES-256 (MongoDB, S3, Redis) | Planned | GDPR Art. 32, CCPA §1798.81.5 |
| **Encryption in Transit** | TLS 1.3 (TLS 1.2 fallback) | Planned | PCI DSS 4.1, GDPR Art. 32 |
| **Audit Logging** | MongoDB append-only logs | Planned | SOC 2 CC7.2, GDPR Art. 30 |
| **Key Management** | AWS KMS customer-managed keys | Planned | NIST 800-57, FIPS 140-2 |
| **Network Isolation** | VPC private subnets, security groups | Planned | CIS AWS Benchmarks |
| **Rate Limiting** | Redis token bucket (per user/IP) | Planned | OWASP API Security Top 10 |
| **Session Management** | Stateless JWT (15-min expiry) | Planned | OWASP Session Management |

#### 6.4.7.3 Data Classification and Protection Matrix

| Data Classification | Examples | Encryption at Rest | Encryption in Transit | Access Logging | Retention |
|--------------------|----------|-------------------|----------------------|----------------|-----------|
| **Public** | Static assets, public documentation | Optional (S3 SSE) | TLS 1.3 required | No | Indefinite |
| **Internal** | Application code, configuration (non-sensitive) | AES-256 required | TLS 1.3 required | Yes | Per policy |
| **Confidential** | User documents, AI conversations | AES-256 required | TLS 1.3 required | Yes (detailed) | User-controlled |
| **Restricted (PII)** | Email addresses, IP addresses | AES-256 + KMS | TLS 1.3 required | Yes (audit trail) | GDPR compliant |
| **Critical** | Audit logs, authentication events | AES-256 + KMS | TLS 1.3 required | Yes (immutable) | 7 years |

#### 6.4.7.4 Rate Limiting Policy Matrix

| Endpoint Category | Rate Limit | Window | Enforcement Point | Bypass Available |
|------------------|------------|--------|------------------|------------------|
| **General API** | 100 requests/minute | 60 seconds | Redis + Middleware | Admin users only |
| **Write Operations** | 20 requests/minute | 60 seconds | Redis + Middleware | No |
| **AI/LLM Endpoints** | 10 requests/minute | 60 seconds | Redis + Middleware | Premium tier (20/min) |
| **File Uploads** | 20 uploads/minute | 60 seconds | Redis + Middleware | No |
| **Authentication** | 5 attempts/minute | 60 seconds | Auth0 + Middleware | No |

**Rate Limit Response**:

```
HTTP/1.1 429 Too Many Requests
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1705320600
Retry-After: 45

{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded for this endpoint",
    "details": {
      "limit": 100,
      "window": "1 minute",
      "retry_after_seconds": 45
    }
  }
}
```

---

### 6.4.8 Compliance and Standards Alignment

#### 6.4.8.1 Regulatory Compliance Mapping

| Compliance Requirement | Security Control | Implementation | Evidence/Audit |
|-----------------------|------------------|----------------|----------------|
| **GDPR Art. 25** (Privacy by Design) | Security architecture from design phase | Defense-in-depth, encryption, access controls | Architecture documentation |
| **GDPR Art. 30** (Records of Processing) | Audit logging, data retention policies | Immutable audit logs, 7-year retention | Audit log exports |
| **GDPR Art. 32** (Security of Processing) | Encryption, pseudonymization, access controls | AES-256, TLS 1.3, PBAC, MFA | Security assessment reports |
| **CCPA §1798.100** (Right to Know) | User data export API (planned) | Structured data export in portable format | API documentation |
| **SOC 2 CC6.1** (Logical Access Controls) | Auth0 authentication, JWT validation | OAuth 2.0, OIDC, permission-based access | Authentication logs |
| **SOC 2 CC7.2** (System Monitoring) | CloudWatch logs, security event tracking | Real-time monitoring, automated alerting | CloudWatch dashboards |

#### 6.4.8.2 Security Standards Alignment

| Standard | Control Area | Implementation | Maturity Level |
|----------|-------------|----------------|----------------|
| **NIST 800-53** | Access Control (AC) | Auth0 OAuth 2.0, PBAC, MFA | Planned |
| **NIST 800-53** | Audit and Accountability (AU) | Comprehensive audit logging, immutable logs | Planned |
| **NIST 800-53** | Identification and Authentication (IA) | Multi-factor authentication, password policies | Planned |
| **OWASP Top 10** | Broken Access Control | Multi-layer authorization, resource ownership | Planned |
| **OWASP Top 10** | Cryptographic Failures | AES-256, TLS 1.3, KMS key management | Planned |
| **OWASP API Security** | API1: Broken Object Level Authorization | Resource ownership validation, admin override | Planned |
| **OWASP API Security** | API4: Lack of Resources & Rate Limiting | Redis token bucket, per-user limits | Planned |
| **CIS AWS Benchmarks** | IAM, Networking, Logging | Security groups, VPC isolation, CloudWatch | Planned |

---

### 6.4.9 Security Architecture Summary

The CheckSameRepoNoPrompt system implements a comprehensive, multi-layered security architecture designed to protect user data, prevent unauthorized access, and ensure regulatory compliance. Key security highlights include:

**Authentication & Authorization**:
- Enterprise-grade Auth0 OAuth 2.0 + OpenID Connect integration
- Multi-factor authentication with multiple verification methods
- Permission-based access control with resource-level authorization
- Stateless JWT tokens with 15-minute expiration and automatic refresh

**Data Protection**:
- AES-256 encryption at rest for all persistent data (MongoDB, S3, Redis)
- TLS 1.3 encryption in transit for all network communication
- AWS KMS customer-managed keys for sensitive backups
- PII classification, anonymization, and GDPR-compliant deletion

**Security Monitoring & Compliance**:
- Comprehensive audit logging with 7-year retention
- Real-time security event tracking with automated alerting
- GDPR, CCPA, and SOC 2 compliance alignment
- Defense-in-depth architecture with network, application, and data layer security

**Implementation Status**: This security architecture represents the planned design for the CheckSameRepoNoPrompt system. The repository currently contains only a README.md file, with all security implementations pending development phase execution.

---

### 6.4.10 References

#### 6.4.10.1 Technical Specification Sections Referenced

- **Section 1.2 - System Overview**: Project implementation status and context
- **Section 2.5 - Non-Functional Requirements**: High-level security requirements and performance targets
- **Section 3.5 - Third-Party Services**: Auth0 configuration, AWS services, OpenAI API integration details
- **Section 4.3 - Authentication and Authorization Flows (Planned)**: Complete OAuth 2.0 flows, JWT validation, MFA implementation, authorization decision logic
- **Section 5.1 - High-Level Architecture**: Security by design principles, multi-tier architecture, data flow patterns
- **Section 5.4 - Cross-Cutting Concerns**: Authentication framework, error handling, security monitoring, performance requirements
- **Section 6.1 - Core Services Architecture**: Service-level security controls, JWT validation middleware, circuit breaker patterns
- **Section 6.2 - Database Design**: Encryption at rest, MongoDB RBAC, audit logging specifications, PII handling, GDPR compliance controls
- **Section 6.3 - Integration Architecture**: API security, TLS configuration, Auth0 integration, rate limiting, presigned URLs

#### 6.4.10.2 Repository Files Examined

- **`README.md`** (root directory): Project title documentation; repository in pre-implementation phase with no security implementation code

#### 6.4.10.3 Repository Folders Explored

- **Root Directory** (`/`): Contains only README.md file; no source code, security configuration files, authentication modules, or infrastructure implementation

#### 6.4.10.4 External Standards and Frameworks Referenced

- **OAuth 2.0 (RFC 6749)**: Authorization framework for API access
- **OpenID Connect (OIDC)**: Authentication layer on OAuth 2.0
- **PKCE (RFC 7636)**: Proof Key for Code Exchange, OAuth security extension
- **JSON Web Token (JWT, RFC 7519)**: Token format for secure claims
- **NIST 800-63B**: Digital Identity Guidelines (Authentication and Lifecycle Management)
- **GDPR (General Data Protection Regulation)**: EU data protection regulation
- **CCPA (California Consumer Privacy Act)**: California privacy law
- **SOC 2 Type II**: Security, availability, and confidentiality audit framework
- **OWASP Top 10**: Web application security risks
- **OWASP API Security Top 10**: API-specific security risks
- **CIS AWS Benchmarks**: AWS security configuration best practices
- **NIST 800-53**: Security and Privacy Controls for Information Systems
- **NIST 800-57**: Key Management Recommendations
- **FIPS 140-2**: Cryptographic module validation standard

#### 6.4.10.5 Key Findings Summary

**Security Architecture Scope**:
- **Comprehensive Defense-in-Depth**: Multi-layer security spanning network, authentication, authorization, application, and data layers
- **Enterprise Authentication**: Auth0-managed OAuth 2.0 + OIDC with multi-factor authentication
- **Zero Trust Model**: Authentication and authorization required at every layer, no implicit trust
- **Encryption Everywhere**: AES-256 at rest, TLS 1.3 in transit, AWS KMS key management
- **Compliance-Ready**: GDPR, CCPA, SOC 2 alignment with 7-year audit log retention

**Implementation Status**:
- **Pre-Implementation Phase**: All security controls documented represent planned architecture
- **No Security Code**: Repository contains only README.md, no authentication modules, encryption configuration, or security middleware
- **Architecture Complete**: Security design fully specified and ready for development phase implementation

**Total Research Depth**: 18 comprehensive searches across repository and technical specification sections, synthesized into cohesive security architecture documentation.

---

**Document Metadata**:
- **Section**: 6.4 Security Architecture
- **Version**: 1.0 (Planned Architecture)
- **Date**: January 2024
- **Status**: Pre-Implementation (Design Phase)
- **Implementation Code**: None (repository contains only README.md)
- **Next Steps**: Development team to implement security controls per this specification during application development phase

## 6.5 Monitoring and Observability

### 6.5.1 Monitoring Architecture Overview

#### 6.5.1.1 Implementation Status

**Current Repository State**: The CheckSameRepoNoPrompt repository is in **pre-implementation phase**, containing only a README.md file with the project title. No monitoring implementation code, CloudWatch configuration, or observability instrumentation exists at this time.

**Documentation Scope**: This section documents the **planned monitoring and observability architecture** based on comprehensive technical specifications. All monitoring infrastructure, metrics collection, alerting mechanisms, and observability patterns described herein represent the intended monitoring strategy that will be implemented during the development phase.

#### 6.5.1.2 Observability Strategy

The CheckSameRepoNoPrompt system implements a comprehensive **three-pillar observability strategy** encompassing logs, metrics, and distributed tracing to ensure complete visibility into system behavior and enable rapid incident response. This cloud-native monitoring approach leverages AWS CloudWatch as the primary observability platform, supplemented by optional third-party integrations for enhanced capabilities.

**Observability Philosophy**: The architecture adopts an "observe everything, alert intelligently" approach where comprehensive instrumentation provides complete system visibility while intelligent alerting focuses operations teams on actionable issues. This strategy enables proactive problem detection, efficient troubleshooting, and continuous performance optimization.

**Core Observability Pillars**:

| Pillar | Technology | Purpose | Retention Period |
|--------|-----------|---------|-----------------|
| **Logs** | CloudWatch Logs | Detailed event records, debugging, audit trails | 30 days active, 90 days archived |
| **Metrics** | CloudWatch Metrics | Quantitative measurements, performance tracking | 15 months (AWS standard) |
| **Traces** | AWS X-Ray (optional) | Request flow visualization across services | 30 days |
| **Alerts** | CloudWatch Alarms | Proactive issue notification, auto-remediation | Real-time (historical in SNS) |

**Monitoring Architecture Principles**:

1. **Comprehensive Instrumentation**: Instrument all system layers from client requests through backend services to data storage
2. **Structured Logging**: JSON-formatted logs enable programmatic analysis and correlation across distributed services
3. **Multi-Dimensional Metrics**: Metrics tagged with dimensions (service, environment, endpoint, user_tier) enable fine-grained analysis
4. **Correlation-First Design**: Request IDs propagate through all services enabling end-to-end request tracing
5. **Alert Fatigue Prevention**: Alert thresholds tuned to minimize false positives while ensuring critical issue detection
6. **Self-Service Observability**: Dashboards provide development, operations, and business teams direct visibility into system health

#### 6.5.1.3 Monitoring System Architecture

The monitoring infrastructure integrates seamlessly with the application architecture, collecting telemetry from all system components and aggregating it in CloudWatch for analysis and alerting.

```mermaid
graph TB
    subgraph "Client Layer"
        Web["Web Application<br/>React"]
        Mobile["Mobile Apps<br/>React Native/Native"]
        Desktop["Desktop Apps<br/>Electron"]
    end
    
    subgraph "Infrastructure Layer"
        ALB["Application Load Balancer<br/>Access Logs → CloudWatch"]
    end
    
    subgraph "Application Layer - ECS Fargate"
        API1["Flask API Instance 1<br/>Structured JSON Logs<br/>Custom Metrics<br/>X-Ray Tracing"]
        API2["Flask API Instance 2<br/>Structured JSON Logs<br/>Custom Metrics<br/>X-Ray Tracing"]
        LangChain["LangChain Service<br/>AI Operation Logs<br/>Token Usage Metrics"]
    end
    
    subgraph "Data Layer"
        MongoDB[("MongoDB<br/>Slow Query Logs<br/>Connection Metrics")]
        Redis[("Redis<br/>Cache Hit Metrics<br/>Memory Usage")]
        S3["S3<br/>Access Logs<br/>Storage Metrics"]
    end
    
    subgraph "AWS CloudWatch - Central Monitoring Platform"
        subgraph "Log Groups"
            LogAPI["/ecs/flask-api<br/>Application Logs"]
            LogLang["/ecs/langchain<br/>AI/ML Logs"]
            LogALB["/aws/alb/access<br/>HTTP Access Logs"]
        end
        
        subgraph "Metrics"
            MetricInfra["Infrastructure Metrics<br/>CPU, Memory, Network"]
            MetricApp["Application Metrics<br/>Requests, Latency, Errors"]
            MetricBiz["Business Metrics<br/>AI Usage, Token Costs"]
        end
        
        subgraph "Alarms"
            AlarmError["High Error Rate<br/>> 5% for 5 min"]
            AlarmLatency["High Latency<br/>p95 > 1000ms"]
            AlarmCPU["High CPU<br/>> 80% for 10 min"]
        end
        
        subgraph "Dashboards"
            DashHealth["System Health<br/>Operations View"]
            DashBusiness["Business Metrics<br/>Product View"]
            DashSecurity["Security Events<br/>Security View"]
        end
    end
    
    subgraph "External Monitoring - Optional"
        XRay["AWS X-Ray<br/>Distributed Tracing<br/>Service Map"]
        DataDog["DataDog APM<br/>Advanced Analytics"]
        Sentry["Sentry<br/>Error Tracking"]
    end
    
    subgraph "Alerting Channels"
        SNS["Amazon SNS<br/>Notification Hub"]
        Email["Email<br/>Operations Team"]
        PagerDuty["PagerDuty<br/>On-Call Escalation"]
        Slack["Slack<br/>Team Notifications"]
    end
    
    Web -.->|User Actions| ALB
    Mobile -.->|User Actions| ALB
    Desktop -.->|User Actions| ALB
    
    ALB -->|Routes Traffic| API1
    ALB -->|Routes Traffic| API2
    ALB -->|Access Logs| LogALB
    
    API1 -->|Logs| LogAPI
    API2 -->|Logs| LogAPI
    API1 -->|Metrics| MetricApp
    API2 -->|Metrics| MetricApp
    API1 -->|Traces| XRay
    API2 -->|Traces| XRay
    
    API1 -->|AI Requests| LangChain
    API2 -->|AI Requests| LangChain
    LangChain -->|Logs| LogLang
    LangChain -->|Token Metrics| MetricBiz
    
    API1 -.->|Queries| MongoDB
    API2 -.->|Queries| MongoDB
    API1 -.->|Cache Ops| Redis
    API2 -.->|Cache Ops| Redis
    API1 -.->|File Ops| S3
    API2 -.->|File Ops| S3
    
    MongoDB -->|Metrics| MetricInfra
    Redis -->|Metrics| MetricInfra
    S3 -->|Metrics| MetricInfra
    
    API1 -.->|Optional| DataDog
    API2 -.->|Optional| DataDog
    API1 -.->|Errors| Sentry
    API2 -.->|Errors| Sentry
    
    AlarmError -->|Triggers| SNS
    AlarmLatency -->|Triggers| SNS
    AlarmCPU -->|Triggers| SNS
    
    SNS -->|Email| Email
    SNS -->|API| PagerDuty
    SNS -->|Webhook| Slack
    
    style LogAPI fill:#E3F2FD
    style LogLang fill:#E3F2FD
    style LogALB fill:#E3F2FD
    style MetricInfra fill:#FFF3E0
    style MetricApp fill:#FFF3E0
    style MetricBiz fill:#FFF3E0
    style AlarmError fill:#FFCDD2
    style AlarmLatency fill:#FFCDD2
    style AlarmCPU fill:#FFCDD2
    style DashHealth fill:#C8E6C9
    style DashBusiness fill:#C8E6C9
    style DashSecurity fill:#C8E6C9
```

---

### 6.5.2 Logging Infrastructure

#### 6.5.2.1 CloudWatch Logs Implementation

**Log Groups Architecture**: The system organizes logs into dedicated CloudWatch Log Groups based on service boundaries, enabling efficient log management, retention policies, and access control.

| Log Group | Source Component | Log Format | Primary Purpose |
|-----------|-----------------|-----------|-----------------|
| `/ecs/flask-api` | Flask API containers | Structured JSON | Application logs, request/response tracking, error debugging |
| `/ecs/langchain` | LangChain AI service | Structured JSON | AI/ML operation logs, token usage, model interactions |
| `/aws/lambda/*` | Lambda functions (future) | Structured JSON | Serverless function execution logs, cold start tracking |
| `/aws/alb/access` | Application Load Balancer | Apache Combined Format | HTTP access patterns, client IPs, response codes, latency |

**Log Retention Strategy**:

- **Active Logs**: 30 days in CloudWatch Logs for real-time analysis and troubleshooting
- **Archived Logs**: Export to S3 after 30 days with Glacier storage class for 90-day retention
- **Audit Logs**: 7-year retention in S3 for compliance requirements (SOC 2, GDPR, CCPA)
- **Cost Optimization**: Automatic lifecycle policies transition logs to cost-effective storage tiers

#### 6.5.2.2 Structured Logging Standard

**JSON Log Format Specification**: All application logs use a standardized JSON structure enabling programmatic parsing, filtering, and correlation across distributed services.

**Standard Log Entry Schema**:

```json
{
  "timestamp": "2024-01-15T10:30:00.000Z",
  "level": "INFO",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456",
  "service": "api",
  "endpoint": "/api/v1/documents",
  "method": "GET",
  "status_code": 200,
  "duration_ms": 45,
  "cache_hit": true,
  "message": "Request processed successfully",
  "metadata": {
    "query_params": {"limit": 10},
    "response_size": 2048
  }
}
```

**Structured Log Field Definitions**:

| Field Name | Data Type | Required | Description |
|-----------|-----------|----------|-------------|
| `timestamp` | ISO 8601 datetime | Yes | Event timestamp in UTC timezone |
| `level` | String enum | Yes | Log severity (DEBUG, INFO, WARNING, ERROR, CRITICAL) |
| `request_id` | UUID v4 | Yes (for requests) | Unique identifier for request correlation across services |
| `user_id` | String | No | Auth0 user identifier for user-specific log filtering |

| Field Name | Data Type | Required | Description |
|-----------|-----------|----------|-------------|
| `service` | String | Yes | Service name (api, langchain, lambda) for service-specific filtering |
| `message` | String | Yes | Human-readable log message describing the event |
| `metadata` | JSON Object | No | Additional context-specific data (query params, performance metrics) |

#### 6.5.2.3 Log Levels and Usage Guidelines

**Log Level Definitions**: Consistent log level usage ensures appropriate signal-to-noise ratio and enables efficient log filtering during troubleshooting.

| Log Level | Use Cases | Example Scenarios | Production Volume |
|-----------|-----------|-------------------|-------------------|
| **DEBUG** | Verbose diagnostic information | Variable values, function entry/exit, loop iterations | Development only (disabled in production) |
| **INFO** | General informational messages | Successful request completion, cache hits, normal state transitions | High volume (majority of logs) |
| **WARNING** | Warning conditions requiring attention | Cache misses, retry attempts, deprecated API usage, high latency | Moderate volume (10-20% of logs) |
| **ERROR** | Error conditions requiring investigation | Failed API calls, validation errors, database connection failures | Low volume (< 5% of logs) |

**CRITICAL Log Level**:

- **Purpose**: Critical failures requiring immediate human intervention
- **Examples**: Service unavailable, data corruption detected, security breach, complete system failure
- **Volume**: Extremely rare (< 0.1% of logs)
- **Automatic Actions**: Triggers PagerDuty alerts, sends SMS to on-call engineer, creates high-priority incident ticket

#### 6.5.2.4 PII Handling and Data Privacy

**Personally Identifiable Information (PII) Protection**: Logging implementation includes automatic PII detection and redaction to ensure compliance with GDPR, CCPA, and data privacy regulations.

**PII Redaction Strategy**:

| Data Type | Redaction Method | Example |
|-----------|-----------------|---------|
| **Passwords** | Complete redaction | `"password": "***REDACTED***"` |
| **JWT Tokens** | Partial display (last 6 chars) | `"token": "...440000"` |
| **Email Addresses** | Hash or mask domain | `"email": "user@***"` |
| **Credit Card Numbers** | Mask middle digits | `"card": "****-****-****-1234"` |

**PII Logging Configuration**:

- **Development Environment**: Full logging enabled for debugging (PII visible)
- **Staging Environment**: PII hashing enabled, original values replaced with SHA-256 hashes
- **Production Environment**: Strict PII redaction, automatic scrubbing before log emission
- **Compliance Mode**: Zero PII logging, user_id hashed using one-way cryptographic function

#### 6.5.2.5 Log Sampling and Volume Management

**Log Sampling Strategy**: High-traffic endpoints implement intelligent log sampling to balance observability with cost efficiency while maintaining complete visibility for errors and critical operations.

**Sampling Rules**:

| Endpoint Category | Sample Rate | Rationale |
|------------------|-------------|-----------|
| Health Check Endpoints (`/health`, `/ping`) | 10% (1 in 10 requests) | High volume, low value, errors logged at 100% |
| Read Operations (GET requests) | 100% (all requests) | Moderate volume, valuable for debugging |
| Write Operations (POST, PUT, DELETE) | 100% (all requests) | Always logged for audit trail and data integrity |
| Error Responses (4xx, 5xx status codes) | 100% (all errors) | Critical for troubleshooting and incident response |

**Log Volume Estimates**:

- **Expected Request Volume**: 1,000 requests/second at peak load
- **Average Log Entry Size**: 512 bytes (JSON-formatted)
- **Daily Log Volume**: ~21 GB/day (1000 req/s × 512 bytes × 86,400 seconds × 50% effective sample rate)
- **Monthly CloudWatch Logs Cost**: ~$30/month (at $0.50/GB ingestion + $0.03/GB storage)

#### 6.5.2.6 Request Correlation and Distributed Tracing

**Request ID Propagation**: Every request receives a unique identifier that propagates through all system components, enabling end-to-end request tracing across distributed services.

**Request ID Lifecycle**:

1. **Generation**: UUID v4 generated at Application Load Balancer or API entry point
2. **Propagation**: Included in all downstream service calls via `X-Request-ID` HTTP header
3. **Logging**: Embedded in every log entry's `request_id` field for correlation
4. **Tracing**: Used as AWS X-Ray trace ID for distributed tracing visualization
5. **Response**: Returned to client in HTTP response headers for client-side correlation

**Log Correlation Query Example**:

The following CloudWatch Logs Insights query retrieves all logs related to a specific request, ordered chronologically to reconstruct the complete request flow:

```sql
fields @timestamp, level, service, message, duration_ms
| filter request_id = "550e8400-e29b-41d4-a716-446655440000"
| sort @timestamp asc
```

**Expected Query Results**: Chronologically ordered log entries showing:

1. ALB access log: Request received, client IP, user agent
2. API entry log: JWT validation, user authentication, permission check
3. Cache query log: Redis cache lookup, cache miss/hit status
4. Database query log: MongoDB query execution, query duration
5. LangChain log (if AI request): LLM API call, token usage
6. API response log: Response preparation, total request duration
7. ALB access log: Response sent, final status code

---

### 6.5.3 Metrics Collection and Monitoring

#### 6.5.3.1 Infrastructure Metrics (Automatic Collection)

**AWS-Managed Infrastructure Metrics**: CloudWatch automatically collects infrastructure-level metrics from managed AWS services without requiring application instrumentation.

| Metric Category | Specific Metrics Collected | Source Service | Collection Frequency |
|----------------|---------------------------|----------------|---------------------|
| **ECS Service** | CPU utilization, memory utilization, task count, task failures | Amazon ECS | 1-minute intervals |
| **Application Load Balancer** | Request count, target response time, 4xx/5xx error rates, active connections | AWS ALB | 1-minute intervals |
| **MongoDB** (if Atlas) | Connection count, query execution time, replica lag, disk IOPS | MongoDB Atlas exporter | 1-minute intervals |
| **Redis** (if ElastiCache) | CPU utilization, memory usage, evicted keys, cache hit rate | Amazon ElastiCache | 1-minute intervals |

**ECS Task Metrics**:

| Metric Name | Unit | Typical Value | Alert Threshold |
|------------|------|---------------|----------------|
| `CPUUtilization` | Percent | 40-60% | > 80% for 5 minutes (scale up) |
| `MemoryUtilization` | Percent | 50-70% | > 85% for 5 minutes (scale up) |
| `RunningTaskCount` | Count | 3-10 tasks | < 2 tasks (insufficient capacity) |
| `TaskStartFailures` | Count | 0 | > 0 (deployment issue) |

#### 6.5.3.2 Application Metrics (Custom Collection)

**Custom Application Metrics**: The Flask API emits custom metrics providing deep visibility into application behavior, performance characteristics, and business outcomes.

**Application Performance Metrics**:

| Metric Name | Type | Purpose | Unit |
|------------|------|---------|------|
| `api.request.count` | Counter | Total API requests by endpoint and method | Count |
| `api.request.duration` | Histogram | Request latency distribution (p50, p95, p99 percentiles) | Milliseconds |
| `api.error.rate` | Gauge | Percentage of failed requests (5xx errors) | Percent |
| `api.cache.hit_rate` | Gauge | Cache effectiveness (Redis hit ratio) | Percent |

**AI/ML Operation Metrics**:

| Metric Name | Type | Purpose | Unit |
|------------|------|---------|------|
| `ai.tokens.consumed` | Counter | LLM token usage for cost tracking and quota management | Count |
| `ai.request.duration` | Histogram | AI request latency (includes LLM API call time) | Milliseconds |
| `ai.model.calls` | Counter | API calls per model (GPT-4, GPT-3.5, embeddings) | Count |
| `ai.cost.estimate` | Counter | Estimated cost based on token usage and model pricing | USD |

**Security and Authentication Metrics**:

| Metric Name | Type | Purpose | Unit |
|------------|------|---------|------|
| `auth.failed.attempts` | Counter | Failed authentication attempts (potential attacks) | Count |
| `auth.jwt.validation.latency` | Histogram | JWT validation performance | Milliseconds |
| `auth.permission.denied` | Counter | Authorization failures by endpoint | Count |
| `rate_limit.exceeded` | Counter | Rate limit violations by user and endpoint | Count |

#### 6.5.3.3 Metric Collection Implementation

**CloudWatch PutMetricData Integration**: The Flask application uses the AWS SDK (Boto3) to emit custom metrics to CloudWatch using the PutMetricData API.

**Metric Emission Strategies**:

1. **Real-Time Emission**: Critical metrics (errors, security events) emitted immediately as events occur
2. **Batched Emission**: Performance metrics batched and emitted every 60 seconds to reduce API calls
3. **Asynchronous Emission**: Metrics emitted in background thread to avoid blocking request processing
4. **Retry Logic**: Failed metric emissions retried with exponential backoff (3 attempts maximum)

**Metric Dimensions**: All custom metrics include dimensions enabling fine-grained filtering and aggregation:

| Dimension Name | Possible Values | Purpose |
|---------------|----------------|---------|
| `Service` | api, langchain, lambda | Isolate metrics by service for service-specific analysis |
| `Environment` | production, staging, development | Separate production metrics from lower environments |
| `Endpoint` | /api/v1/documents, /api/v1/ai/completions | Per-endpoint performance and error tracking |
| `UserTier` | free, premium, enterprise | Compare usage patterns across subscription tiers |

**Example Metric Emission Code Pattern**:

```python
# Pseudocode illustrating metric emission pattern (not actual implementation)
cloudwatch.put_metric_data(
    Namespace='CheckSameRepoNoPrompt/API',
    MetricData=[
        {
            'MetricName': 'api.request.duration',
            'Value': duration_ms,
            'Unit': 'Milliseconds',
            'Timestamp': datetime.utcnow(),
            'Dimensions': [
                {'Name': 'Service', 'Value': 'api'},
                {'Name': 'Endpoint', 'Value': '/api/v1/documents'},
                {'Name': 'Environment', 'Value': 'production'}
            ]
        }
    ]
)
```

#### 6.5.3.4 Business Metrics and KPI Tracking

**Business Intelligence Metrics**: Beyond operational metrics, the system tracks business-focused KPIs providing product teams visibility into user engagement, feature adoption, and revenue drivers.

**User Engagement Metrics**:

| Metric Name | Definition | Business Value |
|------------|------------|----------------|
| `business.active_users.daily` | Unique authenticated users per day | Measure daily active user (DAU) growth |
| `business.active_users.monthly` | Unique authenticated users per 30 days | Track monthly active user (MAU) trends |
| `business.session.duration` | Average time between first and last request in session | Understand user engagement depth |
| `business.feature.adoption` | Usage count per feature (AI, documents, search) | Identify popular features for investment prioritization |

**Revenue and Cost Metrics**:

| Metric Name | Definition | Business Value |
|------------|------------|----------------|
| `business.ai.tokens.cost` | Total LLM token cost per day/month | Monitor AI infrastructure spend |
| `business.revenue.mrr` | Monthly recurring revenue by subscription tier | Track revenue growth and tier distribution |
| `business.churn.rate` | Percentage of users canceling subscriptions | Measure customer retention health |
| `business.cache.savings` | Cost avoided through cache hits | Quantify caching infrastructure ROI |

---

### 6.5.4 Distributed Tracing and Request Flow Visualization

#### 6.5.4.1 AWS X-Ray Integration (Optional)

**Distributed Tracing Architecture**: AWS X-Ray provides end-to-end request tracing across microservices, visualizing request flow from API entry through LangChain to external services (OpenAI, MongoDB).

**X-Ray Implementation Details**:

- **Instrumentation Method**: X-Ray SDK integrated into Flask application and LangChain wrapper
- **Trace Segments**: Each service creates trace segments representing its portion of request processing
- **Subsegments**: Individual operations (database queries, LLM calls, cache lookups) tracked as subsegments
- **Sampling Rate**: 100% sampling for errors, 10% sampling for successful requests to balance observability with cost

**X-Ray Trace Data Components**:

| Trace Component | Content | Purpose |
|----------------|---------|---------|
| **Trace ID** | Unique identifier for entire request | Correlate all segments across services |
| **Segment** | Service-level execution details | Track latency and errors per service |
| **Subsegment** | Operation-level details (DB query, API call) | Identify specific bottlenecks within service |
| **Annotations** | Key-value pairs (user_id, endpoint) | Enable filtering and search in X-Ray console |
| **Metadata** | Additional context (query params, payload size) | Provide debugging context for traces |

**X-Ray Service Map**: Automatically generated visual representation of service dependencies showing:

- Request flow from ALB through API to LangChain to OpenAI and MongoDB
- Average latency per service
- Error rates per service and dependency
- Traffic volume between services

#### 6.5.4.2 Request Trace Flow Example

The following diagram illustrates a complete request trace with timing breakdowns across all system components:

```mermaid
sequenceDiagram
    participant Client
    participant ALB as Application<br/>Load Balancer
    participant API as Flask API
    participant Redis as Redis Cache
    participant Auth0
    participant LangChain
    participant OpenAI
    participant MongoDB
    
    Note over Client,MongoDB: AI Completion Request Trace<br/>Request ID: 550e8400-e29b-41d4-a716-446655440000
    
    Client->>ALB: POST /api/v1/ai/completions<br/>Authorization: Bearer {JWT}<br/>[0ms]
    ALB->>API: Forward Request<br/>[+5ms] (TLS termination)
    
    Note over API: X-Ray Segment Start<br/>Service: flask-api
    
    API->>Redis: GET jwks:auth0 (JWKS cache)<br/>[+10ms]
    Redis-->>API: Cache HIT (public keys)<br/>[+12ms]
    
    API->>Auth0: Validate JWT signature<br/>(using cached keys)<br/>[+12ms]
    Note over API: JWT validation: 8ms
    Auth0-->>API: JWT Valid ✓<br/>[+20ms]
    
    Note over API: Authorization check: 2ms<br/>Permission: ai:completions ✓
    
    API->>Redis: GET ai:prompt:hash123<br/>(Check cached response)<br/>[+25ms]
    Redis-->>API: Cache MISS<br/>[+27ms]
    
    Note over API: X-Ray Subsegment Start<br/>Operation: AI Completion
    
    API->>LangChain: AI Completion Request<br/>{prompt, model, params}<br/>[+30ms]
    
    Note over LangChain: X-Ray Segment Start<br/>Service: langchain
    
    LangChain->>MongoDB: Query conversation history<br/>(if multi-turn)<br/>[+35ms]
    MongoDB-->>LangChain: Previous messages<br/>[+55ms] (20ms query)
    
    LangChain->>LangChain: Build prompt with context<br/>[+60ms] (5ms)
    
    Note over LangChain: X-Ray Subsegment Start<br/>Operation: OpenAI API Call
    
    LangChain->>OpenAI: POST /v1/chat/completions<br/>model: gpt-4<br/>[+65ms]
    Note over OpenAI: LLM Processing<br/>Token Generation
    OpenAI-->>LangChain: AI Response<br/>tokens_used: 500<br/>[+2565ms] (2500ms LLM latency)
    
    Note over LangChain: X-Ray Subsegment End<br/>OpenAI Call: 2500ms
    
    LangChain->>MongoDB: Save AI interaction<br/>(prompt, response, cost)<br/>[+2570ms]
    MongoDB-->>LangChain: Saved ✓<br/>[+2590ms] (20ms write)
    
    Note over LangChain: X-Ray Segment End<br/>LangChain Total: 2560ms
    
    LangChain-->>API: AI Response + Metadata<br/>[+2595ms]
    
    API->>Redis: SET ai:prompt:hash123<br/>(Cache response, TTL=1hr)<br/>[+2600ms]
    Redis-->>API: Cached ✓<br/>[+2605ms]
    
    API->>MongoDB: Log request metrics<br/>(async, non-blocking)<br/>[+2605ms]
    
    Note over API: X-Ray Segment End<br/>API Total: 2600ms<br/>Breakdown: JWT 20ms, AI 2560ms, Cache 20ms
    
    API-->>ALB: 200 OK<br/>JSON response + metadata<br/>[+2610ms]
    ALB-->>Client: Response<br/>[+2615ms]
    
    Note over Client,MongoDB: Total Request Duration: 2615ms<br/>✓ Within p95 target (< 5000ms)
```

**Trace Analysis Insights**:

- **Total Request Duration**: 2,615ms (well within 5-second p95 target for AI requests)
- **Bottleneck Identification**: OpenAI API call accounts for 95% of latency (2,500ms out of 2,615ms)
- **Optimization Opportunities**: 
  - JWT validation optimized through Redis caching (8ms vs. 100ms without cache)
  - AI response caching prevents duplicate LLM calls for identical prompts
  - Asynchronous metric logging prevents blocking response delivery

---

### 6.5.5 Alerting and Incident Response

#### 6.5.5.1 CloudWatch Alarms Configuration

**Intelligent Alerting Strategy**: Alarms configured with carefully tuned thresholds to detect genuine issues while minimizing false positives and alert fatigue.

**Critical System Alarms**:

| Alarm Name | Metric | Threshold Condition | Evaluation Period | Alert Action |
|-----------|--------|-------------------|------------------|--------------|
| High Error Rate | `api.error.rate` | > 5% | 5 minutes | Email operations + PagerDuty |
| API Latency Spike | `api.request.duration` (p95) | > 1000ms | 5 minutes | Email engineering team |
| ECS CPU High | `ECS CPUUtilization` | > 80% | 10 minutes | Auto-scale + email operations |
| Database Connection Pool Exhausted | `MongoDB connections` | > 80% of max | 5 minutes | Email DBA + create incident |

**Secondary Alarms**:

| Alarm Name | Metric | Threshold Condition | Evaluation Period | Alert Action |
|-----------|--------|-------------------|------------------|--------------|
| Cache Hit Rate Low | `api.cache.hit_rate` | < 70% | 15 minutes | Email engineering (tuning needed) |
| Failed Auth Spike | `auth.failed.attempts` | > 100 attempts/min | 5 minutes | Email security team (potential attack) |
| AI Cost Threshold | `ai.tokens.cost` | > $500/day | 1 day | Email finance + engineering |
| Task Launch Failures | `ECS TaskStartFailures` | > 0 | 1 minute | Email operations (deployment issue) |

#### 6.5.5.2 Alert Routing and Escalation

**Multi-Channel Notification Architecture**: CloudWatch Alarms trigger Amazon SNS topics which fan out notifications to multiple channels based on severity and audience.

```mermaid
graph TB
    subgraph "CloudWatch Alarms"
        AlarmCritical[Critical Alarms<br/>Error Rate, Latency, CPU]
        AlarmWarning[Warning Alarms<br/>Cache, Auth, Cost]
        AlarmInfo[Informational Alarms<br/>Capacity, Usage Patterns]
    end
    
    subgraph "Amazon SNS Topics"
        SNSCritical[critical-alerts Topic]
        SNSWarning[warning-alerts Topic]
        SNSInfo[info-alerts Topic]
    end
    
    subgraph "Notification Channels"
        PagerDuty[PagerDuty<br/>On-Call Engineer<br/>SMS + Phone Call]
        Email1[Email<br/>Operations Team<br/>ops@example.com]
        Email2[Email<br/>Engineering Team<br/>eng@example.com]
        Slack[Slack<br/>#alerts Channel<br/>@here Mention]
        Webhook[Custom Webhook<br/>Incident Management System]
    end
    
    subgraph "Auto-Remediation"
        Lambda1[Lambda Function<br/>Auto-Scale ECS]
        Lambda2[Lambda Function<br/>Restart Service]
        Lambda3[Lambda Function<br/>Clear Cache]
    end
    
    AlarmCritical -->|ALARM State| SNSCritical
    AlarmWarning -->|ALARM State| SNSWarning
    AlarmInfo -->|ALARM State| SNSInfo
    
    SNSCritical -->|High Priority| PagerDuty
    SNSCritical -->|Email| Email1
    SNSCritical -->|Webhook| Slack
    SNSCritical -->|Trigger| Lambda1
    
    SNSWarning -->|Email| Email2
    SNSWarning -->|Webhook| Slack
    SNSWarning -->|Trigger| Lambda2
    
    SNSInfo -->|Email| Email2
    
    Lambda1 -->|Increase Task Count| ECS[ECS Auto-Scaling]
    Lambda2 -->|Force Restart| ECS2[ECS Service]
    Lambda3 -->|FLUSHDB| Redis[Redis Cache]
    
    style AlarmCritical fill:#FFCDD2
    style AlarmWarning fill:#FFE0B2
    style AlarmInfo fill:#C8E6C9
    style PagerDuty fill:#B39DDB
    style Lambda1 fill:#81C784
    style Lambda2 fill:#81C784
    style Lambda3 fill:#81C784
```

**Escalation Policy**:

| Severity | Initial Notification | 15-Minute Escalation | 30-Minute Escalation |
|----------|---------------------|---------------------|---------------------|
| **P0 - Critical** | On-call engineer (PagerDuty) | Engineering manager + operations lead | VP Engineering + incident commander |
| **P1 - High** | Operations team (email) | On-call engineer (PagerDuty) | Engineering manager |
| **P2 - Medium** | Engineering team (email) | Operations team (email) | No escalation |
| **P3 - Low** | Email notification only | No escalation | No escalation |

#### 6.5.5.3 Automated Remediation Actions

**Self-Healing Mechanisms**: Critical alarms trigger Lambda functions that automatically remediate common issues without human intervention.

**Auto-Remediation Scenarios**:

| Trigger Alarm | Automated Action | Expected Outcome | Rollback Condition |
|--------------|------------------|------------------|-------------------|
| ECS CPU > 80% | Increase ECS desired task count by 1 (max 10) | Distribute load, reduce CPU utilization | If scaling doesn't reduce CPU within 10 min |
| Memory > 85% | Restart ECS tasks (rolling restart) | Clear memory leaks, refresh task state | If restart fails or repeats within 1 hour |
| Cache Hit Rate < 70% | Warm cache with popular queries | Improve cache effectiveness | If warming doesn't improve hit rate |
| Task Launch Failures | Rollback to previous task definition | Revert to last known good deployment | Manual intervention if rollback fails |

#### 6.5.5.4 Incident Response Workflow

**Structured Incident Management Process**: When alarms trigger, the operations team follows a documented incident response workflow ensuring consistent, efficient issue resolution.

**Incident Response Stages**:

1. **Detection** (0-2 minutes): CloudWatch alarm triggers, notifications sent to on-call engineer
2. **Acknowledgment** (2-5 minutes): Engineer acknowledges alert in PagerDuty, begins investigation
3. **Assessment** (5-15 minutes): Engineer reviews CloudWatch dashboards, logs, and metrics to determine severity and root cause
4. **Communication** (15-30 minutes): Create incident ticket, notify stakeholders, establish communication channels
5. **Mitigation** (30-120 minutes): Apply fixes, deploy hotfixes, or initiate disaster recovery procedures
6. **Resolution** (2-4 hours): Verify system stability, close incident ticket, document resolution
7. **Post-Mortem** (24-48 hours): Conduct blameless post-mortem, document lessons learned, create preventive action items

**Recovery Time Objectives (RTO)** by Scenario:

| Failure Scenario | RTO Target | Recovery Procedure |
|-----------------|-----------|-------------------|
| Single ECS Task Failure | < 1 minute | ECS auto-restarts task, health checks verify recovery |
| MongoDB Primary Failure | < 10 seconds | Replica set auto-failover to secondary node |
| Availability Zone Failure | < 5 minutes | ALB routes traffic to healthy availability zones |
| Full Application Outage | < 30 minutes | Rollback deployment, restart services, verify health checks |

---

### 6.5.6 Dashboards and Visualization

#### 6.5.6.1 CloudWatch Dashboard Architecture

**Multi-Audience Dashboard Strategy**: Specialized dashboards tailored for different teams (operations, engineering, business, security) provide role-specific visibility into system health and performance.

**System Health Dashboard (Operations Team)**:

**Purpose**: Real-time operational health monitoring for incident detection and response

**Dashboard Widgets**:

| Widget Type | Metrics Displayed | Time Range | Refresh Rate |
|------------|------------------|-----------|--------------|
| Line Graph | API request rate (requests/second) by endpoint | Last 3 hours | 1 minute |
| Line Graph | Error rate percentage (4xx, 5xx errors) | Last 3 hours | 1 minute |
| Line Graph | Request latency (p50, p95, p99 percentiles) | Last 3 hours | 1 minute |
| Number Widget | Current ECS task count and health status | Real-time | 1 minute |

| Widget Type | Metrics Displayed | Time Range | Refresh Rate |
|------------|------------------|-----------|--------------|
| Stacked Area | Database query volume (reads vs. writes) | Last 6 hours | 5 minutes |
| Heat Map | Cache hit rate by endpoint | Last 24 hours | 5 minutes |
| Alarm Status | Critical alarms current state (OK, ALARM, INSUFFICIENT_DATA) | Real-time | 1 minute |

**Business Metrics Dashboard (Product Team)**:

**Purpose**: Track user engagement, feature adoption, and revenue drivers

**Dashboard Widgets**:

| Widget | Metrics Displayed | Business Question Answered |
|--------|------------------|---------------------------|
| Number Widget | Daily Active Users (DAU), Monthly Active Users (MAU) | How many users are actively using the platform? |
| Line Graph | AI request volume by model (GPT-4, GPT-3.5) | Which AI features are most popular? |
| Pie Chart | Request distribution by subscription tier | What percentage of requests come from premium vs. free users? |
| Line Graph | Estimated daily AI costs (token usage × pricing) | What is our AI infrastructure spend trend? |

**Security Events Dashboard (Security Team)**:

**Purpose**: Monitor authentication failures, authorization violations, and suspicious activity

**Dashboard Widgets**:

| Widget | Metrics Displayed | Security Concern Addressed |
|--------|------------------|---------------------------|
| Line Graph | Failed authentication attempts per minute | Are we experiencing brute-force attacks? |
| Heat Map | Permission denied events by endpoint and user | Are users attempting unauthorized access? |
| Line Graph | Rate limit violations by IP address | Are we experiencing API abuse or DDoS attempts? |
| Table | Top 10 IP addresses with highest error rates | Which sources are generating the most errors? |

#### 6.5.6.2 Dashboard Layout Specification

**System Health Dashboard Visual Layout**:

```
┌─────────────────────────────────────────────────────────────────┐
│ System Health Dashboard - Production Environment                │
│ Last Updated: 2024-01-15 10:30:00 UTC (Auto-refresh: 1 minute)│
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐        │
│  │ ECS Tasks    │  │ Error Rate   │  │ API Latency  │        │
│  │    8 / 10    │  │    1.2%      │  │  p95: 245ms  │        │
│  │  ✓ Healthy   │  │  ✓ Normal    │  │  ✓ Normal    │        │
│  └──────────────┘  └──────────────┘  └──────────────┘        │
│                                                                 │
│  ┌────────────────────────────────────────────────────────┐   │
│  │ API Request Rate (Last 3 Hours)                       │   │
│  │                                                        │   │
│  │  1200 ┤                                               │   │
│  │  1000 ┤        ╭──╮    ╭──╮                          │   │
│  │   800 ┤     ╭──╯  ╰────╯  ╰──╮                       │   │
│  │   600 ┤  ╭──╯                 ╰───╮                  │   │
│  │   400 ┤──╯                         ╰─────            │   │
│  │       └────────────────────────────────────────────► │   │
│  │        08:00    09:00    10:00    11:00              │   │
│  └────────────────────────────────────────────────────────┘   │
│                                                                 │
│  ┌──────────────────────────┐  ┌──────────────────────────┐  │
│  │ Error Rate (%)           │  │ Latency Percentiles (ms) │  │
│  │  4 ┤                     │  │ 1000 ┤                   │  │
│  │  3 ┤   ╭╮                │  │  800 ┤           p99     │  │
│  │  2 ┤   │╰╮               │  │  600 ┤        p95        │  │
│  │  1 ┤───╯ ╰─────          │  │  400 ┤     p50           │  │
│  │  0 └───────────────────► │  │  200 ┤───────            │  │
│  └──────────────────────────┘  └──────────────────────────┘  │
│                                                                 │
│  ┌────────────────────────────────────────────────────────┐   │
│  │ Active Alarms                                          │   │
│  │  ✓ API Latency: OK                                     │   │
│  │  ✓ Error Rate: OK                                      │   │
│  │  ⚠ Cache Hit Rate: WARNING (68% - below 70% threshold)│   │
│  │  ✓ ECS CPU: OK                                         │   │
│  └────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

---

### 6.5.7 Performance Monitoring and SLA Tracking

#### 6.5.7.1 API Response Time Targets

**Performance SLA Commitments**: The system maintains strict performance targets across different endpoint categories to ensure consistent user experience.

| Endpoint Category | p50 Target | p95 Target | p99 Target |
|------------------|-----------|-----------|-----------|
| Simple CRUD (GET, POST) | < 100ms | < 300ms | < 500ms |
| Complex Queries (Aggregations) | < 300ms | < 800ms | < 1200ms |
| AI Completions (Simple) | < 2000ms | < 5000ms | < 8000ms |
| AI Conversations (Multi-turn) | < 3000ms | < 6000ms | < 10000ms |

**SLA Monitoring Implementation**:

- **CloudWatch Metric**: `api.request.duration` histogram with percentile aggregation (p50, p95, p99)
- **Alert Threshold**: P95 latency > target for 5 consecutive minutes triggers warning alert
- **Business Impact**: Latency SLA breaches tracked monthly, reported to leadership as Key Performance Indicator (KPI)
- **Performance Budget**: Each endpoint has latency budget allocating time across components (network, authentication, business logic, database)

#### 6.5.7.2 Availability and Uptime Tracking

**Availability SLA Targets**:

| Component | SLA Target | Monthly Downtime Allowance | Mechanism |
|-----------|-----------|---------------------------|-----------|
| Overall Application | 99.9% | 43.2 minutes | Multi-AZ deployment, auto-healing |
| Flask API | 99.95% | 21.6 minutes | ECS health checks, auto-restart |
| MongoDB | 99.95% | 21.6 minutes | Replica set auto-failover |
| Auth0 | 99.99% | 4.32 minutes | Auth0 enterprise SLA |

**Uptime Calculation Methodology**:

- **Measurement Period**: Calendar month (first day 00:00:00 UTC to last day 23:59:59 UTC)
- **Downtime Definition**: Any period where >50% of requests return 5xx errors or timeout
- **Exclusions**: Scheduled maintenance windows (announced 7 days in advance), AWS service outages (covered by AWS SLA)
- **Tracking**: CloudWatch Synthetics canary runs every 5 minutes, logs success/failure, calculates uptime percentage

**Synthetic Monitoring**: CloudWatch Synthetics canary scripts simulate user journeys to proactively detect availability issues:

1. **API Health Check Canary**: GET `/health` endpoint every 5 minutes from multiple AWS regions
2. **Authentication Flow Canary**: Complete OAuth flow every 15 minutes to verify Auth0 integration
3. **End-to-End Journey Canary**: Create document → Retrieve document → Delete document every 30 minutes

#### 6.5.7.3 Capacity and Scalability Monitoring

**Capacity Planning Metrics**: Proactive monitoring of resource utilization trends enables capacity planning before reaching limits.

**Capacity Thresholds**:

| Resource | Current Capacity | Usage Threshold (Warning) | Usage Threshold (Critical) |
|----------|-----------------|--------------------------|---------------------------|
| ECS Task Count | 3-10 tasks | 8 tasks (80% of max) | 10 tasks (100% of max) |
| MongoDB Storage | 100 GB provisioned | 80 GB used (80%) | 90 GB used (90%) |
| Redis Memory | 4 GB provisioned | 3.2 GB used (80%) | 3.6 GB used (90%) |
| ALB Target Connections | 5000 concurrent | 4000 connections (80%) | 4500 connections (90%) |

**Growth Trend Analysis**: Weekly automated report analyzes metric trends over past 30 days to predict capacity exhaustion dates:

- **Request Volume Growth**: If request rate increases 10% week-over-week, predict date when current capacity insufficient
- **Data Storage Growth**: Extrapolate database storage growth to predict when additional capacity needed
- **Cost Forecasting**: Estimate future infrastructure costs based on growth trends

---

### 6.5.8 Security Event Monitoring

#### 6.5.8.1 Security Event Tracking

**Security-Focused Logging and Alerting**: Comprehensive monitoring of authentication, authorization, and suspicious activity patterns enables rapid security incident detection and response.

**Security Event Categories**:

| Event Type | Log Level | Example Events | Alert Threshold |
|-----------|-----------|----------------|----------------|
| **Failed Authentication** | WARNING | Invalid credentials, expired JWT, missing token | > 5 attempts/min from single IP |
| **Authorization Failures** | INFO | Permission denied, insufficient privileges | > 50 denials/min for single user |
| **Suspicious Activity** | WARNING | Unusual API usage patterns, geographic anomalies | > 100 requests/hour from new IP |
| **Admin Actions** | AUDIT | User role changes, permission grants, system config | Every occurrence logged |

**Security Metrics Dashboard**:

| Metric | Visualization | Alert Configuration |
|--------|--------------|-------------------|
| Authentication success/failure rate | Line graph (target: > 99% success) | < 95% success rate for 15 minutes |
| JWT validation latency | Histogram (target: < 20ms p95) | p95 > 50ms for 10 minutes |
| Permission denial rate by endpoint | Heat map (baseline: < 1% per endpoint) | > 5% denial rate for any endpoint |
| Rate limit violations | Counter (baseline: < 10/hour) | > 100 violations/hour |

#### 6.5.8.2 Circuit Breaker Monitoring

**Auth0 Circuit Breaker Pattern**: Resilient authentication architecture includes circuit breaker monitoring to detect and respond to Auth0 service degradation.

**Circuit Breaker States**:

| State | Behavior | Metric Tracked | Transition Trigger |
|-------|----------|----------------|-------------------|
| **CLOSED** (Normal) | All requests to Auth0 proceed | Auth0 API error rate | Error rate < 10% |
| **OPEN** (Failure) | Use cached JWKS, extend TTL to 4 hours | Circuit breaker opens counter | Error rate > 50% in 60-second window |
| **HALF-OPEN** (Testing) | Allow 5 test requests to Auth0 | Test request success rate | After 30 seconds in OPEN state |

**Circuit Breaker Metrics**:

- `auth.circuit_breaker.state`: Current circuit breaker state (0=CLOSED, 1=OPEN, 2=HALF-OPEN)
- `auth.circuit_breaker.open_count`: Number of times circuit opened in last 24 hours
- `auth.circuit_breaker.cache_fallback`: Requests served from cached JWKS during circuit open

---

### 6.5.9 Audit Logging and Compliance Monitoring

#### 6.5.9.1 Audit Log Architecture

**Immutable Audit Trail**: Comprehensive audit logging captures all security-relevant events with tamper-proof, append-only storage for compliance requirements.

**Audit Log Schema**:

```json
{
  "_id": "ObjectId('...')",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456789",
  "action": "UPDATE",
  "resource_type": "documents",
  "resource_id": "507f1f77bcf86cd799439014",
  "endpoint": "/api/v1/documents/507f1f77bcf86cd799439014",
  "method": "PUT",
  "ip_address": "203.0.113.45",
  "user_agent": "Mozilla/5.0...",
  "status": "success",
  "permissions_checked": ["write:documents"],
  "authorization_decision": "granted",
  "changes": {
    "before": {"title": "Old Title"},
    "after": {"title": "New Title"}
  }
}
```

**Audit Log Retention and Compliance**:

| Event Category | Retention Period | Compliance Requirement | Storage Location |
|---------------|------------------|----------------------|------------------|
| Authentication Events | 1 year | SOC 2 CC6.1 | MongoDB audit collection |
| Authorization Decisions | 7 years | SOC 2 CC6.2, GDPR Art. 30 | MongoDB audit collection → S3 Glacier |
| Data Modifications | 7 years | GDPR Art. 30, CCPA | MongoDB audit collection → S3 Glacier |
| Administrative Actions | Permanent | SOC 2 CC7.2 | MongoDB audit collection, never deleted |

#### 6.5.9.2 Compliance Monitoring Dashboards

**Compliance Audit Dashboard**: Specialized dashboard for compliance officers and auditors providing visibility into security controls effectiveness.

**Dashboard Components**:

| Widget | Metrics | Compliance Standard Addressed |
|--------|---------|------------------------------|
| Authentication Audit | Login attempts (success/failure), MFA challenges | SOC 2 CC6.1, NIST 800-53 IA-2 |
| Access Control Audit | Permission checks, authorization decisions, admin override usage | SOC 2 CC6.2, NIST 800-53 AC-3 |
| Data Access Audit | Resource access patterns, data modifications, deletion requests | GDPR Art. 30, CCPA §1798.100 |
| Security Incident Log | Failed auth attempts, suspicious activity, circuit breaker activations | SOC 2 CC7.2, NIST 800-53 IR-6 |

---

### 6.5.10 Third-Party Monitoring Integrations (Optional)

#### 6.5.10.1 Enhanced Observability Tools

**Optional Third-Party Platform Integrations**: While CloudWatch provides comprehensive core monitoring, optional integrations with specialized platforms enhance specific observability capabilities.

| Platform | Primary Use Case | Integration Method | Key Benefits |
|----------|-----------------|-------------------|--------------|
| **DataDog APM** | Advanced application performance monitoring | DataDog agent on ECS tasks | Distributed tracing, service dependency mapping, anomaly detection |
| **Sentry** | Error tracking and debugging | Sentry SDK in Flask application | Source code context, user impact tracking, release tracking |
| **LogRocket** | Session replay and frontend monitoring | JavaScript SDK in React application | User session replay, frontend error tracking, performance insights |

**DataDog Integration Architecture**:

- **Agent Deployment**: DataDog agent runs as sidecar container in ECS task definition
- **Metrics Collection**: Automatic collection of infrastructure metrics (CPU, memory, network) and custom application metrics
- **Log Forwarding**: Application logs forwarded to DataDog for centralized log management and search
- **Distributed Tracing**: APM tracing captures request flows across services with automatic instrumentation
- **Cost Consideration**: DataDog pricing based on number of hosts and log volume; evaluate ROI before production deployment

---

### 6.5.11 Runbooks and Operational Procedures

#### 6.5.11.1 Common Incident Runbooks

**Standardized Response Procedures**: Documented runbooks ensure consistent, efficient incident response for common operational scenarios.

**High Error Rate Runbook** (P0 - Critical):

```
Trigger: api.error.rate > 5% for 5 consecutive minutes

Investigation Steps:
1. Check CloudWatch dashboard → Identify which endpoints have high error rates
2. Review recent deployment history → Was there a recent code or infrastructure change?
3. Query CloudWatch Logs Insights → Analyze error messages and stack traces
4. Check external dependencies → Verify Auth0, OpenAI, MongoDB availability
5. Review ECS task health → Ensure all tasks are healthy and passing health checks

Remediation Options:
- If caused by recent deployment: Initiate rollback via ECS (previous task definition)
- If caused by database issue: Restart MongoDB connection pool, verify replica set health
- If caused by external service outage: Activate circuit breaker, enable graceful degradation
- If caused by application bug: Deploy hotfix, notify engineering team for permanent fix

Post-Incident Actions:
- Document root cause in incident report
- Schedule post-mortem meeting within 48 hours
- Create action items to prevent recurrence
- Update runbook if new resolution method discovered
```

**High Latency Runbook** (P1 - High):

```
Trigger: api.request.duration (p95) > 1000ms for 5 consecutive minutes

Investigation Steps:
1. Identify slow endpoints using CloudWatch metrics filtered by endpoint dimension
2. Review X-Ray traces for slow requests → Identify which component is bottleneck
3. Check database query performance → Review MongoDB slow query logs
4. Verify cache hit rate → Ensure Redis caching is functioning correctly
5. Check external API latency → Measure Auth0 and OpenAI response times

Remediation Options:
- If database bottleneck: Add database indexes, optimize queries, scale database vertically
- If cache miss rate high: Warm cache, increase cache TTL, add caching for new endpoints
- If CPU/memory constrained: Scale ECS tasks horizontally (increase desired count)
- If external API slow: Increase timeouts, implement request queuing, contact vendor support

Monitoring:
- After remediation, monitor p95 latency for 30 minutes to confirm improvement
- If latency returns to normal, mark incident as resolved
- If latency persists, escalate to engineering manager for deeper investigation
```

#### 6.5.11.2 Post-Mortem Process

**Blameless Post-Mortem Framework**: After every P0 (Critical) or P1 (High) incident, conduct structured post-mortem to learn and improve system resilience.

**Post-Mortem Document Structure**:

1. **Incident Summary**: Brief description, severity, total duration, user impact
2. **Timeline**: Chronological sequence of events from detection through resolution
3. **Root Cause Analysis**: Technical root cause identified through investigation (Five Whys technique)
4. **Impact Assessment**: Number of affected users, revenue impact, SLA breach calculation
5. **What Went Well**: Effective detection, rapid response, successful mitigation
6. **What Went Wrong**: Delayed detection, unclear procedures, inadequate monitoring
7. **Action Items**: Concrete, assigned tasks to prevent recurrence (improved monitoring, code fixes, runbook updates)

**Post-Mortem Meeting Agenda** (1-hour meeting within 48 hours of incident):

- **0-10 minutes**: Present incident timeline and impact
- **10-30 minutes**: Discuss root cause, ask "Why?" five times to uncover systemic issues
- **30-45 minutes**: Brainstorm prevention strategies and improvement opportunities
- **45-60 minutes**: Assign action items with owners and due dates, document lessons learned

---

### 6.5.12 Implementation Roadmap and Future Enhancements

#### 6.5.12.1 Current Implementation Status

**Repository State**: Pre-implementation phase with no monitoring code deployed

**Priority Implementation Phases**:

| Phase | Monitoring Components | Timeline | Dependencies |
|-------|----------------------|----------|--------------|
| **Phase 1 - Foundation** | CloudWatch Logs (structured JSON), basic metrics (requests, errors), system health dashboard | Week 1-2 | Flask application deployment, CloudWatch permissions |
| **Phase 2 - Alerting** | CloudWatch Alarms (error rate, latency, CPU), SNS notification topics, email alerts | Week 3-4 | Phase 1 complete, SNS topic configuration |
| **Phase 3 - Advanced Metrics** | Custom application metrics (cache hit rate, AI tokens), business metrics dashboard | Week 5-6 | Phase 1 complete, metric emission code |
| **Phase 4 - Tracing** | AWS X-Ray integration, distributed tracing, service map | Week 7-8 | Phase 1-3 complete, X-Ray SDK integration |

#### 6.5.12.2 Future Monitoring Enhancements

**Planned Enhancements** (Post-MVP):

1. **Machine Learning Anomaly Detection**: CloudWatch Anomaly Detection for automatic threshold adjustment based on historical patterns
2. **Cost Optimization Monitoring**: Detailed cost attribution by feature, user tier, and operation; automated cost anomaly alerts
3. **User Experience Monitoring**: Real User Monitoring (RUM) for frontend performance, Core Web Vitals tracking
4. **Predictive Alerting**: Trend-based alerting to predict capacity exhaustion or performance degradation before user impact
5. **Cross-Region Monitoring**: Multi-region deployment monitoring with failover detection and verification

---

### 6.5.13 Monitoring Architecture Summary

The CheckSameRepoNoPrompt system implements a comprehensive, multi-layered monitoring and observability architecture designed to provide complete visibility into system health, performance, and business metrics. Key monitoring highlights include:

**Comprehensive Observability**:
- AWS CloudWatch as primary monitoring platform with logs, metrics, traces, and alarms
- Structured JSON logging with PII redaction and 30-day active retention
- Request ID propagation enabling end-to-end distributed tracing across services
- Optional AWS X-Ray integration for visual service dependency mapping

**Intelligent Alerting**:
- Multi-dimensional metrics (service, environment, endpoint, user tier) enable fine-grained analysis
- CloudWatch Alarms with tuned thresholds minimize false positives while ensuring critical issue detection
- Multi-channel alerting (PagerDuty, email, Slack) with escalation policies
- Automated remediation for common issues (auto-scaling, service restarts)

**Operational Excellence**:
- Role-specific dashboards (operations, business, security, compliance) provide targeted visibility
- Performance SLA tracking with 99.9% uptime target and sub-second response time goals
- Comprehensive audit logging with 7-year retention for compliance (SOC 2, GDPR, CCPA)
- Documented runbooks and blameless post-mortem process for continuous improvement

**Security Monitoring**:
- Real-time security event tracking (failed auth, permission denials, suspicious activity)
- Circuit breaker monitoring for Auth0 integration resilience
- Security metrics dashboard for security team visibility

**Implementation Status**: This monitoring architecture represents the planned design for the CheckSameRepoNoPrompt system. The repository currently contains only a README.md file, with all monitoring implementations pending development phase execution.

---

### 6.5.14 References

#### 6.5.14.1 Technical Specification Sections Referenced

- **Section 5.4.1 - Monitoring and Observability**: Comprehensive monitoring architecture, CloudWatch Logs/Metrics configuration, distributed tracing, alerting strategy
- **Section 5.4.2 - Logging and Tracing**: Structured logging standards, PII handling, request tracing flow, log correlation
- **Section 5.4.3 - Error Handling**: Error classification, standardized error responses, circuit breaker patterns, graceful degradation
- **Section 5.4.5 - Performance Requirements and SLAs**: API response time targets, throughput and scalability targets, availability SLA commitments
- **Section 5.4.6 - Disaster Recovery**: Recovery objectives (RTO/RPO), disaster recovery procedures, failover mechanisms, incident response workflow
- **Section 6.4 - Security Architecture**: Security event tracking, circuit breaker for Auth0, audit logging, compliance controls
- **Section 5.1 - High-Level Architecture**: System overview, component interactions, data flow architecture, integration patterns
- **Section 4.2 - CI/CD Workflows**: ECS health checks, deployment monitoring, automatic rollback procedures

#### 6.5.14.2 Repository Files Examined

- **`README.md`** (root directory): Project title documentation; repository in pre-implementation phase with no monitoring implementation code

#### 6.5.14.3 Repository Folders Explored

- **Root Directory** (`/`): Contains only README.md file; no application code, CloudWatch configuration, monitoring instrumentation, or observability implementation

#### 6.5.14.4 AWS Services and Technologies Referenced

- **Amazon CloudWatch**: Primary monitoring platform (Logs, Metrics, Alarms, Dashboards, Synthetics, Anomaly Detection)
- **AWS X-Ray**: Distributed tracing and service map visualization (optional enhancement)
- **Amazon SNS**: Notification hub for multi-channel alerting (email, PagerDuty, Slack, Lambda triggers)
- **AWS Lambda**: Automated remediation functions triggered by CloudWatch Alarms
- **Amazon ECS**: Container orchestration with built-in health checks and auto-healing
- **Application Load Balancer**: HTTP access logs, target health monitoring, traffic distribution
- **Amazon S3**: Log archival storage with lifecycle policies (Standard → Glacier)
- **AWS Secrets Manager**: Secure credential storage for monitoring integrations

#### 6.5.14.5 Third-Party Monitoring Tools Referenced (Optional)

- **DataDog APM**: Advanced application performance monitoring with distributed tracing
- **Sentry**: Error tracking and debugging with source code context
- **LogRocket**: Session replay and frontend monitoring
- **PagerDuty**: On-call management and incident escalation
- **Slack**: Team collaboration and alert notifications

#### 6.5.14.6 Compliance Standards and Frameworks Referenced

- **SOC 2 Type II**: Security, availability, and confidentiality controls (CC6.1, CC6.2, CC7.2)
- **GDPR (General Data Protection Regulation)**: Article 30 (Records of Processing), Article 32 (Security of Processing)
- **CCPA (California Consumer Privacy Act)**: Data disclosure and audit trail requirements (§1798.100)
- **NIST 800-53**: Security and Privacy Controls (AU - Audit and Accountability, IR - Incident Response)

#### 6.5.14.7 Monitoring Best Practices and Methodologies

- **The Three Pillars of Observability**: Logs, Metrics, Traces (coined by distributed systems community)
- **Google SRE Principles**: SLIs, SLOs, SLAs, error budgets, blameless post-mortems
- **The Four Golden Signals**: Latency, Traffic, Errors, Saturation (from Google SRE Book)
- **USE Method**: Utilization, Saturation, Errors (Brendan Gregg's performance methodology)
- **RED Method**: Rate, Errors, Duration (Tom Wilkie's microservices monitoring methodology)

#### 6.5.14.8 Key Findings Summary

**Monitoring Architecture Scope**:
- **Cloud-Native Monitoring**: Full AWS CloudWatch integration as primary observability platform
- **Structured Observability**: JSON-formatted logs, multi-dimensional metrics, distributed tracing with request IDs
- **Intelligent Alerting**: Tuned alert thresholds with automated remediation and multi-channel escalation
- **Comprehensive Coverage**: Infrastructure metrics (CPU, memory), application metrics (latency, errors), business metrics (AI usage, costs), security metrics (auth failures, suspicious activity)
- **Compliance-Ready**: 7-year audit log retention, immutable append-only logging, GDPR/CCPA/SOC 2 alignment

**Performance Monitoring**:
- **Strict SLA Targets**: 99.9% uptime, p95 latency < 300ms for CRUD operations, < 5 seconds for AI requests
- **Multi-Percentile Tracking**: p50, p95, p99 latency percentiles for comprehensive performance visibility
- **Capacity Planning**: Proactive monitoring of resource utilization trends with growth forecasting
- **Synthetic Monitoring**: CloudWatch Synthetics canaries for proactive availability verification

**Operational Excellence**:
- **Multi-Audience Dashboards**: Specialized views for operations, engineering, business, security, compliance teams
- **Documented Runbooks**: Standardized incident response procedures for common scenarios
- **Blameless Post-Mortems**: Structured learning process after incidents with action item tracking
- **Automated Remediation**: Self-healing mechanisms for common issues (auto-scaling, service restarts, cache warming)

**Implementation Status**:
- **Pre-Implementation Phase**: All monitoring infrastructure documented represents planned architecture
- **No Monitoring Code**: Repository contains only README.md, no CloudWatch configuration, logging instrumentation, or metrics emission code
- **Architecture Complete**: Monitoring design fully specified and ready for development phase implementation
- **Phased Rollout**: Four-phase implementation plan (Foundation → Alerting → Advanced Metrics → Tracing) over 8 weeks

**Total Research Depth**: 4 technical specification sections retrieved and synthesized, comprehensive section-specific research report analyzed, integrated into cohesive monitoring and observability documentation.

---

**Document Metadata**:
- **Section**: 6.5 Monitoring and Observability
- **Version**: 1.0 (Planned Architecture)
- **Date**: January 2024
- **Status**: Pre-Implementation (Design Phase)
- **Implementation Code**: None (repository contains only README.md)
- **Next Steps**: Development team to implement monitoring infrastructure per this specification during application development phase, beginning with Phase 1 (CloudWatch Logs and basic metrics) in weeks 1-2 of deployment.

## 6.6 Testing Strategy

### 6.6.1 Testing Strategy Overview

#### 6.6.1.1 Implementation Status and Approach

The CheckSameRepoNoPrompt system is currently in **pre-implementation phase**, with infrastructure consisting solely of a foundational README.md file. However, this Testing Strategy section documents a comprehensive, production-ready testing framework that has been meticulously planned within the CI/CD workflow specifications (Section 4.2) and architectural design. This strategy represents the complete testing approach that will be implemented as system development progresses.

The repository examination revealed no existing test files, test directories (`tests/`, `__tests__/`, `spec/`), test configuration files (`pytest.ini`, `jest.config.js`), or CI/CD workflow files. Despite this pre-implementation status, the technical specification contains detailed testing strategies embedded within the CI/CD pipeline documentation, providing a robust foundation for quality assurance from the first line of code.

#### 6.6.1.2 Testing Philosophy and Principles

The testing strategy for this multi-platform, cloud-native application follows a **comprehensive quality-first approach** with the following core principles:

**Quality Gates at Every Stage**: Automated testing integrated into CI/CD pipelines ensures no code reaches production without passing rigorous quality checks including linting, type checking, unit tests, integration tests, and build verification.

**Shift-Left Testing**: Testing begins at the earliest stages of development with local pre-commit validation, static analysis, and continuous automated testing during development cycles.

**Test Pyramid Architecture**: The testing strategy follows the classic test pyramid with a broad base of fast unit tests, a middle layer of integration tests, and a focused set of end-to-end tests for critical user journeys.

**Platform-Specific Testing**: Each platform (backend Python/Flask, frontend React/TypeScript, mobile React Native, desktop Electron) receives tailored testing approaches using platform-appropriate frameworks and tools.

**Infrastructure as Code Testing**: Infrastructure provisioning through Terraform includes validation, planning, and review stages to prevent configuration errors and drift.

**Continuous Quality Monitoring**: Post-deployment monitoring with synthetic canaries, performance tracking, and error rate monitoring provides continuous validation of production quality.

### 6.6.2 Unit Testing Strategy

#### 6.6.2.1 Backend Unit Testing (Python/Flask)

#### Testing Framework and Tools

The backend testing infrastructure utilizes the pytest framework ecosystem with comprehensive coverage analysis and quality enforcement tools:

| Tool | Version | Purpose | Integration Point |
|------|---------|---------|------------------|
| pytest | Latest | Primary testing framework | CI/CD test execution |
| pytest-cov | Latest | Coverage measurement and reporting | XML and terminal reports |
| pytest-mock | Latest | Mocking and fixtures | External service isolation |
| Black | Latest | Code formatting validation | Pre-test quality gate |
| Flake8 | Latest | PEP 8 compliance and linting | Pre-test quality gate |
| mypy | Latest | Static type checking | Pre-test quality gate |

**Test Execution Workflow**: The CI/CD pipeline (Section 4.2.1) orchestrates a three-phase testing approach:

1. **Code Quality Phase**: Before any tests execute, the pipeline validates code formatting with `black --check backend/`, enforces PEP 8 compliance with `flake8 backend/ --max-line-length=88` (configured to match Black's line length), and performs strict static type analysis with `mypy backend/ --strict`.

2. **Test Execution Phase**: After code quality validation, pytest executes the complete test suite with `pytest backend/tests/ --cov=backend --cov-report=xml --cov-report=term`, generating both XML coverage reports for Codecov integration and terminal output for immediate developer feedback.

3. **Coverage Reporting Phase**: The pipeline uploads `coverage.xml` to Codecov for trend analysis, pull request coverage impact reporting, and historical coverage tracking across all commits.

#### Test Organization Structure

The backend test suite follows a **mirror directory structure** approach where test files parallel the source code organization:

```
backend/
├── app/
│   ├── auth/
│   │   ├── handlers.py
│   │   └── validators.py
│   ├── api/
│   │   ├── routes.py
│   │   └── middleware.py
│   └── services/
│       ├── ai_service.py
│       └── document_service.py
└── tests/
    ├── unit/
    │   ├── auth/
    │   │   ├── test_handlers.py
    │   │   └── test_validators.py
    │   ├── api/
    │   │   ├── test_routes.py
    │   │   └── test_middleware.py
    │   └── services/
    │       ├── test_ai_service.py
    │       └── test_document_service.py
    ├── integration/
    │   ├── test_auth_flow.py
    │   ├── test_api_integration.py
    │   └── test_database_operations.py
    └── conftest.py
```

**Test Naming Conventions**: Test files follow the `test_<module_name>.py` pattern, while individual test functions use descriptive names: `test_<function_name>_<scenario>_<expected_outcome>`. For example: `test_jwt_validation_with_expired_token_raises_unauthorized`, `test_document_creation_with_valid_data_returns_201`, `test_ai_completion_with_rate_limit_triggers_circuit_breaker`.

**Shared Test Fixtures**: The `conftest.py` file at the test root provides shared fixtures including test database connections, mock external services (Auth0, MongoDB, Redis, LangChain), test data factories, and common test utilities. Pytest's fixture scope system manages fixture lifecycle (function-scoped for isolation, module-scoped for performance where appropriate).

#### Code Coverage Requirements

**Coverage Targets**: While the specific threshold is configurable, the architecture documentation references an **80% code coverage minimum** as an example target for backend services. This threshold applies to line coverage across all backend modules.

**Coverage Enforcement**: The CI/CD pipeline generates coverage reports in multiple formats:
- **XML Format**: Uploaded to Codecov for external analysis and trend tracking
- **Terminal Format**: Displayed in GitHub Actions logs for immediate visibility
- **Pull Request Comments**: Codecov automatically posts coverage deltas on pull requests, showing coverage impact of proposed changes

**Coverage Exclusions**: Standard exclusions include defensive code (exception handlers that should never execute), abstract base class methods marked with `@abstractmethod`, and explicit `# pragma: no cover` annotations for code that cannot be meaningfully tested.

#### Mocking Strategy

**External Service Mocking**: All external dependencies are mocked during unit testing to ensure test isolation, speed, and reliability:

- **Auth0 Authentication**: Mock JWT validation, user profile retrieval, and OAuth token exchange flows
- **MongoDB Operations**: Use pytest-mongo or mongomock for in-memory database simulation
- **Redis Caching**: Use fakeredis for in-memory cache simulation without Redis server dependency
- **LangChain AI Services**: Mock LLM API calls to prevent external API costs and ensure deterministic test results
- **AWS Services**: Mock S3 operations, CloudWatch logging, and X-Ray tracing using moto library

**Mocking Implementation**: Pytest fixtures in `conftest.py` provide pre-configured mocks with realistic behaviors. For example, the `mock_auth0` fixture returns configurable JWT tokens, the `mock_mongodb` fixture provides a clean database slate for each test, and the `mock_langchain` fixture returns predefined AI completion responses.

#### Test Data Management

**Test Data Factories**: Factory pattern implementation using factory_boy or custom factory functions generates realistic test data with minimal boilerplate. Factories support both default values for quick test setup and customization for specific test scenarios.

**Test Database Seeding**: Integration tests use database fixtures that populate test data before test execution and clean up afterward. The `conftest.py` file includes `@pytest.fixture(scope="function", autouse=True)` decorators for automatic database cleanup between tests, ensuring test isolation.

**Fixture Files**: Static test data (JSON payloads, mock API responses, sample documents) resides in `tests/fixtures/` directory, loaded as pytest fixtures or directly imported by test modules.

#### 6.6.2.2 Frontend Unit Testing (React/TypeScript)

#### Testing Framework and Tools

The frontend testing stack leverages modern JavaScript testing tools optimized for React and TypeScript:

| Tool | Version | Purpose | Integration Point |
|------|---------|---------|------------------|
| Jest/Vitest | Latest | Testing framework and runner | CI/CD test execution |
| React Testing Library | Latest | Component testing with user-centric queries | Component interaction testing |
| @testing-library/user-event | Latest | User interaction simulation | Event-driven test scenarios |
| MSW (Mock Service Worker) | Latest | API request mocking at network level | Integration test isolation |
| ESLint | Latest | TypeScript and React linting | Pre-test quality gate |
| Prettier | Latest | Code formatting validation | Pre-test quality gate |
| TypeScript Compiler | 5.0+ | Type checking without code emission | Pre-test quality gate |

**Test Execution Workflow**: The frontend CI/CD pipeline (Section 4.2.2) implements a parallel quality and test validation process:

1. **Code Quality Phase**: Concurrent execution of `npm run lint` (ESLint with React and TypeScript rules), `npm run format:check` (Prettier validation for `.ts`, `.tsx`, and `.css` files), and `tsc --noEmit` (type checking without file generation) ensures code meets quality standards before test execution.

2. **Test Execution Phase**: Jest or Vitest runs with `npm run test -- --coverage --passWithNoTests`, executing component rendering tests, user interaction simulations, hook behavior validation, and state management tests.

3. **Coverage Reporting Phase**: Test coverage reports generate in HTML format for local review and JSON format for programmatic analysis, stored in the `coverage/` directory.

#### Component Testing Approach

**Testing Philosophy**: Frontend tests focus on **user behavior rather than implementation details**, following React Testing Library's guiding principle: "The more your tests resemble the way your software is used, the more confidence they can give you."

**Component Test Categories**:

**Rendering Tests**: Verify components render correctly with default props, various prop combinations, and different application states. Tests use queries like `getByRole`, `getByLabelText`, and `getByText` to find elements as users would, avoiding reliance on implementation details like CSS classes or data-testid attributes except as a last resort.

**User Interaction Tests**: Simulate user actions with `@testing-library/user-event` (preferred over `fireEvent` for realistic interaction timing). Examples include:
- Form submission with valid and invalid data
- Button clicks that trigger state changes or API calls
- Navigation between routes
- Keyboard navigation and accessibility features

**State Management Tests**: Validate component state updates, React context providers, and custom hooks behavior. Tests verify that state changes trigger appropriate UI updates and that side effects execute correctly.

**Accessibility Tests**: Ensure components meet WCAG standards with proper ARIA labels, keyboard navigation support, and screen reader compatibility. Tests verify semantic HTML structure and proper focus management.

#### Test Organization Structure

Frontend tests follow a **co-location strategy** where test files reside adjacent to the components they test:

```
frontend/
├── src/
│   ├── components/
│   │   ├── auth/
│   │   │   ├── LoginForm.tsx
│   │   │   ├── LoginForm.test.tsx
│   │   │   ├── RegisterForm.tsx
│   │   │   └── RegisterForm.test.tsx
│   │   ├── documents/
│   │   │   ├── DocumentList.tsx
│   │   │   ├── DocumentList.test.tsx
│   │   │   ├── DocumentEditor.tsx
│   │   │   └── DocumentEditor.test.tsx
│   │   └── common/
│   │       ├── Button.tsx
│   │       ├── Button.test.tsx
│   │       ├── Modal.tsx
│   │       └── Modal.test.tsx
│   ├── hooks/
│   │   ├── useAuth.ts
│   │   ├── useAuth.test.ts
│   │   ├── useDocument.ts
│   │   └── useDocument.test.ts
│   └── utils/
│       ├── formatters.ts
│       ├── formatters.test.ts
│       ├── validators.ts
│       └── validators.test.ts
└── test/
    ├── setup.ts
    ├── mocks/
    │   ├── handlers.ts
    │   └── server.ts
    └── utils/
        └── test-utils.tsx
```

**Test File Naming**: Component tests use `.test.tsx` extension, while utility and hook tests use `.test.ts`. This convention enables test runner glob patterns to automatically discover all test files.

**Shared Test Utilities**: The `test/utils/test-utils.tsx` file exports a custom `render` function that wraps React Testing Library's render with application-wide providers (React Router, theme providers, context providers), eliminating boilerplate from individual tests.

#### Mock Service Worker (MSW) Integration

**Network-Level Mocking**: MSW intercepts HTTP requests at the network level, providing realistic API mocking without modifying application code. Request handlers defined in `test/mocks/handlers.ts` specify responses for API endpoints:

```typescript
// Example MSW handler structure
export const handlers = [
  rest.get('/api/documents', (req, res, ctx) => {
    return res(ctx.json({ documents: mockDocuments }))
  }),
  rest.post('/api/auth/login', async (req, res, ctx) => {
    const { email, password } = await req.json()
    // Return success or error based on test scenario
  })
]
```

**Test Server Setup**: The `test/setup.ts` file initializes MSW server with `beforeAll`, `afterEach`, and `afterAll` hooks, ensuring consistent mock state across all tests and automatic cleanup between test runs.

### 6.6.3 Integration Testing Strategy

#### 6.6.3.1 Service Integration Testing

**Backend Service Integration**: Integration tests validate interactions between multiple backend components without external service dependencies. These tests use actual Flask application context, real MongoDB connections (test database), and actual Redis instances (test Redis server or docker container) to verify end-to-end request processing.

**Test Scenarios**:
- **Authentication Flow Integration**: Complete OAuth flow from login initiation through Auth0 callback processing to JWT issuance and token storage in Redis
- **Document CRUD Operations**: Create document → store in MongoDB → retrieve from MongoDB → update → delete with proper authorization checks
- **AI Service Integration**: User request → input validation → LangChain service invocation → response processing → persistence with proper error handling

**Integration Test Location**: Tests reside in `backend/tests/integration/` directory, distinguished from unit tests by their use of actual service instances rather than mocks for internal components.

#### 6.6.3.2 API Testing Strategy

**API Contract Testing**: Validate that REST API endpoints conform to documented contracts including request/response schemas, HTTP status codes, error payloads, and header requirements. Tests verify:
- **Request Validation**: Reject invalid payloads with 400 Bad Request and descriptive error messages
- **Authentication Requirements**: Enforce JWT token presence and validity, returning 401 Unauthorized for missing/invalid tokens
- **Authorization Enforcement**: Verify resource ownership and permissions, returning 403 Forbidden for insufficient privileges
- **Response Format**: Ensure consistent JSON structure matching API documentation
- **Error Handling**: Validate error response format, status codes, and error message clarity

**API Performance Testing**: Integration tests include performance assertions ensuring response times meet targets defined in Section 5.4.5:
- Simple CRUD operations (GET, POST): p95 < 300ms
- Complex queries with aggregations: p95 < 800ms
- AI completion requests: p95 < 5000ms

**Test Implementation**: Tests use Flask test client for direct endpoint invocation without HTTP overhead, or requests library for full HTTP stack testing including middleware processing.

#### 6.6.3.3 Database Integration Testing

**MongoDB Integration Tests**: Validate database operations with actual MongoDB instance (test database distinct from development and production databases):

**Schema Validation**: Test MongoDB schema validation rules defined at collection level, ensuring invalid documents are rejected with clear error messages.

**Query Performance**: Verify index effectiveness for common query patterns, ensuring query execution times remain within acceptable bounds.

**Transaction Support**: Test multi-document transactions for operations requiring atomicity (e.g., document creation with associated metadata updates).

**Data Integrity**: Validate referential integrity maintenance through application logic, cascade delete behavior, and orphan prevention.

**Test Database Management**: Integration tests use pytest fixtures with `scope="session"` to create test database once, `scope="function"` to clean collections between tests, and `autouse=True` for automatic setup/teardown without explicit fixture references in test signatures.

#### 6.6.3.4 External Service Mocking

**Auth0 Mocking**: Integration tests mock Auth0 OAuth endpoints using MSW (for HTTP-based mocking) or pytest-mock (for Python SDK mocking). Mock includes:
- OAuth authorization endpoint returning realistic authorization codes
- Token exchange endpoint issuing valid JWT tokens with configurable claims
- User info endpoint providing user profile data
- JWKS (JSON Web Key Set) endpoint for JWT signature verification

**LangChain/LLM Mocking**: AI service integration tests mock LLM API calls to prevent:
- External API costs during testing
- Rate limiting from LLM providers
- Non-deterministic test results from AI model variations
- Dependency on external service availability

Mock implementations provide configurable responses including successful completions, rate limit errors, timeout scenarios, and malformed responses for error handling validation.

**AWS Service Mocking**: Integration tests that touch AWS services (S3 for file uploads, CloudWatch for logging) use the moto library for comprehensive AWS API mocking, providing local implementations of S3 bucket operations, CloudWatch log stream creation, and X-Ray trace segment recording.

#### 6.6.3.5 Test Environment Management

**Local Test Environment**: Docker Compose configuration in the repository root provides isolated test environment with:
- MongoDB 7.0 container with test-specific configuration
- Redis 7 Alpine container for session and cache testing
- Separate containers for backend and frontend when needed

**Automated Cleanup**: Test fixtures ensure environment cleanup between test runs, dropping test databases, flushing Redis databases, and resetting any persistent state. This prevents test interdependencies and ensures consistent test execution regardless of run order.

**Environment Variables**: Test configuration uses separate `.env.test` files with test-specific values (test database URLs, mock service endpoints, debug flags), loaded by pytest-env plugin or test setup code.

### 6.6.4 End-to-End Testing Strategy

#### 6.6.4.1 E2E Test Scenarios

While the current technical specification does not document specific E2E testing frameworks or implementations, the comprehensive monitoring strategy in Section 6.5 includes **CloudWatch Synthetics canaries** that serve as production E2E validation. The planned E2E testing approach should include:

**Critical User Journeys**:
- **Authentication Flow**: User registration → email verification → login → token issuance → authenticated dashboard access
- **Document Management Flow**: Create new document → auto-save draft → edit content → save final version → share with collaborators → retrieve shared document
- **AI Assistance Flow**: Open document editor → request AI completion → receive and insert suggestion → continue editing → save final document
- **Search and Discovery**: Search for documents by keyword → filter by date/type → open document from results → navigate back to search

**Cross-Platform Scenarios**: E2E tests should validate consistent behavior across web (React), mobile (React Native iOS/Android), and desktop (Electron) platforms, ensuring feature parity and proper data synchronization.

#### 6.6.4.2 UI Automation Approach

**Recommended Framework**: While not currently specified, the system architecture suggests **Playwright** or **Cypress** as suitable E2E testing frameworks for their multi-browser support, automatic waiting mechanisms, and rich debugging capabilities.

**Test Organization**: E2E tests should reside in dedicated `e2e/` directory at repository root, separate from unit and integration tests due to different execution requirements (longer runtime, external service dependencies, browser automation overhead).

**Page Object Model**: Tests should implement Page Object Model pattern, encapsulating page-specific locators and actions in reusable page classes, reducing test maintenance burden when UI changes.

#### 6.6.4.3 Test Data Setup and Teardown

**Database Seeding**: E2E tests require realistic test data including user accounts, sample documents, and reference data. Setup scripts should seed test database before E2E suite execution, creating consistent initial state.

**Idempotent Tests**: Each E2E test should create its own isolated test data (unique user accounts, uniquely named documents) to prevent conflicts with parallel test execution and enable test independence.

**Cleanup Strategy**: Post-test cleanup should remove E2E-created data, although this may be less critical in non-production test environments. Alternatively, test environment refresh between E2E runs provides clean slate.

#### 6.6.4.4 Cross-Browser and Cross-Platform Testing

**Browser Matrix**: E2E tests should validate functionality across:
- Chrome (latest stable)
- Firefox (latest stable)
- Safari (latest stable, macOS/iOS)
- Edge (latest stable)

**Mobile Testing**: React Native mobile applications require device-specific E2E testing:
- **iOS**: XCUITest framework for native E2E testing
- **Android**: Espresso or UIAutomator for native E2E testing
- **Cross-platform**: Detox framework for React Native-specific E2E testing across both platforms

**Desktop Testing**: Electron desktop application should include platform-specific E2E tests on macOS, Windows, and Linux, validating platform-specific features (notifications, system tray, file system integration).

### 6.6.5 Mobile Testing Strategy

#### 6.6.5.1 iOS Testing Approach

**Build Testing**: The iOS CI/CD workflow (Section 4.2.3) focuses on build verification and artifact generation:

**Build Tools and Process**:
- **Xcode Build System**: xcodebuild command-line tool compiles iOS application on macos-latest GitHub Actions runners
- **Dependency Management**: CocoaPods installation (`pod install`) resolves native dependencies before build
- **Build Configuration**: Release configuration build validates production-ready code compilation
- **Code Signing**: Certificate validation ensures proper provisioning profile configuration
- **Artifact Generation**: .ipa file generation for distribution through TestFlight or App Store

**Unit Testing**: iOS native code (Swift/Objective-C bridge modules) should use **XCTest** framework:
- Test files organized in Xcode test targets
- UI component tests using XCUITest
- Network mocking with URLProtocol subclasses
- Asynchronous testing with XCTestExpectation

**Integration Testing**: React Native component integration with native modules requires testing across JavaScript-native bridge, validating proper data marshaling and event handling.

#### 6.6.5.2 Android Testing Approach

**Build Testing**: The Android CI/CD workflow (Section 4.2.3) validates build configuration and artifact generation:

**Build Tools and Process**:
- **Gradle Build System**: `./gradlew assembleRelease` generates APK, `./gradlew bundleRelease` generates AAB for Play Store
- **Build Optimization**: ProGuard/R8 minification and obfuscation testing ensures release builds maintain functionality after code shrinking
- **Multi-Architecture Support**: Build validation across ARM and x86 architectures
- **Build Variants**: Testing across different build flavors (development, staging, production)

**Unit Testing**: Android native code (Kotlin/Java bridge modules) should use **JUnit** with Android testing extensions:
- Robolectric for JVM-based Android testing without emulator
- Mockito for dependency mocking
- AndroidX Test for Android component testing

**Instrumentation Testing**: On-device or emulator testing with **Espresso** for UI validation:
- Fragment and Activity lifecycle testing
- User interaction simulation
- Intent verification for inter-component communication

#### 6.6.5.3 React Native Testing

**JavaScript Layer Testing**: Jest with React Native Testing Library for component testing:
- Mock native modules for isolation
- Snapshot testing for UI consistency
- Hook testing with @testing-library/react-hooks

**Cross-Platform Testing**: Validate consistent behavior between iOS and Android implementations, testing platform-specific code paths and conditional rendering.

### 6.6.6 Infrastructure Testing Strategy

#### 6.6.6.1 Terraform Testing Approach

The infrastructure CI/CD workflow (Section 4.2.4) implements a **four-stage validation pipeline** for Terraform infrastructure code:

#### Stage 1: Format Validation

**Command**: `terraform fmt -check -recursive terraform/`

**Purpose**: Enforce consistent Terraform code formatting across all modules and environments, preventing formatting inconsistencies that impede code reviews.

**Failure Impact**: Pipeline fails if any `.tf` files deviate from canonical formatting, requiring developers to run `terraform fmt` locally before pushing.

#### Stage 2: Initialization

**Command**: `terraform init`

**Purpose**: Download required provider plugins (AWS provider, etc.) and configure S3 backend for remote state storage with DynamoDB locking.

**Validation**: Ensures provider version constraints are satisfiable, backend configuration is valid, and state locking mechanism is accessible.

#### Stage 3: Syntax and Semantic Validation

**Command**: `terraform validate`

**Purpose**: Validate Terraform configuration syntax and semantic correctness including:
- HCL syntax correctness
- Resource attribute validity
- Required argument presence
- Type constraint satisfaction
- Module input/output compatibility

**Failure Impact**: Pipeline fails on any configuration errors, preventing invalid infrastructure code from reaching plan/apply stages.

#### Stage 4: Plan Generation and Review

**Command**: `terraform plan`

**Purpose**: Generate execution plan showing infrastructure changes (resources to create, update, or destroy) without applying changes.

**Review Process**: Plan output posted as pull request comment enables team review of infrastructure changes before merge, providing visibility into resource modifications, cost implications, and potential risks.

**Artifact Preservation**: Plan saved as artifact for subsequent apply stage, ensuring applied changes match reviewed plan.

#### 6.6.6.2 Infrastructure Testing Gaps

**Current Limitations**: The existing infrastructure testing strategy focuses on static analysis and plan validation but lacks:

**Compliance Testing**: Tools like Checkov or tfsec for detecting security misconfigurations, policy violations, and compliance issues in Terraform code.

**Cost Estimation**: Infracost integration for pull request cost impact analysis, enabling cost-aware infrastructure decisions.

**Post-Apply Validation**: Tests validating actual infrastructure state matches expected configuration after `terraform apply`, potentially using Terratest or AWS SDK-based validation scripts.

**Drift Detection**: Scheduled runs detecting configuration drift between Terraform state and actual AWS resource configuration.

### 6.6.7 Test Automation

#### 6.6.7.1 CI/CD Integration

**Comprehensive Pipeline Integration**: Testing is deeply integrated into CI/CD workflows across all application components, with automated execution on every code push and pull request.

#### Backend Test Automation

**Trigger Conditions**:
- Push to `main` or `develop` branches affecting `backend/**` paths
- Pull requests to `main` affecting `backend/**` paths

**Automated Stages**:
1. Python environment setup (Python 3.11)
2. Dependency installation from `requirements.txt` and `requirements-dev.txt`
3. Code quality validation (Black, Flake8, mypy)
4. Test suite execution with coverage
5. Coverage report upload to Codecov

**Deployment Gating**: Production deployment to ECS only proceeds after successful test completion, enforcing quality gate before code reaches production.

#### Frontend Test Automation

**Trigger Conditions**:
- Push to `main` or `develop` branches affecting `frontend/**` paths
- Pull requests to `main` affecting `frontend/**` paths

**Automated Stages**:
1. Node.js 18 LTS environment setup
2. npm dependency installation with caching
3. Parallel code quality checks (ESLint, Prettier, TypeScript)
4. Jest/Vitest test suite execution
5. Production build verification

**Build Verification**: Tests run before build stage, but build success is also required before deployment, providing two-tier validation.

#### Mobile Test Automation

**iOS Pipeline**:
- Runs on macos-latest for Xcode availability
- Installs Node.js dependencies and CocoaPods dependencies
- Executes Xcode build with Release configuration
- Stores .ipa artifacts with 90-day retention

**Android Pipeline**:
- Runs on ubuntu-latest with JDK 17
- Installs Node.js dependencies and Android SDK components
- Executes Gradle build generating APK/AAB artifacts
- Validates ProGuard/R8 obfuscation doesn't break functionality

#### Infrastructure Test Automation

**Trigger Conditions**:
- Push to `main` affecting `terraform/**` paths
- Pull requests to `main` affecting `terraform/**` paths

**Automated Stages**:
1. Terraform setup (version 1.6+)
2. Format check validation
3. Terraform init with S3 backend
4. Terraform validate for syntax/semantic checks
5. Terraform plan with output preservation
6. Plan output posted as PR comment for review
7. Terraform apply on `main` branch push (post-merge)

#### 6.6.7.2 Automated Test Triggers

**Primary Triggers**:

| Trigger Type | Branches | Path Filters | Automated Actions |
|-------------|----------|--------------|-------------------|
| Push | main, develop | backend/** | Backend CI/CD pipeline |
| Push | main, develop | frontend/** | Frontend CI/CD pipeline |
| Push | main | mobile/** | iOS and Android builds |
| Push | main | terraform/** | Infrastructure validation and apply |
| Pull Request | main | All paths | Full CI/CD without deployment |

**Manual Triggers**: GitHub Actions workflow_dispatch events enable on-demand test execution for specific scenarios (regression testing, performance baseline establishment, pre-release validation).

**Scheduled Triggers**: Recommended addition of nightly builds running complete test suites including longer-running integration tests, E2E tests, and performance tests not included in standard pull request workflows.

#### 6.6.7.3 Parallel Test Execution

**Frontend Parallel Execution**: Jest and Vitest support parallel test execution by default, running test files concurrently across multiple worker processes based on available CPU cores.

**Backend Parallel Execution**: pytest-xdist plugin (when added) enables parallel test execution with `-n auto` flag, automatically detecting CPU core count and distributing tests across workers.

**GitHub Actions Matrix Builds**: Workflows can use matrix strategy to test across multiple Python versions (3.11, 3.12), Node.js versions (18, 20), or platforms (ubuntu, macos, windows) simultaneously.

**Parallel Stage Execution**: CI/CD workflows can parallelize independent stages (linting, type checking, testing) using GitHub Actions job dependencies and parallel job execution.

#### 6.6.7.4 Test Reporting Requirements

**Coverage Reporting**:
- **Backend**: XML coverage reports uploaded to Codecov for historical tracking, pull request comments showing coverage delta
- **Frontend**: HTML coverage reports generated in `coverage/` directory, JSON reports for programmatic analysis
- **Visualization**: Codecov dashboard provides coverage trends, file-level coverage breakdown, and coverage sunburst diagrams

**Test Result Reporting**:
- **JUnit XML Format**: pytest and Jest generate JUnit-compatible XML for test result parsing by external tools
- **GitHub Actions Annotations**: Test failures appear as annotations on pull request files at failure line numbers
- **Summary Tables**: GitHub Actions summary page displays test execution statistics (passed/failed/skipped counts, execution time)

**Recommended Additions**:
- **Test Analytics Platform**: Integration with tools like Datadog CI Visibility or BuildPulse for test performance trends, flaky test detection, and test suite optimization recommendations
- **Performance Benchmarking**: Automated performance regression detection comparing test execution times across commits
- **Visual Regression Testing**: Screenshot comparison tools like Percy or Chromatic for UI consistency validation

#### 6.6.7.5 Failed Test Handling

**Pipeline Failure**: Any test failure causes immediate CI/CD pipeline failure, preventing merge (for pull requests) or deployment (for direct pushes).

**Failure Visibility**:
- GitHub Actions UI displays failed test details including test name, failure reason, and assertion mismatch
- Pull request checks show failing tests with expandable details
- Email notifications sent to commit authors on test failures (configurable in GitHub Actions)

**Developer Workflow**:
1. Test failure notification received
2. Review failure details in GitHub Actions logs
3. Reproduce failure locally using same test command
4. Fix failing code or test
5. Push fix, triggering automatic pipeline re-run
6. Merge only after all tests pass

**Recommended Practices**:
- **Local Testing**: Developers should run tests locally before pushing using pre-commit hooks
- **Fast Feedback**: Unit tests should execute quickly (< 5 minutes) to enable rapid iteration
- **Clear Failure Messages**: Tests should provide descriptive assertion messages indicating expected vs actual values

#### 6.6.7.6 Flaky Test Management

**Current Status**: The technical specification does not document explicit flaky test management strategies. This represents a gap that should be addressed as testing implementation progresses.

**Recommended Strategies**:

**Flaky Test Detection**: Track test results over multiple runs to identify tests with inconsistent pass/fail behavior. Tools like BuildPulse or Datadog CI Visibility automatically flag flaky tests.

**Quarantine Mechanism**: Temporarily disable identified flaky tests using pytest markers (`@pytest.mark.flaky`) or Jest test skipping, preventing CI/CD disruption while maintaining flaky test visibility.

**Root Cause Analysis**: Common flaky test causes include:
- Race conditions from asynchronous operations without proper waiting
- Test interdependencies causing pass/fail based on execution order
- External service timeouts or unavailability
- Time-based assertions sensitive to execution environment performance
- Insufficient test data cleanup causing state pollution

**Flaky Test Resolution**: Implement test retries with pytest-rerunfailures or Jest --maxRetries for genuinely transient failures, but prioritize fixing root causes over masking flakiness with retries.

### 6.6.8 Performance Testing Strategy

#### 6.6.8.1 Performance Test Requirements

The system architecture defines **specific performance targets** (Section 5.4.5) that guide performance testing requirements:

#### API Response Time Targets

| Endpoint Category | p50 Target | p95 Target | p99 Target | Test Approach |
|------------------|------------|------------|------------|---------------|
| Simple CRUD | < 100ms | < 300ms | < 500ms | Load testing with realistic payloads |
| Complex Queries | < 300ms | < 800ms | < 1200ms | Database query optimization validation |
| AI Completions (Simple) | < 2000ms | < 5000ms | < 8000ms | LLM mock response time simulation |
| AI Conversations (Multi-turn) | < 3000ms | < 6000ms | < 10000ms | Context-aware completion testing |
| File Upload (Presigned URL) | < 500ms | < 1500ms | < 3000ms | S3 presigned URL generation testing |

#### Availability and Reliability Targets

| Component | SLA Target | Monthly Downtime Allowance | Testing Focus |
|-----------|-----------|---------------------------|---------------|
| Overall Application | 99.9% | 43.2 minutes | End-to-end availability monitoring |
| Flask API | 99.95% | 21.6 minutes | Health check responsiveness |
| MongoDB | 99.95% | 21.6 minutes | Replica set failover testing |

**Performance Test Types**:

**Load Testing**: Validate system performance under expected load conditions, simulating typical user concurrency and request rates. Verify response times remain within p95 targets under normal load.

**Stress Testing**: Determine system breaking points by gradually increasing load beyond normal capacity, identifying maximum sustainable throughput and degradation patterns.

**Spike Testing**: Validate system behavior under sudden traffic spikes (e.g., viral content, marketing campaigns), testing auto-scaling responsiveness and rate limiting effectiveness.

**Endurance Testing**: Run sustained load over extended periods (hours or days) to detect memory leaks, connection pool exhaustion, or other resource degradation issues.

#### 6.6.8.2 Load Testing Approach

**Recommended Tools**: While not currently specified, the architecture suggests **k6** or **Apache JMeter** as suitable load testing tools for their scripting capabilities, distributed execution support, and comprehensive metrics.

**Test Scenarios**:

**Authentication Load**: Simulate concurrent login attempts, JWT validation requests, and token refresh operations to validate Auth0 integration performance and circuit breaker behavior under load.

**CRUD Operations Load**: Generate mixed read/write workloads against document management APIs, testing MongoDB query performance, connection pool sizing, and index effectiveness.

**AI Service Load**: Test AI completion endpoints with realistic prompt complexity and context sizes, validating rate limiting, circuit breaker operation, and queue management under high demand.

**Test Environment**: Performance tests should run against staging environment with production-equivalent infrastructure (same ECS task sizes, database instance types, Redis configuration) to ensure realistic results.

**Test Data**: Performance tests require substantial test data volumes (thousands of documents, hundreds of user accounts) to realistically stress database query performance and caching effectiveness.

#### 6.6.8.3 Performance Monitoring and Regression Detection

**Synthetic Monitoring**: CloudWatch Synthetics canaries (Section 6.5) provide continuous production performance validation:

**Health Check Canary**: Every 5 minutes, validates `/health` endpoint availability and response time, alerting on availability < 99.9% or response time > threshold.

**Authentication Flow Canary**: Every 15 minutes, executes complete OAuth flow from authorization through token exchange, validating end-to-end authentication latency.

**End-to-End Journey Canary**: Every 30 minutes, performs create → retrieve → delete document flow, validating complete user journey performance including database operations and API processing.

**Performance Alerting**: CloudWatch Alarms (Section 6.5) trigger on performance degradation:

| Alarm | Metric | Threshold | Action |
|-------|--------|-----------|--------|
| API Latency Spike | `api.request.duration` (p95) | > 1000ms for 5 minutes | Email engineering team |
| High Error Rate | `api.error.rate` | > 5% for 5 minutes | PagerDuty alert + email |
| ECS CPU High | ECS CPUUtilization | > 80% for 10 minutes | Auto-scale + operations email |

**Performance Regression Prevention**: Recommended integration of performance testing into CI/CD with baseline comparison, failing builds when response times regress beyond acceptable thresholds (e.g., 10% degradation).

### 6.6.9 Security Testing Strategy

#### 6.6.9.1 Security Test Scenarios

The comprehensive security architecture (Section 6.4) defines multiple security controls requiring validation through testing:

#### Authentication and Authorization Testing

**JWT Validation Testing**:
- **Expired Token Rejection**: Submit requests with expired JWT tokens, expecting 401 Unauthorized responses
- **Invalid Signature Rejection**: Submit tokens with tampered signatures, expecting 401 Unauthorized responses
- **Missing Claims Validation**: Submit tokens missing required claims (user_id, permissions), expecting 401 Unauthorized responses
- **Malformed Token Handling**: Submit non-JWT tokens or malformed JWT structures, expecting graceful error handling

**Permission-Based Access Control (PBAC) Testing**:
- **Insufficient Permissions**: Attempt operations without required permissions, expecting 403 Forbidden responses
- **Resource Ownership Validation**: Attempt access to other users' documents, expecting 403 Forbidden responses
- **Permission Escalation Prevention**: Attempt to manipulate permission claims, expecting rejection

#### Rate Limiting and Circuit Breaker Testing

**Rate Limit Enforcement**:
- **Threshold Validation**: Send > 100 requests/minute from single IP, expecting 429 Too Many Requests after threshold
- **Sliding Window Validation**: Verify rate limit counter resets properly after time window
- **Distributed Rate Limiting**: Test rate limit consistency across multiple ECS tasks using Redis-backed token bucket

**Circuit Breaker Testing**:
- **CLOSED → OPEN Transition**: Simulate Auth0 failures (> 5 failures in 60 seconds), verify circuit opens and subsequent requests fail fast
- **OPEN → HALF-OPEN Transition**: After 30-second timeout, verify circuit enters half-open state allowing test request
- **HALF-OPEN → CLOSED Transition**: Verify successful test request closes circuit, restoring normal operation

#### Input Validation and Injection Prevention

**SQL/NoSQL Injection Testing**: Submit malicious payloads attempting MongoDB injection attacks, expecting Pydantic validation rejection or safe query sanitization.

**Cross-Site Scripting (XSS) Prevention**: Submit HTML/JavaScript payloads in document content, expecting proper output encoding preventing script execution in browser.

**Command Injection Prevention**: Test file upload paths and system command inputs for injection vulnerabilities, expecting input sanitization preventing command execution.

#### 6.6.9.2 Security Testing Tools and Approaches

**Recommended Additions**: The current specification lacks explicit security testing tool integration. Recommended additions include:

**Static Application Security Testing (SAST)**:
- **Bandit**: Python security linter detecting common security issues in backend code
- **ESLint Security Plugin**: JavaScript/TypeScript security rule validation
- **Semgrep**: Multi-language pattern-based security scanning

**Dynamic Application Security Testing (DAST)**:
- **OWASP ZAP**: Automated web application security scanner
- **Burp Suite**: Manual security testing and vulnerability discovery

**Dependency Scanning**:
- **Snyk**: Vulnerability scanning for Python and npm dependencies
- **GitHub Dependabot**: Automated pull requests for dependency security updates
- **npm audit / pip-audit**: Built-in dependency vulnerability scanning

**Secrets Scanning**:
- **GitGuardian** or **TruffleHog**: Scan commits for accidentally committed secrets
- **GitHub Secret Scanning**: Automatic detection of common secret patterns in commits

#### 6.6.9.3 Compliance and Audit Testing

**Encryption Validation**:
- **TLS Configuration Testing**: Validate TLS 1.3 enforcement, certificate validity, and cipher suite security
- **Encryption at Rest**: Verify MongoDB encryption at rest using AES-256 encryption keys
- **Key Rotation**: Test key rotation procedures for encryption keys without data loss

**Audit Logging Validation**: Test comprehensive audit trail generation for security-relevant events:
- Authentication attempts (successful and failed)
- Authorization failures (permission denied events)
- Data access and modification events
- Administrative actions
- Security configuration changes

**Audit Log Integrity**: Verify audit logs are immutable, tamper-evident, and properly protected from unauthorized access.

### 6.6.10 Quality Metrics and Gates

#### 6.6.10.1 Code Coverage Targets

**Backend Coverage Target**: **80% minimum code coverage** for Python backend services, measured by line coverage across all modules in `backend/` directory.

**Frontend Coverage Target**: While not explicitly specified, industry best practices suggest **70-80% code coverage** for React applications, focusing on component logic and utility functions while excluding trivial UI components.

**Coverage Reporting**: Coverage trends tracked over time using Codecov integration, with pull request comments displaying coverage impact of proposed changes. Coverage decreases trigger review discussions but don't automatically block merges, balancing coverage goals with practical development needs.

**Coverage Exclusions**: Standard exclusions include:
- Test files themselves (`test_*.py`, `*.test.ts`)
- Configuration files (`config.py`, `settings.ts`)
- Migration scripts
- Explicit `# pragma: no cover` annotations for unreachable defensive code

#### 6.6.10.2 Test Success Rate Requirements

**Zero-Tolerance for Failing Tests**: CI/CD pipelines enforce **100% test pass rate** before merge/deployment. No failing tests are acceptable in protected branches (`main`, `develop`).

**Flaky Test Tolerance**: While zero failing tests is required, flaky tests (inconsistent pass/fail) should be identified and quarantined rather than left to disrupt CI/CD. Target **< 1% flakiness rate** across test suite.

**Test Suite Performance**: Unit test suites should complete within **5 minutes** for rapid feedback. Integration tests may run longer but should complete within **15 minutes** to maintain developer productivity.

#### 6.6.10.3 Quality Gates

**Pre-Merge Quality Gates** (enforced on pull requests):

| Gate | Requirement | Enforcement |
|------|-------------|-------------|
| All Tests Pass | 100% pass rate | GitHub required check |
| Code Coverage | No coverage decrease > 1% | Codecov comment review |
| Code Quality | Zero linting/formatting errors | GitHub required check |
| Type Safety | Zero TypeScript/mypy errors | GitHub required check |
| Build Success | Successful production build | GitHub required check |
| Security Scan | No high-severity vulnerabilities | Recommended addition |

**Pre-Deployment Quality Gates** (enforced before production deployment):

| Gate | Requirement | Enforcement |
|------|-------------|-------------|
| Integration Tests | 100% pass rate | CI/CD pipeline check |
| Performance Tests | Response times within targets | Recommended addition |
| Security Scan | No critical vulnerabilities | Recommended addition |
| Smoke Tests | Core functionality validated | Synthetic canary checks |

**Post-Deployment Quality Gates** (monitoring production quality):

| Metric | Target | Alert Threshold | Action |
|--------|--------|----------------|--------|
| Error Rate | < 1% | > 5% for 5 minutes | PagerDuty + email |
| API Latency (p95) | < 1000ms | > 1000ms for 5 minutes | Email engineering |
| Availability | > 99.9% | < 99.9% in rolling hour | PagerDuty + email |
| Canary Success Rate | 100% | Any failure | Email operations |

#### 6.6.10.4 Documentation Requirements

**Test Documentation Standards**:

**Test Case Documentation**: Complex test scenarios should include docstrings explaining:
- What behavior is being tested
- Why this test is important (business/technical context)
- How to reproduce the scenario manually (for E2E tests)
- Expected outcomes and assertion rationale

**Test Coverage Documentation**: README files in test directories should document:
- Test organization structure
- How to run tests locally
- How to run specific test subsets (unit only, integration only)
- Common test failures and troubleshooting
- Test data management procedures

**CI/CD Pipeline Documentation**: Workflow files should include comments explaining:
- Pipeline stage purposes
- Environment variable requirements
- Deployment approval processes
- Rollback procedures

### 6.6.11 Test Environment Architecture

#### 6.6.11.1 Development Environment Testing

**Local Development Setup**: Developers run tests on local workstations using Docker Compose for service orchestration:

**Local Test Infrastructure**:
- **MongoDB Container**: mongo:7.0 image provides isolated test database, reset between test runs
- **Redis Container**: redis:7-alpine image provides session storage and cache testing
- **Mock External Services**: MSW (frontend) and pytest-mock (backend) provide Auth0, LangChain, and AWS service mocks

**Local Test Execution**:
- **Backend**: `pytest backend/tests/` runs complete test suite with local service dependencies
- **Frontend**: `npm run test` executes Jest/Vitest with MSW-mocked APIs
- **Fast Feedback**: Local tests run in seconds (unit tests) to minutes (integration tests) for rapid iteration

**Pre-Commit Validation**: Recommended integration of pre-commit hooks running:
- Code formatting (Black, Prettier)
- Linting (Flake8, ESLint)
- Type checking (mypy, tsc)
- Fast unit tests
Preventing low-quality code from reaching CI/CD pipelines.

#### 6.6.11.2 Staging Environment Testing

**Staging Environment Purpose**: Production-equivalent environment for pre-release validation with realistic infrastructure configuration.

**Staging Infrastructure** (from Section 5.1):
- **Automatic Deployment**: Push to `staging` branch triggers automatic deployment
- **Isolated Resources**: Separate AWS resources (VPC, ECS cluster, RDS/MongoDB instance, S3 buckets) prevent staging-production interference
- **Production Parity**: Same instance types, auto-scaling configuration, and network topology as production
- **Test Data**: Staging database seeded with realistic but non-production data for manual and automated testing

**Staging Test Execution**:
- **Automated Smoke Tests**: Post-deployment smoke tests validate core functionality
- **Manual QA Testing**: QA team performs exploratory testing and user acceptance testing
- **Integration Testing**: Cross-service integration tests run against actual AWS services
- **Performance Testing**: Load tests validate performance with production-like infrastructure

**Staging Limitations**: While production-parity, staging may use smaller instance sizes or reduced replica counts for cost optimization, potentially masking performance issues only visible at production scale.

#### 6.6.11.3 Production Testing and Monitoring

**Production Testing Philosophy**: Production is not a test environment, but continuous monitoring provides ongoing validation of production quality.

**Synthetic Monitoring** (Section 6.5): CloudWatch Synthetics canaries provide automated production testing:

**Health Check Canary** (every 5 minutes):
```javascript
// Simplified canary script structure
const synthetics = require('Synthetics');
const https = require('https');

const healthCheck = async function () {
  const startTime = Date.now();
  const response = await https.get('https://api.example.com/health');
  const latency = Date.now() - startTime;
  
  if (response.statusCode !== 200) {
    throw new Error(`Health check failed: ${response.statusCode}`);
  }
  
  if (latency > 500) {
    throw new Error(`Health check too slow: ${latency}ms`);
  }
};

exports.handler = async () => {
  return await synthetics.executeStep('healthCheck', healthCheck);
};
```

**Authentication Flow Canary** (every 15 minutes): Complete OAuth flow from authorization through JWT token issuance, validating end-to-end authentication functionality.

**End-to-End Journey Canary** (every 30 minutes): Document creation → retrieval → deletion flow, validating complete application functionality including database operations, API processing, and authentication/authorization.

**Real User Monitoring (RUM)**: Frontend applications should integrate RUM solutions (AWS CloudWatch RUM or third-party tools like Datadog RUM) to collect real user performance data, error tracking, and usage analytics.

#### 6.6.11.4 Test Environment Architecture Diagram

```mermaid
graph TB
    subgraph "Development Environment"
        DEV[Developer Workstation]
        LOCAL_DB[(MongoDB Container)]
        LOCAL_REDIS[(Redis Container)]
        LOCAL_MOCK[MSW/pytest-mock<br/>External Service Mocks]
        
        DEV --> LOCAL_DB
        DEV --> LOCAL_REDIS
        DEV --> LOCAL_MOCK
    end
    
    subgraph "CI/CD Test Environment - GitHub Actions"
        CI[GitHub Actions Runner]
        CI_DB[(Test MongoDB)]
        CI_REDIS[(Test Redis)]
        CI_MOCK[Mocked Services]
        
        CI --> CI_DB
        CI --> CI_REDIS
        CI --> CI_MOCK
    end
    
    subgraph "Staging Environment - AWS"
        STAGE_ALB[ALB]
        STAGE_ECS[ECS Fargate Tasks]
        STAGE_DB[(MongoDB/Atlas)]
        STAGE_REDIS[(ElastiCache Redis)]
        STAGE_AUTH[Auth0<br/>Staging Tenant]
        STAGE_S3[(S3 Staging Bucket)]
        
        STAGE_ALB --> STAGE_ECS
        STAGE_ECS --> STAGE_DB
        STAGE_ECS --> STAGE_REDIS
        STAGE_ECS --> STAGE_AUTH
        STAGE_ECS --> STAGE_S3
    end
    
    subgraph "Production Environment - AWS"
        PROD_ALB[ALB]
        PROD_ECS[ECS Fargate Tasks]
        PROD_DB[(MongoDB/Atlas<br/>Replica Set)]
        PROD_REDIS[(ElastiCache Redis<br/>Cluster)]
        PROD_AUTH[Auth0<br/>Production Tenant]
        PROD_S3[(S3 Production Bucket)]
        CANARY[CloudWatch Synthetics<br/>Canaries]
        
        PROD_ALB --> PROD_ECS
        PROD_ECS --> PROD_DB
        PROD_ECS --> PROD_REDIS
        PROD_ECS --> PROD_AUTH
        PROD_ECS --> PROD_S3
        CANARY -.monitors.-> PROD_ALB
    end
    
    DEV -->|git push| CI
    CI -->|deploy on success| STAGE_ECS
    STAGE_ECS -->|manual approval| PROD_ECS
    
    style DEV fill:#e1f5ff
    style CI fill:#fff4e1
    style STAGE_ECS fill:#f0e1ff
    style PROD_ECS fill:#e1ffe1
    style CANARY fill:#ffe1e1
```

### 6.6.12 Test Data Management

#### 6.6.12.1 Test Data Strategy

**Test Data Categories**:

**Static Test Data**: Fixed, well-known test data used across multiple tests for consistency. Examples include:
- Sample user profiles with known attributes
- Reference documents with predictable content
- Configuration objects for common scenarios
- Mock API responses stored in fixture files

**Dynamic Test Data**: Generated programmatically for each test run to ensure uniqueness and prevent conflicts:
- Unique user email addresses (`test_user_${timestamp}@example.com`)
- Uniquely named documents preventing name collisions
- Random but realistic content using faker libraries
- Time-stamped resources enabling parallel test execution

**Anonymized Production Data**: For staging environment validation, production data anonymized with PII (Personally Identifiable Information) removed or replaced with synthetic data.

#### 6.6.12.2 Data Seeding and Teardown

**Unit Test Data Management**:
- **In-Memory Data**: Unit tests use in-memory data structures, avoiding database dependencies
- **Test Fixtures**: pytest fixtures with `scope="function"` create fresh test data for each test, automatically cleaned up after test completion
- **Database Mocking**: mongomock and fakeredis provide in-memory database implementations, reset automatically between tests

**Integration Test Data Management**:
- **Database Seeding**: pytest fixtures with `scope="session"` create test database once, with `scope="function"` fixtures cleaning collections between tests
- **Transactional Rollback**: For databases supporting transactions, wrap each test in transaction rolled back after test completion
- **Explicit Cleanup**: `yield` fixtures in pytest enable setup before test, cleanup after test using try-finally pattern

**E2E Test Data Management**:
- **Pre-Test Seeding**: Seed staging database with comprehensive test dataset before E2E suite execution
- **Idempotent Tests**: Each E2E test creates its own unique test data (unique usernames, document titles) preventing conflicts
- **Post-Test Cleanup**: Optional cleanup of E2E-created data, although full database refresh between test runs may be more practical

**Test Data Version Control**: Large fixture files (mock API responses, sample documents) stored in `tests/fixtures/` directory under version control, ensuring consistent test behavior across environments and over time.

### 6.6.13 Test Execution Flow

```mermaid
flowchart TD
    START([Developer Commits Code]) --> PUSH[git push to GitHub]
    PUSH --> TRIGGER{Which Files<br/>Changed?}
    
    TRIGGER -->|backend/**| BACKEND_PIPELINE
    TRIGGER -->|frontend/**| FRONTEND_PIPELINE
    TRIGGER -->|mobile/**| MOBILE_PIPELINE
    TRIGGER -->|terraform/**| INFRA_PIPELINE
    
    subgraph BACKEND_PIPELINE["Backend Test Pipeline"]
        B1[Setup Python 3.11] --> B2[Install Dependencies]
        B2 --> B3[Code Quality Checks]
        B3 --> B4{Quality<br/>Pass?}
        B4 -->|No| FAIL1[❌ Pipeline Fails]
        B4 -->|Yes| B5[Run pytest Suite]
        B5 --> B6{Tests<br/>Pass?}
        B6 -->|No| FAIL2[❌ Pipeline Fails]
        B6 -->|Yes| B7[Generate Coverage]
        B7 --> B8[Upload to Codecov]
        B8 --> B9{On main<br/>branch?}
        B9 -->|Yes| B10[Build Docker Image]
        B10 --> B11[Push to ECR]
        B11 --> B12[Deploy to ECS]
        B9 -->|No| SUCCESS1[✅ Tests Passed]
    end
    
    subgraph FRONTEND_PIPELINE["Frontend Test Pipeline"]
        F1[Setup Node.js 18] --> F2[Install Dependencies]
        F2 --> F3[Parallel Quality Checks]
        F3 --> F4{Quality<br/>Pass?}
        F4 -->|No| FAIL3[❌ Pipeline Fails]
        F4 -->|Yes| F5[Run Jest/Vitest]
        F5 --> F6{Tests<br/>Pass?}
        F6 -->|No| FAIL4[❌ Pipeline Fails]
        F6 -->|Yes| F7[Production Build]
        F7 --> F8{Build<br/>Success?}
        F8 -->|No| FAIL5[❌ Pipeline Fails]
        F8 -->|Yes| F9{On main<br/>branch?}
        F9 -->|Yes| F10[Deploy to S3/CloudFront]
        F9 -->|No| SUCCESS2[✅ Tests Passed]
    end
    
    subgraph MOBILE_PIPELINE["Mobile Test Pipeline"]
        M1[Setup Build Environment] --> M2[Install Dependencies]
        M2 --> M3[Platform-Specific Build]
        M3 --> M4{Build<br/>Success?}
        M4 -->|No| FAIL6[❌ Pipeline Fails]
        M4 -->|Yes| M5[Store Artifacts]
        M5 --> SUCCESS3[✅ Build Complete]
    end
    
    subgraph INFRA_PIPELINE["Infrastructure Test Pipeline"]
        I1[Setup Terraform] --> I2[Format Check]
        I2 --> I3{Format<br/>Valid?}
        I3 -->|No| FAIL7[❌ Pipeline Fails]
        I3 -->|Yes| I4[Terraform Init]
        I4 --> I5[Terraform Validate]
        I5 --> I6{Valid<br/>Config?}
        I6 -->|No| FAIL8[❌ Pipeline Fails]
        I6 -->|Yes| I7[Terraform Plan]
        I7 --> I8[Post Plan as PR Comment]
        I8 --> I9{On main<br/>branch?}
        I9 -->|Yes| I10[Terraform Apply]
        I9 -->|No| SUCCESS4[✅ Validation Passed]
    end
    
    B12 --> MONITORING[Production Monitoring]
    F10 --> MONITORING
    I10 --> MONITORING
    
    subgraph MONITORING["Continuous Production Testing"]
        C1[Health Check Canary<br/>Every 5 minutes]
        C2[Auth Flow Canary<br/>Every 15 minutes]
        C3[E2E Journey Canary<br/>Every 30 minutes]
        C4{Canary<br/>Pass?}
        C1 --> C4
        C2 --> C4
        C3 --> C4
        C4 -->|No| ALERT[🚨 Alert Operations]
        C4 -->|Yes| C5[✅ Production Healthy]
    end
    
    style START fill:#e1f5ff
    style FAIL1 fill:#ffe1e1
    style FAIL2 fill:#ffe1e1
    style FAIL3 fill:#ffe1e1
    style FAIL4 fill:#ffe1e1
    style FAIL5 fill:#ffe1e1
    style FAIL6 fill:#ffe1e1
    style FAIL7 fill:#ffe1e1
    style FAIL8 fill:#ffe1e1
    style SUCCESS1 fill:#e1ffe1
    style SUCCESS2 fill:#e1ffe1
    style SUCCESS3 fill:#e1ffe1
    style SUCCESS4 fill:#e1ffe1
    style ALERT fill:#ffe1e1
    style C5 fill:#e1ffe1
```

### 6.6.14 Test Data Flow Diagram

```mermaid
flowchart LR
    subgraph "Test Data Sources"
        FIXTURES[Static Fixtures<br/>tests/fixtures/]
        FACTORIES[Data Factories<br/>faker, factory_boy]
        MOCKS[Mock Responses<br/>MSW handlers]
        SEEDS[Database Seeds<br/>Staging data]
    end
    
    subgraph "Unit Tests"
        UT_BACKEND[Backend Unit Tests<br/>pytest]
        UT_FRONTEND[Frontend Unit Tests<br/>Jest/Vitest]
        
        FACTORIES --> UT_BACKEND
        FIXTURES --> UT_BACKEND
        MOCKS --> UT_FRONTEND
        FACTORIES --> UT_FRONTEND
    end
    
    subgraph "Integration Tests"
        IT_API[API Integration Tests]
        IT_DB[(Test Database<br/>MongoDB)]
        IT_CACHE[(Test Cache<br/>Redis)]
        
        FACTORIES --> IT_API
        IT_API --> IT_DB
        IT_API --> IT_CACHE
        MOCKS --> IT_API
    end
    
    subgraph "E2E Tests"
        E2E_TESTS[E2E Test Suite]
        E2E_STAGING[(Staging Database)]
        E2E_SERVICES[Staging Services<br/>Auth0, S3]
        
        SEEDS --> E2E_STAGING
        E2E_STAGING --> E2E_TESTS
        E2E_SERVICES --> E2E_TESTS
    end
    
    subgraph "Production Monitoring"
        CANARY[Synthetic Canaries]
        PROD_ENV[(Production<br/>Environment)]
        
        CANARY --> PROD_ENV
        PROD_ENV --> METRICS[CloudWatch Metrics]
    end
    
    UT_BACKEND --> COVERAGE[Coverage Reports<br/>Codecov]
    UT_FRONTEND --> COVERAGE
    IT_API --> COVERAGE
    
    E2E_TESTS --> RESULTS[Test Results<br/>GitHub Actions]
    CANARY --> ALERTS[CloudWatch Alarms]
    
    style FIXTURES fill:#e1f5ff
    style FACTORIES fill:#e1f5ff
    style MOCKS fill:#e1f5ff
    style SEEDS fill:#e1f5ff
    style IT_DB fill:#fff4e1
    style IT_CACHE fill:#fff4e1
    style E2E_STAGING fill:#f0e1ff
    style PROD_ENV fill:#e1ffe1
    style COVERAGE fill:#ffe1f5
    style RESULTS fill:#ffe1f5
    style ALERTS fill:#ffe1e1
```

### 6.6.15 References

#### Files Examined

- `README.md` - Project title documentation; repository in pre-implementation phase

#### Folders Explored

- `` (root directory) - Contains only README.md, no source code or test infrastructure implemented

#### Technical Specification Sections Referenced

- **Section 1.2 System Overview** - Project context and implementation status confirmation
- **Section 2.5 Non-Functional Requirements** - Quality standards including performance criteria, security requirements, reliability targets, and maintainability standards
- **Section 3.1 Technology Stack Overview** - Multi-tier architecture (Flask, React, React Native, Electron, MongoDB, Redis, Auth0, LangChain)
- **Section 3.3 Frameworks & Libraries** - Backend frameworks (Flask 3.0+, LangChain 0.1.0+), frontend frameworks (React 18.2+, React Native 0.72+, Electron 28+), UI frameworks (TailwindCSS 3.4+)
- **Section 3.7 Development & Deployment** - Comprehensive testing tools (pytest, pytest-cov, Black, Flake8, mypy, Jest/Vitest, React Testing Library, MSW, ESLint, Prettier), CI/CD implementation with GitHub Actions, Docker containerization, Terraform infrastructure as code
- **Section 4.2 CI/CD Workflows** - Detailed backend testing workflow (Section 4.2.1), frontend testing workflow (Section 4.2.2), mobile build testing (Section 4.2.3), infrastructure validation workflow (Section 4.2.4)
- **Section 5.1 High-Level Architecture** - Cloud-native microservices architecture, API-first design, stateless services, multi-AZ deployment, environment structure (development, staging, production)
- **Section 5.4 Cross-Cutting Concerns** - Performance requirements with specific API response time targets (p50/p95/p99 thresholds), availability targets (99.9% overall, 99.95% API/database), monitoring and observability, error handling patterns
- **Section 6.4 Security Architecture** - Auth0 OAuth 2.0 + OIDC authentication, JWT validation requirements, Permission-Based Access Control (PBAC), circuit breaker patterns, rate limiting (Redis token bucket, 100 req/min), encryption standards (AES-256 at rest, TLS 1.3 in transit), audit logging requirements
- **Section 6.5 Monitoring and Observability** - CloudWatch Logs aggregation, CloudWatch Metrics for performance tracking, AWS X-Ray distributed tracing, CloudWatch Alarms (high error rate, API latency spike, ECS CPU), CloudWatch Synthetics for synthetic monitoring (health check every 5 min, auth flow every 15 min, E2E journey every 30 min)

#### Testing Tools and Frameworks Referenced

| Category | Tool | Purpose |
|----------|------|---------|
| Backend Testing | pytest, pytest-cov, pytest-mock | Python test framework, coverage analysis, mocking |
| Backend Quality | Black, Flake8, mypy | Code formatting, linting, static type checking |
| Frontend Testing | Jest/Vitest, React Testing Library | JavaScript test framework, component testing |
| Frontend Quality | ESLint, Prettier, TypeScript | Linting, formatting, type checking |
| API Mocking | MSW (Mock Service Worker) | Network-level API mocking for frontend |
| Database Mocking | mongomock, fakeredis | In-memory database simulation |
| AWS Mocking | moto | AWS service mocking for integration tests |
| Load Testing | k6, Apache JMeter (recommended) | Performance and load testing |
| Security Testing | Bandit, ESLint Security, Snyk (recommended) | Security scanning and vulnerability detection |
| Mobile Testing | XCTest, Espresso, Detox (recommended) | iOS, Android, and React Native testing |
| E2E Testing | Playwright, Cypress (recommended) | Browser automation and E2E testing |
| Infrastructure Testing | Terraform (fmt, validate, plan) | Infrastructure configuration validation |
| Monitoring | CloudWatch Synthetics | Production synthetic monitoring |
| Coverage Reporting | Codecov | Coverage tracking and trend analysis |

#### Performance Targets Referenced (Section 5.4.5)

- Simple CRUD operations: p95 < 300ms, p99 < 500ms
- Complex queries: p95 < 800ms, p99 < 1200ms
- AI completions: p95 < 5000ms, p99 < 8000ms
- Overall application availability: 99.9% (43.2 min downtime/month)
- Flask API availability: 99.95% (21.6 min downtime/month)

#### Quality Standards Referenced

- Code coverage target: 80% minimum (backend)
- Test pass rate: 100% (zero-tolerance for failing tests)
- Flaky test rate target: < 1%
- Unit test execution time: < 5 minutes
- Integration test execution time: < 15 minutes
- Error rate threshold: < 1% normal, alert at > 5%
- API latency p95 threshold: < 1000ms

## 6.1 Core Services Architecture

### 6.1.1 Architecture Overview and Implementation Status

#### 6.1.1.1 Architectural Approach

The CheckSameRepoNoPrompt system is architected as a **cloud-native, microservices-oriented platform** designed to deliver scalable, resilient AI-powered functionality across multiple client platforms. The architecture embraces modern distributed systems principles while maintaining operational simplicity through strategic use of AWS managed services and a phased implementation approach.

**Implementation Status**: This section documents the **planned architecture** for the CheckSameRepoNoPrompt system. As of the current state, the repository contains only project documentation with no source code implementation. All architectural details, service boundaries, and technical specifications described herein represent the designed target architecture based on comprehensive technical planning.

The architecture adopts a three-tier pattern optimized for cloud-native deployment:

1. **Presentation Layer**: Multi-platform client applications (Web, Mobile, Desktop) providing user interfaces
2. **Application Layer**: RESTful API backend with integrated AI/ML capabilities deployed as containerized services
3. **Data Layer**: Distributed data storage combining document database, in-memory cache, object storage, and vector database

#### 6.1.1.2 Core Architectural Principles

The services architecture is grounded in six fundamental principles that guide all design decisions:

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **Cloud-Native Design** | Leverage AWS managed services (ECS Fargate, ALB, S3, CloudWatch) | Minimize operational overhead, automatic scaling |
| **API-First Philosophy** | Single RESTful API serves all client platforms | Consistent business logic, simplified maintenance |
| **Stateless Services** | No server-side session state, JWT-based authentication | Enable horizontal scaling without session affinity |
| **Managed Service Preference** | Auth0, MongoDB Atlas, ElastiCache managed offerings | Reduce infrastructure complexity, focus on features |
| **Event-Driven Caching** | Multi-layer caching with TTL and event-based invalidation | Optimize performance, reduce costs |
| **Security by Design** | Authentication at every layer, TLS encryption, PBAC authorization | Comprehensive security posture |

### 6.1.2 Service Component Architecture

#### 6.1.2.1 Service Inventory and Boundaries

The system comprises five core service components, each with clearly defined responsibilities and integration points:

**Backend Application Services**:

| Service | Deployment | Primary Responsibility | Technology Stack |
|---------|-----------|----------------------|------------------|
| **Flask REST API** | ECS Fargate Container | Business logic orchestration, API gateway, authentication enforcement | Python 3.11+, Flask 3.0+, Gunicorn, PyMongo, redis-py, Boto3 |
| **LangChain AI/ML Service** | Integrated with Flask (Phase 1), Separate ECS Service (Phase 2) | AI workflow orchestration, LLM interaction, RAG processing | LangChain 0.1.0+, OpenAI SDK, Vector DB integration |

**External Managed Services**:

| Service | Provider | Primary Responsibility | Integration Method |
|---------|----------|----------------------|-------------------|
| **Auth0 Identity Platform** | Auth0 SaaS | User authentication, JWT issuance, MFA, social login | OAuth 2.0/OIDC, HTTPS REST API |
| **MongoDB Database** | MongoDB Atlas (recommended) or Self-Hosted | Primary data persistence, conversation storage, metadata | MongoDB Wire Protocol, PyMongo driver |
| **Redis Cache** | Amazon ElastiCache (recommended) or Self-Hosted | Performance caching, rate limiting, distributed locking | Redis Protocol, redis-py client |
| **Amazon S3 Storage** | AWS S3 | Object storage for files, static assets, backups | S3 API, Boto3 SDK, Presigned URLs |

#### 6.1.2.2 Flask REST API Service (Primary Backend)

**Service Boundaries and Responsibilities**:

The Flask REST API serves as the central orchestration layer, handling all client requests and coordinating between data stores, caching layers, and external services. This service enforces business rules, validates inputs, manages authentication state, and provides a unified interface for all client platforms.

**Core Responsibilities**:
- RESTful endpoint exposure with comprehensive API versioning
- JWT validation and permission-based access control enforcement
- Request schema validation using Pydantic models
- Rate limiting and quota enforcement via Redis
- Database and cache operation coordination
- External service integration (Auth0, AWS services)
- Structured logging and metrics emission for observability
- Error handling with standardized response formats

**API Endpoint Structure**:

| Category | Endpoints | HTTP Methods | Authentication |
|----------|-----------|--------------|----------------|
| Authentication | `/api/v1/auth/refresh`, `/api/v1/auth/logout` | POST | Required (refresh token) |
| User Management | `/api/v1/users/me`, `/api/v1/users/{id}` | GET, PUT, DELETE | Required |
| Documents | `/api/v1/documents`, `/api/v1/documents/{id}` | GET, POST, PUT, DELETE | Required |
| AI Features | `/api/v1/ai/completions`, `/api/v1/ai/conversations`, `/api/v1/ai/search` | POST, GET | Required |
| File Operations | `/api/v1/files/upload-url`, `/api/v1/files/{id}` | POST, GET, DELETE | Required |
| System | `/api/version`, `/health` | GET | Public |

**Middleware Processing Pipeline**:

The Flask API implements a comprehensive middleware stack that processes every request through six distinct layers:

1. **CORS Middleware**: Validates request origin against allowlist, configures appropriate CORS headers
2. **Request ID Middleware**: Generates unique UUID for distributed tracing and log correlation
3. **JWT Validation Middleware**: Extracts and validates JWT token, verifies signature against Auth0 JWKS
4. **Rate Limiting Middleware**: Enforces per-user API quotas using Redis-backed counters
5. **Request Logging Middleware**: Records structured JSON logs with request metadata and timing
6. **Error Handling Middleware**: Catches exceptions and formats standardized error responses

**Scaling Configuration**:
- Horizontal scaling via ECS auto-scaling (target: 70% CPU utilization)
- Minimum instances: 2 (high availability)
- Maximum instances: 10 (cost control)
- Connection pooling: 50 MongoDB connections, 20 Redis connections per instance

#### 6.1.2.3 LangChain AI/ML Service

**Service Boundaries and Responsibilities**:

The LangChain service specializes in orchestrating artificial intelligence and machine learning workflows, providing a layer of abstraction between the core API and various LLM providers. This service manages conversation memory, generates embeddings, executes vector searches, and coordinates Retrieval-Augmented Generation workflows.

**Core Responsibilities**:
- LLM interaction management through LangChain abstractions
- Conversation memory storage and retrieval from MongoDB
- Vector embedding generation for semantic search capabilities
- RAG workflow orchestration with context document retrieval
- Prompt engineering and template management
- AI interaction logging for cost tracking and analytics
- Token usage monitoring and optimization

**AI Capability Matrix**:

| Capability | Chain Type | Input Requirements | Output Format | Use Case |
|-----------|-----------|-------------------|---------------|----------|
| Simple Completions | LLMChain | User prompt, model parameters | Generated text response | Basic text generation |
| Conversational AI | ConversationChain | Message, conversation history | Contextual response | Multi-turn dialogues |
| Semantic Search (RAG) | RetrievalQA | Query, vector store reference | Answer with source citations | Knowledge base queries |
| Document Q&A | QAChain | Document content, question | Extracted answer | Document interrogation |

**Evolution Strategy**:
- **Phase 1** (Initial): Modular monolith with service boundaries within Flask application
- **Phase 2** (Future): Extract to separate ECS service with dedicated resource allocation
- **Phase 3** (If Needed): Additional microservices extraction for specialized AI capabilities

**Scaling Configuration**:
- Initial: Scales with Flask API instances
- Phase 2: Independent horizontal scaling based on AI request volume
- Rate limiting: 10 AI requests per minute per user (cost control)
- Response caching: 1-hour TTL for identical prompts to reduce OpenAI costs

#### 6.1.2.4 Auth0 Identity Platform (External)

**Service Boundaries and Responsibilities**:

Auth0 provides enterprise-grade identity and access management as an external SaaS platform, handling all user authentication workflows, JWT token lifecycle management, and multi-factor authentication enforcement. The system integrates Auth0 across all client platforms using platform-specific SDKs and OAuth 2.0 standards.

**Core Responsibilities**:
- User authentication via multiple methods (credentials, social login, SSO)
- JWT access token and refresh token issuance
- Multi-factor authentication challenge and verification
- User profile management and metadata storage
- Permission-based access control configuration
- Security features (breached password detection, anomaly detection)

**Token Management Strategy**:

| Token Type | Format | Lifetime | Storage Location | Purpose |
|-----------|--------|----------|------------------|---------|
| Access Token | JWT (RS256 signed) | 15 minutes | Memory (web), Keychain/Keystore (mobile) | API authorization |
| Refresh Token | Opaque string | 7 days | Secure storage only | Silent token renewal |
| ID Token | JWT (RS256 signed) | 15 minutes | Memory or secure storage | User profile information |

**Authentication Flow Pattern**:

Auth0 implements the Authorization Code Flow with PKCE (Proof Key for Code Exchange), providing protection against authorization code interception attacks. This flow consists of eight distinct steps from login initiation through token storage.

#### 6.1.2.5 Data Layer Services

**MongoDB (Primary Database)**:

MongoDB serves as the primary persistence layer for all application data, providing flexible document storage with powerful querying and aggregation capabilities.

**Planned Collections**:

| Collection | Purpose | Key Indexes | Estimated Size |
|-----------|---------|-------------|----------------|
| `users` | User profiles and preferences | auth0_id (unique), email | 100KB per user |
| `conversations` | AI conversation metadata | user_id, created_at | 10KB per conversation |
| `messages` | Conversation message history | conversation_id, created_at | 5KB per message |
| `documents` | Document metadata and references | user_id, created_at, full-text | 50KB per document |
| `ai_interactions` | AI usage logging and analytics | user_id, created_at, type | 20KB per interaction |
| `analytics` | System event tracking | event_type, user_id, timestamp | 5KB per event |
| `files` | File metadata and S3 references | file_id, user_id | 2KB per file |

**High Availability Configuration**:
- 3-node replica set architecture (1 Primary + 2 Secondary nodes)
- Automatic failover with secondary promotion within 10 seconds
- Write Concern: majority (wait for acknowledgment from majority of nodes)
- Read Concern: majority for consistency-critical operations
- Read Preference: SecondaryPreferred for read-heavy operations

**Redis (Caching Layer)**:

Redis provides in-memory caching and data structures for performance optimization, rate limiting, and distributed coordination.

**Cache Use Cases**:

| Use Case | Data Structure | Key Pattern | TTL | Purpose |
|----------|---------------|-------------|-----|---------|
| API Response Cache | String (JSON) | `cache:{endpoint}:{user_id}:{hash}` | 5-60 min | Reduce database query load |
| JWKS Cache | String (JSON) | `jwks:auth0` | 1 hour | Optimize JWT validation performance |
| Rate Limiting | String (counter) | `ratelimit:{user_id}:{endpoint}` | 1 minute | Enforce API usage quotas |
| LLM Response Cache | String (JSON) | `llm:{prompt_hash}` | 1 hour | Reduce OpenAI API costs |
| Distributed Lock | String (SET NX) | `lock:{resource_id}` | 30 seconds | Prevent cache stampede |

**Amazon S3 (Object Storage)**:

S3 provides scalable object storage for user-generated content, static assets, and backup archives.

**Bucket Strategy**:

| Bucket | Purpose | Access Pattern | Encryption | Lifecycle |
|--------|---------|---------------|------------|-----------|
| `app-uploads-prod` | User-generated files | Private (presigned URLs) | SSE-S3 | Retain indefinitely |
| `app-static-assets` | Frontend static files | Public via CloudFront | SSE-S3 | Retain indefinitely |
| `app-backups` | Database backups | Private | SSE-KMS | Glacier after 90 days |
| `terraform-state` | IaC state files | Private | SSE-S3 | Versioning enabled |

### 6.1.3 Inter-Service Communication Architecture

#### 6.1.3.1 Communication Patterns and Protocols

The system employs a hybrid communication strategy optimizing for simplicity, performance, and reliability across different interaction types.

**Primary Pattern: Synchronous RESTful HTTP/JSON**

All client-to-server and most internal service communications utilize synchronous HTTP requests with JSON payloads. This pattern provides universal compatibility, leverages standard HTTP caching infrastructure, and enables straightforward error handling.

**Communication Decision Matrix**:

| Interaction Type | Pattern | Protocol | Rationale |
|-----------------|---------|----------|-----------|
| Client to API | Synchronous HTTP | HTTPS + JSON | Real-time feedback required |
| API to MongoDB | Direct Driver | MongoDB Wire Protocol | Low-latency requirement |
| API to Redis | Direct Client | Redis Protocol | Sub-millisecond operations |
| API to S3 | Presigned URLs | HTTPS (direct client upload) | Bypass API for large files |
| API to Auth0 | Synchronous HTTP | HTTPS + OIDC | Token validation workflow |
| API to LangChain | Function Call | Python module import | In-process communication |
| API to OpenAI | Synchronous HTTP | HTTPS + JSON | LLM completion requests |

**Future Asynchronous Communication** (Phase 2):

For long-running operations exceeding acceptable synchronous timeouts, the architecture plans Celery task queue implementation with Redis broker support. Use cases include batch file processing, large report generation, and expensive multi-step AI operations.

#### 6.1.3.2 Request Flow Architecture

**Standard API Request Flow**:

```mermaid
sequenceDiagram
    participant Client
    participant ALB as Application Load Balancer
    participant API as Flask API Service
    participant Redis as Redis Cache
    participant Auth0
    participant MongoDB
    participant CloudWatch as CloudWatch Logs

    Note over Client,CloudWatch: Complete API Request Flow

    Client->>ALB: HTTPS Request<br/>Authorization: Bearer {JWT}
    ALB->>API: Route to healthy ECS task<br/>(TLS terminated)
    
    rect rgb(240, 248, 255)
        Note over API: Middleware Processing Pipeline
        API->>API: 1. CORS Validation
        API->>API: 2. Generate Request ID (UUID)
        
        API->>Redis: 3. Check JWKS cache
        alt JWKS Cached
            Redis-->>API: Cached public keys
        else JWKS Not Cached
            API->>Auth0: Fetch JWKS
            Auth0-->>API: Public keys
            API->>Redis: Cache JWKS (1hr TTL)
        end
        
        API->>API: 4. Verify JWT signature
        API->>API: 5. Validate JWT claims
        
        API->>Redis: 6. Check rate limit
        Redis-->>API: Rate limit status
        
        alt Rate Limit Exceeded
            API-->>Client: 429 Too Many Requests
        end
        
        API->>API: 7. Validate request schema
        API->>API: 8. Check permissions
    end
    
    rect rgb(255, 250, 240)
        Note over API,MongoDB: Business Logic Execution
        API->>Redis: Check response cache
        
        alt Cache Hit
            Redis-->>API: Cached response
            API->>CloudWatch: Log cache hit
        else Cache Miss
            API->>MongoDB: Execute query
            MongoDB-->>API: Query results
            API->>API: Transform data
            API->>Redis: Store in cache (TTL)
            API->>CloudWatch: Log cache miss
        end
    end
    
    API->>CloudWatch: Log request completion
    API-->>ALB: HTTP Response
    ALB-->>Client: Return response
```

**AI/ML Processing Flow**:

For AI-powered features utilizing LangChain and LLM providers, the request flow includes additional steps for embedding generation, vector search, and prompt engineering.

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant Redis as Redis Cache
    participant LangChain
    participant VectorDB as Vector Database
    participant OpenAI as OpenAI API
    participant MongoDB

    Note over Client,MongoDB: RAG-Based Semantic Search Flow

    Client->>API: POST /api/v1/ai/search<br/>{query: "user question"}
    
    rect rgb(240, 248, 255)
        Note over API: Authentication & Validation
        API->>API: Validate JWT + Check permissions
        API->>Redis: Check AI rate limit (10/min)
        Redis-->>API: Rate limit OK
    end
    
    rect rgb(255, 250, 240)
        Note over API,OpenAI: AI Processing Pipeline
        API->>Redis: Check cached RAG response
        Redis-->>API: Cache miss
        
        API->>LangChain: Initiate semantic search
        
        LangChain->>OpenAI: Generate query embedding<br/>(text-embedding-ada-002)
        OpenAI-->>LangChain: 1536-dim vector
        
        LangChain->>VectorDB: Vector similarity search<br/>(cosine, top_k=5)
        VectorDB-->>LangChain: Relevant documents + scores
        
        LangChain->>LangChain: Construct prompt:<br/>Query + Context Documents
        
        LangChain->>OpenAI: LLM completion with context<br/>(gpt-4-turbo)
        OpenAI-->>LangChain: Generated answer
        
        LangChain-->>API: Response + source citations
    end
    
    rect rgb(250, 255, 240)
        Note over API,MongoDB: Logging & Caching
        API->>MongoDB: Log AI interaction:<br/>(prompt, response, tokens, cost)
        API->>Redis: Cache response (1hr TTL)
        API->>CloudWatch: Emit custom metrics
    end
    
    API-->>Client: 200 OK<br/>{answer, sources, tokens_used}
```

#### 6.1.3.3 File Upload Architecture

The system implements a presigned URL pattern for file uploads, enabling direct client-to-S3 transfers that bypass the API layer for improved performance and reduced backend load.

**File Upload Flow**:

1. **Presigned URL Request**: Client requests upload URL from `/api/v1/files/upload-url` with filename and content type
2. **Authorization Check**: API validates JWT and verifies file upload permissions
3. **URL Generation**: API generates presigned S3 PUT URL with 15-minute expiration using Boto3
4. **Metadata Creation**: API creates file record in MongoDB with pending status
5. **URL Response**: API returns presigned URL, file_id, and upload parameters
6. **Direct Upload**: Client uploads file directly to S3 using presigned URL (bypasses API)
7. **Upload Confirmation**: Client notifies API via `/api/v1/files/complete` endpoint
8. **Metadata Update**: API updates file status to complete in MongoDB

**Benefits**:
- Eliminates API bandwidth bottleneck for large file transfers
- Reduces backend infrastructure costs by offloading traffic to S3
- Improves upload performance with direct S3 connectivity
- Prevents API timeout issues for large file uploads

### 6.1.4 Service Discovery and Load Balancing

#### 6.1.4.1 Application Load Balancer Configuration

The Application Load Balancer serves as the single entry point for all client traffic, providing intelligent traffic distribution, TLS termination, and health-based routing across ECS Fargate tasks.

**ALB Architecture**:
- **Deployment Scope**: Internet-facing load balancer deployed across 3 availability zones
- **Listener Configuration**: HTTPS listener on port 443 with HTTP-to-HTTPS redirect on port 80
- **TLS Termination**: TLS 1.3 with TLS 1.2 fallback, AWS Certificate Manager certificate
- **Target Type**: IP-based targeting for ECS Fargate tasks
- **Path-Based Routing**: Single target group initially, supports future microservices routing

**Load Balancing Strategy**:

| Aspect | Configuration | Purpose |
|--------|--------------|---------|
| **Algorithm** | Round-robin | Distribute traffic evenly across healthy targets |
| **Cross-Zone** | Enabled | Balance traffic across all availability zones |
| **Sticky Sessions** | Disabled | Stateless API design requires no session affinity |
| **Connection Draining** | 30 seconds | Allow in-flight requests to complete during deployments |
| **Idle Timeout** | 60 seconds | Balance connection reuse and resource utilization |

**Health Check Configuration**:

| Parameter | Value | Purpose |
|-----------|-------|---------|
| Protocol | HTTP | Standard HTTP health check |
| Path | `/health` | Dedicated health endpoint |
| Interval | 30 seconds | Frequency of health checks |
| Timeout | 5 seconds | Maximum wait time for response |
| Healthy Threshold | 2 consecutive successes | Marks target as healthy |
| Unhealthy Threshold | 2 consecutive failures | Removes target from rotation |

#### 6.1.4.2 ECS Service Discovery

Amazon ECS Fargate provides serverless container orchestration with automatic service registration and health-aware task management.

**Service Configuration**:
- **Desired Task Count**: 2 (minimum for high availability)
- **Task Definition**: CPU: 0.5 vCPU, Memory: 1GB, Health check: `/health` endpoint
- **Network Mode**: awsvpc (each task receives dedicated ENI)
- **Subnet Placement**: Private subnets across 3 availability zones
- **Security Groups**: Restrict inbound to ALB only, allow outbound to dependencies

**Dynamic Task Registration**:

```mermaid
graph TB
    subgraph "ECS Fargate Cluster"
        Service[ECS Service<br/>Desired Count: 2-10]
        
        subgraph "Availability Zone 1"
            Task1[ECS Task 1<br/>IP: 10.0.1.10]
        end
        
        subgraph "Availability Zone 2"
            Task2[ECS Task 2<br/>IP: 10.0.2.10]
        end
        
        subgraph "Availability Zone 3"
            Task3[ECS Task 3<br/>IP: 10.0.3.10]
        end
    end
    
    Service -.->|Manages| Task1
    Service -.->|Manages| Task2
    Service -.->|Manages| Task3
    
    subgraph "Application Load Balancer"
        ALB[ALB<br/>Multi-AZ]
        TargetGroup[Target Group<br/>Health Checks]
    end
    
    ALB --> TargetGroup
    
    Task1 -->|Auto-Register<br/>IP Target| TargetGroup
    Task2 -->|Auto-Register<br/>IP Target| TargetGroup
    Task3 -->|Auto-Register<br/>IP Target| TargetGroup
    
    TargetGroup -.->|Health Check<br/>HTTP GET /health| Task1
    TargetGroup -.->|Health Check<br/>HTTP GET /health| Task2
    TargetGroup -.->|Health Check<br/>HTTP GET /health| Task3
    
    subgraph "External Traffic"
        Client[Clients<br/>Web, Mobile, Desktop]
    end
    
    Client -->|HTTPS| ALB
    
    CloudWatch[CloudWatch<br/>Logs & Metrics]
    Task1 -.->|Telemetry| CloudWatch
    Task2 -.->|Telemetry| CloudWatch
    Task3 -.->|Telemetry| CloudWatch
```

**Auto-Healing Mechanisms**:
- **Health Check Failure**: ECS automatically stops and replaces unhealthy tasks
- **Task Crash**: Immediate task restart with exponential backoff
- **Deployment Failure**: Automatic rollback after health check failures
- **Maximum Restart Attempts**: 10 attempts before alerting operations team

### 6.1.5 Scalability Architecture

#### 6.1.5.1 Horizontal Scaling Strategy

The architecture prioritizes horizontal scaling for application services, enabling linear capacity growth by adding identical service instances rather than increasing individual instance resources.

**ECS Auto-Scaling Configuration**:

```mermaid
graph LR
    subgraph "Scaling Triggers"
        CPU[CPU Utilization<br/>Target: 70%]
        Memory[Memory Utilization<br/>Target: 80%]
        Requests[Request Count<br/>Threshold: 1000/min]
    end
    
    subgraph "CloudWatch Alarms"
        ScaleOut[Scale Out Alarm<br/>Threshold Exceeded<br/>Duration: 3 minutes]
        ScaleIn[Scale In Alarm<br/>Below Target<br/>Duration: 10 minutes]
    end
    
    subgraph "Auto-Scaling Actions"
        AddTask[Add 1 ECS Task<br/>Max: 10 tasks]
        RemoveTask[Remove 1 ECS Task<br/>Min: 2 tasks]
    end
    
    CPU --> ScaleOut
    Memory --> ScaleOut
    Requests --> ScaleOut
    
    CPU --> ScaleIn
    Memory --> ScaleIn
    
    ScaleOut --> AddTask
    ScaleIn --> RemoveTask
    
    AddTask -.->|Update| CurrentCapacity[Current Task Count]
    RemoveTask -.->|Update| CurrentCapacity
    
    style ScaleOut fill:#ffcccc
    style ScaleIn fill:#ccffcc
```

**Scaling Parameters**:

| Metric | Scale Out Threshold | Scale In Threshold | Cooldown | Action |
|--------|--------------------|--------------------|----------|--------|
| **CPU Utilization** | > 70% for 3 minutes | < 30% for 10 minutes | 3 minutes | Add/remove 1 task |
| **Memory Utilization** | > 80% for 3 minutes | < 40% for 10 minutes | 3 minutes | Add/remove 1 task |
| **Request Count** | > 1000 req/min per task | N/A | 5 minutes | Add 1 task |

**Capacity Limits**:
- **Minimum Tasks**: 2 (ensures high availability during single task failure)
- **Maximum Tasks**: 10 (cost control and reasonable capacity ceiling)
- **Task Resources**: 0.5 vCPU, 1GB RAM per task
- **Maximum Capacity**: 10,000 requests/minute (10 tasks × 1,000 req/min)

#### 6.1.5.2 Vertical Scaling Strategy

Vertical scaling applies to data layer components where increasing individual instance resources provides better performance than horizontal distribution.

**Database Vertical Scaling Path**:

| Growth Stage | Instance Type | CPU | Memory | Connections | Monthly Cost (Est.) |
|-------------|---------------|-----|--------|-------------|---------------------|
| **Initial** | M10 (Atlas) / t3.medium | 2 vCPU | 4GB | 500 | $60 |
| **Growth** | M20 (Atlas) / t3.large | 2 vCPU | 8GB | 1,500 | $160 |
| **Scale** | M30 (Atlas) / m5.xlarge | 4 vCPU | 16GB | 3,000 | $480 |
| **Enterprise** | M40 (Atlas) / m5.2xlarge | 8 vCPU | 32GB | 6,000 | $960 |

**Horizontal Sharding Trigger**: When single-instance vertical scaling reaches practical limits (M40/M50 tier), implement MongoDB sharding with appropriate shard key (user_id recommended).

**Cache Vertical Scaling Path**:

| Growth Stage | Instance Type | Memory | Max Connections | Throughput | Monthly Cost (Est.) |
|-------------|---------------|--------|----------------|------------|---------------------|
| **Initial** | cache.t3.micro | 0.5GB | 1,000 | 5K ops/sec | $12 |
| **Growth** | cache.t3.small | 1.4GB | 2,500 | 15K ops/sec | $25 |
| **Scale** | cache.m5.large | 6.4GB | 10,000 | 50K ops/sec | $90 |
| **Enterprise** | cache.r5.xlarge | 26GB | 40,000 | 100K ops/sec | $200 |

**Redis Cluster Trigger**: When single-node Redis memory exceeds 25GB or operations exceed 100K ops/sec, migrate to Redis Cluster for horizontal scaling.

#### 6.1.5.3 Resource Allocation Strategy

**Connection Pooling Configuration**:

| Resource | Pool Size per Task | Reuse Strategy | Timeout | Rationale |
|----------|-------------------|----------------|---------|-----------|
| **MongoDB Connections** | 50 | Persistent pool | 30s idle timeout | Balance connection overhead vs availability |
| **Redis Connections** | 20 | Persistent pool | 60s idle timeout | Lower pool size for lightweight operations |
| **HTTP Client (Auth0, OpenAI)** | 10 | Session reuse | 30s timeout | Reuse TLS connections for external APIs |

**Task Resource Allocation**:

The ECS task resource allocation balances memory requirements for application code, connection pools, caching, and request buffering:

```mermaid
pie title ECS Task Memory Allocation (1GB Total)
    "Application Runtime" : 400
    "Connection Pools" : 150
    "Request Buffering" : 100
    "Caching Layer" : 200
    "OS & Overhead" : 150
```

#### 6.1.5.4 Performance Optimization Techniques

**Multi-Layer Caching Strategy**:

The architecture implements four caching layers working in concert to minimize latency and reduce load on origin services:

| Layer | Technology | Scope | TTL Range | Cache Hit Rate Target |
|-------|-----------|-------|-----------|----------------------|
| **Client Cache** | Browser Cache | Per-user, device-local | 0-1 hour | 40% (repeat requests) |
| **CDN Cache** | CloudFront | Edge locations, global | 0-1 year | 80% (static assets) |
| **Application Cache** | Redis | Backend services, shared | 30s-24h | 70% (API responses) |
| **Database Cache** | MongoDB | Query results, internal | Auto-managed | 60% (hot data) |

**Cache-Aside Pattern Implementation**:

```mermaid
flowchart TD
    Start[API Request Received] --> CheckCache{Check Redis Cache}
    
    CheckCache -->|Cache Hit| ReturnCached[Return Cached Response]
    CheckCache -->|Cache Miss| AcquireLock{Acquire Distributed Lock}
    
    AcquireLock -->|Lock Acquired| QueryDB[Query MongoDB]
    AcquireLock -->|Lock Held by Another| WaitRetry[Wait 50ms, Retry Cache Check]
    
    WaitRetry --> CheckCache
    
    QueryDB --> Transform[Transform Data to API Format]
    Transform --> StoreCache[Store in Redis with TTL]
    StoreCache --> ReleaseLock[Release Lock]
    ReleaseLock --> ReturnData[Return Response]
    
    ReturnCached --> LogMetrics[Log Cache Hit Metric]
    ReturnData --> LogMiss[Log Cache Miss Metric]
    
    LogMetrics --> End[End]
    LogMiss --> End
    
    style CheckCache fill:#ffffcc
    style AcquireLock fill:#ffcccc
    style ReturnCached fill:#ccffcc
```

**Database Query Optimization**:

| Optimization Technique | Implementation | Impact |
|----------------------|----------------|---------|
| **Index Strategy** | Compound indexes on frequently queried fields | 10-100x query speedup |
| **Aggregation Pipeline** | Use MongoDB aggregation for complex transformations | Reduce application logic complexity |
| **Read Preference** | SecondaryPreferred for read-heavy operations | Distribute read load across replicas |
| **Projection** | Return only required fields | Reduce network transfer, faster serialization |
| **Connection Pooling** | 50 connections per instance | Eliminate connection establishment overhead |

#### 6.1.5.5 Capacity Planning Guidelines

**Throughput Capacity Targets**:

| Metric | Target Capacity | Current Provisioning | Scaling Trigger |
|--------|----------------|---------------------|-----------------|
| **API Requests** | 1,000 req/sec per task | 2,000 req/sec (2 tasks) | Add tasks at 70% CPU |
| **Concurrent Users** | 10,000 concurrent | Calculated from req/sec | Monitor active connections |
| **Database Queries** | 5,000 queries/sec | M10: 500 queries/sec | Upgrade instance tier |
| **Cache Operations** | 50,000 ops/sec | t3.small: 15K ops/sec | Upgrade cache instance |
| **File Uploads** | 100 concurrent | S3: unlimited | No bottleneck |

**Performance Targets by Endpoint Category**:

| Endpoint Category | p50 Latency | p95 Latency | p99 Latency | Capacity Planning Factor |
|------------------|-------------|-------------|-------------|------------------------|
| **Simple CRUD** | < 100ms | < 300ms | < 500ms | 100 req/sec per task |
| **Complex Queries** | < 300ms | < 800ms | < 1200ms | 50 req/sec per task |
| **AI Completions** | < 2000ms | < 5000ms | < 8000ms | 10 req/sec per task |
| **File Upload URLs** | < 500ms | < 1500ms | < 3000ms | 200 req/sec per task |

**Growth Projection Model**:

```mermaid
graph LR
    subgraph "Month 1-3: Initial"
        Users1[100-500 Users]
        Tasks1[2 ECS Tasks]
        DB1[M10 MongoDB]
        Cache1[t3.micro Redis]
    end
    
    subgraph "Month 4-6: Growth"
        Users2[500-2000 Users]
        Tasks2[3-5 ECS Tasks]
        DB2[M20 MongoDB]
        Cache2[t3.small Redis]
    end
    
    subgraph "Month 7-12: Scale"
        Users3[2000-10000 Users]
        Tasks3[5-8 ECS Tasks]
        DB3[M30 MongoDB]
        Cache3[m5.large Redis]
    end
    
    subgraph "Year 2+: Enterprise"
        Users4[10000+ Users]
        Tasks4[8-10 ECS Tasks]
        DB4[M40+ MongoDB<br/>Consider Sharding]
        Cache4[r5.xlarge Redis<br/>Consider Cluster]
    end
    
    Users1 --> Users2
    Users2 --> Users3
    Users3 --> Users4
    
    Tasks1 --> Tasks2
    Tasks2 --> Tasks3
    Tasks3 --> Tasks4
    
    DB1 --> DB2
    DB2 --> DB3
    DB3 --> DB4
    
    Cache1 --> Cache2
    Cache2 --> Cache3
    Cache3 --> Cache4
```

### 6.1.6 Resilience and Fault Tolerance

#### 6.1.6.1 Circuit Breaker Pattern

The circuit breaker pattern protects the system from cascading failures when external dependencies experience degraded performance or outages. The implementation follows a three-state model with automatic recovery testing.

**Circuit Breaker State Machine**:

```mermaid
stateDiagram-v2
    [*] --> Closed: System Initialization
    
    Closed --> Closed: Requests Succeed<br/>(Track Success Rate)
    Closed --> Open: Error Threshold Exceeded<br/>(50% errors in 60-second window)
    
    Open --> Open: Requests Fail Fast<br/>(Return cached data or error)
    Open --> HalfOpen: Recovery Timeout<br/>(30 seconds elapsed)
    
    HalfOpen --> Closed: Test Requests Succeed<br/>(5 consecutive successful requests)
    HalfOpen --> Open: Test Requests Fail<br/>(Any failure during test period)
    
    note right of Closed
        CLOSED STATE
        - Normal operation mode
        - All requests pass through
        - Track error rate continuously
        - Error window: 60 seconds
        - Threshold: 50% failure rate
    end note
    
    note right of Open
        OPEN STATE
        - Circuit breaker active
        - Fail requests immediately
        - Return cached/fallback data
        - Prevent resource exhaustion
        - Duration: 30 seconds
    end note
    
    note right of HalfOpen
        HALF-OPEN STATE
        - Testing recovery
        - Allow limited requests
        - Require 5 consecutive successes
        - Single failure returns to OPEN
    end note
```

**Circuit Breaker Configuration by Service**:

| External Service | Error Threshold | Open Duration | Test Requests | Fallback Strategy |
|-----------------|----------------|---------------|---------------|------------------|
| **OpenAI API** | 50% errors in 60s | 30 seconds | 5 consecutive | Return cached response or disable AI features |
| **MongoDB** | 50% errors in 60s | 30 seconds | 5 consecutive | Return stale cached data with warning |
| **Redis** | 50% errors in 60s | 30 seconds | 5 consecutive | Direct MongoDB queries, disable caching |
| **Auth0 JWKS** | 50% errors in 60s | 30 seconds | 5 consecutive | Use cached JWKS (extend TTL temporarily) |

#### 6.1.6.2 Retry Mechanisms

The system implements intelligent retry strategies with exponential backoff and jitter to handle transient failures without overwhelming failing services.

**Exponential Backoff Algorithm**:

```
Wait Time = min(base_delay × 2^attempt + random_jitter, max_delay)

Where:
- base_delay: 100ms
- attempt: 0, 1, 2 (max 3 attempts)
- random_jitter: Random(0, 100ms)
- max_delay: 5 seconds
```

**Retry Attempt Timeline**:

| Attempt | Base Wait | Jitter Range | Total Wait Range | Cumulative Max |
|---------|-----------|--------------|------------------|----------------|
| 1st retry | 100ms | 0-100ms | 100-200ms | 200ms |
| 2nd retry | 200ms | 0-100ms | 200-300ms | 500ms |
| 3rd retry | 400ms | 0-100ms | 400-500ms | 1000ms |
| Final failure | - | - | - | Total: ~1 second |

**Retry Decision Matrix**:

| Error Type | Retry | Max Attempts | Rationale |
|-----------|-------|--------------|-----------|
| **Network Timeout** | Yes | 3 | Transient network issue, likely to succeed |
| **Connection Refused** | Yes | 3 | Service may be restarting |
| **Rate Limit (429)** | Yes | 3 | Wait for quota reset |
| **Server Error (5xx)** | Yes | 2 | Service may recover quickly |
| **Authentication Error (401)** | No | 0 | Invalid credentials, retry won't help |
| **Authorization Error (403)** | No | 0 | Insufficient permissions, retry won't help |
| **Not Found (404)** | No | 0 | Resource doesn't exist, retry won't help |
| **Validation Error (400)** | No | 0 | Client error, retry without fix won't help |

**Idempotency Requirements**:

To safely retry operations, the system implements idempotency guarantees:

- **POST Requests**: Include `Idempotency-Key` header (UUID) to prevent duplicate resource creation
- **PUT/DELETE Requests**: Naturally idempotent (same operation repeated yields same result)
- **Database Operations**: Use upsert operations and unique constraints to prevent duplicates
- **External API Calls**: Track request IDs and deduplicate within time window

#### 6.1.6.3 Graceful Degradation Strategy

When external dependencies fail, the system implements graceful degradation to maintain partial functionality rather than complete outage.

**Degradation Response Matrix**:

| Failure Scenario | System Response | User Experience | Data Freshness |
|-----------------|----------------|----------------|----------------|
| **MongoDB Unavailable** | Return cached data from Redis with warning banner | Read-only mode with stale data | Last cached: 5-60 minutes |
| **Redis Unavailable** | Direct MongoDB queries, disable rate limiting | Slower response times, potential overload | Real-time data |
| **OpenAI API Down** | Disable AI features, show maintenance notice | AI features temporarily unavailable | N/A |
| **Auth0 Down** | Use cached JWKS for validation, disable new logins | Existing sessions continue, new logins fail | Cached keys: 1 hour |
| **S3 Unavailable** | Block uploads, serve cached files | Upload disabled, downloads from cache | Recent files only |

**Degradation Level Classification**:

```mermaid
graph TD
    Normal[Normal Operation<br/>All Services Available]
    
    Normal --> Level1{Primary DB Slow}
    Normal --> Level2{Cache Unavailable}
    Normal --> Level3{AI Service Down}
    Normal --> Level4{Multiple Failures}
    
    Level1 --> Degraded1[Level 1: Degraded<br/>Slower responses<br/>All features available]
    
    Level2 --> Degraded2[Level 2: Degraded<br/>Direct DB queries<br/>Higher latency]
    
    Level3 --> Degraded3[Level 3: Partial<br/>Core features only<br/>AI features disabled]
    
    Level4 --> Degraded4[Level 4: Critical<br/>Read-only mode<br/>Maintenance banner]
    
    style Normal fill:#ccffcc
    style Degraded1 fill:#ffffcc
    style Degraded2 fill:#ffeecc
    style Degraded3 fill:#ffddcc
    style Degraded4 fill:#ffcccc
```

#### 6.1.6.4 Fault Tolerance Mechanisms

**Multi-Availability Zone Deployment**:

The architecture distributes all critical components across three AWS availability zones to ensure tolerance of zone-level failures.

```mermaid
graph TB
    subgraph "Availability Zone 1"
        ALB1[ALB Node]
        ECS1[ECS Task]
        NAT1[NAT Gateway]
    end
    
    subgraph "Availability Zone 2"
        ALB2[ALB Node]
        ECS2[ECS Task]
        NAT2[NAT Gateway]
    end
    
    subgraph "Availability Zone 3"
        ALB3[ALB Node]
        ECS3[ECS Task]
        NAT3[NAT Gateway]
    end
    
    Internet[Internet Traffic] --> ALB1
    Internet --> ALB2
    Internet --> ALB3
    
    ALB1 --> ECS1
    ALB1 --> ECS2
    ALB1 --> ECS3
    
    ALB2 --> ECS1
    ALB2 --> ECS2
    ALB2 --> ECS3
    
    ALB3 --> ECS1
    ALB3 --> ECS2
    ALB3 --> ECS3
    
    ECS1 --> NAT1
    ECS2 --> NAT2
    ECS3 --> NAT3
    
    subgraph "Data Layer - Multi-AZ"
        MongoDB[(MongoDB Replica Set<br/>Primary + 2 Secondaries<br/>Distributed across AZs)]
        Redis[(Redis<br/>Multi-AZ if ElastiCache)]
        S3[(S3<br/>Automatic Cross-AZ<br/>Replication)]
    end
    
    ECS1 -.-> MongoDB
    ECS2 -.-> MongoDB
    ECS3 -.-> MongoDB
    
    ECS1 -.-> Redis
    ECS2 -.-> Redis
    ECS3 -.-> Redis
    
    NAT1 -.-> MongoDB
    NAT2 -.-> MongoDB
    NAT3 -.-> MongoDB
```

**Failure Impact Analysis**:

| Failure Type | Components Affected | Automatic Recovery | Recovery Time | Data Loss |
|-------------|--------------------|--------------------|---------------|-----------|
| **Single ECS Task Failure** | 1 task (50% capacity with 2 tasks) | ECS restarts task automatically | < 1 minute | None |
| **Availability Zone Failure** | ALB node, ECS tasks, NAT Gateway in zone | ALB routes to healthy zones | < 5 minutes | None |
| **MongoDB Primary Failure** | Write operations temporarily blocked | Replica set promotes secondary | < 10 seconds | None (acknowledged writes) |
| **Redis Failure** | Cache layer, rate limiting | Direct DB queries, degraded performance | Immediate | Cache data only |
| **ALB Failure** | All incoming traffic | AWS replaces ALB (very rare) | 5-15 minutes | None |

**Auto-Healing Configuration**:

| Component | Health Check | Failure Detection | Healing Action | Timeout |
|-----------|-------------|------------------|----------------|---------|
| **ECS Tasks** | HTTP GET /health every 30s | 2 consecutive failures | Stop and replace task | 60 seconds |
| **ALB Targets** | HTTP GET /health every 30s | 2 consecutive failures | Remove from rotation | 60 seconds |
| **MongoDB Replica** | Replica set heartbeat | 10 seconds no response | Promote secondary to primary | 10 seconds |

### 6.1.7 Disaster Recovery Architecture

#### 6.1.7.1 Backup Strategy

**MongoDB Backup Configuration**:

| Backup Type | Frequency | Retention | Method | Storage Location |
|------------|-----------|-----------|--------|-----------------|
| **Full Backup** | Daily at 2:00 AM UTC | 30 days (daily), 1 year (monthly) | MongoDB Atlas automated or mongodump | S3 bucket: `app-backups` |
| **Point-in-Time** | Continuous (Atlas) | 7 days | Oplog-based continuous backup | MongoDB Atlas internal |
| **Incremental** | Every 6 hours | 7 days | Changed documents only | S3 bucket: `app-backups` |

**S3 Versioning and Lifecycle**:

```mermaid
graph LR
    subgraph "S3 Backup Lifecycle"
        Upload[New Backup Uploaded]
        S3Standard[S3 Standard Storage<br/>First 30 Days]
        S3IA[S3 Infrequent Access<br/>Days 31-90]
        Glacier[S3 Glacier<br/>Days 91-365]
        Delete[Automatic Deletion<br/>After 1 Year]
    end
    
    Upload --> S3Standard
    S3Standard -->|30 days| S3IA
    S3IA -->|60 days| Glacier
    Glacier -->|275 days| Delete
    
    subgraph "Cost Optimization"
        Cost1["Standard: $0.023/GB/month<br/>High availability"]
        Cost2["IA: $0.0125/GB/month<br/>Lower cost, occasional access"]
        Cost3["Glacier: $0.004/GB/month<br/>Archival, rare access"]
    end
    
    S3Standard -.-> Cost1
    S3IA -.-> Cost2
    Glacier -.-> Cost3
```

**Infrastructure as Code Backup**:

All infrastructure is defined in Terraform configuration files stored in Git with state files versioned in S3, enabling complete infrastructure recreation from code.

| Asset | Backup Method | Storage | Restoration Time |
|-------|--------------|---------|------------------|
| **Terraform State** | S3 with versioning | `terraform-state` bucket | < 5 minutes |
| **Terraform Code** | Git repository | GitHub | < 5 minutes |
| **Docker Images** | ECR with lifecycle policy | Amazon ECR | < 10 minutes |
| **Application Code** | Git repository | GitHub | < 5 minutes |
| **Secrets** | AWS Secrets Manager | AWS managed | < 1 minute |

#### 6.1.7.2 Recovery Objectives

**RTO (Recovery Time Objective) and RPO (Recovery Point Objective) Targets**:

| Scenario | RTO | RPO | Recovery Procedure | Complexity |
|----------|-----|-----|-------------------|------------|
| **Single ECS Task Failure** | < 1 minute | 0 (no data loss) | Automatic ECS task restart | Low |
| **MongoDB Primary Failure** | < 10 seconds | 0 (no data loss) | Automatic replica set failover | Low |
| **Availability Zone Failure** | < 5 minutes | 0 (no data loss) | ALB routes to healthy AZ | Low |
| **Region-Wide Failure** | < 4 hours | < 1 hour | Manual failover to secondary region | High |
| **Database Corruption** | < 4 hours | < 24 hours | Restore from daily backup | Medium |
| **Complete Infrastructure Loss** | < 8 hours | < 24 hours | Rebuild via Terraform + restore data | High |

**Recovery Priority Matrix**:

```mermaid
graph TD
    Incident[Incident Detected]
    
    Incident --> Assess{Assess Severity}
    
    Assess -->|P0: Critical Outage| P0[Priority 0<br/>RTO: < 1 hour<br/>Complete system down]
    Assess -->|P1: Major Degradation| P1[Priority 1<br/>RTO: < 4 hours<br/>Core features impacted]
    Assess -->|P2: Minor Degradation| P2[Priority 2<br/>RTO: < 24 hours<br/>Non-critical features]
    Assess -->|P3: Monitoring Alert| P3[Priority 3<br/>RTO: < 1 week<br/>No user impact]
    
    P0 --> Team0[All-hands response<br/>24/7 attention<br/>Executive updates]
    P1 --> Team1[Ops team + Engineers<br/>Regular updates<br/>Stakeholder comm]
    P2 --> Team2[Ops team<br/>Normal hours<br/>Status page update]
    P3 --> Team3[Individual engineer<br/>Normal hours<br/>Internal tracking]
    
    style P0 fill:#ff0000,color:#ffffff
    style P1 fill:#ff9900
    style P2 fill:#ffff00
    style P3 fill:#cccccc
```

#### 6.1.7.3 Disaster Recovery Procedures

**MongoDB Restore Procedure**:

1. **Incident Detection**: CloudWatch alarm triggers for database connectivity issues or data corruption
2. **Impact Assessment**: Determine scope (corrupted collections, missing data, complete failure)
3. **Identify Restore Point**: Determine target timestamp for restoration (last known good state)
4. **Provision New Instance**: Create new MongoDB instance to avoid overwriting production
5. **Restore Data**: 
   - Atlas: Use point-in-time restore feature to target timestamp
   - Self-Hosted: Download backup from S3, execute `mongorestore` command
6. **Verify Data Integrity**: Run validation queries, check record counts, verify critical data
7. **DNS/Configuration Cutover**: Update application configuration to point to restored database
8. **Monitor Performance**: Close monitoring for 24 hours post-recovery
9. **Post-Mortem**: Document incident, root cause, timeline, and preventive measures

**Infrastructure Disaster Recovery**:

```mermaid
flowchart TD
    Start[Disaster Detected] --> Stop[Stop Application Traffic<br/>Update DNS/Status Page]
    
    Stop --> Assess{Infrastructure<br/>Salvageable?}
    
    Assess -->|Yes: Partial Failure| Repair[Repair Failed Components<br/>Replace Tasks/Services]
    Assess -->|No: Complete Loss| Rebuild[Full Infrastructure Rebuild]
    
    Rebuild --> TF1[Clone Terraform Repository]
    TF1 --> TF2[terraform init<br/>Load S3 state]
    TF2 --> TF3[terraform plan<br/>Review changes]
    TF3 --> TF4[terraform apply<br/>Provision infrastructure]
    
    TF4 --> Deploy1[Build Docker Images<br/>Push to ECR]
    Deploy1 --> Deploy2[Deploy ECS Services<br/>Run health checks]
    
    Repair --> RestoreDB{Database<br/>Restore Needed?}
    Deploy2 --> RestoreDB
    
    RestoreDB -->|Yes| DB1[Restore MongoDB Backup]
    RestoreDB -->|No| Verify[Verify System Health]
    
    DB1 --> DB2[Verify Data Integrity]
    DB2 --> Verify
    
    Verify --> Smoke[Run Smoke Tests<br/>Critical User Journeys]
    Smoke --> Monitor[Enable Monitoring<br/>Resume Traffic]
    Monitor --> Postmortem[Schedule Post-Mortem<br/>Document Lessons Learned]
    
    style Start fill:#ffcccc
    style Postmortem fill:#ccffcc
```

#### 6.1.7.4 Data Redundancy and Failover

**MongoDB Replica Set Failover**:

The MongoDB replica set provides automatic failover with zero data loss for acknowledged writes:

```mermaid
sequenceDiagram
    participant App as Application
    participant Primary as MongoDB Primary
    participant Secondary1 as MongoDB Secondary 1
    participant Secondary2 as MongoDB Secondary 2
    
    Note over Primary,Secondary2: Normal Operation
    App->>Primary: Write Request (write concern: majority)
    Primary->>Secondary1: Replicate data
    Primary->>Secondary2: Replicate data
    Secondary1-->>Primary: Acknowledge
    Secondary2-->>Primary: Acknowledge
    Primary-->>App: Write Confirmed
    
    Note over Primary,Secondary2: Primary Failure Event
    rect rgb(255, 200, 200)
        Primary-xSecondary1: Heartbeat timeout
        Primary-xSecondary2: Heartbeat timeout
        Secondary1->>Secondary2: Initiate election
        Secondary2->>Secondary1: Vote for S1
        Secondary1->>Secondary1: Elected as new Primary
    end
    
    Note over Primary,Secondary2: Failover Complete (< 10 seconds)
    App->>Secondary1: Write Request<br/>(now Primary)
    Secondary1->>Secondary2: Replicate data
    Secondary2-->>Secondary1: Acknowledge
    Secondary1-->>App: Write Confirmed
    
    Note over Primary,Secondary2: Recovery
    Primary->>Secondary1: Rejoins as Secondary
    Secondary1->>Primary: Sync missed operations
```

**Failover Characteristics**:
- **Detection Time**: 10 seconds (replica set heartbeat interval)
- **Election Time**: < 5 seconds (raft consensus protocol)
- **Total Failover**: < 10 seconds (detection + election)
- **Data Loss**: None (for writes with majority write concern)
- **Application Impact**: Brief connection error, automatic reconnection

**Application-Level Failover**:

| Component | Primary | Secondary | Failover Trigger | Switchover Time |
|-----------|---------|-----------|------------------|-----------------|
| **ALB** | Active ALB | AWS manages replacement | Health check failure | Automatic, < 1 minute |
| **ECS Tasks** | Running tasks | Standby capacity | Task failure | Automatic, < 1 minute |
| **MongoDB** | Primary node | 2 Secondary nodes | Primary heartbeat timeout | Automatic, < 10 seconds |
| **Redis** | Primary node | Replica (if ElastiCache Multi-AZ) | Node failure | Automatic, < 30 seconds |

### 6.1.8 Security and Observability Integration

#### 6.1.8.1 Monitoring Architecture

**CloudWatch Integration**:

The services architecture integrates comprehensive monitoring through Amazon CloudWatch, capturing logs, metrics, and traces from all components.

**Log Aggregation Strategy**:

| Log Source | Log Group | Format | Retention | Query Pattern |
|-----------|-----------|--------|-----------|---------------|
| **Flask API** | `/ecs/flask-api` | Structured JSON | 30 days | Filter by request_id, user_id, endpoint |
| **LangChain Service** | `/ecs/langchain` | Structured JSON | 30 days | Filter by request_id, prompt_hash, tokens |
| **ALB Access Logs** | `/aws/alb/access` | Apache Combined | 30 days | Filter by client_ip, status_code, latency |
| **Application Errors** | `/ecs/flask-api` (level=ERROR) | Structured JSON | 90 days | Filter by error_type, stack_trace |

**Structured Log Format**:
```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456",
  "service": "api",
  "endpoint": "/api/v1/documents",
  "method": "GET",
  "status_code": 200,
  "duration_ms": 45,
  "cache_hit": true,
  "message": "Request processed successfully"
}
```

**Custom Application Metrics**:

| Metric | Type | Dimensions | Alert Threshold | Business Value |
|--------|------|-----------|----------------|----------------|
| `api.request.count` | Counter | service, endpoint, status | N/A | Traffic analysis |
| `api.request.duration` | Histogram | service, endpoint | p95 > 1000ms | Performance SLA |
| `api.error.rate` | Gauge | service, error_type | > 5% | Reliability SLA |
| `ai.tokens.consumed` | Counter | user_id, model | Budget threshold | Cost control |
| `cache.hit.rate` | Gauge | cache_layer | < 70% | Cache efficiency |
| `auth.failed.attempts` | Counter | ip_address | > 100/min | Security threat |

#### 6.1.8.2 Distributed Tracing

**Request ID Propagation Flow**:

```mermaid
sequenceDiagram
    participant Client
    participant ALB
    participant API
    participant LangChain
    participant MongoDB
    participant OpenAI
    
    Note over Client,OpenAI: Request ID Lifecycle
    
    Client->>ALB: HTTP Request
    Note over ALB: Generate UUID<br/>550e8400-e29b...
    ALB->>API: X-Request-ID: 550e8400...
    
    Note over API: Log: [550e8400] Request received
    
    API->>LangChain: AI request with request_id
    Note over LangChain: Log: [550e8400] AI processing
    
    LangChain->>MongoDB: Store with request_id
    Note over MongoDB: Log: [550e8400] Data persisted
    
    LangChain->>OpenAI: External call
    Note over OpenAI: No request_id<br/>(external service)
    OpenAI-->>LangChain: Response
    
    Note over LangChain: Log: [550e8400] OpenAI complete
    
    LangChain-->>API: Response with request_id
    Note over API: Log: [550e8400] Total: 2450ms
    
    API-->>ALB: Response with X-Request-ID
    ALB-->>Client: Response header includes request_id
```

**Log Correlation Example**:

Using CloudWatch Logs Insights to trace complete request lifecycle:
```
fields @timestamp, level, service, message, duration_ms
| filter request_id = "550e8400-e29b-41d4-a716-446655440000"
| sort @timestamp asc
| display @timestamp, service, message, duration_ms
```

#### 6.1.8.3 Security Monitoring

**Security Event Tracking**:

| Event Type | Log Level | Alert Threshold | Response Action |
|-----------|-----------|----------------|-----------------|
| **Failed Authentication** | WARNING | > 5 attempts/min per IP | Rate limit IP, potential ban |
| **Invalid JWT** | WARNING | > 10/min per endpoint | Investigate token source |
| **Permission Denied** | INFO | > 50/min per user | Review user permissions |
| **Rate Limit Exceeded** | WARNING | > 100/min across users | Check for DDoS attack |
| **Unusual AI Usage** | INFO | > 100 requests/hour per user | Monitor for abuse |

### 6.1.9 References

This section was compiled from the following sources within the technical specification and repository:

**Technical Specification Sections**:
- `5.1 High-Level Architecture` - Overall system architecture, service boundaries, and data flows
- `5.2 Component Details` - Detailed specifications for Flask API, LangChain service, Auth0, MongoDB, Redis, S3, ECS, and ALB components
- `5.3 Technical Decisions` - Architectural rationale including cloud-native approach, microservices orientation, communication patterns, and technology selection
- `5.4 Cross-Cutting Concerns` - Monitoring and observability strategy, error handling, authentication framework, performance targets, and disaster recovery procedures

**Repository Files Examined**:
- `README.md` - Project title documentation (only file in repository, no implementation code)

**Key Findings**:
- **Implementation Status**: Repository contains only README.md with project title "CheckSameRepoNoPrompt"
- **Architecture Status**: All service components, communication patterns, and infrastructure configurations represent planned architecture
- **Deployment Model**: Cloud-native AWS deployment with ECS Fargate, Application Load Balancer, and managed data services
- **Service Pattern**: Microservices-oriented with initial modular monolith, phased extraction strategy
- **Scalability Approach**: Horizontal scaling for application services (2-10 ECS tasks), vertical scaling for data layer
- **Resilience Implementation**: Circuit breaker pattern, exponential backoff retry, graceful degradation, multi-AZ deployment
- **Recovery Targets**: RTO < 4 hours, RPO < 1 hour for critical scenarios

---

**Last Updated**: 2024-01-15  
**Architecture Version**: 1.0 (Planned)  
**Next Review**: Upon implementation commencement

## 6.2 Database Design

### 6.2.1 Overview and Implementation Status

**Current Implementation Status**: This repository contains **only a README.md file** with the project title "CheckSameRepoNoPrompt". No database implementation code exists yet. All database design information documented in this section represents **planned architecture** as specified in the technical specification.

**Database Architecture Philosophy**: The system employs a cloud-native, multi-database architecture optimized for scalability, performance, and developer productivity. This approach leverages MongoDB for flexible document storage, Redis for high-performance caching, Amazon S3 for durable object storage, and a to-be-determined vector database for AI/ML embeddings.

### 6.2.2 Database Technology Stack

| Database Type | Technology | Version | Purpose | Deployment |
|--------------|------------|---------|---------|------------|
| Primary Database | MongoDB | 7.0+ | Document storage, application data | MongoDB Atlas (AWS) or Self-hosted ECS |
| Caching Layer | Redis | 7+ | In-memory cache, session storage | Amazon ElastiCache or Self-hosted ECS |
| Object Storage | Amazon S3 | N/A | File uploads, static assets, backups | AWS Managed |
| Vector Database | TBD | TBD | AI embeddings, semantic search | TBD |

---

### 6.2.3 Schema Design

#### 6.2.3.1 MongoDB Primary Database Architecture

**Deployment Strategy**:
- **Recommended Approach**: MongoDB Atlas (Managed Database-as-a-Service on AWS)
- **Alternative Approach**: Self-Hosted MongoDB on AWS ECS Fargate with persistent EBS volumes

**Selection Rationale**:
- **Schema Flexibility**: Document model accommodates evolving data structures without complex migrations
- **Developer Productivity**: JSON-like documents map naturally to application objects, reducing impedance mismatch
- **Horizontal Scalability**: Built-in sharding capability for distributed data storage as dataset grows
- **Rich Query Language**: Powerful aggregation framework enables complex analytical queries
- **Python Integration**: Excellent support through PyMongo 4.6+ (synchronous) and Motor 3.3+ (async) drivers
- **ACID Transactions**: Multi-document transaction support ensures data consistency for critical operations

#### 6.2.3.2 Entity-Relationship Design

#### Collection: `users`

**Purpose**: Store user profiles, preferences, and metadata supplementing Auth0 identity management.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439011"),
  "auth0_id": "auth0|123456789",
  "email": "user@example.com",
  "preferences": {
    "theme": "dark",
    "language": "en",
    "notifications_enabled": true
  },
  "created_at": ISODate("2024-01-15T10:30:00Z"),
  "updated_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: MongoDB ObjectId (primary key, auto-generated)
- `auth0_id`: String, unique identifier from Auth0 identity provider (indexed, unique constraint)
- `email`: String, user email address (indexed for lookup)
- `preferences`: Object, flexible JSON structure for user-specific settings
- `created_at`: DateTime, account creation timestamp
- `updated_at`: DateTime, last modification timestamp

**Indexes**:
- `auth0_id`: Unique index (ensures one MongoDB record per Auth0 user)
- `email`: Single field index (enables efficient email-based queries)

**Estimated Document Size**: ~100 KB per user

**Relationships**:
- **One-to-Many** with `conversations`: A user owns multiple AI conversations
- **One-to-Many** with `documents`: A user uploads multiple documents
- **One-to-Many** with `files`: A user uploads multiple files
- **One-to-Many** with `ai_interactions`: A user generates multiple AI interactions
- **One-to-Many** with `analytics`: A user triggers multiple analytics events

---

#### Collection: `conversations`

**Purpose**: Store AI conversation metadata, tracking user interactions with the LLM.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439012"),
  "user_id": "auth0|123456789",
  "title": "Project Planning Discussion",
  "model": "gpt-4-turbo",
  "created_at": ISODate("2024-01-15T10:30:00Z"),
  "updated_at": ISODate("2024-01-15T11:45:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `user_id`: String, references `users.auth0_id` (indexed, foreign key relationship)
- `title`: String, conversation title (user-defined or auto-generated)
- `model`: String, LLM model identifier (e.g., "gpt-4-turbo", "gpt-3.5-turbo")
- `created_at`: DateTime, conversation initiation timestamp (indexed for chronological queries)
- `updated_at`: DateTime, last message timestamp

**Indexes**:
- `user_id`: Single field index (efficient user conversation retrieval)
- `created_at`: Single field index (chronological sorting)
- `{user_id: 1, created_at: -1}`: Compound index (optimized for paginated user conversation lists)

**Estimated Document Size**: ~10 KB per conversation

**Relationships**:
- **Many-to-One** with `users`: Many conversations belong to one user
- **One-to-Many** with `messages`: One conversation contains multiple messages

---

#### Collection: `messages`

**Purpose**: Store individual messages within AI conversations, maintaining complete conversation history.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439013"),
  "conversation_id": ObjectId("507f1f77bcf86cd799439012"),
  "role": "user",
  "content": "What are the best practices for database indexing?",
  "tokens": 12,
  "created_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `conversation_id`: ObjectId, references `conversations._id` (indexed, foreign key relationship)
- `role`: String, enum: "user" (human), "assistant" (AI), "system" (system prompt)
- `content`: String, message text content
- `tokens`: Integer, token count for cost tracking and context window management
- `created_at`: DateTime, message creation timestamp (indexed for chronological retrieval)

**Indexes**:
- `conversation_id`: Single field index (efficient message retrieval for conversation)
- `created_at`: Single field index (chronological sorting)
- `{conversation_id: 1, created_at: 1}`: Compound index (optimized chronological message retrieval per conversation)

**Estimated Document Size**: ~5 KB per message

**Relationships**:
- **Many-to-One** with `conversations`: Many messages belong to one conversation

---

#### Collection: `documents`

**Purpose**: Store metadata for user-uploaded documents, with actual file content stored in Amazon S3.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439014"),
  "user_id": "auth0|123456789",
  "s3_key": "uploads/2024/01/15/507f1f77bcf86cd799439014-document.pdf",
  "filename": "quarterly-report-q4-2023.pdf",
  "size": 2048576,
  "mime_type": "application/pdf",
  "created_at": ISODate("2024-01-15T10:30:00Z"),
  "metadata": {
    "tags": ["finance", "quarterly"],
    "description": "Q4 2023 Financial Report"
  }
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `user_id`: String, references `users.auth0_id` (indexed)
- `s3_key`: String, Amazon S3 object key for file retrieval
- `filename`: String, original filename (full-text search indexed)
- `size`: Integer, file size in bytes
- `mime_type`: String, file MIME type (e.g., "application/pdf", "image/jpeg")
- `created_at`: DateTime, upload timestamp (indexed)
- `metadata`: Object, flexible custom metadata (tags, description, etc.)

**Indexes**:
- `user_id`: Single field index (user document retrieval)
- `created_at`: Single field index (chronological sorting)
- `{user_id: 1, created_at: -1}`: Compound index (paginated user document lists)
- Full-text search index on `filename` and `metadata` fields (enables search functionality)

**Estimated Document Size**: ~50 KB per document

**Relationships**:
- **Many-to-One** with `users`: Many documents belong to one user
- **One-to-One** with S3 object: Each document metadata record references one S3 object

---

#### Collection: `ai_interactions`

**Purpose**: Log all AI/ML API interactions for cost tracking, usage analytics, and debugging.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439015"),
  "user_id": "auth0|123456789",
  "type": "completion",
  "prompt": "Summarize the following document...",
  "response": "This document discusses...",
  "tokens": 450,
  "cost": 0.0135,
  "model": "gpt-4-turbo",
  "created_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `user_id`: String, references `users.auth0_id` (indexed)
- `type`: String, enum: "completion", "conversation", "search" (indexed for filtering)
- `prompt`: String, user input/prompt sent to LLM
- `response`: String, LLM-generated response
- `tokens`: Integer, total tokens consumed (prompt + completion)
- `cost`: Decimal, estimated cost in USD based on model pricing
- `model`: String, LLM model identifier
- `created_at`: DateTime, interaction timestamp (indexed)

**Indexes**:
- `user_id`: Single field index (user usage tracking)
- `created_at`: Single field index (time-series queries)
- `type`: Single field index (filter by interaction type)
- `{user_id: 1, created_at: -1, type: 1}`: Compound index (user analytics queries)

**Estimated Document Size**: ~20 KB per interaction

**Relationships**:
- **Many-to-One** with `users`: Many AI interactions belong to one user

---

#### Collection: `analytics`

**Purpose**: Track application events, user behavior, and system metrics for product analytics.

**Schema Structure**:
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439016"),
  "event_type": "document_uploaded",
  "user_id": "auth0|123456789",
  "metadata": {
    "file_size": 2048576,
    "mime_type": "application/pdf",
    "source": "web_app"
  },
  "timestamp": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `_id`: ObjectId (primary key)
- `event_type`: String, event category identifier (indexed)
- `user_id`: String, references `users.auth0_id` (indexed)
- `metadata`: Object, event-specific contextual data
- `timestamp`: DateTime, event occurrence time (indexed)

**Indexes**:
- `event_type`: Single field index (filter events by type)
- `user_id`: Single field index (user behavior tracking)
- `timestamp`: Single field index (time-series analysis)
- `{event_type: 1, timestamp: -1}`: Compound index (event analytics queries)

**Estimated Document Size**: ~5 KB per event

**Relationships**:
- **Many-to-One** with `users`: Many analytics events belong to one user

---

#### Collection: `files`

**Purpose**: Track file upload status and metadata during presigned URL upload workflow.

**Schema Structure**:
```json
{
  "file_id": "uuid-v4-550e8400-e29b-41d4",
  "user_id": "auth0|123456789",
  "s3_key": "uploads/2024/01/15/uuid-v4-550e8400-e29b-41d4.pdf",
  "filename": "document.pdf",
  "size": 2048576,
  "status": "complete",
  "created_at": ISODate("2024-01-15T10:30:00Z")
}
```

**Key Fields**:
- `file_id`: String, UUID v4 unique identifier (unique index, primary key alternative)
- `user_id`: String, references `users.auth0_id` (indexed)
- `s3_key`: String, S3 object key
- `filename`: String, original filename
- `size`: Integer, file size in bytes
- `status`: String, enum: "pending" (upload initiated), "complete" (upload finished), "failed" (upload error)
- `created_at`: DateTime, record creation timestamp

**Indexes**:
- `file_id`: Unique index (primary identifier for file operations)
- `user_id`: Single field index (user file retrieval)
- `{user_id: 1, created_at: -1}`: Compound index (user file lists)

**Estimated Document Size**: ~2 KB per file

**Relationships**:
- **Many-to-One** with `users`: Many files belong to one user
- **One-to-One** with S3 object: Each file record references one S3 object

---

#### 6.2.3.3 Entity-Relationship Diagram

```mermaid
erDiagram
    USERS ||--o{ CONVERSATIONS : "owns"
    USERS ||--o{ DOCUMENTS : "uploads"
    USERS ||--o{ FILES : "uploads"
    USERS ||--o{ AI_INTERACTIONS : "generates"
    USERS ||--o{ ANALYTICS : "triggers"
    
    CONVERSATIONS ||--o{ MESSAGES : "contains"
    
    USERS {
        ObjectId _id PK
        string auth0_id UK "Unique, Indexed"
        string email "Indexed"
        object preferences
        datetime created_at
        datetime updated_at
    }
    
    CONVERSATIONS {
        ObjectId _id PK
        string user_id FK "Indexed, ref: users.auth0_id"
        string title
        string model "LLM model identifier"
        datetime created_at "Indexed"
        datetime updated_at
    }
    
    MESSAGES {
        ObjectId _id PK
        ObjectId conversation_id FK "Indexed, ref: conversations._id"
        string role "Enum: user, assistant, system"
        string content
        integer tokens
        datetime created_at "Indexed"
    }
    
    DOCUMENTS {
        ObjectId _id PK
        string user_id FK "Indexed, ref: users.auth0_id"
        string s3_key "S3 object key"
        string filename "Full-text indexed"
        integer size "Bytes"
        string mime_type
        object metadata "Custom tags, description"
        datetime created_at "Indexed"
    }
    
    AI_INTERACTIONS {
        ObjectId _id PK
        string user_id FK "Indexed, ref: users.auth0_id"
        string type "Indexed, Enum: completion, conversation, search"
        string prompt
        string response
        integer tokens
        decimal cost "USD"
        string model
        datetime created_at "Indexed"
    }
    
    ANALYTICS {
        ObjectId _id PK
        string event_type "Indexed"
        string user_id FK "Indexed, ref: users.auth0_id"
        object metadata "Event-specific data"
        datetime timestamp "Indexed"
    }
    
    FILES {
        string file_id PK "UUID v4, Unique, Indexed"
        string user_id FK "Indexed, ref: users.auth0_id"
        string s3_key "S3 object key"
        string filename
        integer size "Bytes"
        string status "Enum: pending, complete, failed"
        datetime created_at
    }
```

#### 6.2.3.4 Indexing Strategy

**Indexing Philosophy**: Indexes are created based on query patterns, prioritizing frequently executed queries while balancing write performance overhead. All indexes are created with appropriate direction (ascending/descending) to optimize sort operations.

#### Index Categories

**Primary Indexes** (Unique Constraints):

| Collection | Field | Type | Purpose |
|-----------|-------|------|---------|
| `users` | `auth0_id` | Unique | Ensure one MongoDB record per Auth0 user |
| `files` | `file_id` | Unique | Primary identifier for file operations |

**Single Field Indexes** (Lookup and Filter):

| Collection | Field | Purpose | Query Pattern |
|-----------|-------|---------|---------------|
| `users` | `email` | Email-based user lookup | `db.users.find({email: "user@example.com"})` |
| `conversations` | `user_id` | User conversation retrieval | `db.conversations.find({user_id: "auth0\|123"})` |
| `conversations` | `created_at` | Chronological sorting | `db.conversations.find().sort({created_at: -1})` |
| `messages` | `conversation_id` | Message retrieval for conversation | `db.messages.find({conversation_id: ObjectId})` |
| `messages` | `created_at` | Chronological message ordering | `db.messages.find().sort({created_at: 1})` |
| `documents` | `user_id` | User document retrieval | `db.documents.find({user_id: "auth0\|123"})` |
| `documents` | `created_at` | Chronological sorting | `db.documents.find().sort({created_at: -1})` |
| `ai_interactions` | `user_id` | User AI usage tracking | `db.ai_interactions.find({user_id: "auth0\|123"})` |
| `ai_interactions` | `created_at` | Time-series analysis | `db.ai_interactions.find().sort({created_at: -1})` |
| `ai_interactions` | `type` | Filter by interaction type | `db.ai_interactions.find({type: "completion"})` |
| `analytics` | `event_type` | Event type filtering | `db.analytics.find({event_type: "document_uploaded"})` |
| `analytics` | `user_id` | User behavior tracking | `db.analytics.find({user_id: "auth0\|123"})` |
| `analytics` | `timestamp` | Time-series analysis | `db.analytics.find().sort({timestamp: -1})` |
| `files` | `user_id` | User file retrieval | `db.files.find({user_id: "auth0\|123"})` |

**Compound Indexes** (Multi-Field Queries):

| Collection | Fields | Purpose | Query Pattern |
|-----------|--------|---------|---------------|
| `conversations` | `{user_id: 1, created_at: -1}` | Paginated user conversation lists | User-specific conversations sorted by recency |
| `messages` | `{conversation_id: 1, created_at: 1}` | Chronological message retrieval | Messages for specific conversation in order |
| `documents` | `{user_id: 1, created_at: -1}` | Paginated user document lists | User-specific documents sorted by recency |
| `ai_interactions` | `{user_id: 1, created_at: -1, type: 1}` | User AI analytics queries | User-specific AI interactions by type and time |
| `analytics` | `{event_type: 1, timestamp: -1}` | Event analytics queries | Events by type sorted by recency |
| `files` | `{user_id: 1, created_at: -1}` | User file lists | User-specific files sorted by recency |

**Text Indexes** (Full-Text Search):

| Collection | Fields | Purpose |
|-----------|--------|---------|
| `documents` | `filename`, `metadata` | Enable keyword search on document names and custom metadata |

#### Index Performance Targets

| Metric | Target | Rationale |
|--------|--------|-----------|
| Query Execution Time (Indexed) | < 50ms | Ensure responsive user experience |
| Index Size Overhead | < 10% of total data size | Balance query performance with storage costs |
| Index Build Time | Background creation only | Avoid blocking database operations |

#### Index Maintenance Strategy

**Monitoring**:
- Utilize MongoDB profiler to log slow queries (> 100ms execution time)
- Analyze query execution plans using `explain()` to verify index usage
- Track index size growth relative to data size

**Optimization**:
- Review index usage statistics monthly
- Remove unused indexes identified by zero `accesses` count in `db.collection.aggregate([{$indexStats: {}}])`
- Create new indexes based on slow query analysis

**Reindexing**:
- Schedule reindex operations during maintenance windows (Tuesday 2:00 AM - 4:00 AM UTC)
- Use background index builds (`{background: true}`) to minimize impact on operations

---

#### 6.2.3.5 Partitioning Approach

**Current Strategy**: Single MongoDB instance or replica set without sharding (sufficient for initial deployment).

**Sharding Not Required Initially Because**:
- Dataset expected to remain under 500GB in first year
- Single replica set can handle anticipated query load (< 5,000 queries/second)
- Vertical scaling (upgrading instance size) sufficient for growth

**Future Horizontal Sharding Triggers**:

| Trigger Condition | Current Capacity | Action |
|------------------|------------------|--------|
| Dataset size exceeds 1TB | Single instance practical limit | Enable sharding |
| Read/write throughput exceeds 5,000 ops/sec | Single instance saturation | Enable sharding |
| Vertical scaling reaches practical limits | M40/M50 tier in MongoDB Atlas | Transition to sharding |
| Multi-tenancy requirements emerge | Single tenant architecture | Shard by tenant_id |

#### Recommended Shard Key Selection

**Primary Shard Key**: `user_id` or `tenant_id`

**Rationale**:
- **Query Targeting**: Most queries filter by `user_id`, enabling efficient routing to specific shards
- **Data Isolation**: User data naturally partitioned across shards for security and compliance
- **Scalability**: High cardinality field supports balanced distribution across shards
- **Multi-Tenancy**: Facilitates future tenant-level data isolation

**Alternative Shard Keys**:

| Shard Key | Pros | Cons | Use Case |
|-----------|------|------|----------|
| Hashed `_id` | Even distribution | Loses query targeting | No dominant query pattern |
| `created_at` | Time-based partitioning | Hot shard problem | Archival-focused workloads |
| Compound `{user_id, created_at}` | Combines targeting and chronology | Increased complexity | Complex query patterns |

**Sharding Considerations**:
- Avoid low-cardinality shard keys (e.g., `status` with only 3 values)
- Monitor shard distribution balance using MongoDB balancer
- Plan for zone sharding if geographic data residency required (GDPR compliance)

---

#### 6.2.3.6 Replication Configuration

#### MongoDB Replica Set Architecture

**Configuration**: 3-node replica set for high availability and read scalability.

**Node Roles**:

| Node | Role | Responsibilities | Deployment |
|------|------|-----------------|------------|
| **Primary** | Read/Write | Handles all write operations, primary source for reads | AWS Availability Zone 1 |
| **Secondary 1** | Read-Only Replica | Replicates from Primary, serves read queries | AWS Availability Zone 2 |
| **Secondary 2** | Read-Only Replica | Replicates from Primary, serves read queries | AWS Availability Zone 3 |

**Multi-AZ Deployment Benefits**:
- **High Availability**: Automatic failover if Primary fails
- **Disaster Recovery**: Data replicated across physically separate data centers
- **Reduced Latency**: Secondaries distributed geographically for read-heavy workloads
- **Maintenance Windows**: Perform rolling upgrades without downtime

#### Replication Mechanism

**Oplog-Based Replication**:
- Primary node records all write operations in operations log (oplog)
- Secondary nodes continuously pull oplog entries and apply them locally
- Asynchronous replication with eventual consistency (typically < 1 second lag)

**Replication Flow**:
```
Write Operation → Primary Node → Oplog → Secondary Nodes (async) → Data Synchronized
```

#### Write Concern Configuration

**Write Concern**: `majority`

**Behavior**:
- Application write operations wait for acknowledgment from a majority of replica set members (2 out of 3 nodes)
- Ensures write durability (data survives Primary failure)
- Prevents rollback scenarios during failover

**Trade-offs**:
- **Benefit**: Strong durability guarantee, no data loss on failover
- **Cost**: Slightly higher write latency (~5-10ms overhead for network round-trip to Secondary)

**Configuration Example**:
```python
# Pseudocode representation (not actual implementation)
result = db.documents.insert_one(
    document,
    write_concern=WriteConcern(w='majority', wtimeout=5000)
)
```

#### Read Concern Configuration

**Read Concern**: `majority`

**Use Cases**: Consistency-critical operations requiring latest committed data.

**Behavior**:
- Application reads data that has been acknowledged by a majority of replica set members
- Guarantees no rollback of read data during failover
- Essential for financial transactions, audit logs, compliance-critical operations

**Configuration Example**:
```python
# Pseudocode representation
document = db.documents.find_one(
    {'_id': document_id},
    read_concern=ReadConcern('majority')
)
```

#### Read Preference Strategy

**Read Preference Modes**:

| Mode | Use Case | Target Nodes | Rationale |
|------|----------|--------------|-----------|
| **primary** | Write operations, consistency-critical reads | Primary only | Guaranteed latest data |
| **secondaryPreferred** | Read-heavy analytics, reporting | Secondary (fallback: Primary) | Offload read traffic from Primary |
| **nearest** | Geographic distribution (future) | Node with lowest network latency | Minimize read latency for global users |

**Query Routing Strategy**:

| Query Type | Read Preference | Example Query |
|-----------|----------------|---------------|
| User profile reads | `primary` | `db.users.find_one({auth0_id: user_id})` |
| Conversation history | `secondaryPreferred` | `db.messages.find({conversation_id: conv_id})` |
| Analytics queries | `secondaryPreferred` | `db.analytics.aggregate([...])` |
| Document retrieval | `secondaryPreferred` | `db.documents.find({user_id: user_id})` |
| All write operations | `primary` (always) | `db.documents.insert_one(...)` |

**Read Distribution Benefits**:
- Offload 40% of read traffic to Secondary nodes
- Improve write throughput on Primary (reduced read contention)
- Scale read capacity horizontally by adding Secondary nodes

#### Replication Lag Monitoring

**Target Replication Lag**: < 1 second under normal conditions

**Monitoring Metrics**:

| Metric | Alert Threshold | Action |
|--------|----------------|--------|
| Replication lag | > 5 seconds | Investigate network issues, check Secondary resource utilization |
| Oplog window | < 1 hour | Increase oplog size to prevent Secondary falling behind |
| Heartbeat failures | > 3 consecutive failures | Check network connectivity, node health |

**Replication Lag Causes**:
- Network latency or packet loss between nodes
- Heavy write load exceeding Secondary replication capacity
- Secondary node resource constraints (CPU, disk I/O, memory)

#### Automatic Failover Process

**Failure Detection**:
- Replica set members exchange heartbeats every 2 seconds
- **Failure Detection Time**: 10 seconds (5 consecutive missed heartbeats)

**Election Process**:
- Remaining replica set members initiate election using Raft consensus protocol
- **Election Time**: < 5 seconds (typically 2-3 seconds)
- Secondary with highest priority and most up-to-date oplog elected as new Primary

**Total Failover Time**: < 15 seconds from Primary failure to new Primary elected

**Data Loss Guarantee**:
- **Zero data loss** for writes with `majority` write concern
- Uncommitted writes (without majority acknowledgment) may be rolled back

**Application Impact**:
- Brief connection errors (~10-15 seconds) as clients detect new Primary
- PyMongo and Motor drivers automatically reconnect to new Primary
- Implement automatic retry logic in application code for transient connection errors

**Failover Diagram**:

```mermaid
sequenceDiagram
    participant App as Application
    participant P as Primary Node
    participant S1 as Secondary 1
    participant S2 as Secondary 2
    
    Note over P,S2: Normal Operation
    App->>P: Write Request
    P->>S1: Oplog Replication
    P->>S2: Oplog Replication
    P-->>App: Write Acknowledged (majority)
    
    Note over P: Primary Failure Occurs
    P-xApp: Connection Lost
    
    Note over S1,S2: 10 seconds: Heartbeat Timeout
    S1->>S2: Initiate Election
    
    Note over S1,S2: < 5 seconds: Raft Election
    Note over S1: S1 Elected as New Primary
    
    App->>S1: Retry Write Request
    Note over S1: Now Primary
    S1->>S2: Oplog Replication
    S1-->>App: Write Acknowledged
    
    Note over App,S2: Total Downtime: < 15 seconds
```

---

#### 6.2.3.7 Backup Architecture

#### Automated Backup Strategy

**Backup Types and Schedules**:

| Backup Type | Frequency | Method | Storage Location | Retention Policy |
|------------|-----------|--------|------------------|------------------|
| **Full Backup** | Daily at 2:00 AM UTC | MongoDB Atlas automated or mongodump | S3 bucket: `app-backups` | 30 days (daily), 1 year (monthly) |
| **Point-in-Time Backup** | Continuous (oplog-based) | MongoDB Atlas continuous backup | MongoDB Atlas internal | 7 days rolling window |
| **Incremental Backup** | Every 6 hours | Changed documents only | S3 bucket: `app-backups` | 7 days |

#### Backup Lifecycle Management

**S3 Storage Class Transition**:

```mermaid
graph LR
    A[Day 1-30<br/>S3 Standard<br/>$0.023/GB/month] -->|After 30 days| B[Day 31-90<br/>S3 Infrequent Access<br/>$0.0125/GB/month]
    B -->|After 90 days| C[Day 91-365<br/>S3 Glacier<br/>$0.004/GB/month]
    C -->|After 1 year| D[Delete<br/>Except Monthly Backups]
    
    style A fill:#4CAF50
    style B fill:#8BC34A
    style C fill:#2196F3
    style D fill:#FF9800
```

**Lifecycle Rules**:
- **Day 1-30**: S3 Standard (high-frequency access)
- **Day 31-90**: S3 Standard-IA (reduced access, lower cost)
- **Day 91-365**: S3 Glacier (long-term archival, lowest cost)
- **After 1 Year**: Automatic deletion (except first-of-month backups retained indefinitely)

#### MongoDB Atlas Automated Backup Features

**Continuous Backup** (Recommended for Production):
- **Mechanism**: Continuous oplog backup every few seconds
- **Point-in-Time Recovery**: Restore to any second within 7-day window
- **Granularity**: 1-second precision for recovery point selection
- **Use Case**: Recover from data corruption, accidental deletion, application bugs

**Snapshot Backup** (Alternative):
- **Mechanism**: Full database snapshots at scheduled intervals
- **Frequency**: Configurable (hourly, daily, weekly)
- **Retention**: Customizable retention policies
- **Restoration**: Restore entire database to snapshot point

#### Backup Testing and Validation

**Quarterly Restore Drills**:

| Test Type | Frequency | Procedure | Success Criteria |
|-----------|-----------|-----------|------------------|
| **Full Restore** | Quarterly | Restore production backup to test environment | Database fully accessible, data integrity verified |
| **Point-in-Time Restore** | Quarterly | Restore to specific timestamp (e.g., 24 hours ago) | Data matches expected state at target time |
| **Partial Restore** | Quarterly | Restore single collection | Collection data complete, indexes intact |

**Validation Procedures**:
1. **Record Count Verification**: Compare document counts across all collections
2. **Data Integrity Checks**: Verify referential integrity (foreign key relationships)
3. **Index Validation**: Confirm all indexes recreated correctly
4. **Application Testing**: Execute critical application workflows against restored database
5. **Performance Testing**: Verify query performance matches production
6. **Documentation Update**: Document restore procedure with actual timings

**Restore Time Objectives**:
- **Full Database Restore**: < 2 hours (for 100GB database)
- **Single Collection Restore**: < 30 minutes
- **Point-in-Time Restore**: < 1 hour (MongoDB Atlas)

#### Cross-Region Disaster Recovery (Future Enhancement)

**Future Implementation**:
- **Secondary Backup Region**: Replicate backups to geographically distant AWS region (e.g., us-east-1 → us-west-2)
- **S3 Cross-Region Replication**: Asynchronous replication of `app-backups` bucket
- **Manual Failover**: Documented procedure for regional outage recovery
- **RPO**: < 1 hour (time since last backup replication)
- **RTO**: < 4 hours (time to restore and redirect traffic)

---

### 6.2.4 Data Management

#### 6.2.4.1 Migration Procedures

**Current Status**: No database migrations exist yet (no implementation code). This section documents the planned migration strategy for future development.

#### Planned Migration Framework

**Migration Tool Options**:
- **Custom Python Scripts**: Purpose-built migration scripts using PyMongo
- **MongoDB Migration Tools**: Community tools like `mongomigrate` or `migrate-mongo`
- **Application-Level Migrations**: Integrated into Flask application startup

**Migration Structure**:
```
migrations/
├── 001_create_users_collection.py
├── 002_add_preferences_field.py
├── 003_create_conversations_indexes.py
└── README.md
```

**Migration Script Template**:
```python
# Pseudocode representation (not actual implementation)
class Migration:
    def up(self, db):
        """Apply forward migration"""
        db.users.update_many(
            {},
            {'$set': {'preferences': {'theme': 'light', 'language': 'en'}}}
        )
    
    def down(self, db):
        """Rollback migration"""
        db.users.update_many(
            {},
            {'$unset': {'preferences': ''}}
        )
```

#### Migration Types

**Schema Migrations** (Add/Remove Fields):
```python
# Example: Add new field to existing documents
db.documents.update_many(
    {'tags': {'$exists': False}},  # Only documents without tags
    {'$set': {'tags': []}}
)
```

**Data Transformation Migrations**:
```python
# Example: Transform existing data format
for doc in db.documents.find({'old_format_field': {'$exists': True}}):
    new_value = transform(doc['old_format_field'])
    db.documents.update_one(
        {'_id': doc['_id']},
        {'$set': {'new_format_field': new_value}, '$unset': {'old_format_field': ''}}
    )
```

**Index Migrations**:
```python
# Example: Create new compound index
db.conversations.create_index([('user_id', 1), ('created_at', -1)], background=True)
```

#### Migration Execution Workflow

1. **Development Phase**:
   - Develop migration script with `up()` and `down()` methods
   - Test migration on local development database
   - Verify data integrity after migration
   - Test rollback procedure

2. **Staging Environment**:
   - Apply migration to staging database
   - Run full application test suite
   - Validate data consistency
   - Measure migration execution time
   - Verify rollback procedure

3. **Production Deployment**:
   - Schedule migration during maintenance window (Tuesday 2:00 AM - 4:00 AM UTC)
   - Create pre-migration full backup
   - Execute migration with monitoring
   - Validate migration success
   - Monitor application logs and metrics

4. **Post-Migration**:
   - Verify data integrity using validation queries
   - Monitor performance metrics for anomalies
   - Document migration execution time and issues encountered

#### Migration Version Tracking

**Migrations Collection**:
```json
{
  "_id": ObjectId("..."),
  "migration_id": "001_create_users_collection",
  "applied_at": ISODate("2024-01-15T02:05:00Z"),
  "execution_time_ms": 2340,
  "status": "completed"
}
```

**Migration Status**:
- `completed`: Migration applied successfully
- `failed`: Migration encountered error, rolled back
- `partial`: Migration partially completed, manual intervention required

---

#### 6.2.4.2 Versioning Strategy

**Current Approach**: Document versioning **not implemented initially** to reduce complexity.

#### Future Versioning Implementation

**Use Cases Requiring Versioning**:
- Audit trail for document changes (regulatory compliance)
- Collaborative editing with conflict resolution
- Undo/redo functionality for user actions
- Historical analysis of data changes

**Versioning Approach**: Embedded version field with separate history collection.

**Main Document** (Current Version):
```json
{
  "_id": ObjectId("507f1f77bcf86cd799439014"),
  "user_id": "auth0|123456789",
  "title": "Project Proposal",
  "content": "Updated project proposal content...",
  "version": 3,
  "updated_at": ISODate("2024-01-15T10:30:00Z")
}
```

**History Collection** (Version History):
```json
{
  "_id": ObjectId("..."),
  "document_id": ObjectId("507f1f77bcf86cd799439014"),
  "version": 2,
  "content": "Previous project proposal content...",
  "changed_by": "auth0|123456789",
  "changed_at": ISODate("2024-01-14T15:20:00Z"),
  "change_type": "update"
}
```

**Versioning Operations**:

| Operation | Main Document | History Collection |
|-----------|---------------|-------------------|
| **Create** | Insert v1 | No history entry |
| **Update** | Update to v2, store old version in history | Insert v1 history entry |
| **Retrieve Version** | Query history collection by version number | Return specific version |
| **List Versions** | Query history collection by document_id | Return all versions |

**Version Retention Policy**:
- **Recent Versions**: Keep last 30 days of versions online (MongoDB)
- **Archival**: Move older versions to S3 cold storage
- **Compliance**: Retain versions for 7 years in S3 Glacier (audit requirements)

---

#### 6.2.4.3 Archival Policies

#### Data Retention Rules by Data Type

| Data Type | Active Retention | Archival Trigger | Archival Storage | Deletion Policy |
|-----------|-----------------|------------------|------------------|-----------------|
| **User Profiles** | Indefinite | N/A | N/A | Delete on account closure + 30 days |
| **Conversations** | Indefinite (user-controlled) | 1 year inactive | S3 Standard-IA | User can delete anytime |
| **Messages** | Indefinite (user-controlled) | 1 year inactive | S3 Standard-IA | Deleted with parent conversation |
| **AI Interactions** | 6 months online | 6 months age | S3 Standard-IA | Automatic deletion after 2 years |
| **Analytics Events** | 3 months online | 3 months age | S3 Standard-IA | Automatic deletion after 1 year |
| **Audit Logs** | 90 days online | 90 days age | S3 Glacier | Automatic deletion after 7 years |
| **Document Metadata** | Indefinite | N/A | N/A | User can delete anytime |

#### Archival Process Workflow

**Automated Archival Pipeline**:

```mermaid
flowchart TD
    A[Daily Cron Job<br/>2:00 AM UTC] --> B{Identify Documents<br/>Meeting Archival Criteria}
    
    B --> C[Query MongoDB:<br/>created_at < 6 months]
    
    C --> D[Export Documents<br/>to Parquet/JSON]
    
    D --> E[Upload to S3<br/>Bucket: app-archives]
    
    E --> F{Verify Successful<br/>S3 Upload}
    
    F -->|Success| G[Delete from MongoDB]
    F -->|Failed| H[Log Error,<br/>Retry Next Day]
    
    G --> I[Update Archive Metadata<br/>in archives_index Collection]
    
    I --> J[Send Archive Summary<br/>to Operations Team]
    
    H --> J
```

**Archival Execution Steps**:

1. **Identification**: Query MongoDB for documents exceeding retention period
   ```python
   # Pseudocode
   cutoff_date = datetime.now() - timedelta(days=180)
   docs_to_archive = db.ai_interactions.find({'created_at': {'$lt': cutoff_date}})
   ```

2. **Export**: Convert documents to archival format (Parquet for analytics, JSON for general data)
   ```python
   # Pseudocode
   df = pd.DataFrame(list(docs_to_archive))
   df.to_parquet('ai_interactions_2024_q1.parquet', compression='gzip')
   ```

3. **Upload**: Transfer to S3 with appropriate storage class
   ```python
   # Pseudocode
   s3_client.upload_file(
       'ai_interactions_2024_q1.parquet',
       'app-archives',
       'ai_interactions/2024/q1/data.parquet',
       ExtraArgs={'StorageClass': 'STANDARD_IA'}
   )
   ```

4. **Verification**: Confirm successful S3 upload and data integrity
   ```python
   # Pseudocode
   s3_object = s3_client.head_object(Bucket='app-archives', Key='...')
   assert s3_object['ContentLength'] == local_file_size
   ```

5. **Deletion**: Remove archived documents from MongoDB
   ```python
   # Pseudocode
   db.ai_interactions.delete_many({'_id': {'$in': archived_doc_ids}})
   ```

6. **Metadata Update**: Store archive location reference
   ```json
   {
     "_id": ObjectId("..."),
     "collection": "ai_interactions",
     "period": "2024-Q1",
     "document_count": 125000,
     "s3_key": "ai_interactions/2024/q1/data.parquet",
     "archived_at": ISODate("2024-07-15T02:30:00Z")
   }
   ```

#### Archive Retrieval Process

**Use Cases for Archive Retrieval**:
- Compliance audit requests
- User requests for historical data
- Legal discovery requests
- Long-term trend analysis

**Retrieval Procedure**:
1. Query `archives_index` collection to locate archive file
2. Download archive file from S3
3. Load data into temporary analysis environment
4. Extract requested data
5. Optionally restore to MongoDB if frequent access needed

---

#### 6.2.4.4 Data Storage and Retrieval Mechanisms

#### MongoDB Connection Management

**Driver Selection**:

| Driver | Type | Use Case | Version |
|--------|------|----------|---------|
| **PyMongo** | Synchronous | Traditional Flask views, batch jobs | 4.6+ |
| **Motor** | Asynchronous | FastAPI async endpoints, high concurrency | 3.3+ |

**Connection String Management**:
```python
# Pseudocode representation (not actual implementation)
# Connection string retrieved from AWS Secrets Manager
secret = secrets_client.get_secret_value(SecretId='prod/mongodb/connection')
connection_string = json.loads(secret['SecretString'])['MONGODB_URI']

client = MongoClient(
    connection_string,
    maxPoolSize=50,
    minPoolSize=10,
    serverSelectionTimeoutMS=5000
)
```

**Connection Pooling Configuration**:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `maxPoolSize` | 50 connections per API instance | Balance concurrency with MongoDB connection limits |
| `minPoolSize` | 10 connections | Maintain ready connections, reduce latency |
| `maxIdleTimeMS` | 30000 (30 seconds) | Close idle connections to free resources |
| `serverSelectionTimeoutMS` | 5000 (5 seconds) | Fail fast on connection issues |
| `socketTimeoutMS` | 30000 (30 seconds) | Timeout for individual operations |

#### Query Patterns and Best Practices

**Single Document Retrieval**:
```python
# Pseudocode: Fetch single document by ID with user authorization
document = db.documents.find_one({
    '_id': ObjectId(document_id),
    'user_id': user_id  # Ensure user owns document
})

if not document:
    raise NotFoundError("Document not found or access denied")
```

**Paginated List Queries**:
```python
# Pseudocode: Paginated user documents sorted by recency
page = 1
limit = 20
skip = (page - 1) * limit

documents = db.documents.find({'user_id': user_id}) \
    .sort('created_at', -1) \
    .skip(skip) \
    .limit(limit)

total_count = db.documents.count_documents({'user_id': user_id})

return {
    'documents': list(documents),
    'page': page,
    'limit': limit,
    'total': total_count,
    'has_more': skip + limit < total_count
}
```

**Aggregation Pipeline Queries**:
```python
# Pseudocode: User AI usage analytics
pipeline = [
    # Stage 1: Filter by user and date range
    {
        '$match': {
            'user_id': user_id,
            'created_at': {'$gte': start_date, '$lte': end_date}
        }
    },
    # Stage 2: Group by interaction type, sum tokens
    {
        '$group': {
            '_id': '$type',
            'total_interactions': {'$sum': 1},
            'total_tokens': {'$sum': '$tokens'},
            'total_cost': {'$sum': '$cost'}
        }
    },
    # Stage 3: Sort by cost descending
    {
        '$sort': {'total_cost': -1}
    }
]

results = list(db.ai_interactions.aggregate(pipeline))
```

**Bulk Write Operations**:
```python
# Pseudocode: Batch insert multiple documents
from pymongo import InsertOne

operations = [InsertOne(doc) for doc in documents_list]

result = db.documents.bulk_write(
    operations,
    ordered=False,  # Continue on error
    write_concern=WriteConcern(w='majority')
)

print(f"Inserted: {result.inserted_count}, Errors: {len(result.write_errors)}")
```

#### Write Operations with Error Handling

**Insert with Write Concern**:
```python
# Pseudocode: Insert document with majority write concern
from pymongo.write_concern import WriteConcern

result = db.documents.insert_one(
    document,
    write_concern=WriteConcern(w='majority', wtimeout=5000)
)

document_id = result.inserted_id
```

**Update with Optimistic Locking**:
```python
# Pseudocode: Update document with version check (prevent concurrent updates)
result = db.documents.update_one(
    {'_id': document_id, 'version': current_version},
    {
        '$set': {'content': new_content, 'updated_at': datetime.utcnow()},
        '$inc': {'version': 1}
    }
)

if result.matched_count == 0:
    raise ConflictError("Document was modified by another user")
```

**Delete with Cascade**:
```python
# Pseudocode: Delete conversation and all messages (cascade delete)
# Start transaction for atomicity
with client.start_session() as session:
    with session.start_transaction():
        # Delete all messages
        db.messages.delete_many({'conversation_id': conversation_id}, session=session)
        
        # Delete conversation
        result = db.conversations.delete_one({'_id': conversation_id}, session=session)
        
        if result.deleted_count == 0:
            raise NotFoundError("Conversation not found")
```

---

#### 6.2.4.5 Caching Policies

**Comprehensive caching strategy covered in Section 6.2.5 Performance Optimization → 6.2.5.2 Caching Strategy**

---

### 6.2.5 Compliance Considerations

#### 6.2.5.1 Data Retention Rules

**Regulatory Framework**: System designed for compliance with GDPR (General Data Protection Regulation) and CCPA (California Consumer Privacy Act).

#### Active User Data Retention

| Data Category | Retention While Active | Inactive User Policy | Rationale |
|---------------|----------------------|---------------------|-----------|
| **User Profiles** | Indefinite | Retain 2 years after last login | Support account recovery, maintain service continuity |
| **Conversations** | Indefinite (user-controlled) | Retain 2 years after last access | User may return, conversations have long-term value |
| **Documents** | Indefinite (user-controlled) | Retain 2 years after last access | User data ownership principle |
| **AI Interactions** | 2 years online | Archive after 6 months | Cost tracking, compliance audit trail |
| **Analytics Events** | 1 year online | Archive after 3 months | Product analytics, trend analysis |

#### Account Deletion and Right to be Forgotten

**User-Initiated Deletion** (GDPR Article 17):

1. **Grace Period**: 30-day soft delete (account can be restored)
   ```json
   {
     "_id": ObjectId("..."),
     "auth0_id": "auth0|123",
     "status": "pending_deletion",
     "deletion_requested_at": ISODate("2024-01-15T10:30:00Z"),
     "deletion_scheduled_for": ISODate("2024-02-14T10:30:00Z")
   }
   ```

2. **Permanent Deletion** (After 30 days):
   - Delete user profile from `users` collection
   - Delete all conversations and messages
   - Delete all documents metadata (S3 objects deleted)
   - Delete all files metadata (S3 objects deleted)
   - **Anonymize** user_id in analytics and AI interactions (cannot delete aggregated data)
   ```python
   # Pseudocode: Anonymize user_id in historical data
   anonymized_id = hashlib.sha256(user_id.encode()).hexdigest()
   db.analytics.update_many(
       {'user_id': user_id},
       {'$set': {'user_id': anonymized_id}}
   )
   ```

3. **Deletion Certificate**: Generate compliance record
   ```json
   {
     "_id": ObjectId("..."),
     "original_user_id": "REDACTED",
     "deletion_requested_at": ISODate("2024-01-15T10:30:00Z"),
     "deletion_completed_at": ISODate("2024-02-14T10:35:00Z"),
     "data_categories_deleted": [
       "user_profile", "conversations", "messages", "documents", "files"
     ],
     "data_categories_anonymized": ["analytics", "ai_interactions"],
     "deletion_confirmed_by": "automated_process"
   }
   ```

**Exception: Anonymized Aggregated Data**:
- Aggregated analytics cannot be deleted (statistical data, no PII)
- User_id replaced with irreversible cryptographic hash
- Ensures compliance while maintaining business intelligence

#### Audit Log Retention

**Compliance Requirement**: Retain audit logs for 7 years (varies by jurisdiction and industry).

**Audit Log Lifecycle**:
- **Day 1-90**: MongoDB `audit_logs` collection (hot storage, searchable)
- **Day 91-365**: S3 Standard-IA (warm storage, infrequent access)
- **Year 2-7**: S3 Glacier (cold storage, archival)
- **After 7 Years**: Automatic deletion

**Audit Log Access Control**:
- Restricted to compliance team and authorized auditors
- All audit log accesses logged in separate audit trail
- Annual review of access patterns

---

#### 6.2.5.2 Backup and Fault Tolerance Policies

#### Backup Compliance Requirements

**Data Protection Standards**:

| Requirement | Implementation | Compliance Standard |
|-------------|---------------|---------------------|
| **Daily Backups** | Automated daily at 2:00 AM UTC | SOC 2, ISO 27001 |
| **Retention Period** | 30 days online, 1 year archived | GDPR Article 32 (Security) |
| **Backup Testing** | Quarterly restore validation | SOC 2 CC7.4 |
| **Encryption at Rest** | AES-256 encryption | GDPR Article 32, CCPA |
| **Geographic Redundancy** | Cross-region backup (future) | Business continuity requirements |

#### Fault Tolerance Architecture

**High Availability Targets**:

| Component | Availability SLA | Mechanism | RTO | RPO |
|-----------|-----------------|-----------|-----|-----|
| **MongoDB** | 99.95% | 3-node replica set, auto-failover | < 10 seconds | 0 (majority write concern) |
| **Application** | 99.9% | Multi-AZ ECS deployment, auto-scaling | < 5 minutes | 0 (stateless) |
| **S3 Object Storage** | 99.99% | AWS managed redundancy | 0 (AWS SLA) | 0 (durable storage) |
| **Full System** | 99.9% | Combined fault tolerance | < 4 hours | < 1 hour |

**Disaster Scenarios and Recovery**:

| Scenario | Impact | Recovery Procedure | Estimated Downtime |
|----------|--------|-------------------|-------------------|
| **ECS Task Failure** | Single instance down | Automatic task restart | < 1 minute |
| **Availability Zone Failure** | 33% capacity reduction | ALB routes to healthy AZs | 0 (transparent failover) |
| **MongoDB Primary Failure** | Brief connection errors | Replica set auto-elects new Primary | < 15 seconds |
| **Region Failure** | Full service outage | Manual failover to secondary region | < 4 hours (future) |
| **Data Corruption** | Partial data loss | Restore from point-in-time backup | < 2 hours |

---

#### 6.2.5.3 Privacy Controls

#### Data Encryption

**Encryption at Rest**:

| Component | Encryption Method | Key Management | Standard Compliance |
|-----------|------------------|----------------|---------------------|
| **MongoDB** | WiredTiger storage engine encryption | AWS KMS or MongoDB encrypted storage engine | AES-256, FIPS 140-2 |
| **S3 Buckets** | Server-Side Encryption (SSE-S3) | AWS-managed keys | AES-256 |
| **S3 Backups** | Server-Side Encryption (SSE-KMS) | Customer-managed KMS keys | AES-256, audit trail |
| **Redis (Optional)** | ElastiCache encryption at rest | AWS-managed keys | AES-256 |

**Encryption in Transit**:

| Connection Type | Protocol | Certificate Management |
|----------------|----------|------------------------|
| **Client → ALB** | TLS 1.3 | AWS Certificate Manager (ACM) |
| **ALB → ECS** | HTTP (internal VPC) | Private network isolation |
| **ECS → MongoDB** | TLS 1.3 (MongoDB Wire Protocol over TLS) | MongoDB Atlas certificates or self-signed |
| **ECS → Redis** | TLS 1.3 (optional) | ElastiCache in-transit encryption |
| **ECS → S3** | HTTPS (TLS 1.3) | AWS managed |

#### PII (Personally Identifiable Information) Handling

**PII Classification**:

| Data Field | PII Category | Storage Location | Protection Measure |
|-----------|-------------|------------------|-------------------|
| `email` | Direct PII | MongoDB `users` collection | Encrypted at rest, access logged |
| `name` | Direct PII | Auth0 ID token (not stored) | Transient, not persisted |
| `auth0_id` | Pseudonymous identifier | MongoDB (all collections) | Pseudonymization |
| `ip_address` | Indirect PII | Audit logs | Encrypted at rest, 90-day retention |
| `user_id` (analytics) | Pseudonymous | Anonymized hash | One-way hash, irreversible |

**PII Protection Measures**:

**Logging Redaction**:
```python
# Pseudocode: Automatic PII redaction in logs
import logging

class PIIFilter(logging.Filter):
    def filter(self, record):
        record.msg = redact_sensitive_fields(
            record.msg,
            fields=['password', 'token', 'email', 'ssn', 'credit_card']
        )
        return True

logger.addFilter(PIIFilter())
```

**Field-Level Encryption** (Future Enhancement):
```python
# Pseudocode: Encrypt sensitive PII fields before storage
from cryptography.fernet import Fernet

encrypted_email = cipher.encrypt(email.encode())
db.users.update_one(
    {'_id': user_id},
    {'$set': {'email_encrypted': encrypted_email}}
)
```

**Access Audit Trail**:
```python
# Pseudocode: Log all PII accesses
db.audit_logs.insert_one({
    'timestamp': datetime.utcnow(),
    'user_id': admin_user_id,
    'action': 'READ_PII',
    'resource_type': 'users',
    'resource_id': user_id,
    'fields_accessed': ['email', 'name'],
    'ip_address': request.remote_addr,
    'justification': 'Customer support ticket #12345'
})
```

#### Data Anonymization for Analytics

**Anonymization Techniques**:

| Technique | Use Case | Reversibility | GDPR Compliance |
|-----------|----------|---------------|-----------------|
| **Hashing** | User analytics (user_id → hash) | Irreversible (SHA-256) | Fully anonymized |
| **Pseudonymization** | Internal analytics (auth0_id) | Reversible with key | Pseudonymous (still PII) |
| **Aggregation** | Statistical analysis | N/A (no individual data) | Fully anonymized |
| **Differential Privacy** | Research datasets (future) | N/A (statistical noise added) | Fully anonymized |

**Anonymization Example**:
```python
# Pseudocode: Anonymize user_id for research dataset export
import hashlib

def anonymize_user_id(user_id):
    """Irreversibly anonymize user_id"""
    salt = os.environ['ANONYMIZATION_SALT']
    return hashlib.sha256(f"{user_id}{salt}".encode()).hexdigest()

research_data = db.analytics.find({})
for record in research_data:
    record['user_id'] = anonymize_user_id(record['user_id'])
    export_to_csv(record)
```

---

#### 6.2.5.4 Audit Mechanisms

#### Comprehensive Audit Logging

**Audit Log Scope**: All data access, modifications, and deletions logged for compliance and security.

**Audit Log Schema** (`audit_logs` collection):
```json
{
  "_id": ObjectId("..."),
  "timestamp": ISODate("2024-01-15T10:30:00Z"),
  "user_id": "auth0|123456789",
  "action": "UPDATE",
  "resource_type": "documents",
  "resource_id": "507f1f77bcf86cd799439014",
  "ip_address": "203.0.113.45",
  "user_agent": "Mozilla/5.0...",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "changes": {
    "before": {"title": "Old Title"},
    "after": {"title": "New Title"}
  },
  "status": "success"
}
```

**Logged Actions**:

| Action Type | Examples | Retention |
|------------|----------|-----------|
| **CREATE** | New document, new user | 7 years |
| **READ** | View PII, access sensitive data | 7 years |
| **UPDATE** | Modify document, change settings | 7 years |
| **DELETE** | Delete document, delete account | 7 years |
| **AUTH** | Login, logout, token refresh | 1 year |
| **ADMIN** | Admin actions, permission changes | 7 years |

#### Audit Query Capabilities

**Common Audit Queries**:

**View all actions by user**:
```python
# Pseudocode
audit_trail = db.audit_logs.find(
    {'user_id': 'auth0|123456789'}
).sort('timestamp', -1).limit(100)
```

**View all accesses to specific resource**:
```python
# Pseudocode
access_log = db.audit_logs.find({
    'resource_type': 'documents',
    'resource_id': '507f1f77bcf86cd799439014',
    'action': 'READ'
}).sort('timestamp', -1)
```

**Compliance report (all PII accesses in last 90 days)**:
```python
# Pseudocode
from datetime import datetime, timedelta

ninety_days_ago = datetime.utcnow() - timedelta(days=90)

pii_accesses = db.audit_logs.find({
    'timestamp': {'$gte': ninety_days_ago},
    'resource_type': 'users',
    'action': 'READ'
}).sort('timestamp', -1)
```

#### Audit Trail Integrity

**Immutability**:
- Audit logs are **append-only** (no updates or deletes allowed)
- Write permissions restricted to audit logging service
- Read permissions restricted to compliance team and auditors

**Cryptographic Signatures** (Future Enhancement):
```python
# Pseudocode: Sign audit log entries for tamper detection
import hmac
import hashlib

def sign_audit_entry(entry, secret_key):
    """Generate HMAC signature for audit entry"""
    entry_json = json.dumps(entry, sort_keys=True)
    signature = hmac.new(
        secret_key.encode(),
        entry_json.encode(),
        hashlib.sha256
    ).hexdigest()
    entry['signature'] = signature
    return entry
```

**Regular Audit Log Exports**:
- **Frequency**: Weekly export to immutable S3 bucket
- **S3 Object Lock**: Enable WORM (Write Once Read Many) mode
- **Retention**: 7 years in S3 Glacier with compliance mode
- **Verification**: Monthly audit log integrity checks

---

#### 6.2.5.5 Access Controls

#### Database Access Control (RBAC)

**MongoDB User Roles**:

| Role Name | Permissions | Purpose | Assigned To |
|-----------|------------|---------|-------------|
| **application** | Read/write on application collections | Normal application operations | ECS tasks (via IAM role) |
| **backup** | Read-only on all collections | Backup job operations | Backup service |
| **analytics** | Read-only on non-PII fields | Business intelligence queries | Analytics service |
| **admin** | Full database access | Emergency operations, migrations | Database administrators |
| **auditor** | Read-only on audit_logs | Compliance auditing | Compliance team |

**MongoDB Authentication**:
- **Mechanism**: SCRAM-SHA-256 (Salted Challenge Response Authentication Mechanism)
- **Credential Storage**: AWS Secrets Manager (rotated quarterly)
- **Connection String Format**: `mongodb://username:password@host:port/database?authSource=admin`

**Application Role Permissions** (Detailed):
```javascript
// Pseudocode: MongoDB role definition
db.createRole({
  role: "application",
  privileges: [
    {
      resource: { db: "app_db", collection: "users" },
      actions: ["find", "insert", "update", "remove"]
    },
    {
      resource: { db: "app_db", collection: "conversations" },
      actions: ["find", "insert", "update", "remove"]
    },
    // ... other collections
  ],
  roles: []
})
```

#### Application-Level Access Control

**Permission-Based Access Control (PBAC)**:

**JWT Token Claims**:
```json
{
  "sub": "auth0|123456789",
  "permissions": [
    "read:documents",
    "write:documents",
    "delete:documents",
    "read:users"
  ],
  "aud": "https://api.example.com",
  "iss": "https://example.auth0.com/",
  "exp": 1705320600
}
```

**Permission Enforcement**:
```python
# Pseudocode: Endpoint-level permission check
@app.route('/api/v1/documents', methods=['POST'])
@require_auth  # JWT validation
@require_permissions(['write:documents'])  # Permission check
def create_document():
    # User has write:documents permission, proceed
    document = create_document_in_db(request.json)
    return jsonify(document), 201
```

**Resource-Level Authorization**:
```python
# Pseudocode: Verify resource ownership
@app.route('/api/v1/documents/<document_id>', methods=['GET'])
@require_auth
@require_permissions(['read:documents'])
def get_document(document_id):
    document = db.documents.find_one({'_id': ObjectId(document_id)})
    
    # Verify user owns document or document is shared with user
    if document['user_id'] != request.user_id:
        if request.user_id not in document.get('shared_with', []):
            return jsonify({'error': 'Forbidden'}), 403
    
    return jsonify(document), 200
```

**Administrative Access**:
```python
# Pseudocode: Admin permission grants full access
if 'admin:system' in request.user_permissions:
    # Bypass resource ownership checks
    document = db.documents.find_one({'_id': ObjectId(document_id)})
    return jsonify(document), 200
```

#### Network Security

**VPC Isolation**:
- **MongoDB Deployment**: Private subnets only (no public internet access)
- **ECS Tasks**: Private subnets with NAT Gateway for outbound internet
- **ALB**: Public subnets (internet-facing)

**Security Groups**:

| Component | Inbound Rules | Outbound Rules |
|-----------|--------------|----------------|
| **ALB** | Port 443 (HTTPS) from 0.0.0.0/0 | Port 5000 to ECS security group |
| **ECS Tasks** | Port 5000 from ALB security group | All ports to MongoDB, Redis, S3, internet |
| **MongoDB** | Port 27017 from ECS security group | None (no outbound required) |
| **Redis** | Port 6379 from ECS security group | None |

**IP Allowlisting** (MongoDB Atlas):
- If using MongoDB Atlas, configure IP allowlist
- Add NAT Gateway Elastic IP addresses
- No public internet access (0.0.0.0/0 blocked)

---

### 6.2.6 Performance Optimization

#### 6.2.6.1 Query Optimization Patterns

#### Index Usage Verification

**Query Execution Plan Analysis**:
```python
# Pseudocode: Analyze query performance with explain()
explain_result = db.documents.find({
    'user_id': 'auth0|123456789',
    'created_at': {'$gte': start_date}
}).sort('created_at', -1).explain('executionStats')

#### Key metrics to review:
#### - executionTimeMillis: Query execution time
#### - totalKeysExamined: Number of index keys scanned
#### - totalDocsExamined: Number of documents scanned
#### - executionStages: Index usage details

#### Optimal: totalKeysExamined ≈ totalDocsExamined (index covers query)
```

**Query Optimization Checklist**:

| Optimization | Implementation | Impact |
|-------------|----------------|--------|
| **Use Indexes** | Verify `explain()` shows index usage | 10-100x faster queries |
| **Projection** | Return only required fields (`find({}, {title: 1, _id: 1})`) | Reduce network transfer by 50-80% |
| **Limit Results** | Always paginate large result sets | Prevent memory exhaustion |
| **Avoid Collection Scans** | Ensure queries use indexes | 100x+ performance improvement |
| **Compound Index Order** | Match query filter order | Enable index covering |

#### Query Optimization Techniques

**Projection (Field Selection)**:
```python
# BAD: Return entire document (100KB each)
documents = db.documents.find({'user_id': user_id})

#### GOOD: Return only required fields (5KB each)
documents = db.documents.find(
    {'user_id': user_id},
    {'_id': 1, 'title': 1, 'created_at': 1}  # Projection
)
#### Impact: 95% reduction in network transfer
```

**Limit and Skip (Pagination)**:
```python
# BAD: Fetch all documents (potential OOM error)
documents = list(db.documents.find({'user_id': user_id}))

#### GOOD: Paginate results (safe memory usage)
documents = db.documents.find({'user_id': user_id}) \
    .sort('created_at', -1) \
    .skip((page - 1) * limit) \
    .limit(limit)
```

**Aggregation Pipeline (Push Transformations to Database)**:
```python
# BAD: Fetch all data, process in Python
all_interactions = list(db.ai_interactions.find({'user_id': user_id}))
total_tokens = sum(doc['tokens'] for doc in all_interactions)

#### GOOD: Use aggregation pipeline (database-side processing)
pipeline = [
    {'$match': {'user_id': user_id}},
    {'$group': {'_id': None, 'total_tokens': {'$sum': '$tokens'}}}
]
result = list(db.ai_interactions.aggregate(pipeline))[0]
total_tokens = result['total_tokens']
#### Impact: 10-100x faster for large datasets
```

**Index Hints (Force Specific Index)**:
```python
# Force MongoDB to use specific compound index
documents = db.documents.find({'user_id': user_id, 'status': 'active'}) \
    .hint([('user_id', 1), ('created_at', -1)]) \
    .sort('created_at', -1)
```

#### Query Performance Monitoring

**MongoDB Profiler**:
```python
# Enable profiling for slow queries (> 100ms)
db.set_profiling_level(1, slow_ms=100)

#### Query slow operations
slow_queries = db.system.profile.find({
    'millis': {'$gt': 100}
}).sort('ts', -1).limit(20)

for query in slow_queries:
    print(f"Slow query: {query['ns']}, Time: {query['millis']}ms")
    print(f"Query: {query['command']}")
```

**Query Performance Targets**:

| Query Type | Target Latency | Alert Threshold |
|-----------|---------------|-----------------|
| **Indexed Single Document Lookup** | < 10ms | > 50ms |
| **Indexed List Query** (paginated) | < 50ms | > 100ms |
| **Aggregation Query** | < 300ms | > 1000ms |
| **Full Collection Scan** | Avoid entirely | Alert immediately |

---

#### 6.2.6.2 Caching Strategy

#### Multi-Layer Caching Architecture

```mermaid
graph TB
    Client[Client Application]
    
    subgraph "Caching Layers"
        L1[Layer 1: Client Cache<br/>Browser/App Memory]
        L2[Layer 2: CDN Cache<br/>CloudFront]
        L3[Layer 3: Application Cache<br/>Redis]
        L4[Layer 4: Database Cache<br/>MongoDB WiredTiger]
    end
    
    Database[(MongoDB Database)]
    
    Client -->|1. Request| L1
    L1 -->|Cache Miss| L2
    L2 -->|Cache Miss| L3
    L3 -->|Cache Miss| L4
    L4 -->|Cache Miss| Database
    
    Database -.->|Data| L4
    L4 -.->|Data + Cache| L3
    L3 -.->|Data + Cache| L2
    L2 -.->|Data + Cache| L1
    L1 -.->|Data| Client
    
    style L1 fill:#E8F5E9
    style L2 fill:#FFF9C4
    style L3 fill:#FFE0B2
    style L4 fill:#F3E5F5
    style Database fill:#E3F2FD
```

**Layer Comparison**:

| Layer | Technology | Scope | TTL Range | Target Hit Rate | Purpose |
|-------|-----------|-------|-----------|-----------------|---------|
| **Layer 1** | Browser Cache, App Memory | Per-user, device-local | 0 - 1 hour | 40% | Reduce API calls, instant UI updates |
| **Layer 2** | CloudFront CDN | Edge locations, global | 0 - 1 year | 80% (static assets) | Reduce latency, offload origin |
| **Layer 3** | Redis | Backend services, shared | 30s - 24h | 70% | Reduce database load, share across instances |
| **Layer 4** | MongoDB WiredTiger | Database internal | Auto-managed | 60% | Optimize disk I/O, speed up queries |

#### Redis Cache Implementation (Layer 3)

**Use Cases and Data Structures**:

| Use Case | Redis Data Structure | Key Pattern | TTL | Purpose |
|----------|---------------------|-------------|-----|---------|
| **API Response Cache** | String (JSON) | `cache:{endpoint}:{user_id}:{params_hash}` | 5-60 min | Cache expensive database queries |
| **JWKS Cache** | String (JSON) | `jwks:auth0` | 1 hour | Cache Auth0 public keys for JWT validation |
| **Rate Limiting** | String (counter) | `ratelimit:{user_id}:{endpoint}` | 1 minute | Track API request counts per user |
| **LLM Response Cache** | String (JSON) | `llm:{prompt_hash}` | 1 hour | Cache identical LLM prompts (expensive) |
| **Distributed Lock** | String (SET NX EX) | `lock:{resource_id}` | 30 seconds | Prevent cache stampede |
| **Session Storage** | Hash | `session:{session_id}` | 15 minutes | Store temporary session data |

#### Cache-Aside Pattern (Primary Strategy)

```mermaid
flowchart TD
    Start[API Request] --> CheckCache{Check Redis<br/>Cache}
    
    CheckCache -->|Cache Hit| CacheHit[Return Cached Data]
    CheckCache -->|Cache Miss| CacheMiss[Cache Miss]
    
    CacheMiss --> AcquireLock{Try Acquire<br/>Distributed Lock}
    
    AcquireLock -->|Lock Acquired| QueryDB[Query MongoDB]
    AcquireLock -->|Lock Held by Other| WaitRetry[Wait 50ms,<br/>Retry Check Cache]
    
    WaitRetry --> CheckCache
    
    QueryDB --> Transform[Transform Data]
    Transform --> StoreCache[Store in Redis<br/>with TTL]
    StoreCache --> ReleaseLock[Release Lock]
    ReleaseLock --> Return[Return Data to Client]
    
    CacheHit --> LogHit[Log Cache Hit Metric]
    Return --> LogMiss[Log Cache Miss Metric]
    
    LogHit --> End[End]
    LogMiss --> End
    
    style CacheHit fill:#C8E6C9
    style CacheMiss fill:#FFCCBC
    style AcquireLock fill:#FFF9C4
    style QueryDB fill:#BBDEFB
```

**Implementation Pseudocode**:
```python
# Pseudocode: Cache-aside pattern implementation
def get_documents(user_id, page, limit):
    # Generate cache key
    cache_key = f"cache:documents:{user_id}:page{page}:limit{limit}"
    
    # 1. Check cache
    cached_data = redis_client.get(cache_key)
    if cached_data:
        metrics.increment('cache.hit', tags=['endpoint:documents'])
        return json.loads(cached_data)
    
    # 2. Cache miss - acquire lock to prevent stampede
    lock_key = f"lock:documents:{user_id}"
    lock_acquired = redis_client.set(lock_key, '1', nx=True, ex=30)
    
    if not lock_acquired:
        # Another process is fetching data, wait and retry
        time.sleep(0.05)  # 50ms
        return get_documents(user_id, page, limit)  # Retry
    
    try:
        # 3. Query database
        documents = db.documents.find({'user_id': user_id}) \
            .sort('created_at', -1) \
            .skip((page - 1) * limit) \
            .limit(limit)
        
        result = list(documents)
        
        # 4. Store in cache
        redis_client.setex(
            cache_key,
            300,  # 5 minutes TTL
            json.dumps(result, default=str)
        )
        
        metrics.increment('cache.miss', tags=['endpoint:documents'])
        return result
        
    finally:
        # 5. Release lock
        redis_client.delete(lock_key)
```

#### Cache Invalidation Strategies

**Time-Based Expiration (TTL)** - Primary Method:

| Data Type | TTL | Rationale |
|-----------|-----|-----------|
| **Static Configuration** | 24 hours | Rarely changes, safe to cache long |
| **User Profile** | 15 minutes | Matches JWT token lifetime, consistency |
| **API Responses (General)** | 5 minutes | Balance freshness and performance |
| **API Responses (Real-Time)** | 30 seconds | Near real-time data (e.g., active users) |
| **LLM Responses** | 1 hour | Expensive to regenerate, acceptable staleness |
| **JWKS Keys** | 1 hour | Auth0 rotates keys infrequently |

**Event-Based Invalidation** - On Write Operations:
```python
# Pseudocode: Invalidate related cache keys on document creation
def create_document(user_id, document_data):
    # 1. Insert document into MongoDB
    result = db.documents.insert_one(document_data)
    
    # 2. Invalidate all document list cache keys for this user
    pattern = f"cache:documents:{user_id}:*"
    for key in redis_client.scan_iter(match=pattern):
        redis_client.delete(key)
    
    # 3. Optionally invalidate user statistics cache
    redis_client.delete(f"cache:user_stats:{user_id}")
    
    return result
```

**Probabilistic Early Expiration** - Refresh Before TTL Expiry:
```python
# Pseudocode: Refresh cache probabilistically before expiration
import random

def get_cached_data(cache_key, fetch_function, ttl=300):
    cached_data, remaining_ttl = redis_client.get_with_ttl(cache_key)
    
    if cached_data:
        # Probabilistically refresh cache before expiration
        # Higher probability as TTL approaches expiration
        refresh_probability = 1 - (remaining_ttl / ttl)
        
        if random.random() < refresh_probability:
            # Asynchronously refresh cache in background
            background_task(refresh_cache, cache_key, fetch_function, ttl)
        
        return cached_data
    
    # Cache miss, fetch and store
    data = fetch_function()
    redis_client.setex(cache_key, ttl, data)
    return data
```

**Manual Invalidation** - Administrative Override:
```python
# Pseudocode: Admin endpoint to clear specific cache patterns
@app.route('/admin/cache/clear', methods=['POST'])
@require_admin_permission
def clear_cache():
    pattern = request.json.get('pattern')  # e.g., "cache:documents:*"
    
    deleted_count = 0
    for key in redis_client.scan_iter(match=pattern):
        redis_client.delete(key)
        deleted_count += 1
    
    return {'deleted_keys': deleted_count}, 200
```

#### Cache Performance Monitoring

**Key Metrics**:

| Metric | Target | Alert Threshold | Action |
|--------|--------|----------------|--------|
| **Cache Hit Rate** | > 70% | < 60% | Review TTLs, cache key strategies |
| **Cache Memory Usage** | < 80% | > 90% | Scale Redis instance or evict data |
| **Evicted Keys** | < 1% of total | > 5% | Increase memory or reduce TTLs |
| **Average Response Time** | < 10ms | > 50ms | Check network latency, Redis load |

**Monitoring Implementation**:
```python
# Pseudocode: Cache metrics collection
class CacheMetrics:
    def record_hit(self, endpoint):
        metrics.increment('cache.hit', tags=[f'endpoint:{endpoint}'])
    
    def record_miss(self, endpoint):
        metrics.increment('cache.miss', tags=[f'endpoint:{endpoint}'])
    
    def calculate_hit_rate(self, endpoint):
        hits = metrics.count('cache.hit', tags=[f'endpoint:{endpoint}'])
        misses = metrics.count('cache.miss', tags=[f'endpoint:{endpoint}'])
        total = hits + misses
        return (hits / total * 100) if total > 0 else 0

#### CloudWatch custom metric
cloudwatch.put_metric_data(
    Namespace='Application/Cache',
    MetricData=[
        {
            'MetricName': 'CacheHitRate',
            'Value': hit_rate,
            'Unit': 'Percent'
        }
    ]
)
```

---

#### 6.2.6.3 Connection Pooling

#### MongoDB Connection Pool Configuration

**PyMongo Connection Pool**:
```python
# Pseudocode: MongoDB connection pool configuration
from pymongo import MongoClient

client = MongoClient(
    connection_string,
    maxPoolSize=50,        # Maximum connections per instance
    minPoolSize=10,        # Minimum idle connections maintained
    maxIdleTimeMS=30000,   # Close idle connections after 30 seconds
    waitQueueTimeoutMS=5000,  # Max wait time for available connection
    serverSelectionTimeoutMS=5000,  # Max time to select server
    socketTimeoutMS=30000  # Socket operation timeout
)
```

**Connection Pool Parameters**:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `maxPoolSize` | 50 connections per API instance | Balance concurrency with MongoDB connection limits (MongoDB Atlas M10 tier supports ~1,000 connections) |
| `minPoolSize` | 10 connections | Maintain ready connections, reduce latency for burst traffic |
| `maxIdleTimeMS` | 30,000ms (30 seconds) | Close idle connections to free resources |
| `waitQueueTimeoutMS` | 5,000ms (5 seconds) | Fail fast if pool exhausted |
| `serverSelectionTimeoutMS` | 5,000ms (5 seconds) | Fail fast on connection issues (replica set election, network problems) |

**Connection Pool Sizing Calculation**:
```
Ideal Pool Size = (Number of API Instances) × (Connections per Instance)

Example:
- 5 ECS tasks (API instances)
- 50 connections per task
- Total: 250 concurrent MongoDB connections

MongoDB Atlas M10 tier limit: 1,000 connections
Headroom: 75% available for scaling
```

#### Redis Connection Pool Configuration

**redis-py Connection Pool**:
```python
# Pseudocode: Redis connection pool configuration
import redis

pool = redis.ConnectionPool(
    host='redis.example.com',
    port=6379,
    db=0,
    max_connections=20,  # Maximum connections per instance
    socket_timeout=5,    # Socket operation timeout (seconds)
    socket_connect_timeout=5,  # Connection establishment timeout
    retry_on_timeout=True,  # Retry on timeout
    health_check_interval=30  # Health check frequency (seconds)
)

redis_client = redis.Redis(connection_pool=pool)
```

**Connection Pool Parameters**:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `max_connections` | 20 connections per API instance | Redis single-threaded, fewer connections needed than MongoDB |
| `socket_timeout` | 5 seconds | Fail fast on unresponsive Redis |
| `health_check_interval` | 30 seconds | Periodic connection health checks |

#### Connection Pool Benefits

| Benefit | Impact | Quantification |
|---------|--------|----------------|
| **Eliminate Connection Overhead** | Reduce latency | 50-100ms saved per request (no connection establishment) |
| **Improve Database Throughput** | Higher QPS | 10-20% throughput increase (reduced connection churn) |
| **Reduce Database Load** | Fewer authentication/authorization operations | 90% reduction in connection establishment operations |
| **Enable Burst Traffic Handling** | Pre-warmed connections ready | Handle 5x traffic spike without connection delays |

#### Connection Pool Monitoring

**Key Metrics**:

| Metric | Target | Alert Threshold | Action |
|--------|--------|----------------|--------|
| **Active Connections** | 30-70% of max | > 90% | Increase pool size or scale instances |
| **Connection Wait Time** | < 10ms | > 100ms | Pool exhausted, increase size |
| **Connection Errors** | 0 | > 1% of requests | Check network, database health |
| **Idle Connections** | 10-20% of max | < 5% or > 50% | Adjust minPoolSize |

---

#### 6.2.6.4 Read/Write Splitting

#### MongoDB Read Preference Strategy

**Read Preference Configuration**:

| Query Type | Read Preference | Target Nodes | Rationale |
|-----------|----------------|--------------|-----------|
| **All Writes** | `primary` | Primary only (required) | MongoDB writes always go to Primary |
| **Consistency-Critical Reads** | `primary` | Primary only | Latest data guaranteed (e.g., user profile after update) |
| **Analytics Queries** | `secondaryPreferred` | Secondary (fallback: Primary) | Offload read traffic from Primary |
| **Reporting Workloads** | `secondaryPreferred` | Secondary (fallback: Primary) | Acceptable eventual consistency |
| **Document Retrieval** | `secondaryPreferred` | Secondary (fallback: Primary) | User documents (non-critical staleness) |

**Implementation**:
```python
# Pseudocode: Read preference configuration
from pymongo import ReadPreference

#### Write operation (always Primary)
db.documents.insert_one(document)

#### Consistency-critical read (Primary)
user = db.users.find_one(
    {'auth0_id': user_id},
    read_preference=ReadPreference.PRIMARY
)

#### Analytics read (Secondary preferred)
messages = db.messages.find(
    {'conversation_id': conversation_id},
    read_preference=ReadPreference.SECONDARY_PREFERRED
).sort('created_at', 1)
```

#### Read Distribution and Benefits

**Traffic Distribution**:

```mermaid
pie title Read Traffic Distribution
    "Primary (Writes + Critical Reads)" : 60
    "Secondary 1 (Analytics Reads)" : 20
    "Secondary 2 (Analytics Reads)" : 20
```

**Performance Benefits**:

| Benefit | Impact | Quantification |
|---------|--------|----------------|
| **Offload Read Traffic** | Reduce Primary load | 40% of read traffic redirected to Secondaries |
| **Improve Write Throughput** | Reduce contention | 20-30% write throughput increase on Primary |
| **Scale Read Capacity** | Horizontal scaling | Add Secondary nodes to scale reads |
| **High Availability** | Continued reads during Primary failover | Read operations from Secondaries during election |

#### Replication Lag Considerations

**Acceptable Replication Lag**:

| Use Case | Max Acceptable Lag | Action if Exceeded |
|----------|-------------------|-------------------|
| **User Document Retrieval** | < 5 seconds | Acceptable for non-critical data |
| **Analytics Queries** | < 30 seconds | Large lag acceptable for historical analysis |
| **Real-Time Dashboards** | < 1 second | Fall back to Primary if lag > 1s |

**Replication Lag Monitoring**:
```python
# Pseudocode: Check replication lag before read
from pymongo import MongoClient

client = MongoClient(connection_string)
repl_status = client.admin.command('replSetGetStatus')

for member in repl_status['members']:
    if member['stateStr'] == 'SECONDARY':
        lag = member['optimeDate'] - repl_status['date']
        if lag.total_seconds() > 5:
            # Fall back to Primary
            read_preference = ReadPreference.PRIMARY
        else:
            read_preference = ReadPreference.SECONDARY_PREFERRED
```

---

#### 6.2.6.5 Batch Processing Approach

#### Bulk Write Operations

**PyMongo Bulk Write API**:
```python
# Pseudocode: Batch insert 1,000 documents
from pymongo import InsertOne, UpdateOne, DeleteOne

operations = []

#### Build bulk operations
for document in documents_list:
    operations.append(InsertOne(document))

#### Execute bulk write
result = db.documents.bulk_write(
    operations,
    ordered=False,  # Continue on error, don't stop at first failure
    write_concern=WriteConcern(w='majority')
)

print(f"Inserted: {result.inserted_count}")
print(f"Errors: {len(result.write_errors)}")
```

**Batch Write Benefits**:

| Benefit | Single Writes | Bulk Write (1,000 docs) | Improvement |
|---------|--------------|------------------------|-------------|
| **Network Round Trips** | 1,000 round trips | 1 round trip | 1000x reduction |
| **Execution Time** | 10,000ms | 500ms | 20x faster |
| **Connection Overhead** | High (per-operation) | Amortized | 95% reduction |

**Optimal Batch Size**: 1,000 documents per bulk operation (balance memory usage and performance).

#### Batch Query Operations

**Single Query with `$in` Operator**:
```python
# BAD: 100 individual queries (100 network round trips)
documents = []
for doc_id in document_ids:
    doc = db.documents.find_one({'_id': ObjectId(doc_id)})
    documents.append(doc)

#### GOOD: Single query with $in (1 network round trip)
documents = list(db.documents.find({
    '_id': {'$in': [ObjectId(doc_id) for doc_id in document_ids]}
}))
#### Impact: 100x faster (100 queries → 1 query)
```

**Batch Update Operations**:
```python
# Pseudocode: Update multiple documents in single operation
result = db.documents.update_many(
    {'user_id': user_id, 'status': 'pending'},
    {'$set': {'status': 'processed', 'processed_at': datetime.utcnow()}}
)

print(f"Updated {result.modified_count} documents")
```

#### Background Job Batching

**Archival Job** (Batch Process Old Data):
```python
# Pseudocode: Archive old documents in batches
def archive_old_documents():
    cutoff_date = datetime.utcnow() - timedelta(days=365)
    batch_size = 1000
    
    while True:
        # Fetch batch of old documents
        old_documents = list(db.documents.find({
            'created_at': {'$lt': cutoff_date}
        }).limit(batch_size))
        
        if not old_documents:
            break  # No more documents to archive
        
        # Export to S3
        export_to_s3(old_documents)
        
        # Delete from MongoDB
        doc_ids = [doc['_id'] for doc in old_documents]
        db.documents.delete_many({'_id': {'$in': doc_ids}})
        
        print(f"Archived and deleted {len(doc_ids)} documents")
```

**Analytics Job** (Batch Aggregation):
```python
# Pseudocode: Generate daily analytics report
def generate_daily_analytics():
    yesterday = datetime.utcnow() - timedelta(days=1)
    
    # Single aggregation pipeline (efficient batch processing)
    pipeline = [
        {'$match': {'timestamp': {'$gte': yesterday}}},
        {'$group': {
            '_id': '$event_type',
            'count': {'$sum': 1},
            'unique_users': {'$addToSet': '$user_id'}
        }},
        {'$sort': {'count': -1}}
    ]
    
    results = list(db.analytics.aggregate(pipeline))
    
    # Store aggregated results
    db.daily_reports.insert_one({
        'date': yesterday,
        'metrics': results,
        'generated_at': datetime.utcnow()
    })
```

#### Streaming Large Result Sets

**MongoDB Cursors for Large Datasets**:
```python
# Pseudocode: Stream results instead of loading all in memory
def export_all_documents():
    # BAD: Load all documents in memory (OOM risk)
    # documents = list(db.documents.find())  # DON'T DO THIS
    
    # GOOD: Use cursor to stream results
    cursor = db.documents.find().batch_size(500)
    
    for document in cursor:
        # Process one document at a time
        export_to_csv(document)
        
        # Memory usage: Constant (only ~500 docs in memory at once)
```

**Batch Size Configuration**:
- **Small Batches** (100-500): Lower memory usage, more network round trips
- **Large Batches** (1,000-5,000): Higher memory usage, fewer network round trips
- **Default**: 500 documents per cursor batch (good balance)

---

### 6.2.7 Vector Database Design (To Be Determined)

#### 6.2.7.1 Vector Database Requirement

**Purpose**: Store and query high-dimensional vector embeddings for AI-powered features:
- Semantic search across user documents
- Document similarity and recommendations
- Retrieval-Augmented Generation (RAG) for contextual AI responses
- Conversation context retrieval

**Embedding Specifications**:
- **Model**: OpenAI text-embedding-ada-002
- **Dimensions**: 1536 (fixed)
- **Similarity Metric**: Cosine similarity
- **Expected Volume**: Millions of vectors at scale

#### 6.2.7.2 Vector Database Options Under Consideration

| Option | Type | Pros | Cons | LangChain Support | Estimated Cost |
|--------|------|------|------|-------------------|----------------|
| **MongoDB Atlas Vector Search** | Integrated | Same database, no new service, unified data model | Limited advanced vector search features | Native | Included in Atlas |
| **Pinecone** | Managed SaaS | High performance, fully managed, purpose-built | Additional cost, vendor lock-in | Excellent | $70/month (Starter) |
| **Weaviate** | Self-Hosted or Managed | Feature-rich, ML model integration, open-source | Requires management (self-hosted) | Excellent | Free (self-hosted) |
| **Qdrant** | Self-Hosted or Managed | High performance, optimized for LangChain, Rust-based | Operational overhead (self-hosted) | Excellent | Free (self-hosted) |

#### 6.2.7.3 Selection Criteria

| Criterion | Weight | MongoDB Atlas | Pinecone | Weaviate | Qdrant |
|-----------|--------|--------------|----------|----------|--------|
| **Scale of Operations** (QPS) | High | Medium | High | High | High |
| **Cost** | High | Low | High | Low (self-hosted) | Low (self-hosted) |
| **Integration Complexity** | Medium | Low | Low | Medium | Medium |
| **Query Performance** | High | Medium | High | High | High |
| **Operational Overhead** | High | None | None | High (self-hosted) | High (self-hosted) |
| **LangChain Support** | Medium | Good | Excellent | Excellent | Excellent |

**Decision Timeline**: To be finalized during implementation phase based on actual usage patterns and budget constraints.

#### 6.2.7.4 Planned Vector Data Model

**Vector Document Structure** (Conceptual):
```json
{
  "vector_id": "uuid-v4-550e8400-e29b",
  "document_id": "507f1f77bcf86cd799439014",
  "user_id": "auth0|123456789",
  "embedding": [0.123, -0.456, 0.789, ...],  // 1536 dimensions
  "text_content": "This is the original text chunk that was embedded...",
  "metadata": {
    "chunk_index": 0,
    "total_chunks": 5,
    "source": "quarterly-report-q4-2023.pdf",
    "page_number": 3
  },
  "created_at": "2024-01-15T10:30:00Z"
}
```

**Key Fields**:
- `vector_id`: Unique identifier for vector
- `document_id`: References MongoDB `documents` collection
- `user_id`: User ownership (for access control)
- `embedding`: 1536-dimensional vector array
- `text_content`: Original text (for context retrieval)
- `metadata`: Contextual information (source, location, etc.)

#### 6.2.7.5 Vector Search Query Flow

```mermaid
sequenceDiagram
    participant User
    participant API as Flask API
    participant Embeddings as OpenAI Embeddings API
    participant VectorDB as Vector Database
    participant MongoDB
    participant LLM as OpenAI LLM
    
    User->>API: Semantic Search Query<br/>"Find documents about Q4 revenue"
    
    API->>Embeddings: Generate Query Embedding
    Embeddings-->>API: [0.123, -0.456, ...] (1536-dim)
    
    API->>VectorDB: Vector Similarity Search<br/>top_k=5, similarity=cosine
    VectorDB-->>API: Top 5 Similar Vectors<br/>with scores
    
    API->>MongoDB: Fetch Document Metadata<br/>for vector IDs
    MongoDB-->>API: Document metadata
    
    Note over API: Construct RAG Prompt
    
    API->>LLM: Prompt: "Based on context:<br/>[retrieved text chunks]<br/>Answer: ..."
    LLM-->>API: Generated Response<br/>with context
    
    API-->>User: Response + Source Citations
```

#### 6.2.7.6 Vector Indexing Strategy

**Index Type**: HNSW (Hierarchical Navigable Small World)
- **Algorithm**: Approximate nearest neighbor search
- **Trade-off**: Slight accuracy loss for massive speed gain

**HNSW Parameters**:

| Parameter | Value | Impact |
|-----------|-------|--------|
| `M` | 16 | Number of connections per layer (higher = better accuracy, slower build) |
| `ef_construction` | 200 | Index build quality (higher = better accuracy, slower build) |
| `ef_search` | 100 | Query time accuracy (higher = better accuracy, slower query) |

**Performance Targets**:

| Metric | Target | Scale |
|--------|--------|-------|
| **Vector Search Latency** | < 100ms | top_k=5 queries |
| **Index Build Time** | < 5 minutes | 1 million vectors |
| **Query Throughput** | > 100 QPS | Concurrent queries |

#### 6.2.7.7 Vector Database Scaling Strategy

**Initial Deployment**: Single node (up to 10 million vectors)

**Growth Strategy**:
- **Phase 1** (0-1M vectors): Single node, vertical scaling
- **Phase 2** (1M-10M vectors): Optimize index parameters, increase instance size
- **Phase 3** (10M+ vectors): Horizontal sharding by user_id or collection_id

**Sharding Approach** (Future):
- Shard by `user_id` to isolate tenant data
- Each shard handles subset of users
- Query routing based on user context

---

### 6.2.8 Object Storage (Amazon S3)

#### 6.2.8.1 S3 Bucket Strategy and Organization

**Bucket Architecture**:

| Bucket Name | Purpose | Access Pattern | Encryption | Versioning | Lifecycle Policy |
|-------------|---------|---------------|------------|------------|------------------|
| `app-uploads-prod` | User-generated content (documents, media) | Private (presigned URLs) | SSE-S3 | Disabled | Retain indefinitely |
| `app-uploads-staging` | Staging environment uploads | Private (presigned URLs) | SSE-S3 | Disabled | Delete after 30 days |
| `app-static-assets` | Frontend static files (HTML, CSS, JS, images) | Public via CloudFront CDN | SSE-S3 | Disabled | Retain indefinitely |
| `app-backups` | Database backups, archives | Private | SSE-KMS | Enabled | Glacier after 90 days |
| `app-archives` | Archived data (old conversations, analytics) | Private | SSE-S3 | Disabled | Retain per retention policy |
| `app-logs` | Application and infrastructure log archives | Private | SSE-S3 | Disabled | Delete after 1 year |
| `terraform-state` | Terraform state files | Private | SSE-S3 | Enabled | Retain all versions |

#### 6.2.8.2 File Upload Architecture (Presigned URLs)

**Presigned URL Upload Flow**:

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant MongoDB
    participant S3 as Amazon S3
    
    Client->>API: POST /api/v1/files/upload-url<br/>{filename, size, mime_type}
    
    Note over API: Validate JWT,<br/>Check permissions
    
    API->>API: Generate unique file_id<br/>(UUID v4)
    
    API->>S3: Generate Presigned PUT URL<br/>(15-minute expiration)
    S3-->>API: Presigned URL
    
    API->>MongoDB: Insert file record<br/>{file_id, status: "pending"}
    MongoDB-->>API: Success
    
    API-->>Client: {upload_url, file_id}
    
    Note over Client: Direct Upload to S3
    Client->>S3: PUT file data<br/>(bypass API)
    S3-->>Client: 200 OK
    
    Client->>API: POST /api/v1/files/complete<br/>{file_id}
    
    API->>MongoDB: Update file status<br/>{file_id, status: "complete"}
    
    API-->>Client: {file_id, status: "complete"}
```

**Presigned URL Benefits**:

| Benefit | Traditional Upload | Presigned URL | Improvement |
|---------|------------------|---------------|-------------|
| **API Bandwidth** | 100 MB/request through API | 0 MB (direct to S3) | Eliminate API bottleneck |
| **Upload Performance** | Limited by API instance | Direct S3 (high throughput) | 5-10x faster |
| **API Timeout Risk** | Timeout for large files | No timeout (direct S3) | Support multi-GB files |
| **Infrastructure Cost** | High (data transfer through API) | Low (no API data transfer) | 80% cost reduction |

**Presigned URL Generation**:
```python
# Pseudocode: Generate presigned URL for file upload
import boto3
from datetime import timedelta

s3_client = boto3.client('s3')

def generate_upload_url(file_id, filename, mime_type):
    s3_key = f"uploads/{datetime.utcnow().year}/{datetime.utcnow().month}/{file_id}-{filename}"
    
    presigned_url = s3_client.generate_presigned_url(
        'put_object',
        Params={
            'Bucket': 'app-uploads-prod',
            'Key': s3_key,
            'ContentType': mime_type
        },
        ExpiresIn=900  # 15 minutes
    )
    
    return presigned_url, s3_key
```

#### 6.2.8.3 S3 Security Configuration

**Server-Side Encryption**:

| Bucket | Encryption Type | Key Management | Purpose |
|--------|---------------|---------------|---------|
| `app-uploads-*` | SSE-S3 | AWS-managed keys | User files (standard encryption) |
| `app-static-assets` | SSE-S3 | AWS-managed keys | Public static assets |
| `app-backups` | SSE-KMS | Customer-managed KMS keys | Sensitive backups (audit trail of access) |
| `app-archives` | SSE-S3 | AWS-managed keys | Archived data |
| `terraform-state` | SSE-S3 | AWS-managed keys | Infrastructure state |

**Bucket Access Policies**:

**Private Buckets** (Default Deny):
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::app-uploads-prod",
        "arn:aws:s3:::app-uploads-prod/*"
      ],
      "Condition": {
        "Bool": {
          "aws:SecureTransport": "false"
        }
      }
    }
  ]
}
```

**Public Bucket via CloudFront** (`app-static-assets`):
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "cloudfront.amazonaws.com"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::app-static-assets/*",
      "Condition": {
        "StringEquals": {
          "AWS:SourceArn": "arn:aws:cloudfront::account-id:distribution/distribution-id"
        }
      }
    }
  ]
}
```

**IAM Role for ECS Tasks**:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::app-uploads-prod/*",
        "arn:aws:s3:::app-backups/*"
      ]
    }
  ]
}
```

**CORS Configuration** (for client-side uploads):
```json
[
  {
    "AllowedOrigins": ["https://app.example.com"],
    "AllowedMethods": ["GET", "PUT", "POST"],
    "AllowedHeaders": ["*"],
    "MaxAgeSeconds": 3600
  }
]
```

#### 6.2.8.4 S3 Lifecycle Management

**Backup Bucket Lifecycle** (`app-backups`):

```mermaid
graph LR
    A[Upload to S3 Standard] -->|After 30 days| B[Transition to S3 Standard-IA]
    B -->|After 90 days| C[Transition to S3 Glacier]
    C -->|After 1 year| D[Delete Daily Backups<br/>Retain Monthly]
    
    style A fill:#4CAF50
    style B fill:#8BC34A
    style C fill:#2196F3
    style D fill:#FF9800
```

**Lifecycle Policy Configuration**:
```json
{
  "Rules": [
    {
      "Id": "TransitionToGlacier",
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        }
      ],
      "Expiration": {
        "Days": 365
      }
    },
    {
      "Id": "DeleteIncompleteUploads",
      "Status": "Enabled",
      "AbortIncompleteMultipartUpload": {
        "DaysAfterInitiation": 7
      }
    }
  ]
}
```

**Storage Cost Optimization**:

| Storage Class | Use Case | Cost per GB/Month | Retrieval Cost |
|--------------|----------|-------------------|---------------|
| **S3 Standard** | Active data (< 30 days) | $0.023 | None |
| **S3 Standard-IA** | Infrequent access (30-90 days) | $0.0125 | $0.01/GB |
| **S3 Glacier** | Long-term archival (> 90 days) | $0.004 | $0.03/GB + time |
| **S3 Glacier Deep Archive** | Compliance archival (> 1 year) | $0.00099 | $0.02/GB + 12 hours |

---

### 6.2.9 Data Flow Architecture

```mermaid
flowchart TB
    Client[Client Application<br/>Web/Mobile/Desktop]
    
    subgraph "Application Layer"
        ALB[Application Load Balancer]
        API[Flask REST API<br/>ECS Fargate]
        LangChain[LangChain AI Service]
    end
    
    subgraph "Caching Layer"
        Redis[(Redis Cache<br/>ElastiCache)]
        CacheOps["• API Response Cache<br/>• JWKS Cache<br/>• Rate Limit Counters<br/>• LLM Response Cache<br/>• Distributed Locks"]
    end
    
    subgraph "Primary Database"
        MongoDB[(MongoDB 7.0+<br/>3-Node Replica Set)]
        Collections["• users<br/>• conversations<br/>• messages<br/>• documents<br/>• ai_interactions<br/>• analytics<br/>• files"]
    end
    
    subgraph "Vector Database (TBD)"
        VectorDB[(Vector Database<br/>Pinecone/Weaviate/Qdrant)]
        Embeddings["• Document Embeddings<br/>• Semantic Search<br/>• RAG Context Retrieval"]
    end
    
    subgraph "Object Storage"
        S3[(Amazon S3)]
        Buckets["• app-uploads-prod<br/>• app-static-assets<br/>• app-backups<br/>• app-archives"]
    end
    
    subgraph "External Services"
        Auth0[Auth0 Identity Provider]
        OpenAI[OpenAI API<br/>LLM + Embeddings]
    end
    
    Client -->|1. HTTPS + JWT| ALB
    ALB -->|2. Load Balance| API
    
    API -->|3. Validate JWT| Auth0
    Auth0 -.->|JWKS| API
    
    API -->|4. Check Cache| Redis
    Redis -->|Cache Operations| CacheOps
    
    API -->|5. Query/Write| MongoDB
    MongoDB -->|Collections| Collections
    
    API -->|6. AI Requests| LangChain
    LangChain -->|Generate Embeddings| OpenAI
    LangChain -->|Vector Search| VectorDB
    VectorDB -->|Similar Vectors| Embeddings
    LangChain -->|LLM Completion| OpenAI
    
    API -->|7. File Operations| S3
    S3 -->|Buckets| Buckets
    
    MongoDB -.->|8. Daily Backups| S3
    MongoDB -.->|9. Oplog Replication| MongoDB
    
    API -->|10. Cache Response| Redis
    API -->|11. Return Response| ALB
    ALB -->|12. HTTPS| Client
    
    style Redis fill:#FFE6E6
    style MongoDB fill:#E6F3FF
    style VectorDB fill:#E6FFE6
    style S3 fill:#FFF9E6
    style Auth0 fill:#F3E5F5
    style OpenAI fill:#FFF3E0
```

---

### 6.2.10 Replication Architecture Diagram

```mermaid
graph TB
    subgraph "MongoDB Replica Set - Multi-AZ Deployment"
        subgraph "Availability Zone 1 (us-east-1a)"
            Primary[(MongoDB Primary<br/>Read/Write<br/>Oplog Source)]
        end
        
        subgraph "Availability Zone 2 (us-east-1b)"
            Secondary1[(MongoDB Secondary 1<br/>Read-Only<br/>Oplog Consumer)]
        end
        
        subgraph "Availability Zone 3 (us-east-1c)"
            Secondary2[(MongoDB Secondary 2<br/>Read-Only<br/>Oplog Consumer)]
        end
    end
    
    subgraph "Application Layer - Multi-AZ"
        API1[API Instance 1<br/>ECS Task - AZ1]
        API2[API Instance 2<br/>ECS Task - AZ2]
        API3[API Instance 3<br/>ECS Task - AZ3]
    end
    
    subgraph "Load Balancer"
        ALB[Application Load Balancer<br/>Multi-AZ Distribution]
    end
    
    Client[Clients<br/>Web/Mobile/Desktop] -->|HTTPS| ALB
    ALB -->|Load Balance| API1
    ALB -->|Load Balance| API2
    ALB -->|Load Balance| API3
    
    API1 -->|Writes<br/>w: majority| Primary
    API2 -->|Writes<br/>w: majority| Primary
    API3 -->|Writes<br/>w: majority| Primary
    
    API1 -.->|Reads<br/>SecondaryPreferred| Secondary1
    API2 -.->|Reads<br/>SecondaryPreferred| Secondary2
    API3 -.->|Reads<br/>SecondaryPreferred| Secondary1
    
    Primary ==>|Oplog Replication<br/>Asynchronous| Secondary1
    Primary ==>|Oplog Replication<br/>Asynchronous| Secondary2
    
    Secondary1 -.->|Heartbeat<br/>Every 2 seconds| Primary
    Secondary2 -.->|Heartbeat<br/>Every 2 seconds| Primary
    
    subgraph "Write Concern Configuration"
        WriteNote["Write Concern: majority<br/>Waits for 2/3 nodes<br/>Ensures zero data loss"]
    end
    
    subgraph "Read Preference Strategy"
        ReadNote["Read Preference:<br/>• Primary: Writes + Critical Reads<br/>• SecondaryPreferred: Analytics<br/>• Distribution: 60/20/20"]
    end
    
    subgraph "Failover Behavior"
        FailNote["Automatic Failover:<br/>1. Heartbeat timeout: 10 seconds<br/>2. Raft election: < 5 seconds<br/>3. Secondary promoted to Primary<br/>4. Total downtime: < 15 seconds"]
    end
    
    style Primary fill:#4CAF50,stroke:#2E7D32,stroke-width:3px
    style Secondary1 fill:#8BC34A,stroke:#558B2F,stroke-width:2px
    style Secondary2 fill:#8BC34A,stroke:#558B2F,stroke-width:2px
    style WriteNote fill:#E1F5FE,stroke:#0277BD
    style ReadNote fill:#F3E5F5,stroke:#6A1B9A
    style FailNote fill:#FFE0B2,stroke:#E65100
```

---

### 6.2.11 References

#### 6.2.11.1 Repository Files Examined

- **`README.md`**: Project title documentation (no database implementation code found)

#### 6.2.11.2 Repository Folders Explored

- **Root Directory** (`/`): Contains only README.md file; no source code, database configuration, or implementation files

#### 6.2.11.3 Technical Specification Sections Referenced

- **Section 3.1 - Technology Stack Overview**: Overall architecture and technology approach
- **Section 3.6 - Databases & Storage**: Comprehensive database, caching, and storage architecture specifications
- **Section 5.1 - High-Level Architecture**: System architecture overview, data flow patterns
- **Section 5.2 - Component Details**: Detailed component specifications including data models, indexes, and interfaces
- **Section 5.4 - Cross-Cutting Concerns**: Monitoring, error handling, authentication, performance requirements, disaster recovery procedures
- **Section 6.1 - Core Services Architecture**: Service-level architecture with database integration details

#### 6.2.11.4 Key Findings Summary

**Implementation Status**: 
- Repository contains **only README.md** with project title "CheckSameRepoNoPrompt"
- **No database implementation code exists** (no Python files, configuration files, or infrastructure code)
- All database design represents **planned architecture** documented in technical specification

**Database Design Scope**:
- **Primary Database**: MongoDB 7.0+ (NoSQL document database)
- **Caching Layer**: Redis 7+ (likely Amazon ElastiCache)
- **Object Storage**: Amazon S3 with defined bucket strategy
- **Vector Database**: To be determined (Pinecone, Weaviate, Qdrant, or MongoDB Atlas Vector Search)

**Collections Documented**: 7 primary MongoDB collections
- `users` (user profiles, preferences)
- `conversations` (AI conversation metadata)
- `messages` (conversation history)
- `documents` (document metadata, S3 references)
- `ai_interactions` (AI usage logging, cost tracking)
- `analytics` (application event tracking)
- `files` (file upload status, metadata)

**Architecture Highlights**:
- **High Availability**: 3-node MongoDB replica set with automatic failover (< 15 seconds)
- **Backup Strategy**: Daily automated backups, 30-day retention, point-in-time recovery
- **Performance Targets**: < 50ms for indexed queries, < 300ms for aggregations
- **Compliance**: GDPR/CCPA considerations, 7-year audit log retention
- **Caching**: Multi-layer caching (client, CDN, Redis, MongoDB) targeting 70% cache hit rate
- **Scalability**: Horizontal scaling via sharding (future), vertical scaling initially

**Total Research Depth**: 11 comprehensive searches across repository and technical specification sections

---

**Document Metadata**:
- **Section**: 6.2 Database Design
- **Version**: 1.0 (Planned Architecture)
- **Date**: January 2024
- **Status**: Pre-Implementation (Design Phase)
- **Implementation Code**: None (repository contains only README.md)

## 6.3 Integration Architecture

#### Implementation Status Notice

**Current Repository State**: The CheckSameRepoNoPrompt repository is in **pre-implementation phase**, containing only a README.md file with the project title. No source code, configuration files, or infrastructure implementations exist at this time.

**Documentation Scope**: This section documents the **planned integration architecture** based on comprehensive technical specifications. All integration patterns, API designs, and external system interfaces described herein represent the intended architecture that will be implemented during the development phase.

---

### 6.3.1 Integration Architecture Overview

The CheckSameRepoNoPrompt system implements a **cloud-native, API-first integration architecture** designed to support multi-platform client applications, external service integrations, and scalable AI/ML capabilities. The architecture emphasizes standards-based protocols, secure authentication, and resilient communication patterns.

#### 6.3.1.1 Integration Philosophy

The system's integration architecture adheres to the following core principles:

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **API-First Design** | Single RESTful API serves all platforms | Consistent business logic, simplified maintenance |
| **Standards-Based Protocols** | OAuth 2.0, OIDC, HTTPS, JSON | Interoperability, industry best practices |
| **Stateless Communication** | JWT tokens, no server-side sessions | Horizontal scalability, simplified infrastructure |
| **Secure by Default** | Authentication at every layer, TLS encryption | Comprehensive security posture |

#### 6.3.1.2 Integration Layers

```mermaid
graph TB
    subgraph "Client Layer"
        WebApp[Web Application<br/>React + TypeScript]
        MobileApps[Mobile Applications<br/>React Native, iOS, Android]
        DesktopApps[Desktop Applications<br/>Electron, macOS Native]
    end
    
    subgraph "API Gateway Layer"
        ALB[Application Load Balancer<br/>TLS Termination, Routing]
        RateLimit[Rate Limiting<br/>Redis-Based]
    end
    
    subgraph "Application Integration Layer"
        FlaskAPI[Flask REST API<br/>Business Logic Orchestration]
        AuthMiddleware[Authentication Middleware<br/>JWT Validation]
        AuthZMiddleware[Authorization Middleware<br/>Permission Checks]
    end
    
    subgraph "Service Integration Layer"
        LangChain[LangChain AI Service<br/>AI/ML Orchestration]
        CacheLayer[Redis Cache<br/>Response Caching]
        DatabaseLayer[MongoDB<br/>Data Persistence]
    end
    
    subgraph "External Service Integration"
        Auth0[Auth0<br/>Identity Provider]
        OpenAI[OpenAI API<br/>LLM Provider]
        AWS[AWS Services<br/>S3, CloudWatch, Secrets Manager]
    end
    
    WebApp -->|HTTPS + JWT| ALB
    MobileApps -->|HTTPS + JWT| ALB
    DesktopApps -->|HTTPS + JWT| ALB
    
    ALB --> RateLimit
    RateLimit --> FlaskAPI
    
    FlaskAPI --> AuthMiddleware
    AuthMiddleware -->|JWT Validation| Auth0
    AuthMiddleware --> AuthZMiddleware
    AuthZMiddleware --> CacheLayer
    
    CacheLayer -->|Cache Miss| DatabaseLayer
    FlaskAPI --> LangChain
    LangChain -->|LLM Calls| OpenAI
    LangChain -->|Vector Search| DatabaseLayer
    
    FlaskAPI -->|File Operations| AWS
    FlaskAPI -->|Logging| AWS
    FlaskAPI -->|Secrets| AWS
    
    style FlaskAPI fill:#4CAF50
    style Auth0 fill:#F3E5F5
    style OpenAI fill:#FFF3E0
    style AWS fill:#E3F2FD
```

---

### 6.3.2 API Design

#### 6.3.2.1 Protocol Specifications

**RESTful API Architecture**:

| Aspect | Specification | Rationale |
|--------|--------------|-----------|
| **Protocol** | HTTPS (TLS 1.3 with TLS 1.2 fallback) | Security, encryption in transit |
| **Data Format** | JSON (request/response bodies) | Universal compatibility, human-readable |
| **API Style** | RESTful with resource-based URLs | Industry standard, predictable patterns |
| **Versioning** | URI path versioning (`/api/v1/`) | Backward compatibility, clear version identification |

**HTTP Methods and Semantics**:

| Method | Usage | Idempotent | Safe |
|--------|-------|------------|------|
| **GET** | Retrieve resources | Yes | Yes |
| **POST** | Create resources | No | No |
| **PUT** | Update resources (full replacement) | Yes | No |
| **DELETE** | Remove resources | Yes | No |

**API Endpoint Structure**:

```
Base URL: https://api.example.com
Pattern: /api/{version}/{resource}/{id}/{sub-resource}

Examples:
- GET    /api/v1/documents              - List documents
- GET    /api/v1/documents/{id}         - Get specific document
- POST   /api/v1/documents              - Create document
- PUT    /api/v1/documents/{id}         - Update document
- DELETE /api/v1/documents/{id}         - Delete document
- POST   /api/v1/ai/completions         - AI text completion
- POST   /api/v1/ai/conversations       - Start/continue conversation
- POST   /api/v1/files/upload-url       - Get presigned upload URL
```

#### 6.3.2.2 Authentication Methods

**Auth0 OAuth 2.0 / OpenID Connect Integration**:

The system implements **Authorization Code Flow with PKCE** (Proof Key for Code Exchange) for all client platforms:

```mermaid
sequenceDiagram
    participant User
    participant Client as Client Application
    participant Auth0
    participant API as Flask API Backend
    
    User->>Client: Click "Login"
    Client->>Client: Generate code_verifier<br/>Generate code_challenge
    Client->>Auth0: Authorization Request<br/>response_type=code<br/>code_challenge={hash}
    Auth0->>User: Display Login Page
    User->>Auth0: Enter Credentials + MFA
    Auth0->>Client: Authorization Code<br/>(via callback URL)
    Client->>Auth0: Token Request<br/>grant_type=authorization_code<br/>code_verifier={original}
    Auth0->>Client: Access Token (JWT)<br/>Refresh Token<br/>ID Token
    Client->>API: API Request<br/>Authorization: Bearer {JWT}
    API->>Auth0: Validate JWT<br/>(fetch JWKS, verify signature)
    Auth0-->>API: JWT Valid + User Context
    API->>Client: Protected Resource
```

**JWT Token Structure**:

```json
{
  "header": {
    "alg": "RS256",
    "typ": "JWT",
    "kid": "key-identifier"
  },
  "payload": {
    "iss": "https://your-tenant.auth0.com/",
    "sub": "auth0|123456789",
    "aud": "your-api-identifier",
    "iat": 1672531200,
    "exp": 1672532100,
    "azp": "your-client-id",
    "scope": "openid profile email",
    "permissions": ["read:documents", "write:documents"]
  },
  "signature": "..."
}
```

**Token Lifecycle Management**:

| Token Type | Lifetime | Storage | Purpose |
|-----------|----------|---------|---------|
| **Access Token** | 15 minutes | Memory (web), Keychain/Keystore (mobile) | API authorization |
| **Refresh Token** | 7 days | Secure storage only | Silent token renewal |
| **ID Token** | 15 minutes | Memory or secure storage | User profile information |

#### 6.3.2.3 Authorization Framework

**Permission-Based Access Control (PBAC)**:

**Permission Naming Convention**: `{action}:{resource}`

| Permission | Description | Example Endpoint |
|-----------|-------------|------------------|
| `read:documents` | View document metadata and content | `GET /api/v1/documents` |
| `write:documents` | Create and update documents | `POST /api/v1/documents` |
| `delete:documents` | Delete documents | `DELETE /api/v1/documents/{id}` |
| `ai:completions` | Access AI text generation | `POST /api/v1/ai/completions` |

**Authorization Enforcement Pattern**:

```python
# Pseudocode: Multi-level authorization
@app.route('/api/v1/documents/<document_id>', methods=['GET'])
@require_auth  # Layer 1: Validate JWT
@require_permissions(['read:documents'])  # Layer 2: Check permissions
def get_document(document_id):
    document = db.documents.find_one({'_id': document_id})
    
    # Layer 3: Resource-level authorization
    if document['user_id'] != request.user_id:
        if request.user_id not in document.get('shared_with', []):
            # Layer 4: Admin override
            if 'admin:system' not in request.permissions:
                return {'error': 'Forbidden'}, 403
    
    return document, 200
```

#### 6.3.2.4 Rate Limiting Strategy

**Redis-Based Distributed Rate Limiting**:

| Endpoint Category | Rate Limit | Window | Rationale |
|------------------|------------|--------|-----------|
| **General API** | 100 requests/minute | 60 seconds | Prevent abuse, fair usage |
| **Write Operations** | 20 requests/minute | 60 seconds | Protect database from write floods |
| **AI/LLM Endpoints** | 10 requests/minute | 60 seconds | Cost control (expensive operations) |
| **File Uploads** | 20 uploads/minute | 60 seconds | Prevent storage abuse |

**Rate Limit Implementation**:

```python
# Pseudocode: Token bucket algorithm with Redis
def check_rate_limit(user_id, endpoint_category):
    key = f"ratelimit:{user_id}:{endpoint_category}"
    current = redis.incr(key)
    
    if current == 1:
        # First request in window, set expiration
        redis.expire(key, 60)  # 60-second window
    
    limit = get_limit_for_category(endpoint_category)
    
    if current > limit:
        remaining_ttl = redis.ttl(key)
        raise RateLimitExceeded(
            retry_after=remaining_ttl,
            limit=limit,
            current=current
        )
    
    return {
        'limit': limit,
        'remaining': limit - current,
        'reset_at': time.time() + remaining_ttl
    }
```

**Rate Limit Response Headers**:

```
HTTP/1.1 429 Too Many Requests
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1705320600
Retry-After: 45

{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded for this endpoint",
    "details": {
      "limit": 100,
      "window": "1 minute",
      "retry_after": 45
    }
  }
}
```

#### 6.3.2.5 API Versioning Approach

**URI Path Versioning Strategy**:

```
Current Version: /api/v1/*
Future Versions: /api/v2/*, /api/v3/*, etc.

Versioning Rules:
- Breaking changes require new version (v2, v3)
- Non-breaking changes deployed to existing version
- Each version maintained for minimum 12 months after replacement
- Deprecation notices provided 6 months in advance
```

**Version Lifecycle**:

| Stage | Status | Example | Support Level |
|-------|--------|---------|---------------|
| **Current** | Active, recommended | `/api/v1/` | Full support, new features |
| **Deprecated** | Active, discouraged | `/api/v0/` (hypothetical) | Bug fixes only, 6-month notice |
| **Sunset** | Removed | N/A | No support, returns 410 Gone |

**Backward Compatibility Guidelines**:

**Non-Breaking Changes** (Same version):
- Adding new optional fields to requests
- Adding new fields to responses
- Adding new endpoints
- Adding new HTTP methods to existing endpoints

**Breaking Changes** (New version required):
- Removing or renaming fields
- Changing field types
- Changing authentication methods
- Modifying error response formats

#### 6.3.2.6 API Documentation Standards

**OpenAPI (Swagger) Specification** (Planned):

```yaml
# Example OpenAPI 3.0 specification snippet
openapi: 3.0.0
info:
  title: CheckSameRepoNoPrompt API
  version: 1.0.0
  description: RESTful API for AI-powered document management

servers:
  - url: https://api.example.com/api/v1
    description: Production server

paths:
  /documents:
    get:
      summary: List documents
      security:
        - BearerAuth: [read:documents]
      parameters:
        - name: limit
          in: query
          schema:
            type: integer
            default: 20
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/Document'

components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
```

**Documentation Features**:
- Interactive API explorer (Swagger UI)
- Code examples in multiple languages
- Authentication flow documentation
- Rate limiting details
- Error code reference
- Webhooks documentation (future)

---

### 6.3.3 Message Processing

#### 6.3.3.1 Event Processing Patterns

**CloudWatch Logs for Event Streaming**:

The system implements **structured logging** to CloudWatch Logs for event processing and analysis:

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456",
  "service": "api",
  "event_type": "document_created",
  "endpoint": "/api/v1/documents",
  "method": "POST",
  "status_code": 201,
  "duration_ms": 145,
  "metadata": {
    "document_id": "507f1f77bcf86cd799439014",
    "file_size": 2048576,
    "mime_type": "application/pdf"
  }
}
```

**Event Types Logged**:

| Event Category | Event Types | Purpose |
|---------------|-------------|---------|
| **User Actions** | `user_login`, `user_logout`, `document_created`, `document_updated` | User behavior analytics |
| **System Events** | `api_request`, `cache_hit`, `cache_miss`, `rate_limit_exceeded` | Performance monitoring |
| **Security Events** | `auth_failed`, `permission_denied`, `suspicious_activity` | Security monitoring |
| **AI Events** | `ai_completion`, `ai_conversation`, `ai_search` | Cost tracking, usage analytics |

#### 6.3.3.2 Cache-Based Message Pattern

**Redis as Lightweight Message Layer**:

The system uses Redis for **cache-aside pattern** and **pub/sub messaging** (planned future):

**Cache Invalidation Event Pattern** (Current):

```python
# Pseudocode: Event-based cache invalidation
def update_document(document_id, updates):
    # 1. Update database
    result = db.documents.update_one(
        {'_id': document_id},
        {'$set': updates}
    )
    
    # 2. Publish cache invalidation event
    invalidate_cache_keys([
        f"cache:documents:{user_id}:*",  # All user document lists
        f"cache:documents:{document_id}:*",  # Specific document caches
        f"cache:search:*"  # Search result caches
    ])
    
    # 3. Emit CloudWatch event
    emit_event('document_updated', {
        'document_id': document_id,
        'user_id': user_id,
        'fields_updated': updates.keys()
    })
    
    return result
```

**Pub/Sub Messaging** (Future Enhancement):

```python
# Pseudocode: Redis Pub/Sub for real-time updates
# Publisher (API):
redis.publish('document:updates', json.dumps({
    'event': 'document_created',
    'document_id': document_id,
    'user_id': user_id,
    'timestamp': datetime.utcnow().isoformat()
}))

#### Subscriber (WebSocket service, future):
pubsub = redis.pubsub()
pubsub.subscribe('document:updates')

for message in pubsub.listen():
    if message['type'] == 'message':
        event_data = json.loads(message['data'])
        notify_connected_clients(event_data)
```

#### 6.3.3.3 Asynchronous Processing (Future)

**Celery Task Queue** (Planned for Long-Running Operations):

```python
# Pseudocode: Celery tasks for async processing
from celery import Celery

app = Celery('tasks', broker='redis://localhost:6379/0')

@app.task
def process_large_document(document_id):
    """Async document processing (OCR, indexing, embedding generation)"""
    document = db.documents.find_one({'_id': document_id})
    
    # 1. Extract text (OCR if PDF/image)
    text_content = extract_text(document)
    
    # 2. Generate embeddings for semantic search
    embeddings = generate_embeddings(text_content)
    
    # 3. Store in vector database
    store_embeddings(document_id, embeddings)
    
    # 4. Update document status
    db.documents.update_one(
        {'_id': document_id},
        {'$set': {'processing_status': 'complete'}}
    )
    
    return {'status': 'complete', 'document_id': document_id}

#### Enqueue task from API:
task = process_large_document.delay(document_id)
return {'task_id': task.id, 'status': 'processing'}
```

**Use Cases for Async Processing**:
- Large file processing (OCR, conversion)
- Batch operations (bulk updates, exports)
- Scheduled tasks (data archival, cleanup)
- Email notifications
- Report generation

#### 6.3.3.4 Error Handling and Retry Strategy

**Circuit Breaker Pattern for External Services**:

```mermaid
stateDiagram-v2
    [*] --> Closed
    
    Closed --> Closed: Requests succeed
    Closed --> Open: 50% errors in 60s window
    
    Open --> Open: Fail fast (no backend calls)
    Open --> HalfOpen: After 30 seconds
    
    HalfOpen --> Closed: 5 successful test requests
    HalfOpen --> Open: Any test request fails
    
    note right of Closed
        CLOSED: Normal operation
        All requests pass through
        Monitor error rate
    end note
    
    note right of Open
        OPEN: Circuit breaker active
        Return cached/fallback data
        Prevent cascading failures
    end note
    
    note right of HalfOpen
        HALF-OPEN: Testing recovery
        Allow limited requests
        Determine if service healthy
    end note
```

**Exponential Backoff Retry Algorithm**:

```python
# Pseudocode: Retry with exponential backoff
import time
import random

def retry_with_backoff(func, max_retries=3, base_delay=0.1):
    """
    Retry function with exponential backoff and jitter
    
    Wait times:
    - Attempt 1: 0.1s + jitter (0-0.1s) = 0.1-0.2s
    - Attempt 2: 0.2s + jitter = 0.2-0.3s
    - Attempt 3: 0.4s + jitter = 0.4-0.5s
    """
    for attempt in range(max_retries):
        try:
            return func()
        except RetryableException as e:
            if attempt == max_retries - 1:
                raise  # Final attempt failed, propagate error
            
            # Calculate exponential backoff with jitter
            delay = base_delay * (2 ** attempt)
            jitter = random.uniform(0, base_delay)
            total_delay = min(delay + jitter, 5.0)  # Max 5 seconds
            
            time.sleep(total_delay)
```

**Retry Decision Matrix**:

| Error Type | Retry | Max Attempts | Idempotency Required |
|-----------|-------|--------------|---------------------|
| Network timeout | Yes | 3 | Yes |
| Connection refused | Yes | 3 | Yes |
| Rate limit (429) | Yes | 2 | Yes |
| Server error (5xx) | Yes | 2 | Yes |

---

### 6.3.4 External Systems Integration

#### 6.3.4.1 Auth0 Identity Platform Integration

**Integration Architecture**:

```mermaid
graph TB
    subgraph "Client Applications"
        WebApp[Web App - React]
        MobileApp[Mobile Apps - RN/Native]
        DesktopApp[Desktop - Electron]
    end
    
    subgraph "Auth0 Platform"
        UniversalLogin[Universal Login Page]
        TokenEndpoint[Token Endpoint]
        JWKS[JWKS Endpoint<br/>Public Keys]
        UserManagement[User Management API]
    end
    
    subgraph "Backend Services"
        FlaskAPI[Flask API]
        AuthMiddleware[Auth Middleware]
        RedisCache[Redis<br/>JWKS Cache]
    end
    
    WebApp -->|1. Redirect to login| UniversalLogin
    MobileApp -->|1. OAuth 2.0 + PKCE| UniversalLogin
    DesktopApp -->|1. OAuth 2.0 + PKCE| UniversalLogin
    
    UniversalLogin -->|2. Auth code| WebApp
    UniversalLogin -->|2. Auth code| MobileApp
    UniversalLogin -->|2. Auth code| DesktopApp
    
    WebApp -->|3. Exchange code| TokenEndpoint
    MobileApp -->|3. Exchange code| TokenEndpoint
    DesktopApp -->|3. Exchange code| TokenEndpoint
    
    TokenEndpoint -->|4. JWT tokens| WebApp
    TokenEndpoint -->|4. JWT tokens| MobileApp
    TokenEndpoint -->|4. JWT tokens| DesktopApp
    
    WebApp -->|5. API request + JWT| FlaskAPI
    MobileApp -->|5. API request + JWT| FlaskAPI
    DesktopApp -->|5. API request + JWT| FlaskAPI
    
    FlaskAPI --> AuthMiddleware
    AuthMiddleware -->|6. Check cache| RedisCache
    RedisCache -->|Cache miss| JWKS
    JWKS -->|Public keys| AuthMiddleware
    AuthMiddleware -->|Cache keys| RedisCache
    
    AuthMiddleware -->|7. JWT valid| FlaskAPI
```

**Integration Details**:

| Integration Point | Protocol | Data Exchange | Purpose |
|------------------|----------|---------------|---------|
| **User Authentication** | OAuth 2.0 + PKCE | Authorization code, tokens | Secure user login across platforms |
| **Token Validation** | HTTPS REST | JWT verification via JWKS | Validate API requests |
| **User Profile Management** | Auth0 Management API | User metadata CRUD | Sync user data |
| **MFA Enforcement** | Auth0 MFA API | Challenge/response | Additional security layer |

**JWKS Caching Strategy**:

```python
# Pseudocode: JWKS caching for performance
def get_jwks():
    """Fetch Auth0 public keys with Redis caching"""
    cache_key = "jwks:auth0"
    
    # Check cache first
    cached_jwks = redis.get(cache_key)
    if cached_jwks:
        return json.loads(cached_jwks)
    
    # Cache miss: fetch from Auth0
    response = requests.get(
        f"https://{AUTH0_DOMAIN}/.well-known/jwks.json"
    )
    jwks = response.json()
    
    # Cache for 1 hour
    redis.setex(cache_key, 3600, json.dumps(jwks))
    
    return jwks
```

#### 6.3.4.2 OpenAI API Integration (Optional)

**LangChain Abstraction Layer**:

```mermaid
sequenceDiagram
    participant API as Flask API
    participant Lang as LangChain Service
    participant Cache as Redis Cache
    participant OpenAI as OpenAI API
    participant MongoDB
    
    API->>Lang: AI Completion Request<br/>{prompt, model}
    Lang->>Cache: Check prompt cache
    
    alt Cache Hit
        Cache-->>Lang: Cached response
        Lang-->>API: Return cached result
    else Cache Miss
        Lang->>Lang: Build prompt with template
        Lang->>OpenAI: POST /v1/chat/completions<br/>{messages, model, max_tokens}
        OpenAI-->>Lang: Completion response<br/>{text, tokens_used}
        Lang->>Cache: Store response (TTL: 1 hour)
        Lang->>MongoDB: Log interaction<br/>(cost tracking)
        Lang-->>API: Return completion
    end
```

**Integration Configuration**:

| Aspect | Specification | Value |
|--------|--------------|-------|
| **API Endpoint** | Base URL | `https://api.openai.com/v1` |
| **Authentication** | API Key | Stored in AWS Secrets Manager |
| **Models Supported** | LLM models | gpt-3.5-turbo, gpt-4, gpt-4-turbo |
| **Embeddings Model** | Vector embeddings | text-embedding-ada-002 (1536 dimensions) |

**API Request Example**:

```python
# Pseudocode: OpenAI API integration via LangChain
from langchain.llms import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

#### Initialize LLM with configuration
llm = ChatOpenAI(
    model="gpt-4-turbo",
    temperature=0.7,
    max_tokens=500,
    openai_api_key=get_secret("openai_api_key"),
    timeout=30,
    max_retries=2
)

#### Build prompt from template
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant."),
    ("user", "{user_input}")
])

#### Execute LLM call
response = llm.predict(
    prompt_template.format(user_input=user_query)
)

#### Log for cost tracking
log_ai_interaction(
    user_id=user_id,
    model="gpt-4-turbo",
    prompt=user_query,
    response=response,
    tokens_used=calculate_tokens(user_query, response),
    cost_usd=calculate_cost(tokens_used, "gpt-4-turbo")
)
```

#### 6.3.4.3 AWS Services Integration

**AWS Services Architecture**:

```mermaid
graph TB
    subgraph "Application Services"
        FlaskAPI[Flask API<br/>ECS Fargate]
        LangChain[LangChain Service<br/>ECS Fargate]
    end
    
    subgraph "AWS Infrastructure Services"
        ECS[Amazon ECS<br/>Container Orchestration]
        ALB[Application Load Balancer<br/>TLS Termination]
        S3[Amazon S3<br/>Object Storage]
        CloudWatch[CloudWatch<br/>Logs & Metrics]
        SecretsManager[Secrets Manager<br/>Credential Storage]
        ECR[Elastic Container Registry<br/>Docker Images]
    end
    
    subgraph "External Clients"
        Clients[Web/Mobile/Desktop<br/>Clients]
    end
    
    Clients -->|HTTPS| ALB
    ALB -->|Route| FlaskAPI
    
    ECS -.->|Orchestrate| FlaskAPI
    ECS -.->|Orchestrate| LangChain
    
    FlaskAPI -->|Read/Write| S3
    FlaskAPI -->|Logs| CloudWatch
    FlaskAPI -->|Fetch secrets| SecretsManager
    
    LangChain -->|Logs| CloudWatch
    LangChain -->|Fetch secrets| SecretsManager
    
    ECS -->|Pull images| ECR
    
    style FlaskAPI fill:#4CAF50
    style S3 fill:#FFF9E6
    style CloudWatch fill:#E3F2FD
    style SecretsManager fill:#F3E5F5
```

**AWS Service Integrations**:

| Service | Integration Method | Purpose | Data Exchange Pattern |
|---------|-------------------|---------|----------------------|
| **ECS Fargate** | AWS SDK (Boto3), Task Definitions | Container orchestration | ECS API calls for deployment |
| **S3** | Boto3 SDK, Presigned URLs | File storage | Direct client uploads, API downloads |
| **CloudWatch Logs** | CloudWatch Logs SDK | Centralized logging | Structured JSON logs |
| **Secrets Manager** | Boto3 SDK | Secure credential storage | Secret retrieval at runtime |

**S3 Presigned URL Pattern**:

```python
# Pseudocode: Generate presigned URL for file upload
import boto3
from datetime import timedelta

s3_client = boto3.client('s3')

def generate_upload_url(filename, mime_type, user_id):
    """Generate presigned URL for direct client upload"""
    file_id = str(uuid.uuid4())
    s3_key = f"uploads/{datetime.now().year}/{datetime.now().month}/{file_id}-{filename}"
    
    # Generate presigned PUT URL (15-minute expiration)
    presigned_url = s3_client.generate_presigned_url(
        'put_object',
        Params={
            'Bucket': 'app-uploads-prod',
            'Key': s3_key,
            'ContentType': mime_type
        },
        ExpiresIn=900  # 15 minutes
    )
    
    # Store file metadata in MongoDB
    db.files.insert_one({
        'file_id': file_id,
        'user_id': user_id,
        's3_key': s3_key,
        'filename': filename,
        'status': 'pending',
        'created_at': datetime.utcnow()
    })
    
    return {
        'upload_url': presigned_url,
        'file_id': file_id,
        's3_key': s3_key
    }
```

#### 6.3.4.4 MongoDB Integration

**Connection and Query Pattern**:

```python
# Pseudocode: MongoDB connection with replica set
from pymongo import MongoClient, ReadPreference, WriteConcern

#### Initialize connection with configuration
client = MongoClient(
    connection_string,
    maxPoolSize=50,  # Connection pool
    minPoolSize=10,
    serverSelectionTimeoutMS=5000,
    connectTimeoutMS=10000
)

db = client['app_database']

#### Write with majority write concern (durability)
db.documents.insert_one(
    document,
    write_concern=WriteConcern(w='majority', wtimeout=5000)
)

#### Read from secondary (offload primary)
documents = db.documents.find(
    {'user_id': user_id},
    read_preference=ReadPreference.SECONDARY_PREFERRED
).sort('created_at', -1).limit(20)
```

**Integration Patterns**:

| Pattern | Use Case | Implementation |
|---------|----------|----------------|
| **Direct Driver Connection** | All database operations | PyMongo with connection pooling |
| **Replica Set Failover** | High availability | Automatic promotion on primary failure (< 10s) |
| **Read Scaling** | Distribute read load | SecondaryPreferred read preference |
| **Transaction Support** | Multi-document atomicity | MongoDB multi-document transactions |

---

### 6.3.5 Integration Flow Diagrams

#### 6.3.5.1 Complete API Request Flow

```mermaid
sequenceDiagram
    participant Client
    participant ALB as Application Load Balancer
    participant API as Flask API
    participant Auth0
    participant Redis as Redis Cache
    participant MongoDB
    participant CloudWatch
    
    Client->>ALB: HTTPS Request<br/>Authorization: Bearer {JWT}
    ALB->>ALB: TLS Termination<br/>Health Check Routing
    ALB->>API: Forward to Healthy Instance
    
    API->>CloudWatch: Log Request (request_id, endpoint, user)
    
    rect rgb(240, 248, 255)
        Note over API: Authentication & Authorization
        API->>Redis: Check JWKS Cache
        alt JWKS Cached
            Redis-->>API: Cached Public Keys
        else JWKS Not Cached
            API->>Auth0: Fetch JWKS
            Auth0-->>API: Public Keys
            API->>Redis: Cache JWKS (1hr TTL)
        end
        
        API->>API: Verify JWT Signature<br/>Validate Claims (exp, iss, aud)
        API->>API: Extract User Context<br/>(user_id, permissions)
        
        API->>Redis: Check Rate Limit
        Redis-->>API: Rate Limit OK
        
        API->>API: Validate Request Schema<br/>(Pydantic)
        API->>API: Check Permissions<br/>(PBAC)
    end
    
    rect rgb(255, 250, 240)
        Note over API,MongoDB: Business Logic Execution
        API->>API: Generate Cache Key
        API->>Redis: Check Response Cache
        
        alt Cache Hit
            Redis-->>API: Cached Response
            API->>CloudWatch: Log Cache Hit
        else Cache Miss
            Redis-->>API: Cache Miss
            API->>MongoDB: Execute Query
            MongoDB-->>API: Query Results
            API->>API: Transform Data to API Format
            API->>Redis: Store in Cache (TTL)
            API->>CloudWatch: Log Cache Miss
        end
    end
    
    API->>CloudWatch: Log Response (status, duration)
    API-->>ALB: HTTP Response
    ALB-->>Client: HTTPS Response
```

#### 6.3.5.2 AI/ML Processing Flow

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant Redis
    participant LangChain
    participant OpenAI
    participant VectorDB as Vector Database
    participant MongoDB
    
    Client->>API: POST /api/v1/ai/search<br/>{query: "Find documents about X"}
    
    API->>API: Validate JWT<br/>Check ai:search permission
    API->>Redis: Check AI rate limit (10/min)
    Redis-->>API: Rate limit OK
    
    API->>Redis: Check cached RAG response
    Redis-->>API: Cache miss
    
    API->>LangChain: Semantic search request
    
    rect rgb(255, 250, 240)
        Note over LangChain,VectorDB: RAG Pipeline
        LangChain->>OpenAI: Generate query embedding<br/>text-embedding-ada-002
        OpenAI-->>LangChain: 1536-dim vector
        
        LangChain->>VectorDB: Vector similarity search<br/>(cosine, top_k=5)
        VectorDB-->>LangChain: Top 5 relevant documents
        
        LangChain->>LangChain: Construct prompt:<br/>Context: [retrieved docs]<br/>Question: [user query]
        
        LangChain->>OpenAI: LLM completion<br/>gpt-4-turbo
        OpenAI-->>LangChain: Generated answer
    end
    
    LangChain-->>API: Response + source citations
    
    API->>MongoDB: Log AI interaction<br/>(prompt, response, tokens, cost)
    API->>Redis: Cache response (1hr TTL)
    API->>Client: 200 OK<br/>{answer, sources, tokens_used}
```

#### 6.3.5.3 File Upload Flow (Presigned URL)

```mermaid
sequenceDiagram
    participant Client
    participant API as Flask API
    participant MongoDB
    participant S3 as Amazon S3
    
    Note over Client,S3: Phase 1: Request Upload URL
    Client->>API: POST /api/v1/files/upload-url<br/>{filename, size, mime_type}
    API->>API: Validate JWT<br/>Check permissions
    API->>API: Generate file_id (UUID)
    API->>S3: Generate presigned PUT URL<br/>(15-min expiration)
    S3-->>API: Presigned URL
    API->>MongoDB: Create file record<br/>{file_id, status: pending}
    API->>Client: {upload_url, file_id}
    
    Note over Client,S3: Phase 2: Direct Upload to S3
    Client->>S3: PUT file data<br/>(using presigned URL)
    S3-->>Client: 200 OK
    
    Note over Client,S3: Phase 3: Confirm Upload
    Client->>API: POST /api/v1/files/complete<br/>{file_id}
    API->>MongoDB: Update file status<br/>{file_id, status: complete}
    API->>Client: {file_id, status: complete}
```

---

### 6.3.6 Integration Diagrams

#### 6.3.6.1 System Integration Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        WebClient[Web Application<br/>React + TypeScript]
        MobileClient[Mobile Applications<br/>iOS, Android, React Native]
        DesktopClient[Desktop Applications<br/>Electron, macOS Native]
    end
    
    subgraph "API Gateway & Load Balancing"
        ALB[Application Load Balancer<br/>- TLS Termination<br/>- Health Checks<br/>- Multi-AZ Distribution]
    end
    
    subgraph "Application Services - ECS Fargate"
        FlaskAPI[Flask REST API<br/>- Business Logic<br/>- Authentication Middleware<br/>- Rate Limiting<br/>- Request Validation]
        LangChainSvc[LangChain AI Service<br/>- LLM Orchestration<br/>- RAG Processing<br/>- Prompt Engineering]
    end
    
    subgraph "Data Layer"
        MongoDB[(MongoDB Replica Set<br/>- Primary + 2 Secondaries<br/>- Auto-failover<br/>- Read Scaling)]
        Redis[(Redis Cache<br/>- API Response Cache<br/>- Rate Limit Counters<br/>- JWKS Cache)]
        S3[(Amazon S3<br/>- User File Storage<br/>- Backups<br/>- Static Assets)]
        VectorDB[(Vector Database<br/>- Document Embeddings<br/>- Semantic Search<br/>- 1536-dim vectors)]
    end
    
    subgraph "External Services"
        Auth0Cloud[Auth0<br/>- User Authentication<br/>- JWT Issuance<br/>- MFA<br/>- User Management]
        OpenAICloud[OpenAI API<br/>- GPT-4 Turbo<br/>- GPT-3.5 Turbo<br/>- text-embedding-ada-002]
        AWSServices[AWS Services<br/>- CloudWatch Logs/Metrics<br/>- Secrets Manager<br/>- ECR<br/>- Certificate Manager]
    end
    
    WebClient -->|1. HTTPS + JWT| ALB
    MobileClient -->|1. HTTPS + JWT| ALB
    DesktopClient -->|1. HTTPS + JWT| ALB
    
    ALB -->|2. Load Balance| FlaskAPI
    
    WebClient -.->|OAuth 2.0 Login| Auth0Cloud
    MobileClient -.->|OAuth 2.0 Login| Auth0Cloud
    DesktopClient -.->|OAuth 2.0 Login| Auth0Cloud
    
    FlaskAPI -->|3. JWT Validation| Auth0Cloud
    FlaskAPI <-->|4. Cache Ops| Redis
    FlaskAPI <-->|5. Data CRUD| MongoDB
    FlaskAPI -->|6. File Ops| S3
    FlaskAPI -->|7. AI Requests| LangChainSvc
    
    LangChainSvc -->|8. LLM Calls| OpenAICloud
    LangChainSvc -->|9. Embeddings| OpenAICloud
    LangChainSvc <-->|10. Vector Search| VectorDB
    LangChainSvc <-->|11. Memory Storage| MongoDB
    
    FlaskAPI -.->|Logs/Metrics| AWSServices
    LangChainSvc -.->|Logs/Metrics| AWSServices
    FlaskAPI -.->|Fetch Secrets| AWSServices
    
    style FlaskAPI fill:#4CAF50
    style LangChainSvc fill:#66BB6A
    style MongoDB fill:#E3F2FD
    style Redis fill:#FFE6E6
    style S3 fill:#FFF9E6
    style VectorDB fill:#E8F5E9
    style Auth0Cloud fill:#F3E5F5
    style OpenAICloud fill:#FFF3E0
    style AWSServices fill:#E1F5FE
```

#### 6.3.6.2 Authentication Integration Flow

```mermaid
flowchart TD
    Start([User Initiates Login]) --> PlatformCheck{Platform?}
    
    PlatformCheck -->|Web| WebFlow[Web Browser Flow]
    PlatformCheck -->|Mobile| MobileFlow[Mobile Native Flow]
    PlatformCheck -->|Desktop| DesktopFlow[Desktop App Flow]
    
    WebFlow --> Auth0Universal[Auth0 Universal Login<br/>HTTPS Redirect]
    MobileFlow --> Auth0Mobile[Auth0 via ASWebAuthenticationSession iOS<br/>or Chrome Custom Tabs Android]
    DesktopFlow --> Auth0Desktop[Auth0 via System Browser<br/>Custom Protocol Handler]
    
    Auth0Universal --> UserAuth[User Authenticates<br/>Credentials + MFA]
    Auth0Mobile --> UserAuth
    Auth0Desktop --> UserAuth
    
    UserAuth --> Auth0Issue[Auth0 Issues Tokens:<br/>- Access Token JWT 15min<br/>- Refresh Token 7 days<br/>- ID Token]
    
    Auth0Issue --> StoreTokens{Store Tokens}
    StoreTokens -->|Web| WebStore[Browser Memory<br/>Auth0 SDK]
    StoreTokens -->|Mobile| MobileStore[iOS Keychain<br/>Android Keystore]
    StoreTokens -->|Desktop| DesktopStore[Electron SafeStorage]
    
    WebStore --> APIRequest[Make API Request<br/>Authorization: Bearer JWT]
    MobileStore --> APIRequest
    DesktopStore --> APIRequest
    
    APIRequest --> ValidateJWT[API Validates JWT:<br/>1. Check JWKS Cache Redis<br/>2. Verify Signature RS256<br/>3. Validate Claims]
    
    ValidateJWT --> JWTValid{JWT Valid?}
    JWTValid -->|No| Return401[Return 401 Unauthorized]
    JWTValid -->|Yes| ExtractContext[Extract User Context:<br/>user_id, permissions]
    
    ExtractContext --> CheckPerms{Has Required<br/>Permissions?}
    CheckPerms -->|No| Return403[Return 403 Forbidden]
    CheckPerms -->|Yes| ProcessRequest[Process API Request]
    
    ProcessRequest --> Success[Return 200 OK + Data]
    
    Return401 --> End([End])
    Return403 --> End
    Success --> End
    
    style UserAuth fill:#FFF3E0
    style Auth0Issue fill:#F3E5F5
    style ValidateJWT fill:#E3F2FD
    style ProcessRequest fill:#C8E6C9
```

---

### 6.3.7 References

#### Technical Specification Sections Referenced
- `1.2 System Overview` - Project context, implementation status
- `3.1 Technology Stack Overview` - Overall technology approach and architecture
- `3.5 Third-Party Services` - Auth0, AWS, OpenAI integration details
- `4.3 Authentication and Authorization Flows (Planned)` - OAuth 2.0, JWT, PBAC specifications
- `4.4 API Request Processing Flows (Planned)` - Request handling, caching, error handling patterns
- `4.5 AI/ML Processing Workflows (Planned)` - LLM integration, RAG workflows, embedding generation
- `5.1 High-Level Architecture` - System architecture, data flows, component interactions
- `5.4 Cross-Cutting Concerns` - Monitoring, logging, error handling, performance requirements
- `6.1 Core Services Architecture` - Service specifications, communication patterns, scalability
- `6.2 Database Design` - Data models, integration patterns, replication architecture

#### Repository Files Examined
- `README.md` (root) - Project title documentation; repository in pre-implementation phase with no source code

#### Implementation Status
**Pre-Implementation Phase**: All integration architecture patterns, API designs, and external system interfaces documented in this section represent planned design specifications. The repository currently contains only a README.md file with no implemented code, configuration files, or infrastructure.

## 6.4 Security Architecture

### 6.4.1 Security Architecture Overview

#### 6.4.1.1 Implementation Status

**Current Repository State**: The CheckSameRepoNoPrompt repository is in **pre-implementation phase**, containing only a README.md file with the project title. No security implementation code, authentication modules, or security configuration files exist at this time.

**Documentation Scope**: This section documents the **planned security architecture** based on comprehensive technical specifications. All security frameworks, authentication flows, and data protection mechanisms described herein represent the intended security posture that will be implemented during the development phase.

#### 6.4.1.2 Security Design Philosophy

The CheckSameRepoNoPrompt system implements a **defense-in-depth security architecture** designed to protect user data, prevent unauthorized access, and ensure regulatory compliance. The security framework adheres to industry best practices and established standards including OAuth 2.0, OpenID Connect, and enterprise encryption protocols.

**Core Security Principles**:

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **Zero Trust Architecture** | Authentication and authorization at every layer | No implicit trust, continuous verification |
| **Defense in Depth** | Multiple security layers (network, transport, application, data) | Redundant protection, failure resilience |
| **Security by Design** | Security integrated from architecture phase | Proactive rather than reactive security |
| **Least Privilege Access** | Permission-based access control, minimal grants | Reduced attack surface, limited breach impact |

**Security Layers**:

```mermaid
graph TB
    subgraph "Security Layer Architecture"
        subgraph "Layer 1: Network Security"
            VPC[VPC Isolation<br/>Private Subnets]
            SG[Security Groups<br/>Port Restrictions]
            TLS[TLS 1.3 Encryption<br/>Certificate Management]
        end
        
        subgraph "Layer 2: Authentication"
            Auth0[Auth0 Identity Provider<br/>OAuth 2.0 + OIDC]
            MFA[Multi-Factor Authentication<br/>SMS, TOTP, Email]
            JWT[JWT Token Management<br/>RS256 Signatures]
        end
        
        subgraph "Layer 3: Authorization"
            PBAC[Permission-Based Access Control<br/>action:resource format]
            ResourceAuth[Resource-Level Authorization<br/>Ownership Validation]
            AdminOverride[Administrative Override<br/>admin:system permission]
        end
        
        subgraph "Layer 4: Application Security"
            RateLimit[Rate Limiting<br/>Redis Token Bucket]
            InputVal[Input Validation<br/>Pydantic Schemas]
            CORS[CORS Configuration<br/>Origin Restrictions]
        end
        
        subgraph "Layer 5: Data Protection"
            EncryptRest[Encryption at Rest<br/>AES-256]
            EncryptTransit[Encryption in Transit<br/>TLS 1.3]
            Audit[Audit Logging<br/>Immutable Append-Only]
        end
    end
    
    Client[Client Applications] -->|HTTPS| VPC
    VPC --> SG
    SG --> TLS
    TLS --> Auth0
    Auth0 --> MFA
    MFA --> JWT
    JWT --> PBAC
    PBAC --> ResourceAuth
    ResourceAuth --> AdminOverride
    AdminOverride --> RateLimit
    RateLimit --> InputVal
    InputVal --> CORS
    CORS --> EncryptRest
    EncryptRest --> EncryptTransit
    EncryptTransit --> Audit
    Audit --> Protected[Protected Resources]
    
    style Layer1 fill:#FFEBEE
    style Layer2 fill:#F3E5F5
    style Layer3 fill:#E8EAF6
    style Layer4 fill:#E0F2F1
    style Layer5 fill:#FFF9C4
    style Protected fill:#C8E6C9
```

---

### 6.4.2 Authentication Framework

#### 6.4.2.1 Identity Management

**Auth0 Enterprise Identity Platform**:

The system delegates all identity management to Auth0, a cloud-based identity-as-a-service provider that implements OAuth 2.0 and OpenID Connect standards. This approach provides enterprise-grade authentication with minimal operational overhead.

**Auth0 Configuration**:

| Component | Specification | Purpose |
|-----------|---------------|---------|
| **Authentication Protocol** | OAuth 2.0 with OIDC | Industry-standard secure authentication |
| **Authorization Flow** | Authorization Code Flow with PKCE | Mitigate authorization code interception |
| **User Database** | Auth0 managed | Centralized identity store with profile metadata |
| **Social Identity Providers** | Google, Facebook, Apple, GitHub | Simplified user onboarding |

**User Identity Structure**:

```json
{
  "user_id": "auth0|123456789",
  "email": "user@example.com",
  "email_verified": true,
  "name": "John Doe",
  "picture": "https://gravatar.com/avatar/...",
  "identities": [
    {
      "provider": "auth0",
      "user_id": "123456789",
      "connection": "Username-Password-Authentication",
      "isSocial": false
    }
  ],
  "created_at": "2024-01-15T10:30:00.000Z",
  "updated_at": "2024-01-20T14:45:00.000Z",
  "last_login": "2024-01-20T14:45:00.000Z",
  "logins_count": 42,
  "app_metadata": {
    "roles": ["user", "editor"],
    "tenant_id": "company-123"
  },
  "user_metadata": {
    "preferences": {
      "theme": "dark",
      "language": "en"
    }
  }
}
```

**Identity Synchronization**:

Auth0 serves as the source of truth for authentication, while MongoDB stores supplementary user data for application-specific features:

- **Auth0 Store**: Authentication credentials, email verification, MFA settings, login history
- **MongoDB Store**: User preferences, application settings, subscription tier, usage statistics

**User Lifecycle Management**:

| Event | Auth0 Action | MongoDB Action | Security Implication |
|-------|-------------|----------------|---------------------|
| **User Registration** | Create Auth0 user, send verification email | Create user profile on first login | Email verification prevents fake accounts |
| **Email Verification** | Mark email_verified=true | No action required | Enable full account access |
| **Password Reset** | Auth0 password reset flow | No action required | User-initiated, secure reset link |
| **Account Deletion** | Disable Auth0 user (soft delete) | 30-day grace period, then permanent deletion | GDPR Article 17 compliance |

#### 6.4.2.2 Multi-Factor Authentication (MFA)

**MFA Implementation**:

Auth0 provides built-in multi-factor authentication with multiple verification methods:

| MFA Method | Delivery Mechanism | Security Level | User Experience |
|-----------|-------------------|----------------|-----------------|
| **SMS OTP** | Text message to registered phone | Medium (vulnerable to SIM swap) | High friction, universal support |
| **TOTP Authenticator** | Time-based codes (Google Authenticator, Authy) | High (offline generation) | Medium friction, requires app |
| **Email OTP** | Code sent to verified email | Low (email compromise risk) | High friction, fallback option |
| **Push Notifications** | Auth0 Guardian app approval | High (biometric optional) | Low friction, best UX |

**MFA Enforcement Policies**:

```
Global MFA Policy: Optional (user-configurable)
Admin Users: Required MFA (TOTP or Push)
High-Risk Actions: Step-up authentication (additional MFA challenge)
New Device Login: Optional MFA prompt
```

**MFA Authentication Flow**:

The following diagram illustrates the complete authentication workflow including MFA challenges:

```mermaid
sequenceDiagram
    participant User
    participant Client as Client Application<br/>(Web/Mobile/Desktop)
    participant Auth0 as Auth0<br/>Identity Provider
    participant API as Backend API<br/>(Flask)
    participant DB as MongoDB<br/>Database

    Note over User,DB: Initial Application Access
    
    User->>Client: Launch Application
    Client->>Client: Check Local Storage<br/>for JWT Token
    
    alt Token Exists and Valid
        Client->>API: API Request<br/>(Authorization: Bearer {JWT})
        API->>API: Validate JWT Signature<br/>Check Expiration
        API->>DB: Query User Data
        DB->>API: Return User Profile
        API->>Client: Return Protected Resource
        Client->>User: Display Application
    else Token Expired or Invalid
        Client->>Client: Attempt Token Refresh
        Client->>Auth0: Refresh Token Request<br/>(grant_type=refresh_token)
        
        alt Refresh Token Valid
            Auth0->>Auth0: Validate Refresh Token
            Auth0->>Client: New Access Token<br/>+ Refresh Token
            Client->>Client: Store New Tokens
            Client->>User: Continue to Application
        else Refresh Token Invalid
            Client->>User: Redirect to Login
        end
    else No Token Present
        Client->>User: Redirect to Login
    end
    
    Note over User,DB: Login Flow
    
    User->>Client: Click "Login" Button
    Client->>Auth0: Redirect to Universal Login<br/>(response_type=code, scope=openid profile email)
    Auth0->>User: Display Login Page
    
    User->>Auth0: Enter Credentials<br/>(Email/Password or Social)
    Auth0->>Auth0: Validate Credentials
    
    alt Credentials Invalid
        Auth0->>User: Display Error<br/>"Invalid credentials"
        User->>Auth0: Retry Login
    else MFA Enabled
        Auth0->>User: Prompt for MFA Code<br/>(SMS/Authenticator App)
        User->>Auth0: Provide MFA Code
        Auth0->>Auth0: Validate MFA Code
        
        alt MFA Invalid
            Auth0->>User: Display Error<br/>"Invalid MFA code"
            User->>Auth0: Retry MFA
        end
    end
    
    Auth0->>Client: Authorization Code<br/>(via Callback URL)
    Client->>Auth0: Exchange Code for Tokens<br/>(grant_type=authorization_code)
    Auth0->>Auth0: Validate Authorization Code
    Auth0->>Client: Access Token (JWT)<br/>+ Refresh Token<br/>+ ID Token
    
    Client->>Client: Validate ID Token<br/>Extract User Info
    Client->>Client: Store Tokens Securely<br/>(Keychain/Keystore/Secure Storage)
    
    Client->>API: Create/Update User Profile<br/>(Authorization: Bearer {JWT})
    API->>API: Validate JWT<br/>Extract Auth0 User ID
    API->>DB: Upsert User Document<br/>(auth0_id, email, name, metadata)
    DB->>API: Confirm User Stored
    API->>Client: Return User Profile
    
    Client->>User: Redirect to Main Application
    User->>Client: Interact with Application
```

**MFA Recovery Mechanisms**:

| Scenario | Recovery Method | Security Control |
|----------|----------------|------------------|
| **Lost MFA Device** | Recovery codes (generated at MFA setup) | User must securely store 10 one-time codes |
| **Lost Recovery Codes** | Identity verification via email | Requires email access + account details |
| **Locked Account** | Admin manual unlock | Audit logged, requires justification |

#### 6.4.2.3 Session Management

**Stateless JWT-Based Sessions**:

The system implements **stateless authentication** using JSON Web Tokens (JWT), eliminating the need for server-side session storage. This architecture provides horizontal scalability and simplified infrastructure management.

**Token Types and Lifecycle**:

| Token Type | Purpose | Lifetime | Storage Location | Security Features |
|-----------|---------|----------|------------------|-------------------|
| **Access Token** | API authorization | 15 minutes | Memory (web), Keychain (iOS), Keystore (Android) | Short-lived, RS256 signed, expires automatically |
| **Refresh Token** | Silent renewal | 7 days | Secure storage only (never exposed to JavaScript) | Long-lived, one-time use, rotation enabled |
| **ID Token** | User profile | 15 minutes | Memory or secure storage | OpenID Connect standard, profile claims |

**JWT Access Token Structure**:

```json
{
  "header": {
    "alg": "RS256",
    "typ": "JWT",
    "kid": "key-identifier-abc123"
  },
  "payload": {
    "iss": "https://your-tenant.auth0.com/",
    "sub": "auth0|123456789",
    "aud": "your-api-identifier",
    "iat": 1672531200,
    "exp": 1672532100,
    "azp": "your-client-id",
    "scope": "openid profile email",
    "permissions": [
      "read:documents",
      "write:documents",
      "ai:completions"
    ]
  },
  "signature": "RS256_signature_bytes..."
}
```

**Session Security Controls**:

| Control | Implementation | Threat Mitigated |
|---------|----------------|------------------|
| **Short Token Lifetime** | 15-minute expiration | Limits window for token theft exploitation |
| **Refresh Token Rotation** | New refresh token issued on each use | Prevents refresh token replay attacks |
| **Token Binding** | IP address tracking (optional) | Detects token theft and cross-device usage |
| **Secure Storage** | Platform-specific secure storage | Prevents token extraction from device |

**Token Refresh Flow**:

```
1. Client detects Access Token approaching expiration (< 5 minutes remaining)
2. Client sends Refresh Token to Auth0 token endpoint
3. Auth0 validates Refresh Token (not revoked, not expired)
4. Auth0 issues new Access Token + new Refresh Token (rotation)
5. Client replaces old tokens with new tokens
6. Old Refresh Token becomes invalid (one-time use)
```

**Session Termination**:

| Termination Type | Trigger | Effect |
|-----------------|---------|--------|
| **User Logout** | User clicks logout button | Tokens cleared from local storage, Auth0 session terminated |
| **Token Expiration** | Access Token expires (15 min) | Automatic refresh attempt, or redirect to login |
| **Refresh Token Expiration** | Refresh Token expires (7 days) | User must re-authenticate via Auth0 |
| **Administrative Revocation** | Admin revokes user session | All tokens invalidated immediately via Auth0 Management API |

#### 6.4.2.4 Token Handling and Validation

**JWT Validation Process**:

Every API request requires a valid JWT token in the Authorization header. The backend performs comprehensive validation to ensure token authenticity and integrity:

```mermaid
flowchart TD
    Start([API Request Received]) --> ExtractHeader[Extract Authorization Header]
    ExtractHeader --> HeaderExists{Header<br/>Present?}
    
    HeaderExists -->|No| Return401Missing[Return 401 Unauthorized<br/>Error: Missing Authorization header]
    HeaderExists -->|Yes| ParseHeader["Parse Header<br/>Format: Bearer {token}"]
    
    ParseHeader --> FormatValid{Format<br/>Valid?}
    FormatValid -->|No| Return401Format[Return 401 Unauthorized<br/>Error: Invalid Authorization format]
    FormatValid -->|Yes| ExtractToken[Extract JWT Token<br/>from Bearer scheme]
    
    ExtractToken --> DecodeToken[Decode JWT<br/>Extract Header, Payload, Signature]
    DecodeToken --> CheckAlgorithm{Algorithm<br/>is RS256?}
    
    CheckAlgorithm -->|No| Return401Algo[Return 401 Unauthorized<br/>Error: Unsupported algorithm]
    CheckAlgorithm -->|Yes| FetchJWKS[Fetch Auth0 JWKS<br/>Public Key Set]
    
    FetchJWKS --> JWKSSuccess{JWKS<br/>Retrieved?}
    JWKSSuccess -->|No| Return503[Return 503 Service Unavailable<br/>Error: Cannot verify token]
    JWKSSuccess -->|Yes| SelectKey[Select Public Key<br/>by kid from JWT header]
    
    SelectKey --> VerifySignature[Verify JWT Signature<br/>with Public Key]
    VerifySignature --> SignatureValid{Signature<br/>Valid?}
    
    SignatureValid -->|No| Return401Sig[Return 401 Unauthorized<br/>Error: Invalid token signature]
    SignatureValid -->|Yes| CheckExpiration[Check Expiration<br/>exp claim vs. current time]
    
    CheckExpiration --> NotExpired{Token Not<br/>Expired?}
    NotExpired -->|No| Return401Exp[Return 401 Unauthorized<br/>Error: Token expired]
    NotExpired -->|Yes| CheckIssuer[Verify Issuer<br/>iss claim matches Auth0 domain]
    
    CheckIssuer --> IssuerValid{Issuer<br/>Valid?}
    IssuerValid -->|No| Return401Iss[Return 401 Unauthorized<br/>Error: Invalid issuer]
    IssuerValid -->|Yes| CheckAudience[Verify Audience<br/>aud claim matches API identifier]
    
    CheckAudience --> AudienceValid{Audience<br/>Valid?}
    AudienceValid -->|No| Return401Aud[Return 401 Unauthorized<br/>Error: Invalid audience]
    AudienceValid -->|Yes| ExtractClaims[Extract User Claims<br/>sub, permissions, scope]
    
    ExtractClaims --> StoreContext[Store User Context<br/>in Request Object]
    StoreContext --> ProceedRequest[✅ Proceed to<br/>Business Logic]
    
    Return401Missing --> End([End Request])
    Return401Format --> End
    Return401Algo --> End
    Return503 --> End
    Return401Sig --> End
    Return401Exp --> End
    Return401Iss --> End
    Return401Aud --> End
    ProceedRequest --> End
    
    style ProceedRequest fill:#c8e6c9
    style Return401Missing fill:#ffcdd2
    style Return401Format fill:#ffcdd2
    style Return401Algo fill:#ffcdd2
    style Return503 fill:#ffecb3
    style Return401Sig fill:#ffcdd2
    style Return401Exp fill:#ffcdd2
    style Return401Iss fill:#ffcdd2
    style Return401Aud fill:#ffcdd2
```

**JWT Validation Steps**:

1. **Header Extraction**: Parse `Authorization: Bearer {token}` header format
2. **Algorithm Verification**: Ensure JWT uses RS256 (RSA signature with SHA-256)
3. **JWKS Retrieval**: Fetch Auth0 JSON Web Key Set containing public keys for signature verification
4. **Signature Verification**: Use public key matching `kid` (Key ID) from JWT header to verify cryptographic signature
5. **Claims Validation**:
   - `exp` (Expiration): Token must not be expired
   - `iss` (Issuer): Must match Auth0 tenant domain
   - `aud` (Audience): Must match API identifier configured in Auth0
6. **User Context Extraction**: Extract `sub` (subject/user_id) and `permissions` array for authorization

**JWKS Caching Strategy**:

To minimize latency and reduce external dependencies, Auth0 public keys are cached in Redis:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| **Cache Key** | `jwks:auth0` | Single key for all Auth0 public keys |
| **TTL (Time to Live)** | 3600 seconds (1 hour) | Balance freshness with performance |
| **Cache Miss Behavior** | Fetch from Auth0 `/.well-known/jwks.json` | Fallback to source of truth |
| **Key Rotation Handling** | Automatic cache invalidation | Auth0 notifies of key changes |

**JWT Validation Performance Targets**:

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Validation Latency** | < 20ms | Minimize overhead on API requests |
| **JWKS Cache Hit Rate** | > 95% | Reduce Auth0 API calls |
| **Validation Success Rate** | > 99.9% | High reliability requirement |

#### 6.4.2.5 Password Policies

**Password Security Delegation**:

All password policies are enforced by Auth0, eliminating the need for custom password handling in the application. This approach reduces security risk and ensures consistent enforcement across all authentication methods.

**Auth0 Password Policy Configuration**:

| Policy Component | Specification | Enforcement |
|-----------------|---------------|-------------|
| **Minimum Length** | 8 characters | Auth0 validates on registration and password change |
| **Complexity Requirements** | At least 3 of: lowercase, uppercase, number, symbol | Auth0 password strength meter |
| **Password History** | Prevent reuse of last 5 passwords | Auth0 stores password hashes securely |
| **Breached Password Detection** | Integration with HaveIBeenPwned database | Auto-reject compromised passwords |
| **Account Lockout** | 10 failed attempts = 30-minute lockout | Brute force protection |

**Password Reset Flow**:

```
1. User clicks "Forgot Password" link
2. User enters email address
3. Auth0 sends secure reset link (expires in 24 hours)
4. User clicks link, redirected to Auth0 password reset page
5. User enters new password (validated against policies)
6. Auth0 updates password hash
7. User redirected to login page with success message
8. All existing sessions invalidated (security measure)
```

**Security Enhancements**:

- **Rate Limiting**: Password reset requests limited to 3 per hour per email
- **Email Verification**: Reset links only sent to verified email addresses
- **Geographic Validation**: Suspicious location triggers additional verification
- **Notification**: User receives email notification of password change

---

### 6.4.3 Authorization System

#### 6.4.3.1 Permission-Based Access Control (PBAC)

**Authorization Framework**:

The system implements **Permission-Based Access Control (PBAC)**, a fine-grained authorization model where each operation requires specific permissions embedded in the JWT token. This approach provides flexibility and scalability compared to traditional role-based models.

**Permission Naming Convention**:

```
Format: {action}:{resource}

Examples:
- read:documents      → View document metadata and content
- write:documents     → Create and update documents
- delete:documents    → Delete documents
- read:users          → View user profiles
- write:users         → Update user profiles (own profile only)
- ai:completions      → Access AI text generation endpoints
- ai:conversations    → Start and manage AI conversations
- admin:system        → Full administrative access (overrides all checks)
```

**Standard Permission Catalog**:

| Permission | HTTP Methods | Endpoints | Resource Scope |
|-----------|-------------|-----------|----------------|
| `read:documents` | GET | `/api/v1/documents`, `/api/v1/documents/{id}` | User's own documents + shared documents |
| `write:documents` | POST, PUT | `/api/v1/documents`, `/api/v1/documents/{id}` | User's own documents |
| `delete:documents` | DELETE | `/api/v1/documents/{id}` | User's own documents |
| `ai:completions` | POST | `/api/v1/ai/completions` | AI text generation (rate limited) |

**Authorization Decision Flow**:

```mermaid
flowchart TD
    Start([Authenticated Request]) --> ExtractPerms[Extract Permissions<br/>from JWT Claims]
    ExtractPerms --> RouteReq{What<br/>Operation?}
    
    RouteReq -->|Read Operation| CheckRead[Check Read Permission]
    RouteReq -->|Write Operation| CheckWrite[Check Write Permission]
    RouteReq -->|Delete Operation| CheckDelete[Check Delete Permission]
    RouteReq -->|Admin Operation| CheckAdmin[Check Admin Permission]
    
    CheckRead --> HasReadPerm{Has read:resource<br/>Permission?}
    HasReadPerm -->|No| Return403Read[Return 403 Forbidden<br/>Insufficient permissions]
    HasReadPerm -->|Yes| ResourceLevel[Resource-Level Check]
    
    CheckWrite --> HasWritePerm{Has write:resource<br/>Permission?}
    HasWritePerm -->|No| Return403Write[Return 403 Forbidden<br/>Insufficient permissions]
    HasWritePerm -->|Yes| ResourceLevel
    
    CheckDelete --> HasDeletePerm{Has delete:resource<br/>Permission?}
    HasDeletePerm -->|No| Return403Delete[Return 403 Forbidden<br/>Insufficient permissions]
    HasDeletePerm -->|Yes| ResourceLevel
    
    CheckAdmin --> HasAdminPerm{Has admin<br/>Permission?}
    HasAdminPerm -->|No| Return403Admin[Return 403 Forbidden<br/>Admin access required]
    HasAdminPerm -->|Yes| ExecuteOp[Execute Admin Operation]
    
    ResourceLevel --> FetchResource[Fetch Resource<br/>from Database]
    FetchResource --> ResourceExists{Resource<br/>Exists?}
    
    ResourceExists -->|No| Return404[Return 404 Not Found<br/>Resource does not exist]
    ResourceExists -->|Yes| CheckOwnership{User Owns<br/>Resource?}
    
    CheckOwnership -->|No| CheckShared{Resource<br/>Shared with User?}
    CheckOwnership -->|Yes| ExecuteOp
    
    CheckShared -->|No| Return403Owner[Return 403 Forbidden<br/>Access denied to resource]
    CheckShared -->|Yes| ExecuteOp
    
    ExecuteOp --> LogAccess[Log Access Event<br/>Audit Trail]
    LogAccess --> Success[✅ Operation Successful<br/>Return Result]
    
    Return403Read --> End([End Request])
    Return403Write --> End
    Return403Delete --> End
    Return403Admin --> End
    Return404 --> End
    Return403Owner --> End
    Success --> End
    
    style ExecuteOp fill:#e8f5e9
    style Success fill:#c8e6c9
    style Return403Read fill:#ffcdd2
    style Return403Write fill:#ffcdd2
    style Return403Delete fill:#ffcdd2
    style Return403Admin fill:#ffcdd2
    style Return403Owner fill:#ffcdd2
    style Return404 fill:#fff9c4
```

**Permission Enforcement Layers**:

1. **Endpoint-Level**: Validate user has required permission for endpoint (e.g., `write:documents` for document creation)
2. **Resource-Level**: Verify user owns or has access to specific resource (e.g., document belongs to user or is shared)
3. **Administrative Override**: `admin:system` permission bypasses resource-level checks for operational purposes

#### 6.4.3.2 Role-Based Access Control (RBAC)

**Role Definitions**:

While the system uses permission-based authorization, Auth0 implements roles as convenient permission bundles. Users are assigned one or more roles, and the JWT token contains all permissions from assigned roles.

| Role Name | Assigned Permissions | Typical User Type | Use Case |
|-----------|---------------------|-------------------|----------|
| **Viewer** | `read:documents`, `ai:completions` | Read-only user, guest | View documents, use AI features, no modifications |
| **User** | `read:documents`, `write:documents`, `ai:completions`, `ai:conversations` | Standard user | Full document management, AI interactions |
| **Admin** | All permissions including `admin:system` | System administrator | Full system access, user management, configuration |

**Role Assignment Methods**:

- **Auth0 Dashboard**: Administrators assign roles via Auth0 Management Console
- **Auth0 Management API**: Programmatic role assignment for automation and bulk operations
- **Rule-Based Assignment**: Auth0 Rules automatically assign roles based on user attributes (e.g., email domain)

#### 6.4.3.3 Resource Authorization

**Multi-Layer Resource Protection**:

Even with valid endpoint permissions, users must prove ownership or explicit sharing access to resources:

**Ownership Validation Pattern**:

```
1. Extract user_id from JWT token (sub claim)
2. Fetch resource from database by resource_id
3. Compare resource.owner_id with JWT user_id
4. If match → Grant access
5. If mismatch → Check resource.shared_with array
6. If user_id in shared_with → Grant access
7. Otherwise → Return 403 Forbidden
```

**Resource Sharing Model**:

```json
{
  "_id": "507f1f77bcf86cd799439014",
  "user_id": "auth0|123456789",
  "title": "Project Proposal",
  "owner_id": "auth0|123456789",
  "shared_with": [
    {
      "user_id": "auth0|987654321",
      "permission": "read",
      "shared_at": "2024-01-15T10:30:00Z"
    },
    {
      "user_id": "auth0|555666777",
      "permission": "write",
      "shared_at": "2024-01-16T14:00:00Z"
    }
  ],
  "visibility": "private"
}
```

#### 6.4.3.4 Policy Enforcement Points

**Security Enforcement Architecture**:

```
Client Request
    ↓
[1] ALB (Application Load Balancer)
    - TLS termination
    - Rate limiting (infrastructure level)
    - Health check routing
    ↓
[2] API Middleware Layer
    - JWT validation
    - User context extraction
    - Request logging
    ↓
[3] Authorization Middleware
    - Permission checks (PBAC)
    - Rate limiting (user-specific)
    - Input validation
    ↓
[4] Business Logic Layer
    - Resource ownership validation
    - Admin override checks
    - Data transformation
    ↓
[5] Data Access Layer
    - MongoDB RBAC (application user permissions)
    - Query execution
    - Response formatting
```

**Enforcement Point Responsibilities**:

| Layer | Enforcement Type | Rejections Logged |
|-------|-----------------|-------------------|
| **ALB** | Network-level rate limiting, TLS enforcement | Yes (CloudWatch) |
| **API Middleware** | JWT signature and expiration validation | Yes (Application logs + CloudWatch) |
| **Authorization Middleware** | Permission validation, user rate limiting | Yes (Audit logs) |
| **Business Logic** | Resource ownership, sharing rules | Yes (Audit logs) |
| **Data Access** | MongoDB role-based access, query validation | Yes (Database logs) |

#### 6.4.3.5 Audit Logging

**Comprehensive Audit Trail**:

All authorization decisions and resource access attempts are logged for compliance, security monitoring, and incident investigation.

**Audit Log Schema**:

```json
{
  "_id": "ObjectId('...')",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456789",
  "action": "UPDATE",
  "resource_type": "documents",
  "resource_id": "507f1f77bcf86cd799439014",
  "endpoint": "/api/v1/documents/507f1f77bcf86cd799439014",
  "method": "PUT",
  "ip_address": "203.0.113.45",
  "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)...",
  "status": "success",
  "permissions_checked": ["write:documents"],
  "authorization_decision": "granted",
  "changes": {
    "before": {"title": "Old Title"},
    "after": {"title": "New Title"}
  }
}
```

**Logged Security Events**:

| Event Category | Example Events | Retention Period |
|---------------|----------------|------------------|
| **Authentication** | Login success/failure, MFA challenges, token refresh | 1 year |
| **Authorization** | Permission denied, resource access granted/denied | 7 years |
| **Data Modification** | CREATE, UPDATE, DELETE operations with change tracking | 7 years |
| **Administrative** | Role assignments, permission changes, user deletions | Permanent |

**Audit Log Security Controls**:

- **Immutability**: Append-only storage, no updates or deletions permitted
- **Integrity**: Cryptographic signatures planned for tamper detection
- **Access Control**: Restricted to compliance team and authorized auditors
- **Retention**: 7-year retention for compliance (SOC 2, GDPR, CCPA)

---

### 6.4.4 Data Protection

#### 6.4.4.1 Encryption Standards

**Encryption at Rest**:

All persistent data is encrypted using AES-256 encryption, meeting industry standards for data protection:

| Component | Encryption Method | Key Management | Algorithm |
|-----------|------------------|----------------|-----------|
| **MongoDB** | WiredTiger storage engine encryption | AWS KMS or MongoDB encrypted storage engine | AES-256-GCM |
| **S3 Buckets (User Uploads)** | Server-Side Encryption (SSE-S3) | AWS-managed keys | AES-256 |
| **S3 Buckets (Backups)** | Server-Side Encryption (SSE-KMS) | Customer-managed AWS KMS keys | AES-256 |
| **Redis Cache** | ElastiCache encryption at rest (optional) | AWS-managed keys | AES-256 |

**Encryption in Transit**:

All network communication is encrypted using TLS (Transport Layer Security):

| Connection Path | Protocol | Certificate Management | Cipher Suites |
|----------------|----------|------------------------|---------------|
| **Client → ALB** | TLS 1.3 (TLS 1.2 fallback) | AWS Certificate Manager (ACM) | ECDHE-RSA-AES256-GCM-SHA384, ECDHE-RSA-AES128-GCM-SHA256 |
| **ALB → ECS Tasks** | HTTP (internal VPC) | Private network isolation (no encryption needed) | N/A (isolated VPC) |
| **ECS → MongoDB** | TLS 1.3 (MongoDB Wire Protocol) | MongoDB Atlas managed certificates | MongoDB default TLS configuration |
| **ECS → Redis** | TLS 1.3 (optional) | ElastiCache in-transit encryption | Redis default TLS configuration |
| **ECS → S3** | HTTPS (TLS 1.3) | AWS managed | AWS S3 TLS configuration |

**TLS Configuration Best Practices**:

- **TLS 1.3 Preferred**: Use latest protocol version for maximum security
- **TLS 1.2 Fallback**: Support older clients while maintaining strong security
- **Cipher Suite Selection**: Forward secrecy (ECDHE), authenticated encryption (GCM)
- **Certificate Validation**: Strict certificate verification, no self-signed certificates in production
- **HSTS Header**: `Strict-Transport-Security: max-age=31536000; includeSubDomains` forces HTTPS

#### 6.4.4.2 Key Management

**AWS Key Management Service (KMS)**:

Customer-managed keys provide enhanced security and auditability for sensitive data:

| Key Purpose | Key Type | Rotation Policy | Access Control |
|------------|----------|----------------|----------------|
| **S3 Backup Encryption** | Customer-managed KMS key | Automatic annual rotation | IAM policy: backup service only |
| **Secrets Encryption** | AWS Secrets Manager managed key | Automatic 90-day rotation | IAM policy: ECS task role |
| **Future PII Encryption** | Customer-managed KMS key (planned) | Automatic annual rotation | IAM policy: application service |

**KMS Security Benefits**:

- **Audit Trail**: CloudTrail logs every key usage event (who, when, what)
- **Fine-Grained Access**: IAM policies control which services can use keys
- **Key Rotation**: Automatic rotation without decrypting data
- **Cross-Region Replication**: Multi-region keys for disaster recovery

**Auth0 JWKS (JSON Web Key Set) Management**:

Auth0 manages JWT signing keys with automatic rotation:

| Aspect | Implementation | Security Benefit |
|--------|----------------|------------------|
| **Key Algorithm** | RS256 (RSA 2048-bit) | Asymmetric cryptography, public key distribution |
| **Key Rotation** | Auth0 automatic rotation (configurable) | Limits exposure window for compromised keys |
| **Key Distribution** | JWKS endpoint: `https://{tenant}.auth0.com/.well-known/jwks.json` | Public keys accessible for token validation |
| **Key Caching** | Redis cache (1-hour TTL) | Performance optimization without security trade-off |

#### 6.4.4.3 Data Masking Rules

**PII (Personally Identifiable Information) Classification**:

| Data Field | PII Category | Storage Location | Protection Measure |
|-----------|-------------|------------------|-------------------|
| `email` | Direct PII | MongoDB `users.email` | Encrypted at rest, access logged, GDPR protected |
| `name` | Direct PII | Auth0 ID token (transient) | Not stored in MongoDB, Auth0-managed |
| `auth0_id` | Pseudonymous identifier | MongoDB (all collections) | Pseudonymization strategy, foreign key |
| `ip_address` | Indirect PII | Audit logs, analytics | Encrypted at rest, 90-day retention, anonymized for analytics |
| `user_agent` | Indirect PII | Audit logs | Encrypted at rest, 90-day retention |

**Logging Redaction**:

Application logs automatically redact sensitive fields to prevent accidental PII exposure:

```
Redacted Fields: password, token, api_key, secret, credit_card, ssn, email (in certain contexts)

Example:
❌ BAD LOG:  "User login: email=user@example.com, password=secretpass123"
✅ GOOD LOG: "User login: email=***REDACTED***, password=***REDACTED***"
```

**Database-Level Masking (Future Enhancement)**:

Planned field-level encryption for highly sensitive PII:

```
Sensitive Fields: Social Security Numbers, Credit Card Numbers, Healthcare Data
Encryption Method: Application-level encryption before database storage
Key Management: AWS KMS customer-managed keys
Access: Decrypt only when explicitly authorized and logged
```

#### 6.4.4.4 Secure Communication

**HTTPS Enforcement**:

All client-to-API communication occurs exclusively over HTTPS with strict security configurations:

| Configuration | Value | Purpose |
|--------------|-------|---------|
| **HTTPS Redirect** | HTTP → HTTPS automatic redirect at ALB | Prevent unencrypted traffic |
| **HSTS Header** | `max-age=31536000; includeSubDomains; preload` | Enforce HTTPS for 1 year, include all subdomains |
| **Certificate Provider** | AWS Certificate Manager (ACM) | Free, automatic renewal, AWS-managed |
| **Certificate Validation** | Domain validation (DV) | Prove domain ownership |

**Internal Network Security**:

Backend services communicate within a private VPC with additional security layers:

```mermaid
graph TB
    subgraph "Public Subnet"
        ALB[Application Load Balancer<br/>Public IP<br/>Ports: 443 HTTPS]
    end
    
    subgraph "Private Subnet A"
        ECS1[ECS Task 1<br/>No Public IP<br/>Port 5000]
        MongoDB1[MongoDB Primary<br/>No Public IP<br/>Port 27017]
    end
    
    subgraph "Private Subnet B"
        ECS2[ECS Task 2<br/>No Public IP<br/>Port 5000]
        MongoDB2[MongoDB Secondary 1<br/>No Public IP<br/>Port 27017]
    end
    
    subgraph "Private Subnet C"
        ECS3[ECS Task 3<br/>No Public IP<br/>Port 5000]
        MongoDB3[MongoDB Secondary 2<br/>No Public IP<br/>Port 27017]
    end
    
    subgraph "NAT Gateway"
        NAT[NAT Gateway<br/>Outbound Internet<br/>For ECS → External APIs]
    end
    
    Internet[Internet] -->|HTTPS 443| ALB
    ALB -->|HTTP 5000| ECS1
    ALB -->|HTTP 5000| ECS2
    ALB -->|HTTP 5000| ECS3
    
    ECS1 -->|MongoDB Protocol TLS| MongoDB1
    ECS2 -->|MongoDB Protocol TLS| MongoDB2
    ECS3 -->|MongoDB Protocol TLS| MongoDB3
    
    MongoDB1 -.->|Replication TLS| MongoDB2
    MongoDB1 -.->|Replication TLS| MongoDB3
    
    ECS1 -.->|External API Calls| NAT
    ECS2 -.->|External API Calls| NAT
    ECS3 -.->|External API Calls| NAT
    NAT -.->|HTTPS| Internet
    
    style ALB fill:#FFCDD2
    style ECS1 fill:#C8E6C9
    style ECS2 fill:#C8E6C9
    style ECS3 fill:#C8E6C9
    style MongoDB1 fill:#BBDEFB
    style MongoDB2 fill:#BBDEFB
    style MongoDB3 fill:#BBDEFB
    style NAT fill:#FFF9C4
```

**Security Group Configuration**:

| Component | Inbound Rules | Outbound Rules | Security Rationale |
|-----------|--------------|----------------|-------------------|
| **ALB** | Port 443 from 0.0.0.0/0 (internet) | Port 5000 to ECS security group | Accept public HTTPS, route to backend |
| **ECS Tasks** | Port 5000 from ALB security group only | All ports to MongoDB, Redis, S3, internet | Isolated backend, controlled access |
| **MongoDB** | Port 27017 from ECS security group only | None required | Database isolation, ECS-only access |
| **Redis** | Port 6379 from ECS security group only | None required | Cache isolation, ECS-only access |

#### 6.4.4.5 Compliance Controls

**Regulatory Framework**:

The system is designed to comply with major data protection regulations:

| Regulation | Applicability | Key Requirements | Implementation Status |
|-----------|---------------|------------------|----------------------|
| **GDPR** (EU) | All EU users | Data protection, right to be forgotten, consent | Planned compliance |
| **CCPA** (California) | California residents | Data disclosure, deletion rights, opt-out | Planned compliance |
| **SOC 2 Type II** | SaaS products | Security, availability, confidentiality | Architecture aligned |

**GDPR Article 17: Right to Be Forgotten**:

User-initiated account deletion process with 30-day grace period:

```
Day 0: User requests account deletion
    ↓
    - Account marked as "pending_deletion"
    - User receives confirmation email
    - 30-day grace period begins (user can cancel)
    ↓
Day 30: Automatic permanent deletion
    ↓
    - Delete user profile from MongoDB users collection
    - Delete all conversations and messages
    - Delete all document metadata (S3 objects deleted)
    - Delete all file metadata (S3 objects deleted)
    - Anonymize user_id in analytics (irreversible hash)
    - Anonymize user_id in AI interactions (cost tracking preserved)
    ↓
Day 30+: Deletion certificate generated
    ↓
    - Audit log entry: data categories deleted/anonymized
    - Compliance record retained for 7 years
```

**Data Retention Policies**:

| Data Type | Active Retention | Archival Trigger | Archival Storage | Final Deletion |
|-----------|-----------------|------------------|------------------|----------------|
| **User Profiles** | Indefinite | N/A | N/A | Account closure + 30 days |
| **Conversations** | Indefinite (user-controlled) | 1 year inactive | S3 Standard-IA | User deletion or account closure |
| **AI Interactions** | 6 months online | 6 months age | S3 Standard-IA | Automatic after 2 years |
| **Analytics Events** | 3 months online | 3 months age | S3 Standard-IA | Automatic after 1 year |
| **Audit Logs** | 90 days online | 90 days age | S3 Glacier | Automatic after 7 years |

**Data Anonymization for Analytics**:

Irreversible anonymization technique for deleted users:

```
Method: One-way cryptographic hash (SHA-256 with salt)
Input: auth0_id + secret_salt
Output: Anonymous user identifier

Example:
Original: auth0|123456789
Salt: randomly_generated_secret_per_environment
Hash: sha256(auth0|123456789 + salt)
Result: a3f5b8c2d9e1f7a4b6c8d0e2f4a6b8c0d2e4f6a8b0c2d4e6f8a0b2c4d6e8f0a2

Properties:
✓ Irreversible: Cannot derive original user_id from hash
✓ Consistent: Same user_id always produces same hash
✓ Privacy-preserving: Maintains analytics integrity without PII
✓ GDPR-compliant: Fully anonymized data, no longer personal data
```

---

### 6.4.5 Security Monitoring and Incident Response

#### 6.4.5.1 Security Event Tracking

**CloudWatch Security Monitoring**:

Comprehensive security event logging with automated alerting for suspicious patterns:

| Event Type | Log Level | Alert Threshold | Automated Response |
|-----------|-----------|----------------|-------------------|
| **Failed Authentication** | WARNING | > 5 attempts/min from single IP | IP rate limit increase, potential temporary ban |
| **Invalid JWT Token** | WARNING | > 10/min for single endpoint | Investigate token source, possible compromised credentials |
| **Permission Denied** | INFO | > 50/min for single user | Review user permissions, investigate potential attack |
| **Rate Limit Exceeded** | WARNING | > 100/min across all users | DDoS detection, enable stricter rate limiting |
| **Unusual AI Usage** | INFO | > 100 requests/hour per user | Cost abuse monitoring, potential account investigation |
| **Admin Actions** | AUDIT | Every occurrence | Audit log, notification to security team |

**Security Metrics Dashboard**:

```
Real-Time Monitoring Metrics:
- Authentication success/failure rate (target: > 99% success)
- JWT validation latency (target: < 20ms)
- Permission denial rate by endpoint (baseline: < 1%)
- Rate limit hits per hour (baseline: < 10)
- Audit log write throughput (monitor for data loss)
```

#### 6.4.5.2 Circuit Breaker for Auth0

**Resilient Authentication**:

Circuit breaker pattern protects the system from Auth0 service degradation:

| Circuit State | Behavior | Transition Trigger |
|--------------|----------|-------------------|
| **CLOSED** (Normal) | All JWT validation requests to Auth0 | Error rate < 10% |
| **OPEN** (Failure) | Use cached JWKS, extend cache TTL to 4 hours, fail new authentications gracefully | Error rate > 50% in 60-second window |
| **HALF-OPEN** (Testing) | Allow 5 test requests to Auth0 | After 30 seconds in OPEN state |

**Fallback Strategy**:

```
Auth0 Unavailable:
1. Use cached JWKS public keys (extend TTL from 1 hour to 4 hours)
2. Continue validating existing tokens with cached keys
3. Reject new authentication attempts with 503 Service Unavailable
4. Display user-friendly error: "Authentication service temporarily unavailable"
5. Monitor Auth0 status page for incident updates
6. Automatically recover when Auth0 returns to healthy state
```

---

### 6.4.6 Security Architecture Diagrams

#### 6.4.6.1 Security Zone Architecture

```mermaid
graph TB
    subgraph "Internet Zone - Untrusted"
        Internet[Public Internet<br/>Clients, Attackers]
    end
    
    subgraph "Public Zone - DMZ"
        CloudFront[CloudFront CDN<br/>Static Assets<br/>DDoS Protection]
        ALB[Application Load Balancer<br/>TLS Termination<br/>WAF Integration<br/>Ports: 443 HTTPS]
    end
    
    subgraph "Application Zone - Private Subnet"
        subgraph "ECS Fargate Tasks"
            API1[API Instance 1<br/>JWT Validation<br/>Business Logic]
            API2[API Instance 2<br/>JWT Validation<br/>Business Logic]
            API3[API Instance 3<br/>JWT Validation<br/>Business Logic]
        end
        
        AppSG[Security Group: ECS<br/>Inbound: ALB only<br/>Outbound: Data zone + internet]
    end
    
    subgraph "Data Zone - Private Subnet"
        subgraph "Databases"
            MongoDB[(MongoDB Replica Set<br/>3 Nodes<br/>Port 27017<br/>TLS Encrypted)]
            Redis[(Redis Cache<br/>Port 6379<br/>TLS Optional)]
        end
        
        DataSG[Security Group: Databases<br/>Inbound: ECS only<br/>Outbound: None]
    end
    
    subgraph "Storage Zone - AWS Managed"
        S3[(Amazon S3<br/>Encrypted Buckets<br/>Private Access<br/>Presigned URLs)]
    end
    
    subgraph "External Services Zone"
        Auth0[Auth0<br/>Identity Provider<br/>User Authentication]
        OpenAI[OpenAI API<br/>LLM Services<br/>Embeddings]
    end
    
    subgraph "Management Zone"
        NAT[NAT Gateway<br/>Outbound Internet<br/>For ECS Tasks]
        Bastion[Bastion Host future<br/>SSH Access<br/>Operational Management]
    end
    
    Internet -->|HTTPS 443| CloudFront
    Internet -->|HTTPS 443| ALB
    CloudFront -->|CDN Origin| S3
    
    ALB -->|HTTP 5000<br/>Internal VPC| API1
    ALB -->|HTTP 5000<br/>Internal VPC| API2
    ALB -->|HTTP 5000<br/>Internal VPC| API3
    
    API1 -->|MongoDB Protocol<br/>TLS 27017| MongoDB
    API2 -->|MongoDB Protocol<br/>TLS 27017| MongoDB
    API3 -->|MongoDB Protocol<br/>TLS 27017| MongoDB
    
    API1 -->|Redis Protocol<br/>6379| Redis
    API2 -->|Redis Protocol<br/>6379| Redis
    API3 -->|Redis Protocol<br/>6379| Redis
    
    API1 -->|HTTPS<br/>Presigned URLs| S3
    API2 -->|HTTPS<br/>Presigned URLs| S3
    API3 -->|HTTPS<br/>Presigned URLs| S3
    
    API1 -.->|HTTPS<br/>via NAT| Auth0
    API2 -.->|HTTPS<br/>via NAT| Auth0
    API3 -.->|HTTPS<br/>via NAT| Auth0
    
    API1 -.->|HTTPS<br/>via NAT| OpenAI
    API2 -.->|HTTPS<br/>via NAT| OpenAI
    API3 -.->|HTTPS<br/>via NAT| OpenAI
    
    AppSG -.->|Egress Control| NAT
    NAT -.->|Internet Gateway| Internet
    
    style Internet fill:#FFCDD2,stroke:#C62828,stroke-width:3px
    style CloudFront fill:#E1F5FE,stroke:#0277BD,stroke-width:2px
    style ALB fill:#FFF9C4,stroke:#F57F17,stroke-width:2px
    style API1 fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px
    style API2 fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px
    style API3 fill:#C8E6C9,stroke:#2E7D32,stroke-width:2px
    style MongoDB fill:#BBDEFB,stroke:#1565C0,stroke-width:2px
    style Redis fill:#FFE0B2,stroke:#E65100,stroke-width:2px
    style S3 fill:#F3E5F5,stroke:#6A1B9A,stroke-width:2px
    style Auth0 fill:#FCE4EC,stroke:#C2185B,stroke-width:2px
    style OpenAI fill:#FFF3E0,stroke:#EF6C00,stroke-width:2px
    style NAT fill:#E0F2F1,stroke:#00695C,stroke-width:2px
```

**Security Zone Descriptions**:

| Zone | Trust Level | Components | Security Controls |
|------|------------|------------|------------------|
| **Internet Zone** | Untrusted | Public clients, potential attackers | DDoS protection (CloudFront, AWS Shield), WAF rules |
| **Public Zone (DMZ)** | Limited trust | ALB, CloudFront | TLS termination, rate limiting, health checks |
| **Application Zone** | Trusted (authenticated) | ECS Fargate tasks | JWT validation, PBAC, input validation, isolated VPC |
| **Data Zone** | Highly trusted | MongoDB, Redis | No public access, security groups, encryption at rest |
| **Storage Zone** | Highly trusted | Amazon S3 | Private buckets, presigned URLs, server-side encryption |
| **External Services** | Third-party trust | Auth0, OpenAI | TLS connections, API key authentication, circuit breakers |
| **Management Zone** | Operational trust | NAT Gateway, Bastion (future) | Outbound internet only, operational access controls |

---

### 6.4.7 Security Control Matrices

#### 6.4.7.1 Access Control Matrix

| User Role | read:documents | write:documents | delete:documents | ai:completions | ai:conversations | admin:system |
|-----------|----------------|-----------------|------------------|----------------|------------------|--------------|
| **Viewer** | ✓ | ✗ | ✗ | ✓ | ✗ | ✗ |
| **User** | ✓ | ✓ | ✗ | ✓ | ✓ | ✗ |
| **Admin** | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |

**Permission Inheritance**: Admin role inherits all permissions from lower roles plus administrative capabilities.

#### 6.4.7.2 Security Control Implementation Matrix

| Security Control | Implementation | Status | Compliance Standard |
|------------------|----------------|--------|---------------------|
| **Authentication** | Auth0 OAuth 2.0 + OIDC | Planned | SOC 2 CC6.1, ISO 27001 A.9 |
| **Multi-Factor Authentication** | Auth0 MFA (SMS, TOTP, Push) | Planned | NIST 800-63B AAL2 |
| **Authorization** | JWT PBAC with resource checks | Planned | SOC 2 CC6.2 |
| **Encryption at Rest** | AES-256 (MongoDB, S3, Redis) | Planned | GDPR Art. 32, CCPA §1798.81.5 |
| **Encryption in Transit** | TLS 1.3 (TLS 1.2 fallback) | Planned | PCI DSS 4.1, GDPR Art. 32 |
| **Audit Logging** | MongoDB append-only logs | Planned | SOC 2 CC7.2, GDPR Art. 30 |
| **Key Management** | AWS KMS customer-managed keys | Planned | NIST 800-57, FIPS 140-2 |
| **Network Isolation** | VPC private subnets, security groups | Planned | CIS AWS Benchmarks |
| **Rate Limiting** | Redis token bucket (per user/IP) | Planned | OWASP API Security Top 10 |
| **Session Management** | Stateless JWT (15-min expiry) | Planned | OWASP Session Management |

#### 6.4.7.3 Data Classification and Protection Matrix

| Data Classification | Examples | Encryption at Rest | Encryption in Transit | Access Logging | Retention |
|--------------------|----------|-------------------|----------------------|----------------|-----------|
| **Public** | Static assets, public documentation | Optional (S3 SSE) | TLS 1.3 required | No | Indefinite |
| **Internal** | Application code, configuration (non-sensitive) | AES-256 required | TLS 1.3 required | Yes | Per policy |
| **Confidential** | User documents, AI conversations | AES-256 required | TLS 1.3 required | Yes (detailed) | User-controlled |
| **Restricted (PII)** | Email addresses, IP addresses | AES-256 + KMS | TLS 1.3 required | Yes (audit trail) | GDPR compliant |
| **Critical** | Audit logs, authentication events | AES-256 + KMS | TLS 1.3 required | Yes (immutable) | 7 years |

#### 6.4.7.4 Rate Limiting Policy Matrix

| Endpoint Category | Rate Limit | Window | Enforcement Point | Bypass Available |
|------------------|------------|--------|------------------|------------------|
| **General API** | 100 requests/minute | 60 seconds | Redis + Middleware | Admin users only |
| **Write Operations** | 20 requests/minute | 60 seconds | Redis + Middleware | No |
| **AI/LLM Endpoints** | 10 requests/minute | 60 seconds | Redis + Middleware | Premium tier (20/min) |
| **File Uploads** | 20 uploads/minute | 60 seconds | Redis + Middleware | No |
| **Authentication** | 5 attempts/minute | 60 seconds | Auth0 + Middleware | No |

**Rate Limit Response**:

```
HTTP/1.1 429 Too Many Requests
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1705320600
Retry-After: 45

{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded for this endpoint",
    "details": {
      "limit": 100,
      "window": "1 minute",
      "retry_after_seconds": 45
    }
  }
}
```

---

### 6.4.8 Compliance and Standards Alignment

#### 6.4.8.1 Regulatory Compliance Mapping

| Compliance Requirement | Security Control | Implementation | Evidence/Audit |
|-----------------------|------------------|----------------|----------------|
| **GDPR Art. 25** (Privacy by Design) | Security architecture from design phase | Defense-in-depth, encryption, access controls | Architecture documentation |
| **GDPR Art. 30** (Records of Processing) | Audit logging, data retention policies | Immutable audit logs, 7-year retention | Audit log exports |
| **GDPR Art. 32** (Security of Processing) | Encryption, pseudonymization, access controls | AES-256, TLS 1.3, PBAC, MFA | Security assessment reports |
| **CCPA §1798.100** (Right to Know) | User data export API (planned) | Structured data export in portable format | API documentation |
| **SOC 2 CC6.1** (Logical Access Controls) | Auth0 authentication, JWT validation | OAuth 2.0, OIDC, permission-based access | Authentication logs |
| **SOC 2 CC7.2** (System Monitoring) | CloudWatch logs, security event tracking | Real-time monitoring, automated alerting | CloudWatch dashboards |

#### 6.4.8.2 Security Standards Alignment

| Standard | Control Area | Implementation | Maturity Level |
|----------|-------------|----------------|----------------|
| **NIST 800-53** | Access Control (AC) | Auth0 OAuth 2.0, PBAC, MFA | Planned |
| **NIST 800-53** | Audit and Accountability (AU) | Comprehensive audit logging, immutable logs | Planned |
| **NIST 800-53** | Identification and Authentication (IA) | Multi-factor authentication, password policies | Planned |
| **OWASP Top 10** | Broken Access Control | Multi-layer authorization, resource ownership | Planned |
| **OWASP Top 10** | Cryptographic Failures | AES-256, TLS 1.3, KMS key management | Planned |
| **OWASP API Security** | API1: Broken Object Level Authorization | Resource ownership validation, admin override | Planned |
| **OWASP API Security** | API4: Lack of Resources & Rate Limiting | Redis token bucket, per-user limits | Planned |
| **CIS AWS Benchmarks** | IAM, Networking, Logging | Security groups, VPC isolation, CloudWatch | Planned |

---

### 6.4.9 Security Architecture Summary

The CheckSameRepoNoPrompt system implements a comprehensive, multi-layered security architecture designed to protect user data, prevent unauthorized access, and ensure regulatory compliance. Key security highlights include:

**Authentication & Authorization**:
- Enterprise-grade Auth0 OAuth 2.0 + OpenID Connect integration
- Multi-factor authentication with multiple verification methods
- Permission-based access control with resource-level authorization
- Stateless JWT tokens with 15-minute expiration and automatic refresh

**Data Protection**:
- AES-256 encryption at rest for all persistent data (MongoDB, S3, Redis)
- TLS 1.3 encryption in transit for all network communication
- AWS KMS customer-managed keys for sensitive backups
- PII classification, anonymization, and GDPR-compliant deletion

**Security Monitoring & Compliance**:
- Comprehensive audit logging with 7-year retention
- Real-time security event tracking with automated alerting
- GDPR, CCPA, and SOC 2 compliance alignment
- Defense-in-depth architecture with network, application, and data layer security

**Implementation Status**: This security architecture represents the planned design for the CheckSameRepoNoPrompt system. The repository currently contains only a README.md file, with all security implementations pending development phase execution.

---

### 6.4.10 References

#### 6.4.10.1 Technical Specification Sections Referenced

- **Section 1.2 - System Overview**: Project implementation status and context
- **Section 2.5 - Non-Functional Requirements**: High-level security requirements and performance targets
- **Section 3.5 - Third-Party Services**: Auth0 configuration, AWS services, OpenAI API integration details
- **Section 4.3 - Authentication and Authorization Flows (Planned)**: Complete OAuth 2.0 flows, JWT validation, MFA implementation, authorization decision logic
- **Section 5.1 - High-Level Architecture**: Security by design principles, multi-tier architecture, data flow patterns
- **Section 5.4 - Cross-Cutting Concerns**: Authentication framework, error handling, security monitoring, performance requirements
- **Section 6.1 - Core Services Architecture**: Service-level security controls, JWT validation middleware, circuit breaker patterns
- **Section 6.2 - Database Design**: Encryption at rest, MongoDB RBAC, audit logging specifications, PII handling, GDPR compliance controls
- **Section 6.3 - Integration Architecture**: API security, TLS configuration, Auth0 integration, rate limiting, presigned URLs

#### 6.4.10.2 Repository Files Examined

- **`README.md`** (root directory): Project title documentation; repository in pre-implementation phase with no security implementation code

#### 6.4.10.3 Repository Folders Explored

- **Root Directory** (`/`): Contains only README.md file; no source code, security configuration files, authentication modules, or infrastructure implementation

#### 6.4.10.4 External Standards and Frameworks Referenced

- **OAuth 2.0 (RFC 6749)**: Authorization framework for API access
- **OpenID Connect (OIDC)**: Authentication layer on OAuth 2.0
- **PKCE (RFC 7636)**: Proof Key for Code Exchange, OAuth security extension
- **JSON Web Token (JWT, RFC 7519)**: Token format for secure claims
- **NIST 800-63B**: Digital Identity Guidelines (Authentication and Lifecycle Management)
- **GDPR (General Data Protection Regulation)**: EU data protection regulation
- **CCPA (California Consumer Privacy Act)**: California privacy law
- **SOC 2 Type II**: Security, availability, and confidentiality audit framework
- **OWASP Top 10**: Web application security risks
- **OWASP API Security Top 10**: API-specific security risks
- **CIS AWS Benchmarks**: AWS security configuration best practices
- **NIST 800-53**: Security and Privacy Controls for Information Systems
- **NIST 800-57**: Key Management Recommendations
- **FIPS 140-2**: Cryptographic module validation standard

#### 6.4.10.5 Key Findings Summary

**Security Architecture Scope**:
- **Comprehensive Defense-in-Depth**: Multi-layer security spanning network, authentication, authorization, application, and data layers
- **Enterprise Authentication**: Auth0-managed OAuth 2.0 + OIDC with multi-factor authentication
- **Zero Trust Model**: Authentication and authorization required at every layer, no implicit trust
- **Encryption Everywhere**: AES-256 at rest, TLS 1.3 in transit, AWS KMS key management
- **Compliance-Ready**: GDPR, CCPA, SOC 2 alignment with 7-year audit log retention

**Implementation Status**:
- **Pre-Implementation Phase**: All security controls documented represent planned architecture
- **No Security Code**: Repository contains only README.md, no authentication modules, encryption configuration, or security middleware
- **Architecture Complete**: Security design fully specified and ready for development phase implementation

**Total Research Depth**: 18 comprehensive searches across repository and technical specification sections, synthesized into cohesive security architecture documentation.

---

**Document Metadata**:
- **Section**: 6.4 Security Architecture
- **Version**: 1.0 (Planned Architecture)
- **Date**: January 2024
- **Status**: Pre-Implementation (Design Phase)
- **Implementation Code**: None (repository contains only README.md)
- **Next Steps**: Development team to implement security controls per this specification during application development phase

## 6.5 Monitoring and Observability

### 6.5.1 Monitoring Architecture Overview

#### 6.5.1.1 Implementation Status

**Current Repository State**: The CheckSameRepoNoPrompt repository is in **pre-implementation phase**, containing only a README.md file with the project title. No monitoring implementation code, CloudWatch configuration, or observability instrumentation exists at this time.

**Documentation Scope**: This section documents the **planned monitoring and observability architecture** based on comprehensive technical specifications. All monitoring infrastructure, metrics collection, alerting mechanisms, and observability patterns described herein represent the intended monitoring strategy that will be implemented during the development phase.

#### 6.5.1.2 Observability Strategy

The CheckSameRepoNoPrompt system implements a comprehensive **three-pillar observability strategy** encompassing logs, metrics, and distributed tracing to ensure complete visibility into system behavior and enable rapid incident response. This cloud-native monitoring approach leverages AWS CloudWatch as the primary observability platform, supplemented by optional third-party integrations for enhanced capabilities.

**Observability Philosophy**: The architecture adopts an "observe everything, alert intelligently" approach where comprehensive instrumentation provides complete system visibility while intelligent alerting focuses operations teams on actionable issues. This strategy enables proactive problem detection, efficient troubleshooting, and continuous performance optimization.

**Core Observability Pillars**:

| Pillar | Technology | Purpose | Retention Period |
|--------|-----------|---------|-----------------|
| **Logs** | CloudWatch Logs | Detailed event records, debugging, audit trails | 30 days active, 90 days archived |
| **Metrics** | CloudWatch Metrics | Quantitative measurements, performance tracking | 15 months (AWS standard) |
| **Traces** | AWS X-Ray (optional) | Request flow visualization across services | 30 days |
| **Alerts** | CloudWatch Alarms | Proactive issue notification, auto-remediation | Real-time (historical in SNS) |

**Monitoring Architecture Principles**:

1. **Comprehensive Instrumentation**: Instrument all system layers from client requests through backend services to data storage
2. **Structured Logging**: JSON-formatted logs enable programmatic analysis and correlation across distributed services
3. **Multi-Dimensional Metrics**: Metrics tagged with dimensions (service, environment, endpoint, user_tier) enable fine-grained analysis
4. **Correlation-First Design**: Request IDs propagate through all services enabling end-to-end request tracing
5. **Alert Fatigue Prevention**: Alert thresholds tuned to minimize false positives while ensuring critical issue detection
6. **Self-Service Observability**: Dashboards provide development, operations, and business teams direct visibility into system health

#### 6.5.1.3 Monitoring System Architecture

The monitoring infrastructure integrates seamlessly with the application architecture, collecting telemetry from all system components and aggregating it in CloudWatch for analysis and alerting.

```mermaid
graph TB
    subgraph "Client Layer"
        Web["Web Application<br/>React"]
        Mobile["Mobile Apps<br/>React Native/Native"]
        Desktop["Desktop Apps<br/>Electron"]
    end
    
    subgraph "Infrastructure Layer"
        ALB["Application Load Balancer<br/>Access Logs → CloudWatch"]
    end
    
    subgraph "Application Layer - ECS Fargate"
        API1["Flask API Instance 1<br/>Structured JSON Logs<br/>Custom Metrics<br/>X-Ray Tracing"]
        API2["Flask API Instance 2<br/>Structured JSON Logs<br/>Custom Metrics<br/>X-Ray Tracing"]
        LangChain["LangChain Service<br/>AI Operation Logs<br/>Token Usage Metrics"]
    end
    
    subgraph "Data Layer"
        MongoDB[("MongoDB<br/>Slow Query Logs<br/>Connection Metrics")]
        Redis[("Redis<br/>Cache Hit Metrics<br/>Memory Usage")]
        S3["S3<br/>Access Logs<br/>Storage Metrics"]
    end
    
    subgraph "AWS CloudWatch - Central Monitoring Platform"
        subgraph "Log Groups"
            LogAPI["/ecs/flask-api<br/>Application Logs"]
            LogLang["/ecs/langchain<br/>AI/ML Logs"]
            LogALB["/aws/alb/access<br/>HTTP Access Logs"]
        end
        
        subgraph "Metrics"
            MetricInfra["Infrastructure Metrics<br/>CPU, Memory, Network"]
            MetricApp["Application Metrics<br/>Requests, Latency, Errors"]
            MetricBiz["Business Metrics<br/>AI Usage, Token Costs"]
        end
        
        subgraph "Alarms"
            AlarmError["High Error Rate<br/>> 5% for 5 min"]
            AlarmLatency["High Latency<br/>p95 > 1000ms"]
            AlarmCPU["High CPU<br/>> 80% for 10 min"]
        end
        
        subgraph "Dashboards"
            DashHealth["System Health<br/>Operations View"]
            DashBusiness["Business Metrics<br/>Product View"]
            DashSecurity["Security Events<br/>Security View"]
        end
    end
    
    subgraph "External Monitoring - Optional"
        XRay["AWS X-Ray<br/>Distributed Tracing<br/>Service Map"]
        DataDog["DataDog APM<br/>Advanced Analytics"]
        Sentry["Sentry<br/>Error Tracking"]
    end
    
    subgraph "Alerting Channels"
        SNS["Amazon SNS<br/>Notification Hub"]
        Email["Email<br/>Operations Team"]
        PagerDuty["PagerDuty<br/>On-Call Escalation"]
        Slack["Slack<br/>Team Notifications"]
    end
    
    Web -.->|User Actions| ALB
    Mobile -.->|User Actions| ALB
    Desktop -.->|User Actions| ALB
    
    ALB -->|Routes Traffic| API1
    ALB -->|Routes Traffic| API2
    ALB -->|Access Logs| LogALB
    
    API1 -->|Logs| LogAPI
    API2 -->|Logs| LogAPI
    API1 -->|Metrics| MetricApp
    API2 -->|Metrics| MetricApp
    API1 -->|Traces| XRay
    API2 -->|Traces| XRay
    
    API1 -->|AI Requests| LangChain
    API2 -->|AI Requests| LangChain
    LangChain -->|Logs| LogLang
    LangChain -->|Token Metrics| MetricBiz
    
    API1 -.->|Queries| MongoDB
    API2 -.->|Queries| MongoDB
    API1 -.->|Cache Ops| Redis
    API2 -.->|Cache Ops| Redis
    API1 -.->|File Ops| S3
    API2 -.->|File Ops| S3
    
    MongoDB -->|Metrics| MetricInfra
    Redis -->|Metrics| MetricInfra
    S3 -->|Metrics| MetricInfra
    
    API1 -.->|Optional| DataDog
    API2 -.->|Optional| DataDog
    API1 -.->|Errors| Sentry
    API2 -.->|Errors| Sentry
    
    AlarmError -->|Triggers| SNS
    AlarmLatency -->|Triggers| SNS
    AlarmCPU -->|Triggers| SNS
    
    SNS -->|Email| Email
    SNS -->|API| PagerDuty
    SNS -->|Webhook| Slack
    
    style LogAPI fill:#E3F2FD
    style LogLang fill:#E3F2FD
    style LogALB fill:#E3F2FD
    style MetricInfra fill:#FFF3E0
    style MetricApp fill:#FFF3E0
    style MetricBiz fill:#FFF3E0
    style AlarmError fill:#FFCDD2
    style AlarmLatency fill:#FFCDD2
    style AlarmCPU fill:#FFCDD2
    style DashHealth fill:#C8E6C9
    style DashBusiness fill:#C8E6C9
    style DashSecurity fill:#C8E6C9
```

---

### 6.5.2 Logging Infrastructure

#### 6.5.2.1 CloudWatch Logs Implementation

**Log Groups Architecture**: The system organizes logs into dedicated CloudWatch Log Groups based on service boundaries, enabling efficient log management, retention policies, and access control.

| Log Group | Source Component | Log Format | Primary Purpose |
|-----------|-----------------|-----------|-----------------|
| `/ecs/flask-api` | Flask API containers | Structured JSON | Application logs, request/response tracking, error debugging |
| `/ecs/langchain` | LangChain AI service | Structured JSON | AI/ML operation logs, token usage, model interactions |
| `/aws/lambda/*` | Lambda functions (future) | Structured JSON | Serverless function execution logs, cold start tracking |
| `/aws/alb/access` | Application Load Balancer | Apache Combined Format | HTTP access patterns, client IPs, response codes, latency |

**Log Retention Strategy**:

- **Active Logs**: 30 days in CloudWatch Logs for real-time analysis and troubleshooting
- **Archived Logs**: Export to S3 after 30 days with Glacier storage class for 90-day retention
- **Audit Logs**: 7-year retention in S3 for compliance requirements (SOC 2, GDPR, CCPA)
- **Cost Optimization**: Automatic lifecycle policies transition logs to cost-effective storage tiers

#### 6.5.2.2 Structured Logging Standard

**JSON Log Format Specification**: All application logs use a standardized JSON structure enabling programmatic parsing, filtering, and correlation across distributed services.

**Standard Log Entry Schema**:

```json
{
  "timestamp": "2024-01-15T10:30:00.000Z",
  "level": "INFO",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456",
  "service": "api",
  "endpoint": "/api/v1/documents",
  "method": "GET",
  "status_code": 200,
  "duration_ms": 45,
  "cache_hit": true,
  "message": "Request processed successfully",
  "metadata": {
    "query_params": {"limit": 10},
    "response_size": 2048
  }
}
```

**Structured Log Field Definitions**:

| Field Name | Data Type | Required | Description |
|-----------|-----------|----------|-------------|
| `timestamp` | ISO 8601 datetime | Yes | Event timestamp in UTC timezone |
| `level` | String enum | Yes | Log severity (DEBUG, INFO, WARNING, ERROR, CRITICAL) |
| `request_id` | UUID v4 | Yes (for requests) | Unique identifier for request correlation across services |
| `user_id` | String | No | Auth0 user identifier for user-specific log filtering |

| Field Name | Data Type | Required | Description |
|-----------|-----------|----------|-------------|
| `service` | String | Yes | Service name (api, langchain, lambda) for service-specific filtering |
| `message` | String | Yes | Human-readable log message describing the event |
| `metadata` | JSON Object | No | Additional context-specific data (query params, performance metrics) |

#### 6.5.2.3 Log Levels and Usage Guidelines

**Log Level Definitions**: Consistent log level usage ensures appropriate signal-to-noise ratio and enables efficient log filtering during troubleshooting.

| Log Level | Use Cases | Example Scenarios | Production Volume |
|-----------|-----------|-------------------|-------------------|
| **DEBUG** | Verbose diagnostic information | Variable values, function entry/exit, loop iterations | Development only (disabled in production) |
| **INFO** | General informational messages | Successful request completion, cache hits, normal state transitions | High volume (majority of logs) |
| **WARNING** | Warning conditions requiring attention | Cache misses, retry attempts, deprecated API usage, high latency | Moderate volume (10-20% of logs) |
| **ERROR** | Error conditions requiring investigation | Failed API calls, validation errors, database connection failures | Low volume (< 5% of logs) |

**CRITICAL Log Level**:

- **Purpose**: Critical failures requiring immediate human intervention
- **Examples**: Service unavailable, data corruption detected, security breach, complete system failure
- **Volume**: Extremely rare (< 0.1% of logs)
- **Automatic Actions**: Triggers PagerDuty alerts, sends SMS to on-call engineer, creates high-priority incident ticket

#### 6.5.2.4 PII Handling and Data Privacy

**Personally Identifiable Information (PII) Protection**: Logging implementation includes automatic PII detection and redaction to ensure compliance with GDPR, CCPA, and data privacy regulations.

**PII Redaction Strategy**:

| Data Type | Redaction Method | Example |
|-----------|-----------------|---------|
| **Passwords** | Complete redaction | `"password": "***REDACTED***"` |
| **JWT Tokens** | Partial display (last 6 chars) | `"token": "...440000"` |
| **Email Addresses** | Hash or mask domain | `"email": "user@***"` |
| **Credit Card Numbers** | Mask middle digits | `"card": "****-****-****-1234"` |

**PII Logging Configuration**:

- **Development Environment**: Full logging enabled for debugging (PII visible)
- **Staging Environment**: PII hashing enabled, original values replaced with SHA-256 hashes
- **Production Environment**: Strict PII redaction, automatic scrubbing before log emission
- **Compliance Mode**: Zero PII logging, user_id hashed using one-way cryptographic function

#### 6.5.2.5 Log Sampling and Volume Management

**Log Sampling Strategy**: High-traffic endpoints implement intelligent log sampling to balance observability with cost efficiency while maintaining complete visibility for errors and critical operations.

**Sampling Rules**:

| Endpoint Category | Sample Rate | Rationale |
|------------------|-------------|-----------|
| Health Check Endpoints (`/health`, `/ping`) | 10% (1 in 10 requests) | High volume, low value, errors logged at 100% |
| Read Operations (GET requests) | 100% (all requests) | Moderate volume, valuable for debugging |
| Write Operations (POST, PUT, DELETE) | 100% (all requests) | Always logged for audit trail and data integrity |
| Error Responses (4xx, 5xx status codes) | 100% (all errors) | Critical for troubleshooting and incident response |

**Log Volume Estimates**:

- **Expected Request Volume**: 1,000 requests/second at peak load
- **Average Log Entry Size**: 512 bytes (JSON-formatted)
- **Daily Log Volume**: ~21 GB/day (1000 req/s × 512 bytes × 86,400 seconds × 50% effective sample rate)
- **Monthly CloudWatch Logs Cost**: ~$30/month (at $0.50/GB ingestion + $0.03/GB storage)

#### 6.5.2.6 Request Correlation and Distributed Tracing

**Request ID Propagation**: Every request receives a unique identifier that propagates through all system components, enabling end-to-end request tracing across distributed services.

**Request ID Lifecycle**:

1. **Generation**: UUID v4 generated at Application Load Balancer or API entry point
2. **Propagation**: Included in all downstream service calls via `X-Request-ID` HTTP header
3. **Logging**: Embedded in every log entry's `request_id` field for correlation
4. **Tracing**: Used as AWS X-Ray trace ID for distributed tracing visualization
5. **Response**: Returned to client in HTTP response headers for client-side correlation

**Log Correlation Query Example**:

The following CloudWatch Logs Insights query retrieves all logs related to a specific request, ordered chronologically to reconstruct the complete request flow:

```sql
fields @timestamp, level, service, message, duration_ms
| filter request_id = "550e8400-e29b-41d4-a716-446655440000"
| sort @timestamp asc
```

**Expected Query Results**: Chronologically ordered log entries showing:

1. ALB access log: Request received, client IP, user agent
2. API entry log: JWT validation, user authentication, permission check
3. Cache query log: Redis cache lookup, cache miss/hit status
4. Database query log: MongoDB query execution, query duration
5. LangChain log (if AI request): LLM API call, token usage
6. API response log: Response preparation, total request duration
7. ALB access log: Response sent, final status code

---

### 6.5.3 Metrics Collection and Monitoring

#### 6.5.3.1 Infrastructure Metrics (Automatic Collection)

**AWS-Managed Infrastructure Metrics**: CloudWatch automatically collects infrastructure-level metrics from managed AWS services without requiring application instrumentation.

| Metric Category | Specific Metrics Collected | Source Service | Collection Frequency |
|----------------|---------------------------|----------------|---------------------|
| **ECS Service** | CPU utilization, memory utilization, task count, task failures | Amazon ECS | 1-minute intervals |
| **Application Load Balancer** | Request count, target response time, 4xx/5xx error rates, active connections | AWS ALB | 1-minute intervals |
| **MongoDB** (if Atlas) | Connection count, query execution time, replica lag, disk IOPS | MongoDB Atlas exporter | 1-minute intervals |
| **Redis** (if ElastiCache) | CPU utilization, memory usage, evicted keys, cache hit rate | Amazon ElastiCache | 1-minute intervals |

**ECS Task Metrics**:

| Metric Name | Unit | Typical Value | Alert Threshold |
|------------|------|---------------|----------------|
| `CPUUtilization` | Percent | 40-60% | > 80% for 5 minutes (scale up) |
| `MemoryUtilization` | Percent | 50-70% | > 85% for 5 minutes (scale up) |
| `RunningTaskCount` | Count | 3-10 tasks | < 2 tasks (insufficient capacity) |
| `TaskStartFailures` | Count | 0 | > 0 (deployment issue) |

#### 6.5.3.2 Application Metrics (Custom Collection)

**Custom Application Metrics**: The Flask API emits custom metrics providing deep visibility into application behavior, performance characteristics, and business outcomes.

**Application Performance Metrics**:

| Metric Name | Type | Purpose | Unit |
|------------|------|---------|------|
| `api.request.count` | Counter | Total API requests by endpoint and method | Count |
| `api.request.duration` | Histogram | Request latency distribution (p50, p95, p99 percentiles) | Milliseconds |
| `api.error.rate` | Gauge | Percentage of failed requests (5xx errors) | Percent |
| `api.cache.hit_rate` | Gauge | Cache effectiveness (Redis hit ratio) | Percent |

**AI/ML Operation Metrics**:

| Metric Name | Type | Purpose | Unit |
|------------|------|---------|------|
| `ai.tokens.consumed` | Counter | LLM token usage for cost tracking and quota management | Count |
| `ai.request.duration` | Histogram | AI request latency (includes LLM API call time) | Milliseconds |
| `ai.model.calls` | Counter | API calls per model (GPT-4, GPT-3.5, embeddings) | Count |
| `ai.cost.estimate` | Counter | Estimated cost based on token usage and model pricing | USD |

**Security and Authentication Metrics**:

| Metric Name | Type | Purpose | Unit |
|------------|------|---------|------|
| `auth.failed.attempts` | Counter | Failed authentication attempts (potential attacks) | Count |
| `auth.jwt.validation.latency` | Histogram | JWT validation performance | Milliseconds |
| `auth.permission.denied` | Counter | Authorization failures by endpoint | Count |
| `rate_limit.exceeded` | Counter | Rate limit violations by user and endpoint | Count |

#### 6.5.3.3 Metric Collection Implementation

**CloudWatch PutMetricData Integration**: The Flask application uses the AWS SDK (Boto3) to emit custom metrics to CloudWatch using the PutMetricData API.

**Metric Emission Strategies**:

1. **Real-Time Emission**: Critical metrics (errors, security events) emitted immediately as events occur
2. **Batched Emission**: Performance metrics batched and emitted every 60 seconds to reduce API calls
3. **Asynchronous Emission**: Metrics emitted in background thread to avoid blocking request processing
4. **Retry Logic**: Failed metric emissions retried with exponential backoff (3 attempts maximum)

**Metric Dimensions**: All custom metrics include dimensions enabling fine-grained filtering and aggregation:

| Dimension Name | Possible Values | Purpose |
|---------------|----------------|---------|
| `Service` | api, langchain, lambda | Isolate metrics by service for service-specific analysis |
| `Environment` | production, staging, development | Separate production metrics from lower environments |
| `Endpoint` | /api/v1/documents, /api/v1/ai/completions | Per-endpoint performance and error tracking |
| `UserTier` | free, premium, enterprise | Compare usage patterns across subscription tiers |

**Example Metric Emission Code Pattern**:

```python
# Pseudocode illustrating metric emission pattern (not actual implementation)
cloudwatch.put_metric_data(
    Namespace='CheckSameRepoNoPrompt/API',
    MetricData=[
        {
            'MetricName': 'api.request.duration',
            'Value': duration_ms,
            'Unit': 'Milliseconds',
            'Timestamp': datetime.utcnow(),
            'Dimensions': [
                {'Name': 'Service', 'Value': 'api'},
                {'Name': 'Endpoint', 'Value': '/api/v1/documents'},
                {'Name': 'Environment', 'Value': 'production'}
            ]
        }
    ]
)
```

#### 6.5.3.4 Business Metrics and KPI Tracking

**Business Intelligence Metrics**: Beyond operational metrics, the system tracks business-focused KPIs providing product teams visibility into user engagement, feature adoption, and revenue drivers.

**User Engagement Metrics**:

| Metric Name | Definition | Business Value |
|------------|------------|----------------|
| `business.active_users.daily` | Unique authenticated users per day | Measure daily active user (DAU) growth |
| `business.active_users.monthly` | Unique authenticated users per 30 days | Track monthly active user (MAU) trends |
| `business.session.duration` | Average time between first and last request in session | Understand user engagement depth |
| `business.feature.adoption` | Usage count per feature (AI, documents, search) | Identify popular features for investment prioritization |

**Revenue and Cost Metrics**:

| Metric Name | Definition | Business Value |
|------------|------------|----------------|
| `business.ai.tokens.cost` | Total LLM token cost per day/month | Monitor AI infrastructure spend |
| `business.revenue.mrr` | Monthly recurring revenue by subscription tier | Track revenue growth and tier distribution |
| `business.churn.rate` | Percentage of users canceling subscriptions | Measure customer retention health |
| `business.cache.savings` | Cost avoided through cache hits | Quantify caching infrastructure ROI |

---

### 6.5.4 Distributed Tracing and Request Flow Visualization

#### 6.5.4.1 AWS X-Ray Integration (Optional)

**Distributed Tracing Architecture**: AWS X-Ray provides end-to-end request tracing across microservices, visualizing request flow from API entry through LangChain to external services (OpenAI, MongoDB).

**X-Ray Implementation Details**:

- **Instrumentation Method**: X-Ray SDK integrated into Flask application and LangChain wrapper
- **Trace Segments**: Each service creates trace segments representing its portion of request processing
- **Subsegments**: Individual operations (database queries, LLM calls, cache lookups) tracked as subsegments
- **Sampling Rate**: 100% sampling for errors, 10% sampling for successful requests to balance observability with cost

**X-Ray Trace Data Components**:

| Trace Component | Content | Purpose |
|----------------|---------|---------|
| **Trace ID** | Unique identifier for entire request | Correlate all segments across services |
| **Segment** | Service-level execution details | Track latency and errors per service |
| **Subsegment** | Operation-level details (DB query, API call) | Identify specific bottlenecks within service |
| **Annotations** | Key-value pairs (user_id, endpoint) | Enable filtering and search in X-Ray console |
| **Metadata** | Additional context (query params, payload size) | Provide debugging context for traces |

**X-Ray Service Map**: Automatically generated visual representation of service dependencies showing:

- Request flow from ALB through API to LangChain to OpenAI and MongoDB
- Average latency per service
- Error rates per service and dependency
- Traffic volume between services

#### 6.5.4.2 Request Trace Flow Example

The following diagram illustrates a complete request trace with timing breakdowns across all system components:

```mermaid
sequenceDiagram
    participant Client
    participant ALB as Application<br/>Load Balancer
    participant API as Flask API
    participant Redis as Redis Cache
    participant Auth0
    participant LangChain
    participant OpenAI
    participant MongoDB
    
    Note over Client,MongoDB: AI Completion Request Trace<br/>Request ID: 550e8400-e29b-41d4-a716-446655440000
    
    Client->>ALB: POST /api/v1/ai/completions<br/>Authorization: Bearer {JWT}<br/>[0ms]
    ALB->>API: Forward Request<br/>[+5ms] (TLS termination)
    
    Note over API: X-Ray Segment Start<br/>Service: flask-api
    
    API->>Redis: GET jwks:auth0 (JWKS cache)<br/>[+10ms]
    Redis-->>API: Cache HIT (public keys)<br/>[+12ms]
    
    API->>Auth0: Validate JWT signature<br/>(using cached keys)<br/>[+12ms]
    Note over API: JWT validation: 8ms
    Auth0-->>API: JWT Valid ✓<br/>[+20ms]
    
    Note over API: Authorization check: 2ms<br/>Permission: ai:completions ✓
    
    API->>Redis: GET ai:prompt:hash123<br/>(Check cached response)<br/>[+25ms]
    Redis-->>API: Cache MISS<br/>[+27ms]
    
    Note over API: X-Ray Subsegment Start<br/>Operation: AI Completion
    
    API->>LangChain: AI Completion Request<br/>{prompt, model, params}<br/>[+30ms]
    
    Note over LangChain: X-Ray Segment Start<br/>Service: langchain
    
    LangChain->>MongoDB: Query conversation history<br/>(if multi-turn)<br/>[+35ms]
    MongoDB-->>LangChain: Previous messages<br/>[+55ms] (20ms query)
    
    LangChain->>LangChain: Build prompt with context<br/>[+60ms] (5ms)
    
    Note over LangChain: X-Ray Subsegment Start<br/>Operation: OpenAI API Call
    
    LangChain->>OpenAI: POST /v1/chat/completions<br/>model: gpt-4<br/>[+65ms]
    Note over OpenAI: LLM Processing<br/>Token Generation
    OpenAI-->>LangChain: AI Response<br/>tokens_used: 500<br/>[+2565ms] (2500ms LLM latency)
    
    Note over LangChain: X-Ray Subsegment End<br/>OpenAI Call: 2500ms
    
    LangChain->>MongoDB: Save AI interaction<br/>(prompt, response, cost)<br/>[+2570ms]
    MongoDB-->>LangChain: Saved ✓<br/>[+2590ms] (20ms write)
    
    Note over LangChain: X-Ray Segment End<br/>LangChain Total: 2560ms
    
    LangChain-->>API: AI Response + Metadata<br/>[+2595ms]
    
    API->>Redis: SET ai:prompt:hash123<br/>(Cache response, TTL=1hr)<br/>[+2600ms]
    Redis-->>API: Cached ✓<br/>[+2605ms]
    
    API->>MongoDB: Log request metrics<br/>(async, non-blocking)<br/>[+2605ms]
    
    Note over API: X-Ray Segment End<br/>API Total: 2600ms<br/>Breakdown: JWT 20ms, AI 2560ms, Cache 20ms
    
    API-->>ALB: 200 OK<br/>JSON response + metadata<br/>[+2610ms]
    ALB-->>Client: Response<br/>[+2615ms]
    
    Note over Client,MongoDB: Total Request Duration: 2615ms<br/>✓ Within p95 target (< 5000ms)
```

**Trace Analysis Insights**:

- **Total Request Duration**: 2,615ms (well within 5-second p95 target for AI requests)
- **Bottleneck Identification**: OpenAI API call accounts for 95% of latency (2,500ms out of 2,615ms)
- **Optimization Opportunities**: 
  - JWT validation optimized through Redis caching (8ms vs. 100ms without cache)
  - AI response caching prevents duplicate LLM calls for identical prompts
  - Asynchronous metric logging prevents blocking response delivery

---

### 6.5.5 Alerting and Incident Response

#### 6.5.5.1 CloudWatch Alarms Configuration

**Intelligent Alerting Strategy**: Alarms configured with carefully tuned thresholds to detect genuine issues while minimizing false positives and alert fatigue.

**Critical System Alarms**:

| Alarm Name | Metric | Threshold Condition | Evaluation Period | Alert Action |
|-----------|--------|-------------------|------------------|--------------|
| High Error Rate | `api.error.rate` | > 5% | 5 minutes | Email operations + PagerDuty |
| API Latency Spike | `api.request.duration` (p95) | > 1000ms | 5 minutes | Email engineering team |
| ECS CPU High | `ECS CPUUtilization` | > 80% | 10 minutes | Auto-scale + email operations |
| Database Connection Pool Exhausted | `MongoDB connections` | > 80% of max | 5 minutes | Email DBA + create incident |

**Secondary Alarms**:

| Alarm Name | Metric | Threshold Condition | Evaluation Period | Alert Action |
|-----------|--------|-------------------|------------------|--------------|
| Cache Hit Rate Low | `api.cache.hit_rate` | < 70% | 15 minutes | Email engineering (tuning needed) |
| Failed Auth Spike | `auth.failed.attempts` | > 100 attempts/min | 5 minutes | Email security team (potential attack) |
| AI Cost Threshold | `ai.tokens.cost` | > $500/day | 1 day | Email finance + engineering |
| Task Launch Failures | `ECS TaskStartFailures` | > 0 | 1 minute | Email operations (deployment issue) |

#### 6.5.5.2 Alert Routing and Escalation

**Multi-Channel Notification Architecture**: CloudWatch Alarms trigger Amazon SNS topics which fan out notifications to multiple channels based on severity and audience.

```mermaid
graph TB
    subgraph "CloudWatch Alarms"
        AlarmCritical[Critical Alarms<br/>Error Rate, Latency, CPU]
        AlarmWarning[Warning Alarms<br/>Cache, Auth, Cost]
        AlarmInfo[Informational Alarms<br/>Capacity, Usage Patterns]
    end
    
    subgraph "Amazon SNS Topics"
        SNSCritical[critical-alerts Topic]
        SNSWarning[warning-alerts Topic]
        SNSInfo[info-alerts Topic]
    end
    
    subgraph "Notification Channels"
        PagerDuty[PagerDuty<br/>On-Call Engineer<br/>SMS + Phone Call]
        Email1[Email<br/>Operations Team<br/>ops@example.com]
        Email2[Email<br/>Engineering Team<br/>eng@example.com]
        Slack[Slack<br/>#alerts Channel<br/>@here Mention]
        Webhook[Custom Webhook<br/>Incident Management System]
    end
    
    subgraph "Auto-Remediation"
        Lambda1[Lambda Function<br/>Auto-Scale ECS]
        Lambda2[Lambda Function<br/>Restart Service]
        Lambda3[Lambda Function<br/>Clear Cache]
    end
    
    AlarmCritical -->|ALARM State| SNSCritical
    AlarmWarning -->|ALARM State| SNSWarning
    AlarmInfo -->|ALARM State| SNSInfo
    
    SNSCritical -->|High Priority| PagerDuty
    SNSCritical -->|Email| Email1
    SNSCritical -->|Webhook| Slack
    SNSCritical -->|Trigger| Lambda1
    
    SNSWarning -->|Email| Email2
    SNSWarning -->|Webhook| Slack
    SNSWarning -->|Trigger| Lambda2
    
    SNSInfo -->|Email| Email2
    
    Lambda1 -->|Increase Task Count| ECS[ECS Auto-Scaling]
    Lambda2 -->|Force Restart| ECS2[ECS Service]
    Lambda3 -->|FLUSHDB| Redis[Redis Cache]
    
    style AlarmCritical fill:#FFCDD2
    style AlarmWarning fill:#FFE0B2
    style AlarmInfo fill:#C8E6C9
    style PagerDuty fill:#B39DDB
    style Lambda1 fill:#81C784
    style Lambda2 fill:#81C784
    style Lambda3 fill:#81C784
```

**Escalation Policy**:

| Severity | Initial Notification | 15-Minute Escalation | 30-Minute Escalation |
|----------|---------------------|---------------------|---------------------|
| **P0 - Critical** | On-call engineer (PagerDuty) | Engineering manager + operations lead | VP Engineering + incident commander |
| **P1 - High** | Operations team (email) | On-call engineer (PagerDuty) | Engineering manager |
| **P2 - Medium** | Engineering team (email) | Operations team (email) | No escalation |
| **P3 - Low** | Email notification only | No escalation | No escalation |

#### 6.5.5.3 Automated Remediation Actions

**Self-Healing Mechanisms**: Critical alarms trigger Lambda functions that automatically remediate common issues without human intervention.

**Auto-Remediation Scenarios**:

| Trigger Alarm | Automated Action | Expected Outcome | Rollback Condition |
|--------------|------------------|------------------|-------------------|
| ECS CPU > 80% | Increase ECS desired task count by 1 (max 10) | Distribute load, reduce CPU utilization | If scaling doesn't reduce CPU within 10 min |
| Memory > 85% | Restart ECS tasks (rolling restart) | Clear memory leaks, refresh task state | If restart fails or repeats within 1 hour |
| Cache Hit Rate < 70% | Warm cache with popular queries | Improve cache effectiveness | If warming doesn't improve hit rate |
| Task Launch Failures | Rollback to previous task definition | Revert to last known good deployment | Manual intervention if rollback fails |

#### 6.5.5.4 Incident Response Workflow

**Structured Incident Management Process**: When alarms trigger, the operations team follows a documented incident response workflow ensuring consistent, efficient issue resolution.

**Incident Response Stages**:

1. **Detection** (0-2 minutes): CloudWatch alarm triggers, notifications sent to on-call engineer
2. **Acknowledgment** (2-5 minutes): Engineer acknowledges alert in PagerDuty, begins investigation
3. **Assessment** (5-15 minutes): Engineer reviews CloudWatch dashboards, logs, and metrics to determine severity and root cause
4. **Communication** (15-30 minutes): Create incident ticket, notify stakeholders, establish communication channels
5. **Mitigation** (30-120 minutes): Apply fixes, deploy hotfixes, or initiate disaster recovery procedures
6. **Resolution** (2-4 hours): Verify system stability, close incident ticket, document resolution
7. **Post-Mortem** (24-48 hours): Conduct blameless post-mortem, document lessons learned, create preventive action items

**Recovery Time Objectives (RTO)** by Scenario:

| Failure Scenario | RTO Target | Recovery Procedure |
|-----------------|-----------|-------------------|
| Single ECS Task Failure | < 1 minute | ECS auto-restarts task, health checks verify recovery |
| MongoDB Primary Failure | < 10 seconds | Replica set auto-failover to secondary node |
| Availability Zone Failure | < 5 minutes | ALB routes traffic to healthy availability zones |
| Full Application Outage | < 30 minutes | Rollback deployment, restart services, verify health checks |

---

### 6.5.6 Dashboards and Visualization

#### 6.5.6.1 CloudWatch Dashboard Architecture

**Multi-Audience Dashboard Strategy**: Specialized dashboards tailored for different teams (operations, engineering, business, security) provide role-specific visibility into system health and performance.

**System Health Dashboard (Operations Team)**:

**Purpose**: Real-time operational health monitoring for incident detection and response

**Dashboard Widgets**:

| Widget Type | Metrics Displayed | Time Range | Refresh Rate |
|------------|------------------|-----------|--------------|
| Line Graph | API request rate (requests/second) by endpoint | Last 3 hours | 1 minute |
| Line Graph | Error rate percentage (4xx, 5xx errors) | Last 3 hours | 1 minute |
| Line Graph | Request latency (p50, p95, p99 percentiles) | Last 3 hours | 1 minute |
| Number Widget | Current ECS task count and health status | Real-time | 1 minute |

| Widget Type | Metrics Displayed | Time Range | Refresh Rate |
|------------|------------------|-----------|--------------|
| Stacked Area | Database query volume (reads vs. writes) | Last 6 hours | 5 minutes |
| Heat Map | Cache hit rate by endpoint | Last 24 hours | 5 minutes |
| Alarm Status | Critical alarms current state (OK, ALARM, INSUFFICIENT_DATA) | Real-time | 1 minute |

**Business Metrics Dashboard (Product Team)**:

**Purpose**: Track user engagement, feature adoption, and revenue drivers

**Dashboard Widgets**:

| Widget | Metrics Displayed | Business Question Answered |
|--------|------------------|---------------------------|
| Number Widget | Daily Active Users (DAU), Monthly Active Users (MAU) | How many users are actively using the platform? |
| Line Graph | AI request volume by model (GPT-4, GPT-3.5) | Which AI features are most popular? |
| Pie Chart | Request distribution by subscription tier | What percentage of requests come from premium vs. free users? |
| Line Graph | Estimated daily AI costs (token usage × pricing) | What is our AI infrastructure spend trend? |

**Security Events Dashboard (Security Team)**:

**Purpose**: Monitor authentication failures, authorization violations, and suspicious activity

**Dashboard Widgets**:

| Widget | Metrics Displayed | Security Concern Addressed |
|--------|------------------|---------------------------|
| Line Graph | Failed authentication attempts per minute | Are we experiencing brute-force attacks? |
| Heat Map | Permission denied events by endpoint and user | Are users attempting unauthorized access? |
| Line Graph | Rate limit violations by IP address | Are we experiencing API abuse or DDoS attempts? |
| Table | Top 10 IP addresses with highest error rates | Which sources are generating the most errors? |

#### 6.5.6.2 Dashboard Layout Specification

**System Health Dashboard Visual Layout**:

```
┌─────────────────────────────────────────────────────────────────┐
│ System Health Dashboard - Production Environment                │
│ Last Updated: 2024-01-15 10:30:00 UTC (Auto-refresh: 1 minute)│
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐        │
│  │ ECS Tasks    │  │ Error Rate   │  │ API Latency  │        │
│  │    8 / 10    │  │    1.2%      │  │  p95: 245ms  │        │
│  │  ✓ Healthy   │  │  ✓ Normal    │  │  ✓ Normal    │        │
│  └──────────────┘  └──────────────┘  └──────────────┘        │
│                                                                 │
│  ┌────────────────────────────────────────────────────────┐   │
│  │ API Request Rate (Last 3 Hours)                       │   │
│  │                                                        │   │
│  │  1200 ┤                                               │   │
│  │  1000 ┤        ╭──╮    ╭──╮                          │   │
│  │   800 ┤     ╭──╯  ╰────╯  ╰──╮                       │   │
│  │   600 ┤  ╭──╯                 ╰───╮                  │   │
│  │   400 ┤──╯                         ╰─────            │   │
│  │       └────────────────────────────────────────────► │   │
│  │        08:00    09:00    10:00    11:00              │   │
│  └────────────────────────────────────────────────────────┘   │
│                                                                 │
│  ┌──────────────────────────┐  ┌──────────────────────────┐  │
│  │ Error Rate (%)           │  │ Latency Percentiles (ms) │  │
│  │  4 ┤                     │  │ 1000 ┤                   │  │
│  │  3 ┤   ╭╮                │  │  800 ┤           p99     │  │
│  │  2 ┤   │╰╮               │  │  600 ┤        p95        │  │
│  │  1 ┤───╯ ╰─────          │  │  400 ┤     p50           │  │
│  │  0 └───────────────────► │  │  200 ┤───────            │  │
│  └──────────────────────────┘  └──────────────────────────┘  │
│                                                                 │
│  ┌────────────────────────────────────────────────────────┐   │
│  │ Active Alarms                                          │   │
│  │  ✓ API Latency: OK                                     │   │
│  │  ✓ Error Rate: OK                                      │   │
│  │  ⚠ Cache Hit Rate: WARNING (68% - below 70% threshold)│   │
│  │  ✓ ECS CPU: OK                                         │   │
│  └────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

---

### 6.5.7 Performance Monitoring and SLA Tracking

#### 6.5.7.1 API Response Time Targets

**Performance SLA Commitments**: The system maintains strict performance targets across different endpoint categories to ensure consistent user experience.

| Endpoint Category | p50 Target | p95 Target | p99 Target |
|------------------|-----------|-----------|-----------|
| Simple CRUD (GET, POST) | < 100ms | < 300ms | < 500ms |
| Complex Queries (Aggregations) | < 300ms | < 800ms | < 1200ms |
| AI Completions (Simple) | < 2000ms | < 5000ms | < 8000ms |
| AI Conversations (Multi-turn) | < 3000ms | < 6000ms | < 10000ms |

**SLA Monitoring Implementation**:

- **CloudWatch Metric**: `api.request.duration` histogram with percentile aggregation (p50, p95, p99)
- **Alert Threshold**: P95 latency > target for 5 consecutive minutes triggers warning alert
- **Business Impact**: Latency SLA breaches tracked monthly, reported to leadership as Key Performance Indicator (KPI)
- **Performance Budget**: Each endpoint has latency budget allocating time across components (network, authentication, business logic, database)

#### 6.5.7.2 Availability and Uptime Tracking

**Availability SLA Targets**:

| Component | SLA Target | Monthly Downtime Allowance | Mechanism |
|-----------|-----------|---------------------------|-----------|
| Overall Application | 99.9% | 43.2 minutes | Multi-AZ deployment, auto-healing |
| Flask API | 99.95% | 21.6 minutes | ECS health checks, auto-restart |
| MongoDB | 99.95% | 21.6 minutes | Replica set auto-failover |
| Auth0 | 99.99% | 4.32 minutes | Auth0 enterprise SLA |

**Uptime Calculation Methodology**:

- **Measurement Period**: Calendar month (first day 00:00:00 UTC to last day 23:59:59 UTC)
- **Downtime Definition**: Any period where >50% of requests return 5xx errors or timeout
- **Exclusions**: Scheduled maintenance windows (announced 7 days in advance), AWS service outages (covered by AWS SLA)
- **Tracking**: CloudWatch Synthetics canary runs every 5 minutes, logs success/failure, calculates uptime percentage

**Synthetic Monitoring**: CloudWatch Synthetics canary scripts simulate user journeys to proactively detect availability issues:

1. **API Health Check Canary**: GET `/health` endpoint every 5 minutes from multiple AWS regions
2. **Authentication Flow Canary**: Complete OAuth flow every 15 minutes to verify Auth0 integration
3. **End-to-End Journey Canary**: Create document → Retrieve document → Delete document every 30 minutes

#### 6.5.7.3 Capacity and Scalability Monitoring

**Capacity Planning Metrics**: Proactive monitoring of resource utilization trends enables capacity planning before reaching limits.

**Capacity Thresholds**:

| Resource | Current Capacity | Usage Threshold (Warning) | Usage Threshold (Critical) |
|----------|-----------------|--------------------------|---------------------------|
| ECS Task Count | 3-10 tasks | 8 tasks (80% of max) | 10 tasks (100% of max) |
| MongoDB Storage | 100 GB provisioned | 80 GB used (80%) | 90 GB used (90%) |
| Redis Memory | 4 GB provisioned | 3.2 GB used (80%) | 3.6 GB used (90%) |
| ALB Target Connections | 5000 concurrent | 4000 connections (80%) | 4500 connections (90%) |

**Growth Trend Analysis**: Weekly automated report analyzes metric trends over past 30 days to predict capacity exhaustion dates:

- **Request Volume Growth**: If request rate increases 10% week-over-week, predict date when current capacity insufficient
- **Data Storage Growth**: Extrapolate database storage growth to predict when additional capacity needed
- **Cost Forecasting**: Estimate future infrastructure costs based on growth trends

---

### 6.5.8 Security Event Monitoring

#### 6.5.8.1 Security Event Tracking

**Security-Focused Logging and Alerting**: Comprehensive monitoring of authentication, authorization, and suspicious activity patterns enables rapid security incident detection and response.

**Security Event Categories**:

| Event Type | Log Level | Example Events | Alert Threshold |
|-----------|-----------|----------------|----------------|
| **Failed Authentication** | WARNING | Invalid credentials, expired JWT, missing token | > 5 attempts/min from single IP |
| **Authorization Failures** | INFO | Permission denied, insufficient privileges | > 50 denials/min for single user |
| **Suspicious Activity** | WARNING | Unusual API usage patterns, geographic anomalies | > 100 requests/hour from new IP |
| **Admin Actions** | AUDIT | User role changes, permission grants, system config | Every occurrence logged |

**Security Metrics Dashboard**:

| Metric | Visualization | Alert Configuration |
|--------|--------------|-------------------|
| Authentication success/failure rate | Line graph (target: > 99% success) | < 95% success rate for 15 minutes |
| JWT validation latency | Histogram (target: < 20ms p95) | p95 > 50ms for 10 minutes |
| Permission denial rate by endpoint | Heat map (baseline: < 1% per endpoint) | > 5% denial rate for any endpoint |
| Rate limit violations | Counter (baseline: < 10/hour) | > 100 violations/hour |

#### 6.5.8.2 Circuit Breaker Monitoring

**Auth0 Circuit Breaker Pattern**: Resilient authentication architecture includes circuit breaker monitoring to detect and respond to Auth0 service degradation.

**Circuit Breaker States**:

| State | Behavior | Metric Tracked | Transition Trigger |
|-------|----------|----------------|-------------------|
| **CLOSED** (Normal) | All requests to Auth0 proceed | Auth0 API error rate | Error rate < 10% |
| **OPEN** (Failure) | Use cached JWKS, extend TTL to 4 hours | Circuit breaker opens counter | Error rate > 50% in 60-second window |
| **HALF-OPEN** (Testing) | Allow 5 test requests to Auth0 | Test request success rate | After 30 seconds in OPEN state |

**Circuit Breaker Metrics**:

- `auth.circuit_breaker.state`: Current circuit breaker state (0=CLOSED, 1=OPEN, 2=HALF-OPEN)
- `auth.circuit_breaker.open_count`: Number of times circuit opened in last 24 hours
- `auth.circuit_breaker.cache_fallback`: Requests served from cached JWKS during circuit open

---

### 6.5.9 Audit Logging and Compliance Monitoring

#### 6.5.9.1 Audit Log Architecture

**Immutable Audit Trail**: Comprehensive audit logging captures all security-relevant events with tamper-proof, append-only storage for compliance requirements.

**Audit Log Schema**:

```json
{
  "_id": "ObjectId('...')",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "user_id": "auth0|123456789",
  "action": "UPDATE",
  "resource_type": "documents",
  "resource_id": "507f1f77bcf86cd799439014",
  "endpoint": "/api/v1/documents/507f1f77bcf86cd799439014",
  "method": "PUT",
  "ip_address": "203.0.113.45",
  "user_agent": "Mozilla/5.0...",
  "status": "success",
  "permissions_checked": ["write:documents"],
  "authorization_decision": "granted",
  "changes": {
    "before": {"title": "Old Title"},
    "after": {"title": "New Title"}
  }
}
```

**Audit Log Retention and Compliance**:

| Event Category | Retention Period | Compliance Requirement | Storage Location |
|---------------|------------------|----------------------|------------------|
| Authentication Events | 1 year | SOC 2 CC6.1 | MongoDB audit collection |
| Authorization Decisions | 7 years | SOC 2 CC6.2, GDPR Art. 30 | MongoDB audit collection → S3 Glacier |
| Data Modifications | 7 years | GDPR Art. 30, CCPA | MongoDB audit collection → S3 Glacier |
| Administrative Actions | Permanent | SOC 2 CC7.2 | MongoDB audit collection, never deleted |

#### 6.5.9.2 Compliance Monitoring Dashboards

**Compliance Audit Dashboard**: Specialized dashboard for compliance officers and auditors providing visibility into security controls effectiveness.

**Dashboard Components**:

| Widget | Metrics | Compliance Standard Addressed |
|--------|---------|------------------------------|
| Authentication Audit | Login attempts (success/failure), MFA challenges | SOC 2 CC6.1, NIST 800-53 IA-2 |
| Access Control Audit | Permission checks, authorization decisions, admin override usage | SOC 2 CC6.2, NIST 800-53 AC-3 |
| Data Access Audit | Resource access patterns, data modifications, deletion requests | GDPR Art. 30, CCPA §1798.100 |
| Security Incident Log | Failed auth attempts, suspicious activity, circuit breaker activations | SOC 2 CC7.2, NIST 800-53 IR-6 |

---

### 6.5.10 Third-Party Monitoring Integrations (Optional)

#### 6.5.10.1 Enhanced Observability Tools

**Optional Third-Party Platform Integrations**: While CloudWatch provides comprehensive core monitoring, optional integrations with specialized platforms enhance specific observability capabilities.

| Platform | Primary Use Case | Integration Method | Key Benefits |
|----------|-----------------|-------------------|--------------|
| **DataDog APM** | Advanced application performance monitoring | DataDog agent on ECS tasks | Distributed tracing, service dependency mapping, anomaly detection |
| **Sentry** | Error tracking and debugging | Sentry SDK in Flask application | Source code context, user impact tracking, release tracking |
| **LogRocket** | Session replay and frontend monitoring | JavaScript SDK in React application | User session replay, frontend error tracking, performance insights |

**DataDog Integration Architecture**:

- **Agent Deployment**: DataDog agent runs as sidecar container in ECS task definition
- **Metrics Collection**: Automatic collection of infrastructure metrics (CPU, memory, network) and custom application metrics
- **Log Forwarding**: Application logs forwarded to DataDog for centralized log management and search
- **Distributed Tracing**: APM tracing captures request flows across services with automatic instrumentation
- **Cost Consideration**: DataDog pricing based on number of hosts and log volume; evaluate ROI before production deployment

---

### 6.5.11 Runbooks and Operational Procedures

#### 6.5.11.1 Common Incident Runbooks

**Standardized Response Procedures**: Documented runbooks ensure consistent, efficient incident response for common operational scenarios.

**High Error Rate Runbook** (P0 - Critical):

```
Trigger: api.error.rate > 5% for 5 consecutive minutes

Investigation Steps:
1. Check CloudWatch dashboard → Identify which endpoints have high error rates
2. Review recent deployment history → Was there a recent code or infrastructure change?
3. Query CloudWatch Logs Insights → Analyze error messages and stack traces
4. Check external dependencies → Verify Auth0, OpenAI, MongoDB availability
5. Review ECS task health → Ensure all tasks are healthy and passing health checks

Remediation Options:
- If caused by recent deployment: Initiate rollback via ECS (previous task definition)
- If caused by database issue: Restart MongoDB connection pool, verify replica set health
- If caused by external service outage: Activate circuit breaker, enable graceful degradation
- If caused by application bug: Deploy hotfix, notify engineering team for permanent fix

Post-Incident Actions:
- Document root cause in incident report
- Schedule post-mortem meeting within 48 hours
- Create action items to prevent recurrence
- Update runbook if new resolution method discovered
```

**High Latency Runbook** (P1 - High):

```
Trigger: api.request.duration (p95) > 1000ms for 5 consecutive minutes

Investigation Steps:
1. Identify slow endpoints using CloudWatch metrics filtered by endpoint dimension
2. Review X-Ray traces for slow requests → Identify which component is bottleneck
3. Check database query performance → Review MongoDB slow query logs
4. Verify cache hit rate → Ensure Redis caching is functioning correctly
5. Check external API latency → Measure Auth0 and OpenAI response times

Remediation Options:
- If database bottleneck: Add database indexes, optimize queries, scale database vertically
- If cache miss rate high: Warm cache, increase cache TTL, add caching for new endpoints
- If CPU/memory constrained: Scale ECS tasks horizontally (increase desired count)
- If external API slow: Increase timeouts, implement request queuing, contact vendor support

Monitoring:
- After remediation, monitor p95 latency for 30 minutes to confirm improvement
- If latency returns to normal, mark incident as resolved
- If latency persists, escalate to engineering manager for deeper investigation
```

#### 6.5.11.2 Post-Mortem Process

**Blameless Post-Mortem Framework**: After every P0 (Critical) or P1 (High) incident, conduct structured post-mortem to learn and improve system resilience.

**Post-Mortem Document Structure**:

1. **Incident Summary**: Brief description, severity, total duration, user impact
2. **Timeline**: Chronological sequence of events from detection through resolution
3. **Root Cause Analysis**: Technical root cause identified through investigation (Five Whys technique)
4. **Impact Assessment**: Number of affected users, revenue impact, SLA breach calculation
5. **What Went Well**: Effective detection, rapid response, successful mitigation
6. **What Went Wrong**: Delayed detection, unclear procedures, inadequate monitoring
7. **Action Items**: Concrete, assigned tasks to prevent recurrence (improved monitoring, code fixes, runbook updates)

**Post-Mortem Meeting Agenda** (1-hour meeting within 48 hours of incident):

- **0-10 minutes**: Present incident timeline and impact
- **10-30 minutes**: Discuss root cause, ask "Why?" five times to uncover systemic issues
- **30-45 minutes**: Brainstorm prevention strategies and improvement opportunities
- **45-60 minutes**: Assign action items with owners and due dates, document lessons learned

---

### 6.5.12 Implementation Roadmap and Future Enhancements

#### 6.5.12.1 Current Implementation Status

**Repository State**: Pre-implementation phase with no monitoring code deployed

**Priority Implementation Phases**:

| Phase | Monitoring Components | Timeline | Dependencies |
|-------|----------------------|----------|--------------|
| **Phase 1 - Foundation** | CloudWatch Logs (structured JSON), basic metrics (requests, errors), system health dashboard | Week 1-2 | Flask application deployment, CloudWatch permissions |
| **Phase 2 - Alerting** | CloudWatch Alarms (error rate, latency, CPU), SNS notification topics, email alerts | Week 3-4 | Phase 1 complete, SNS topic configuration |
| **Phase 3 - Advanced Metrics** | Custom application metrics (cache hit rate, AI tokens), business metrics dashboard | Week 5-6 | Phase 1 complete, metric emission code |
| **Phase 4 - Tracing** | AWS X-Ray integration, distributed tracing, service map | Week 7-8 | Phase 1-3 complete, X-Ray SDK integration |

#### 6.5.12.2 Future Monitoring Enhancements

**Planned Enhancements** (Post-MVP):

1. **Machine Learning Anomaly Detection**: CloudWatch Anomaly Detection for automatic threshold adjustment based on historical patterns
2. **Cost Optimization Monitoring**: Detailed cost attribution by feature, user tier, and operation; automated cost anomaly alerts
3. **User Experience Monitoring**: Real User Monitoring (RUM) for frontend performance, Core Web Vitals tracking
4. **Predictive Alerting**: Trend-based alerting to predict capacity exhaustion or performance degradation before user impact
5. **Cross-Region Monitoring**: Multi-region deployment monitoring with failover detection and verification

---

### 6.5.13 Monitoring Architecture Summary

The CheckSameRepoNoPrompt system implements a comprehensive, multi-layered monitoring and observability architecture designed to provide complete visibility into system health, performance, and business metrics. Key monitoring highlights include:

**Comprehensive Observability**:
- AWS CloudWatch as primary monitoring platform with logs, metrics, traces, and alarms
- Structured JSON logging with PII redaction and 30-day active retention
- Request ID propagation enabling end-to-end distributed tracing across services
- Optional AWS X-Ray integration for visual service dependency mapping

**Intelligent Alerting**:
- Multi-dimensional metrics (service, environment, endpoint, user tier) enable fine-grained analysis
- CloudWatch Alarms with tuned thresholds minimize false positives while ensuring critical issue detection
- Multi-channel alerting (PagerDuty, email, Slack) with escalation policies
- Automated remediation for common issues (auto-scaling, service restarts)

**Operational Excellence**:
- Role-specific dashboards (operations, business, security, compliance) provide targeted visibility
- Performance SLA tracking with 99.9% uptime target and sub-second response time goals
- Comprehensive audit logging with 7-year retention for compliance (SOC 2, GDPR, CCPA)
- Documented runbooks and blameless post-mortem process for continuous improvement

**Security Monitoring**:
- Real-time security event tracking (failed auth, permission denials, suspicious activity)
- Circuit breaker monitoring for Auth0 integration resilience
- Security metrics dashboard for security team visibility

**Implementation Status**: This monitoring architecture represents the planned design for the CheckSameRepoNoPrompt system. The repository currently contains only a README.md file, with all monitoring implementations pending development phase execution.

---

### 6.5.14 References

#### 6.5.14.1 Technical Specification Sections Referenced

- **Section 5.4.1 - Monitoring and Observability**: Comprehensive monitoring architecture, CloudWatch Logs/Metrics configuration, distributed tracing, alerting strategy
- **Section 5.4.2 - Logging and Tracing**: Structured logging standards, PII handling, request tracing flow, log correlation
- **Section 5.4.3 - Error Handling**: Error classification, standardized error responses, circuit breaker patterns, graceful degradation
- **Section 5.4.5 - Performance Requirements and SLAs**: API response time targets, throughput and scalability targets, availability SLA commitments
- **Section 5.4.6 - Disaster Recovery**: Recovery objectives (RTO/RPO), disaster recovery procedures, failover mechanisms, incident response workflow
- **Section 6.4 - Security Architecture**: Security event tracking, circuit breaker for Auth0, audit logging, compliance controls
- **Section 5.1 - High-Level Architecture**: System overview, component interactions, data flow architecture, integration patterns
- **Section 4.2 - CI/CD Workflows**: ECS health checks, deployment monitoring, automatic rollback procedures

#### 6.5.14.2 Repository Files Examined

- **`README.md`** (root directory): Project title documentation; repository in pre-implementation phase with no monitoring implementation code

#### 6.5.14.3 Repository Folders Explored

- **Root Directory** (`/`): Contains only README.md file; no application code, CloudWatch configuration, monitoring instrumentation, or observability implementation

#### 6.5.14.4 AWS Services and Technologies Referenced

- **Amazon CloudWatch**: Primary monitoring platform (Logs, Metrics, Alarms, Dashboards, Synthetics, Anomaly Detection)
- **AWS X-Ray**: Distributed tracing and service map visualization (optional enhancement)
- **Amazon SNS**: Notification hub for multi-channel alerting (email, PagerDuty, Slack, Lambda triggers)
- **AWS Lambda**: Automated remediation functions triggered by CloudWatch Alarms
- **Amazon ECS**: Container orchestration with built-in health checks and auto-healing
- **Application Load Balancer**: HTTP access logs, target health monitoring, traffic distribution
- **Amazon S3**: Log archival storage with lifecycle policies (Standard → Glacier)
- **AWS Secrets Manager**: Secure credential storage for monitoring integrations

#### 6.5.14.5 Third-Party Monitoring Tools Referenced (Optional)

- **DataDog APM**: Advanced application performance monitoring with distributed tracing
- **Sentry**: Error tracking and debugging with source code context
- **LogRocket**: Session replay and frontend monitoring
- **PagerDuty**: On-call management and incident escalation
- **Slack**: Team collaboration and alert notifications

#### 6.5.14.6 Compliance Standards and Frameworks Referenced

- **SOC 2 Type II**: Security, availability, and confidentiality controls (CC6.1, CC6.2, CC7.2)
- **GDPR (General Data Protection Regulation)**: Article 30 (Records of Processing), Article 32 (Security of Processing)
- **CCPA (California Consumer Privacy Act)**: Data disclosure and audit trail requirements (§1798.100)
- **NIST 800-53**: Security and Privacy Controls (AU - Audit and Accountability, IR - Incident Response)

#### 6.5.14.7 Monitoring Best Practices and Methodologies

- **The Three Pillars of Observability**: Logs, Metrics, Traces (coined by distributed systems community)
- **Google SRE Principles**: SLIs, SLOs, SLAs, error budgets, blameless post-mortems
- **The Four Golden Signals**: Latency, Traffic, Errors, Saturation (from Google SRE Book)
- **USE Method**: Utilization, Saturation, Errors (Brendan Gregg's performance methodology)
- **RED Method**: Rate, Errors, Duration (Tom Wilkie's microservices monitoring methodology)

#### 6.5.14.8 Key Findings Summary

**Monitoring Architecture Scope**:
- **Cloud-Native Monitoring**: Full AWS CloudWatch integration as primary observability platform
- **Structured Observability**: JSON-formatted logs, multi-dimensional metrics, distributed tracing with request IDs
- **Intelligent Alerting**: Tuned alert thresholds with automated remediation and multi-channel escalation
- **Comprehensive Coverage**: Infrastructure metrics (CPU, memory), application metrics (latency, errors), business metrics (AI usage, costs), security metrics (auth failures, suspicious activity)
- **Compliance-Ready**: 7-year audit log retention, immutable append-only logging, GDPR/CCPA/SOC 2 alignment

**Performance Monitoring**:
- **Strict SLA Targets**: 99.9% uptime, p95 latency < 300ms for CRUD operations, < 5 seconds for AI requests
- **Multi-Percentile Tracking**: p50, p95, p99 latency percentiles for comprehensive performance visibility
- **Capacity Planning**: Proactive monitoring of resource utilization trends with growth forecasting
- **Synthetic Monitoring**: CloudWatch Synthetics canaries for proactive availability verification

**Operational Excellence**:
- **Multi-Audience Dashboards**: Specialized views for operations, engineering, business, security, compliance teams
- **Documented Runbooks**: Standardized incident response procedures for common scenarios
- **Blameless Post-Mortems**: Structured learning process after incidents with action item tracking
- **Automated Remediation**: Self-healing mechanisms for common issues (auto-scaling, service restarts, cache warming)

**Implementation Status**:
- **Pre-Implementation Phase**: All monitoring infrastructure documented represents planned architecture
- **No Monitoring Code**: Repository contains only README.md, no CloudWatch configuration, logging instrumentation, or metrics emission code
- **Architecture Complete**: Monitoring design fully specified and ready for development phase implementation
- **Phased Rollout**: Four-phase implementation plan (Foundation → Alerting → Advanced Metrics → Tracing) over 8 weeks

**Total Research Depth**: 4 technical specification sections retrieved and synthesized, comprehensive section-specific research report analyzed, integrated into cohesive monitoring and observability documentation.

---

**Document Metadata**:
- **Section**: 6.5 Monitoring and Observability
- **Version**: 1.0 (Planned Architecture)
- **Date**: January 2024
- **Status**: Pre-Implementation (Design Phase)
- **Implementation Code**: None (repository contains only README.md)
- **Next Steps**: Development team to implement monitoring infrastructure per this specification during application development phase, beginning with Phase 1 (CloudWatch Logs and basic metrics) in weeks 1-2 of deployment.

## 6.6 Testing Strategy

### 6.6.1 Testing Strategy Overview

#### 6.6.1.1 Implementation Status and Approach

The CheckSameRepoNoPrompt system is currently in **pre-implementation phase**, with infrastructure consisting solely of a foundational README.md file. However, this Testing Strategy section documents a comprehensive, production-ready testing framework that has been meticulously planned within the CI/CD workflow specifications (Section 4.2) and architectural design. This strategy represents the complete testing approach that will be implemented as system development progresses.

The repository examination revealed no existing test files, test directories (`tests/`, `__tests__/`, `spec/`), test configuration files (`pytest.ini`, `jest.config.js`), or CI/CD workflow files. Despite this pre-implementation status, the technical specification contains detailed testing strategies embedded within the CI/CD pipeline documentation, providing a robust foundation for quality assurance from the first line of code.

#### 6.6.1.2 Testing Philosophy and Principles

The testing strategy for this multi-platform, cloud-native application follows a **comprehensive quality-first approach** with the following core principles:

**Quality Gates at Every Stage**: Automated testing integrated into CI/CD pipelines ensures no code reaches production without passing rigorous quality checks including linting, type checking, unit tests, integration tests, and build verification.

**Shift-Left Testing**: Testing begins at the earliest stages of development with local pre-commit validation, static analysis, and continuous automated testing during development cycles.

**Test Pyramid Architecture**: The testing strategy follows the classic test pyramid with a broad base of fast unit tests, a middle layer of integration tests, and a focused set of end-to-end tests for critical user journeys.

**Platform-Specific Testing**: Each platform (backend Python/Flask, frontend React/TypeScript, mobile React Native, desktop Electron) receives tailored testing approaches using platform-appropriate frameworks and tools.

**Infrastructure as Code Testing**: Infrastructure provisioning through Terraform includes validation, planning, and review stages to prevent configuration errors and drift.

**Continuous Quality Monitoring**: Post-deployment monitoring with synthetic canaries, performance tracking, and error rate monitoring provides continuous validation of production quality.

### 6.6.2 Unit Testing Strategy

#### 6.6.2.1 Backend Unit Testing (Python/Flask)

#### Testing Framework and Tools

The backend testing infrastructure utilizes the pytest framework ecosystem with comprehensive coverage analysis and quality enforcement tools:

| Tool | Version | Purpose | Integration Point |
|------|---------|---------|------------------|
| pytest | Latest | Primary testing framework | CI/CD test execution |
| pytest-cov | Latest | Coverage measurement and reporting | XML and terminal reports |
| pytest-mock | Latest | Mocking and fixtures | External service isolation |
| Black | Latest | Code formatting validation | Pre-test quality gate |
| Flake8 | Latest | PEP 8 compliance and linting | Pre-test quality gate |
| mypy | Latest | Static type checking | Pre-test quality gate |

**Test Execution Workflow**: The CI/CD pipeline (Section 4.2.1) orchestrates a three-phase testing approach:

1. **Code Quality Phase**: Before any tests execute, the pipeline validates code formatting with `black --check backend/`, enforces PEP 8 compliance with `flake8 backend/ --max-line-length=88` (configured to match Black's line length), and performs strict static type analysis with `mypy backend/ --strict`.

2. **Test Execution Phase**: After code quality validation, pytest executes the complete test suite with `pytest backend/tests/ --cov=backend --cov-report=xml --cov-report=term`, generating both XML coverage reports for Codecov integration and terminal output for immediate developer feedback.

3. **Coverage Reporting Phase**: The pipeline uploads `coverage.xml` to Codecov for trend analysis, pull request coverage impact reporting, and historical coverage tracking across all commits.

#### Test Organization Structure

The backend test suite follows a **mirror directory structure** approach where test files parallel the source code organization:

```
backend/
├── app/
│   ├── auth/
│   │   ├── handlers.py
│   │   └── validators.py
│   ├── api/
│   │   ├── routes.py
│   │   └── middleware.py
│   └── services/
│       ├── ai_service.py
│       └── document_service.py
└── tests/
    ├── unit/
    │   ├── auth/
    │   │   ├── test_handlers.py
    │   │   └── test_validators.py
    │   ├── api/
    │   │   ├── test_routes.py
    │   │   └── test_middleware.py
    │   └── services/
    │       ├── test_ai_service.py
    │       └── test_document_service.py
    ├── integration/
    │   ├── test_auth_flow.py
    │   ├── test_api_integration.py
    │   └── test_database_operations.py
    └── conftest.py
```

**Test Naming Conventions**: Test files follow the `test_<module_name>.py` pattern, while individual test functions use descriptive names: `test_<function_name>_<scenario>_<expected_outcome>`. For example: `test_jwt_validation_with_expired_token_raises_unauthorized`, `test_document_creation_with_valid_data_returns_201`, `test_ai_completion_with_rate_limit_triggers_circuit_breaker`.

**Shared Test Fixtures**: The `conftest.py` file at the test root provides shared fixtures including test database connections, mock external services (Auth0, MongoDB, Redis, LangChain), test data factories, and common test utilities. Pytest's fixture scope system manages fixture lifecycle (function-scoped for isolation, module-scoped for performance where appropriate).

#### Code Coverage Requirements

**Coverage Targets**: While the specific threshold is configurable, the architecture documentation references an **80% code coverage minimum** as an example target for backend services. This threshold applies to line coverage across all backend modules.

**Coverage Enforcement**: The CI/CD pipeline generates coverage reports in multiple formats:
- **XML Format**: Uploaded to Codecov for external analysis and trend tracking
- **Terminal Format**: Displayed in GitHub Actions logs for immediate visibility
- **Pull Request Comments**: Codecov automatically posts coverage deltas on pull requests, showing coverage impact of proposed changes

**Coverage Exclusions**: Standard exclusions include defensive code (exception handlers that should never execute), abstract base class methods marked with `@abstractmethod`, and explicit `# pragma: no cover` annotations for code that cannot be meaningfully tested.

#### Mocking Strategy

**External Service Mocking**: All external dependencies are mocked during unit testing to ensure test isolation, speed, and reliability:

- **Auth0 Authentication**: Mock JWT validation, user profile retrieval, and OAuth token exchange flows
- **MongoDB Operations**: Use pytest-mongo or mongomock for in-memory database simulation
- **Redis Caching**: Use fakeredis for in-memory cache simulation without Redis server dependency
- **LangChain AI Services**: Mock LLM API calls to prevent external API costs and ensure deterministic test results
- **AWS Services**: Mock S3 operations, CloudWatch logging, and X-Ray tracing using moto library

**Mocking Implementation**: Pytest fixtures in `conftest.py` provide pre-configured mocks with realistic behaviors. For example, the `mock_auth0` fixture returns configurable JWT tokens, the `mock_mongodb` fixture provides a clean database slate for each test, and the `mock_langchain` fixture returns predefined AI completion responses.

#### Test Data Management

**Test Data Factories**: Factory pattern implementation using factory_boy or custom factory functions generates realistic test data with minimal boilerplate. Factories support both default values for quick test setup and customization for specific test scenarios.

**Test Database Seeding**: Integration tests use database fixtures that populate test data before test execution and clean up afterward. The `conftest.py` file includes `@pytest.fixture(scope="function", autouse=True)` decorators for automatic database cleanup between tests, ensuring test isolation.

**Fixture Files**: Static test data (JSON payloads, mock API responses, sample documents) resides in `tests/fixtures/` directory, loaded as pytest fixtures or directly imported by test modules.

#### 6.6.2.2 Frontend Unit Testing (React/TypeScript)

#### Testing Framework and Tools

The frontend testing stack leverages modern JavaScript testing tools optimized for React and TypeScript:

| Tool | Version | Purpose | Integration Point |
|------|---------|---------|------------------|
| Jest/Vitest | Latest | Testing framework and runner | CI/CD test execution |
| React Testing Library | Latest | Component testing with user-centric queries | Component interaction testing |
| @testing-library/user-event | Latest | User interaction simulation | Event-driven test scenarios |
| MSW (Mock Service Worker) | Latest | API request mocking at network level | Integration test isolation |
| ESLint | Latest | TypeScript and React linting | Pre-test quality gate |
| Prettier | Latest | Code formatting validation | Pre-test quality gate |
| TypeScript Compiler | 5.0+ | Type checking without code emission | Pre-test quality gate |

**Test Execution Workflow**: The frontend CI/CD pipeline (Section 4.2.2) implements a parallel quality and test validation process:

1. **Code Quality Phase**: Concurrent execution of `npm run lint` (ESLint with React and TypeScript rules), `npm run format:check` (Prettier validation for `.ts`, `.tsx`, and `.css` files), and `tsc --noEmit` (type checking without file generation) ensures code meets quality standards before test execution.

2. **Test Execution Phase**: Jest or Vitest runs with `npm run test -- --coverage --passWithNoTests`, executing component rendering tests, user interaction simulations, hook behavior validation, and state management tests.

3. **Coverage Reporting Phase**: Test coverage reports generate in HTML format for local review and JSON format for programmatic analysis, stored in the `coverage/` directory.

#### Component Testing Approach

**Testing Philosophy**: Frontend tests focus on **user behavior rather than implementation details**, following React Testing Library's guiding principle: "The more your tests resemble the way your software is used, the more confidence they can give you."

**Component Test Categories**:

**Rendering Tests**: Verify components render correctly with default props, various prop combinations, and different application states. Tests use queries like `getByRole`, `getByLabelText`, and `getByText` to find elements as users would, avoiding reliance on implementation details like CSS classes or data-testid attributes except as a last resort.

**User Interaction Tests**: Simulate user actions with `@testing-library/user-event` (preferred over `fireEvent` for realistic interaction timing). Examples include:
- Form submission with valid and invalid data
- Button clicks that trigger state changes or API calls
- Navigation between routes
- Keyboard navigation and accessibility features

**State Management Tests**: Validate component state updates, React context providers, and custom hooks behavior. Tests verify that state changes trigger appropriate UI updates and that side effects execute correctly.

**Accessibility Tests**: Ensure components meet WCAG standards with proper ARIA labels, keyboard navigation support, and screen reader compatibility. Tests verify semantic HTML structure and proper focus management.

#### Test Organization Structure

Frontend tests follow a **co-location strategy** where test files reside adjacent to the components they test:

```
frontend/
├── src/
│   ├── components/
│   │   ├── auth/
│   │   │   ├── LoginForm.tsx
│   │   │   ├── LoginForm.test.tsx
│   │   │   ├── RegisterForm.tsx
│   │   │   └── RegisterForm.test.tsx
│   │   ├── documents/
│   │   │   ├── DocumentList.tsx
│   │   │   ├── DocumentList.test.tsx
│   │   │   ├── DocumentEditor.tsx
│   │   │   └── DocumentEditor.test.tsx
│   │   └── common/
│   │       ├── Button.tsx
│   │       ├── Button.test.tsx
│   │       ├── Modal.tsx
│   │       └── Modal.test.tsx
│   ├── hooks/
│   │   ├── useAuth.ts
│   │   ├── useAuth.test.ts
│   │   ├── useDocument.ts
│   │   └── useDocument.test.ts
│   └── utils/
│       ├── formatters.ts
│       ├── formatters.test.ts
│       ├── validators.ts
│       └── validators.test.ts
└── test/
    ├── setup.ts
    ├── mocks/
    │   ├── handlers.ts
    │   └── server.ts
    └── utils/
        └── test-utils.tsx
```

**Test File Naming**: Component tests use `.test.tsx` extension, while utility and hook tests use `.test.ts`. This convention enables test runner glob patterns to automatically discover all test files.

**Shared Test Utilities**: The `test/utils/test-utils.tsx` file exports a custom `render` function that wraps React Testing Library's render with application-wide providers (React Router, theme providers, context providers), eliminating boilerplate from individual tests.

#### Mock Service Worker (MSW) Integration

**Network-Level Mocking**: MSW intercepts HTTP requests at the network level, providing realistic API mocking without modifying application code. Request handlers defined in `test/mocks/handlers.ts` specify responses for API endpoints:

```typescript
// Example MSW handler structure
export const handlers = [
  rest.get('/api/documents', (req, res, ctx) => {
    return res(ctx.json({ documents: mockDocuments }))
  }),
  rest.post('/api/auth/login', async (req, res, ctx) => {
    const { email, password } = await req.json()
    // Return success or error based on test scenario
  })
]
```

**Test Server Setup**: The `test/setup.ts` file initializes MSW server with `beforeAll`, `afterEach`, and `afterAll` hooks, ensuring consistent mock state across all tests and automatic cleanup between test runs.

### 6.6.3 Integration Testing Strategy

#### 6.6.3.1 Service Integration Testing

**Backend Service Integration**: Integration tests validate interactions between multiple backend components without external service dependencies. These tests use actual Flask application context, real MongoDB connections (test database), and actual Redis instances (test Redis server or docker container) to verify end-to-end request processing.

**Test Scenarios**:
- **Authentication Flow Integration**: Complete OAuth flow from login initiation through Auth0 callback processing to JWT issuance and token storage in Redis
- **Document CRUD Operations**: Create document → store in MongoDB → retrieve from MongoDB → update → delete with proper authorization checks
- **AI Service Integration**: User request → input validation → LangChain service invocation → response processing → persistence with proper error handling

**Integration Test Location**: Tests reside in `backend/tests/integration/` directory, distinguished from unit tests by their use of actual service instances rather than mocks for internal components.

#### 6.6.3.2 API Testing Strategy

**API Contract Testing**: Validate that REST API endpoints conform to documented contracts including request/response schemas, HTTP status codes, error payloads, and header requirements. Tests verify:
- **Request Validation**: Reject invalid payloads with 400 Bad Request and descriptive error messages
- **Authentication Requirements**: Enforce JWT token presence and validity, returning 401 Unauthorized for missing/invalid tokens
- **Authorization Enforcement**: Verify resource ownership and permissions, returning 403 Forbidden for insufficient privileges
- **Response Format**: Ensure consistent JSON structure matching API documentation
- **Error Handling**: Validate error response format, status codes, and error message clarity

**API Performance Testing**: Integration tests include performance assertions ensuring response times meet targets defined in Section 5.4.5:
- Simple CRUD operations (GET, POST): p95 < 300ms
- Complex queries with aggregations: p95 < 800ms
- AI completion requests: p95 < 5000ms

**Test Implementation**: Tests use Flask test client for direct endpoint invocation without HTTP overhead, or requests library for full HTTP stack testing including middleware processing.

#### 6.6.3.3 Database Integration Testing

**MongoDB Integration Tests**: Validate database operations with actual MongoDB instance (test database distinct from development and production databases):

**Schema Validation**: Test MongoDB schema validation rules defined at collection level, ensuring invalid documents are rejected with clear error messages.

**Query Performance**: Verify index effectiveness for common query patterns, ensuring query execution times remain within acceptable bounds.

**Transaction Support**: Test multi-document transactions for operations requiring atomicity (e.g., document creation with associated metadata updates).

**Data Integrity**: Validate referential integrity maintenance through application logic, cascade delete behavior, and orphan prevention.

**Test Database Management**: Integration tests use pytest fixtures with `scope="session"` to create test database once, `scope="function"` to clean collections between tests, and `autouse=True` for automatic setup/teardown without explicit fixture references in test signatures.

#### 6.6.3.4 External Service Mocking

**Auth0 Mocking**: Integration tests mock Auth0 OAuth endpoints using MSW (for HTTP-based mocking) or pytest-mock (for Python SDK mocking). Mock includes:
- OAuth authorization endpoint returning realistic authorization codes
- Token exchange endpoint issuing valid JWT tokens with configurable claims
- User info endpoint providing user profile data
- JWKS (JSON Web Key Set) endpoint for JWT signature verification

**LangChain/LLM Mocking**: AI service integration tests mock LLM API calls to prevent:
- External API costs during testing
- Rate limiting from LLM providers
- Non-deterministic test results from AI model variations
- Dependency on external service availability

Mock implementations provide configurable responses including successful completions, rate limit errors, timeout scenarios, and malformed responses for error handling validation.

**AWS Service Mocking**: Integration tests that touch AWS services (S3 for file uploads, CloudWatch for logging) use the moto library for comprehensive AWS API mocking, providing local implementations of S3 bucket operations, CloudWatch log stream creation, and X-Ray trace segment recording.

#### 6.6.3.5 Test Environment Management

**Local Test Environment**: Docker Compose configuration in the repository root provides isolated test environment with:
- MongoDB 7.0 container with test-specific configuration
- Redis 7 Alpine container for session and cache testing
- Separate containers for backend and frontend when needed

**Automated Cleanup**: Test fixtures ensure environment cleanup between test runs, dropping test databases, flushing Redis databases, and resetting any persistent state. This prevents test interdependencies and ensures consistent test execution regardless of run order.

**Environment Variables**: Test configuration uses separate `.env.test` files with test-specific values (test database URLs, mock service endpoints, debug flags), loaded by pytest-env plugin or test setup code.

### 6.6.4 End-to-End Testing Strategy

#### 6.6.4.1 E2E Test Scenarios

While the current technical specification does not document specific E2E testing frameworks or implementations, the comprehensive monitoring strategy in Section 6.5 includes **CloudWatch Synthetics canaries** that serve as production E2E validation. The planned E2E testing approach should include:

**Critical User Journeys**:
- **Authentication Flow**: User registration → email verification → login → token issuance → authenticated dashboard access
- **Document Management Flow**: Create new document → auto-save draft → edit content → save final version → share with collaborators → retrieve shared document
- **AI Assistance Flow**: Open document editor → request AI completion → receive and insert suggestion → continue editing → save final document
- **Search and Discovery**: Search for documents by keyword → filter by date/type → open document from results → navigate back to search

**Cross-Platform Scenarios**: E2E tests should validate consistent behavior across web (React), mobile (React Native iOS/Android), and desktop (Electron) platforms, ensuring feature parity and proper data synchronization.

#### 6.6.4.2 UI Automation Approach

**Recommended Framework**: While not currently specified, the system architecture suggests **Playwright** or **Cypress** as suitable E2E testing frameworks for their multi-browser support, automatic waiting mechanisms, and rich debugging capabilities.

**Test Organization**: E2E tests should reside in dedicated `e2e/` directory at repository root, separate from unit and integration tests due to different execution requirements (longer runtime, external service dependencies, browser automation overhead).

**Page Object Model**: Tests should implement Page Object Model pattern, encapsulating page-specific locators and actions in reusable page classes, reducing test maintenance burden when UI changes.

#### 6.6.4.3 Test Data Setup and Teardown

**Database Seeding**: E2E tests require realistic test data including user accounts, sample documents, and reference data. Setup scripts should seed test database before E2E suite execution, creating consistent initial state.

**Idempotent Tests**: Each E2E test should create its own isolated test data (unique user accounts, uniquely named documents) to prevent conflicts with parallel test execution and enable test independence.

**Cleanup Strategy**: Post-test cleanup should remove E2E-created data, although this may be less critical in non-production test environments. Alternatively, test environment refresh between E2E runs provides clean slate.

#### 6.6.4.4 Cross-Browser and Cross-Platform Testing

**Browser Matrix**: E2E tests should validate functionality across:
- Chrome (latest stable)
- Firefox (latest stable)
- Safari (latest stable, macOS/iOS)
- Edge (latest stable)

**Mobile Testing**: React Native mobile applications require device-specific E2E testing:
- **iOS**: XCUITest framework for native E2E testing
- **Android**: Espresso or UIAutomator for native E2E testing
- **Cross-platform**: Detox framework for React Native-specific E2E testing across both platforms

**Desktop Testing**: Electron desktop application should include platform-specific E2E tests on macOS, Windows, and Linux, validating platform-specific features (notifications, system tray, file system integration).

### 6.6.5 Mobile Testing Strategy

#### 6.6.5.1 iOS Testing Approach

**Build Testing**: The iOS CI/CD workflow (Section 4.2.3) focuses on build verification and artifact generation:

**Build Tools and Process**:
- **Xcode Build System**: xcodebuild command-line tool compiles iOS application on macos-latest GitHub Actions runners
- **Dependency Management**: CocoaPods installation (`pod install`) resolves native dependencies before build
- **Build Configuration**: Release configuration build validates production-ready code compilation
- **Code Signing**: Certificate validation ensures proper provisioning profile configuration
- **Artifact Generation**: .ipa file generation for distribution through TestFlight or App Store

**Unit Testing**: iOS native code (Swift/Objective-C bridge modules) should use **XCTest** framework:
- Test files organized in Xcode test targets
- UI component tests using XCUITest
- Network mocking with URLProtocol subclasses
- Asynchronous testing with XCTestExpectation

**Integration Testing**: React Native component integration with native modules requires testing across JavaScript-native bridge, validating proper data marshaling and event handling.

#### 6.6.5.2 Android Testing Approach

**Build Testing**: The Android CI/CD workflow (Section 4.2.3) validates build configuration and artifact generation:

**Build Tools and Process**:
- **Gradle Build System**: `./gradlew assembleRelease` generates APK, `./gradlew bundleRelease` generates AAB for Play Store
- **Build Optimization**: ProGuard/R8 minification and obfuscation testing ensures release builds maintain functionality after code shrinking
- **Multi-Architecture Support**: Build validation across ARM and x86 architectures
- **Build Variants**: Testing across different build flavors (development, staging, production)

**Unit Testing**: Android native code (Kotlin/Java bridge modules) should use **JUnit** with Android testing extensions:
- Robolectric for JVM-based Android testing without emulator
- Mockito for dependency mocking
- AndroidX Test for Android component testing

**Instrumentation Testing**: On-device or emulator testing with **Espresso** for UI validation:
- Fragment and Activity lifecycle testing
- User interaction simulation
- Intent verification for inter-component communication

#### 6.6.5.3 React Native Testing

**JavaScript Layer Testing**: Jest with React Native Testing Library for component testing:
- Mock native modules for isolation
- Snapshot testing for UI consistency
- Hook testing with @testing-library/react-hooks

**Cross-Platform Testing**: Validate consistent behavior between iOS and Android implementations, testing platform-specific code paths and conditional rendering.

### 6.6.6 Infrastructure Testing Strategy

#### 6.6.6.1 Terraform Testing Approach

The infrastructure CI/CD workflow (Section 4.2.4) implements a **four-stage validation pipeline** for Terraform infrastructure code:

#### Stage 1: Format Validation

**Command**: `terraform fmt -check -recursive terraform/`

**Purpose**: Enforce consistent Terraform code formatting across all modules and environments, preventing formatting inconsistencies that impede code reviews.

**Failure Impact**: Pipeline fails if any `.tf` files deviate from canonical formatting, requiring developers to run `terraform fmt` locally before pushing.

#### Stage 2: Initialization

**Command**: `terraform init`

**Purpose**: Download required provider plugins (AWS provider, etc.) and configure S3 backend for remote state storage with DynamoDB locking.

**Validation**: Ensures provider version constraints are satisfiable, backend configuration is valid, and state locking mechanism is accessible.

#### Stage 3: Syntax and Semantic Validation

**Command**: `terraform validate`

**Purpose**: Validate Terraform configuration syntax and semantic correctness including:
- HCL syntax correctness
- Resource attribute validity
- Required argument presence
- Type constraint satisfaction
- Module input/output compatibility

**Failure Impact**: Pipeline fails on any configuration errors, preventing invalid infrastructure code from reaching plan/apply stages.

#### Stage 4: Plan Generation and Review

**Command**: `terraform plan`

**Purpose**: Generate execution plan showing infrastructure changes (resources to create, update, or destroy) without applying changes.

**Review Process**: Plan output posted as pull request comment enables team review of infrastructure changes before merge, providing visibility into resource modifications, cost implications, and potential risks.

**Artifact Preservation**: Plan saved as artifact for subsequent apply stage, ensuring applied changes match reviewed plan.

#### 6.6.6.2 Infrastructure Testing Gaps

**Current Limitations**: The existing infrastructure testing strategy focuses on static analysis and plan validation but lacks:

**Compliance Testing**: Tools like Checkov or tfsec for detecting security misconfigurations, policy violations, and compliance issues in Terraform code.

**Cost Estimation**: Infracost integration for pull request cost impact analysis, enabling cost-aware infrastructure decisions.

**Post-Apply Validation**: Tests validating actual infrastructure state matches expected configuration after `terraform apply`, potentially using Terratest or AWS SDK-based validation scripts.

**Drift Detection**: Scheduled runs detecting configuration drift between Terraform state and actual AWS resource configuration.

### 6.6.7 Test Automation

#### 6.6.7.1 CI/CD Integration

**Comprehensive Pipeline Integration**: Testing is deeply integrated into CI/CD workflows across all application components, with automated execution on every code push and pull request.

#### Backend Test Automation

**Trigger Conditions**:
- Push to `main` or `develop` branches affecting `backend/**` paths
- Pull requests to `main` affecting `backend/**` paths

**Automated Stages**:
1. Python environment setup (Python 3.11)
2. Dependency installation from `requirements.txt` and `requirements-dev.txt`
3. Code quality validation (Black, Flake8, mypy)
4. Test suite execution with coverage
5. Coverage report upload to Codecov

**Deployment Gating**: Production deployment to ECS only proceeds after successful test completion, enforcing quality gate before code reaches production.

#### Frontend Test Automation

**Trigger Conditions**:
- Push to `main` or `develop` branches affecting `frontend/**` paths
- Pull requests to `main` affecting `frontend/**` paths

**Automated Stages**:
1. Node.js 18 LTS environment setup
2. npm dependency installation with caching
3. Parallel code quality checks (ESLint, Prettier, TypeScript)
4. Jest/Vitest test suite execution
5. Production build verification

**Build Verification**: Tests run before build stage, but build success is also required before deployment, providing two-tier validation.

#### Mobile Test Automation

**iOS Pipeline**:
- Runs on macos-latest for Xcode availability
- Installs Node.js dependencies and CocoaPods dependencies
- Executes Xcode build with Release configuration
- Stores .ipa artifacts with 90-day retention

**Android Pipeline**:
- Runs on ubuntu-latest with JDK 17
- Installs Node.js dependencies and Android SDK components
- Executes Gradle build generating APK/AAB artifacts
- Validates ProGuard/R8 obfuscation doesn't break functionality

#### Infrastructure Test Automation

**Trigger Conditions**:
- Push to `main` affecting `terraform/**` paths
- Pull requests to `main` affecting `terraform/**` paths

**Automated Stages**:
1. Terraform setup (version 1.6+)
2. Format check validation
3. Terraform init with S3 backend
4. Terraform validate for syntax/semantic checks
5. Terraform plan with output preservation
6. Plan output posted as PR comment for review
7. Terraform apply on `main` branch push (post-merge)

#### 6.6.7.2 Automated Test Triggers

**Primary Triggers**:

| Trigger Type | Branches | Path Filters | Automated Actions |
|-------------|----------|--------------|-------------------|
| Push | main, develop | backend/** | Backend CI/CD pipeline |
| Push | main, develop | frontend/** | Frontend CI/CD pipeline |
| Push | main | mobile/** | iOS and Android builds |
| Push | main | terraform/** | Infrastructure validation and apply |
| Pull Request | main | All paths | Full CI/CD without deployment |

**Manual Triggers**: GitHub Actions workflow_dispatch events enable on-demand test execution for specific scenarios (regression testing, performance baseline establishment, pre-release validation).

**Scheduled Triggers**: Recommended addition of nightly builds running complete test suites including longer-running integration tests, E2E tests, and performance tests not included in standard pull request workflows.

#### 6.6.7.3 Parallel Test Execution

**Frontend Parallel Execution**: Jest and Vitest support parallel test execution by default, running test files concurrently across multiple worker processes based on available CPU cores.

**Backend Parallel Execution**: pytest-xdist plugin (when added) enables parallel test execution with `-n auto` flag, automatically detecting CPU core count and distributing tests across workers.

**GitHub Actions Matrix Builds**: Workflows can use matrix strategy to test across multiple Python versions (3.11, 3.12), Node.js versions (18, 20), or platforms (ubuntu, macos, windows) simultaneously.

**Parallel Stage Execution**: CI/CD workflows can parallelize independent stages (linting, type checking, testing) using GitHub Actions job dependencies and parallel job execution.

#### 6.6.7.4 Test Reporting Requirements

**Coverage Reporting**:
- **Backend**: XML coverage reports uploaded to Codecov for historical tracking, pull request comments showing coverage delta
- **Frontend**: HTML coverage reports generated in `coverage/` directory, JSON reports for programmatic analysis
- **Visualization**: Codecov dashboard provides coverage trends, file-level coverage breakdown, and coverage sunburst diagrams

**Test Result Reporting**:
- **JUnit XML Format**: pytest and Jest generate JUnit-compatible XML for test result parsing by external tools
- **GitHub Actions Annotations**: Test failures appear as annotations on pull request files at failure line numbers
- **Summary Tables**: GitHub Actions summary page displays test execution statistics (passed/failed/skipped counts, execution time)

**Recommended Additions**:
- **Test Analytics Platform**: Integration with tools like Datadog CI Visibility or BuildPulse for test performance trends, flaky test detection, and test suite optimization recommendations
- **Performance Benchmarking**: Automated performance regression detection comparing test execution times across commits
- **Visual Regression Testing**: Screenshot comparison tools like Percy or Chromatic for UI consistency validation

#### 6.6.7.5 Failed Test Handling

**Pipeline Failure**: Any test failure causes immediate CI/CD pipeline failure, preventing merge (for pull requests) or deployment (for direct pushes).

**Failure Visibility**:
- GitHub Actions UI displays failed test details including test name, failure reason, and assertion mismatch
- Pull request checks show failing tests with expandable details
- Email notifications sent to commit authors on test failures (configurable in GitHub Actions)

**Developer Workflow**:
1. Test failure notification received
2. Review failure details in GitHub Actions logs
3. Reproduce failure locally using same test command
4. Fix failing code or test
5. Push fix, triggering automatic pipeline re-run
6. Merge only after all tests pass

**Recommended Practices**:
- **Local Testing**: Developers should run tests locally before pushing using pre-commit hooks
- **Fast Feedback**: Unit tests should execute quickly (< 5 minutes) to enable rapid iteration
- **Clear Failure Messages**: Tests should provide descriptive assertion messages indicating expected vs actual values

#### 6.6.7.6 Flaky Test Management

**Current Status**: The technical specification does not document explicit flaky test management strategies. This represents a gap that should be addressed as testing implementation progresses.

**Recommended Strategies**:

**Flaky Test Detection**: Track test results over multiple runs to identify tests with inconsistent pass/fail behavior. Tools like BuildPulse or Datadog CI Visibility automatically flag flaky tests.

**Quarantine Mechanism**: Temporarily disable identified flaky tests using pytest markers (`@pytest.mark.flaky`) or Jest test skipping, preventing CI/CD disruption while maintaining flaky test visibility.

**Root Cause Analysis**: Common flaky test causes include:
- Race conditions from asynchronous operations without proper waiting
- Test interdependencies causing pass/fail based on execution order
- External service timeouts or unavailability
- Time-based assertions sensitive to execution environment performance
- Insufficient test data cleanup causing state pollution

**Flaky Test Resolution**: Implement test retries with pytest-rerunfailures or Jest --maxRetries for genuinely transient failures, but prioritize fixing root causes over masking flakiness with retries.

### 6.6.8 Performance Testing Strategy

#### 6.6.8.1 Performance Test Requirements

The system architecture defines **specific performance targets** (Section 5.4.5) that guide performance testing requirements:

#### API Response Time Targets

| Endpoint Category | p50 Target | p95 Target | p99 Target | Test Approach |
|------------------|------------|------------|------------|---------------|
| Simple CRUD | < 100ms | < 300ms | < 500ms | Load testing with realistic payloads |
| Complex Queries | < 300ms | < 800ms | < 1200ms | Database query optimization validation |
| AI Completions (Simple) | < 2000ms | < 5000ms | < 8000ms | LLM mock response time simulation |
| AI Conversations (Multi-turn) | < 3000ms | < 6000ms | < 10000ms | Context-aware completion testing |
| File Upload (Presigned URL) | < 500ms | < 1500ms | < 3000ms | S3 presigned URL generation testing |

#### Availability and Reliability Targets

| Component | SLA Target | Monthly Downtime Allowance | Testing Focus |
|-----------|-----------|---------------------------|---------------|
| Overall Application | 99.9% | 43.2 minutes | End-to-end availability monitoring |
| Flask API | 99.95% | 21.6 minutes | Health check responsiveness |
| MongoDB | 99.95% | 21.6 minutes | Replica set failover testing |

**Performance Test Types**:

**Load Testing**: Validate system performance under expected load conditions, simulating typical user concurrency and request rates. Verify response times remain within p95 targets under normal load.

**Stress Testing**: Determine system breaking points by gradually increasing load beyond normal capacity, identifying maximum sustainable throughput and degradation patterns.

**Spike Testing**: Validate system behavior under sudden traffic spikes (e.g., viral content, marketing campaigns), testing auto-scaling responsiveness and rate limiting effectiveness.

**Endurance Testing**: Run sustained load over extended periods (hours or days) to detect memory leaks, connection pool exhaustion, or other resource degradation issues.

#### 6.6.8.2 Load Testing Approach

**Recommended Tools**: While not currently specified, the architecture suggests **k6** or **Apache JMeter** as suitable load testing tools for their scripting capabilities, distributed execution support, and comprehensive metrics.

**Test Scenarios**:

**Authentication Load**: Simulate concurrent login attempts, JWT validation requests, and token refresh operations to validate Auth0 integration performance and circuit breaker behavior under load.

**CRUD Operations Load**: Generate mixed read/write workloads against document management APIs, testing MongoDB query performance, connection pool sizing, and index effectiveness.

**AI Service Load**: Test AI completion endpoints with realistic prompt complexity and context sizes, validating rate limiting, circuit breaker operation, and queue management under high demand.

**Test Environment**: Performance tests should run against staging environment with production-equivalent infrastructure (same ECS task sizes, database instance types, Redis configuration) to ensure realistic results.

**Test Data**: Performance tests require substantial test data volumes (thousands of documents, hundreds of user accounts) to realistically stress database query performance and caching effectiveness.

#### 6.6.8.3 Performance Monitoring and Regression Detection

**Synthetic Monitoring**: CloudWatch Synthetics canaries (Section 6.5) provide continuous production performance validation:

**Health Check Canary**: Every 5 minutes, validates `/health` endpoint availability and response time, alerting on availability < 99.9% or response time > threshold.

**Authentication Flow Canary**: Every 15 minutes, executes complete OAuth flow from authorization through token exchange, validating end-to-end authentication latency.

**End-to-End Journey Canary**: Every 30 minutes, performs create → retrieve → delete document flow, validating complete user journey performance including database operations and API processing.

**Performance Alerting**: CloudWatch Alarms (Section 6.5) trigger on performance degradation:

| Alarm | Metric | Threshold | Action |
|-------|--------|-----------|--------|
| API Latency Spike | `api.request.duration` (p95) | > 1000ms for 5 minutes | Email engineering team |
| High Error Rate | `api.error.rate` | > 5% for 5 minutes | PagerDuty alert + email |
| ECS CPU High | ECS CPUUtilization | > 80% for 10 minutes | Auto-scale + operations email |

**Performance Regression Prevention**: Recommended integration of performance testing into CI/CD with baseline comparison, failing builds when response times regress beyond acceptable thresholds (e.g., 10% degradation).

### 6.6.9 Security Testing Strategy

#### 6.6.9.1 Security Test Scenarios

The comprehensive security architecture (Section 6.4) defines multiple security controls requiring validation through testing:

#### Authentication and Authorization Testing

**JWT Validation Testing**:
- **Expired Token Rejection**: Submit requests with expired JWT tokens, expecting 401 Unauthorized responses
- **Invalid Signature Rejection**: Submit tokens with tampered signatures, expecting 401 Unauthorized responses
- **Missing Claims Validation**: Submit tokens missing required claims (user_id, permissions), expecting 401 Unauthorized responses
- **Malformed Token Handling**: Submit non-JWT tokens or malformed JWT structures, expecting graceful error handling

**Permission-Based Access Control (PBAC) Testing**:
- **Insufficient Permissions**: Attempt operations without required permissions, expecting 403 Forbidden responses
- **Resource Ownership Validation**: Attempt access to other users' documents, expecting 403 Forbidden responses
- **Permission Escalation Prevention**: Attempt to manipulate permission claims, expecting rejection

#### Rate Limiting and Circuit Breaker Testing

**Rate Limit Enforcement**:
- **Threshold Validation**: Send > 100 requests/minute from single IP, expecting 429 Too Many Requests after threshold
- **Sliding Window Validation**: Verify rate limit counter resets properly after time window
- **Distributed Rate Limiting**: Test rate limit consistency across multiple ECS tasks using Redis-backed token bucket

**Circuit Breaker Testing**:
- **CLOSED → OPEN Transition**: Simulate Auth0 failures (> 5 failures in 60 seconds), verify circuit opens and subsequent requests fail fast
- **OPEN → HALF-OPEN Transition**: After 30-second timeout, verify circuit enters half-open state allowing test request
- **HALF-OPEN → CLOSED Transition**: Verify successful test request closes circuit, restoring normal operation

#### Input Validation and Injection Prevention

**SQL/NoSQL Injection Testing**: Submit malicious payloads attempting MongoDB injection attacks, expecting Pydantic validation rejection or safe query sanitization.

**Cross-Site Scripting (XSS) Prevention**: Submit HTML/JavaScript payloads in document content, expecting proper output encoding preventing script execution in browser.

**Command Injection Prevention**: Test file upload paths and system command inputs for injection vulnerabilities, expecting input sanitization preventing command execution.

#### 6.6.9.2 Security Testing Tools and Approaches

**Recommended Additions**: The current specification lacks explicit security testing tool integration. Recommended additions include:

**Static Application Security Testing (SAST)**:
- **Bandit**: Python security linter detecting common security issues in backend code
- **ESLint Security Plugin**: JavaScript/TypeScript security rule validation
- **Semgrep**: Multi-language pattern-based security scanning

**Dynamic Application Security Testing (DAST)**:
- **OWASP ZAP**: Automated web application security scanner
- **Burp Suite**: Manual security testing and vulnerability discovery

**Dependency Scanning**:
- **Snyk**: Vulnerability scanning for Python and npm dependencies
- **GitHub Dependabot**: Automated pull requests for dependency security updates
- **npm audit / pip-audit**: Built-in dependency vulnerability scanning

**Secrets Scanning**:
- **GitGuardian** or **TruffleHog**: Scan commits for accidentally committed secrets
- **GitHub Secret Scanning**: Automatic detection of common secret patterns in commits

#### 6.6.9.3 Compliance and Audit Testing

**Encryption Validation**:
- **TLS Configuration Testing**: Validate TLS 1.3 enforcement, certificate validity, and cipher suite security
- **Encryption at Rest**: Verify MongoDB encryption at rest using AES-256 encryption keys
- **Key Rotation**: Test key rotation procedures for encryption keys without data loss

**Audit Logging Validation**: Test comprehensive audit trail generation for security-relevant events:
- Authentication attempts (successful and failed)
- Authorization failures (permission denied events)
- Data access and modification events
- Administrative actions
- Security configuration changes

**Audit Log Integrity**: Verify audit logs are immutable, tamper-evident, and properly protected from unauthorized access.

### 6.6.10 Quality Metrics and Gates

#### 6.6.10.1 Code Coverage Targets

**Backend Coverage Target**: **80% minimum code coverage** for Python backend services, measured by line coverage across all modules in `backend/` directory.

**Frontend Coverage Target**: While not explicitly specified, industry best practices suggest **70-80% code coverage** for React applications, focusing on component logic and utility functions while excluding trivial UI components.

**Coverage Reporting**: Coverage trends tracked over time using Codecov integration, with pull request comments displaying coverage impact of proposed changes. Coverage decreases trigger review discussions but don't automatically block merges, balancing coverage goals with practical development needs.

**Coverage Exclusions**: Standard exclusions include:
- Test files themselves (`test_*.py`, `*.test.ts`)
- Configuration files (`config.py`, `settings.ts`)
- Migration scripts
- Explicit `# pragma: no cover` annotations for unreachable defensive code

#### 6.6.10.2 Test Success Rate Requirements

**Zero-Tolerance for Failing Tests**: CI/CD pipelines enforce **100% test pass rate** before merge/deployment. No failing tests are acceptable in protected branches (`main`, `develop`).

**Flaky Test Tolerance**: While zero failing tests is required, flaky tests (inconsistent pass/fail) should be identified and quarantined rather than left to disrupt CI/CD. Target **< 1% flakiness rate** across test suite.

**Test Suite Performance**: Unit test suites should complete within **5 minutes** for rapid feedback. Integration tests may run longer but should complete within **15 minutes** to maintain developer productivity.

#### 6.6.10.3 Quality Gates

**Pre-Merge Quality Gates** (enforced on pull requests):

| Gate | Requirement | Enforcement |
|------|-------------|-------------|
| All Tests Pass | 100% pass rate | GitHub required check |
| Code Coverage | No coverage decrease > 1% | Codecov comment review |
| Code Quality | Zero linting/formatting errors | GitHub required check |
| Type Safety | Zero TypeScript/mypy errors | GitHub required check |
| Build Success | Successful production build | GitHub required check |
| Security Scan | No high-severity vulnerabilities | Recommended addition |

**Pre-Deployment Quality Gates** (enforced before production deployment):

| Gate | Requirement | Enforcement |
|------|-------------|-------------|
| Integration Tests | 100% pass rate | CI/CD pipeline check |
| Performance Tests | Response times within targets | Recommended addition |
| Security Scan | No critical vulnerabilities | Recommended addition |
| Smoke Tests | Core functionality validated | Synthetic canary checks |

**Post-Deployment Quality Gates** (monitoring production quality):

| Metric | Target | Alert Threshold | Action |
|--------|--------|----------------|--------|
| Error Rate | < 1% | > 5% for 5 minutes | PagerDuty + email |
| API Latency (p95) | < 1000ms | > 1000ms for 5 minutes | Email engineering |
| Availability | > 99.9% | < 99.9% in rolling hour | PagerDuty + email |
| Canary Success Rate | 100% | Any failure | Email operations |

#### 6.6.10.4 Documentation Requirements

**Test Documentation Standards**:

**Test Case Documentation**: Complex test scenarios should include docstrings explaining:
- What behavior is being tested
- Why this test is important (business/technical context)
- How to reproduce the scenario manually (for E2E tests)
- Expected outcomes and assertion rationale

**Test Coverage Documentation**: README files in test directories should document:
- Test organization structure
- How to run tests locally
- How to run specific test subsets (unit only, integration only)
- Common test failures and troubleshooting
- Test data management procedures

**CI/CD Pipeline Documentation**: Workflow files should include comments explaining:
- Pipeline stage purposes
- Environment variable requirements
- Deployment approval processes
- Rollback procedures

### 6.6.11 Test Environment Architecture

#### 6.6.11.1 Development Environment Testing

**Local Development Setup**: Developers run tests on local workstations using Docker Compose for service orchestration:

**Local Test Infrastructure**:
- **MongoDB Container**: mongo:7.0 image provides isolated test database, reset between test runs
- **Redis Container**: redis:7-alpine image provides session storage and cache testing
- **Mock External Services**: MSW (frontend) and pytest-mock (backend) provide Auth0, LangChain, and AWS service mocks

**Local Test Execution**:
- **Backend**: `pytest backend/tests/` runs complete test suite with local service dependencies
- **Frontend**: `npm run test` executes Jest/Vitest with MSW-mocked APIs
- **Fast Feedback**: Local tests run in seconds (unit tests) to minutes (integration tests) for rapid iteration

**Pre-Commit Validation**: Recommended integration of pre-commit hooks running:
- Code formatting (Black, Prettier)
- Linting (Flake8, ESLint)
- Type checking (mypy, tsc)
- Fast unit tests
Preventing low-quality code from reaching CI/CD pipelines.

#### 6.6.11.2 Staging Environment Testing

**Staging Environment Purpose**: Production-equivalent environment for pre-release validation with realistic infrastructure configuration.

**Staging Infrastructure** (from Section 5.1):
- **Automatic Deployment**: Push to `staging` branch triggers automatic deployment
- **Isolated Resources**: Separate AWS resources (VPC, ECS cluster, RDS/MongoDB instance, S3 buckets) prevent staging-production interference
- **Production Parity**: Same instance types, auto-scaling configuration, and network topology as production
- **Test Data**: Staging database seeded with realistic but non-production data for manual and automated testing

**Staging Test Execution**:
- **Automated Smoke Tests**: Post-deployment smoke tests validate core functionality
- **Manual QA Testing**: QA team performs exploratory testing and user acceptance testing
- **Integration Testing**: Cross-service integration tests run against actual AWS services
- **Performance Testing**: Load tests validate performance with production-like infrastructure

**Staging Limitations**: While production-parity, staging may use smaller instance sizes or reduced replica counts for cost optimization, potentially masking performance issues only visible at production scale.

#### 6.6.11.3 Production Testing and Monitoring

**Production Testing Philosophy**: Production is not a test environment, but continuous monitoring provides ongoing validation of production quality.

**Synthetic Monitoring** (Section 6.5): CloudWatch Synthetics canaries provide automated production testing:

**Health Check Canary** (every 5 minutes):
```javascript
// Simplified canary script structure
const synthetics = require('Synthetics');
const https = require('https');

const healthCheck = async function () {
  const startTime = Date.now();
  const response = await https.get('https://api.example.com/health');
  const latency = Date.now() - startTime;
  
  if (response.statusCode !== 200) {
    throw new Error(`Health check failed: ${response.statusCode}`);
  }
  
  if (latency > 500) {
    throw new Error(`Health check too slow: ${latency}ms`);
  }
};

exports.handler = async () => {
  return await synthetics.executeStep('healthCheck', healthCheck);
};
```

**Authentication Flow Canary** (every 15 minutes): Complete OAuth flow from authorization through JWT token issuance, validating end-to-end authentication functionality.

**End-to-End Journey Canary** (every 30 minutes): Document creation → retrieval → deletion flow, validating complete application functionality including database operations, API processing, and authentication/authorization.

**Real User Monitoring (RUM)**: Frontend applications should integrate RUM solutions (AWS CloudWatch RUM or third-party tools like Datadog RUM) to collect real user performance data, error tracking, and usage analytics.

#### 6.6.11.4 Test Environment Architecture Diagram

```mermaid
graph TB
    subgraph "Development Environment"
        DEV[Developer Workstation]
        LOCAL_DB[(MongoDB Container)]
        LOCAL_REDIS[(Redis Container)]
        LOCAL_MOCK[MSW/pytest-mock<br/>External Service Mocks]
        
        DEV --> LOCAL_DB
        DEV --> LOCAL_REDIS
        DEV --> LOCAL_MOCK
    end
    
    subgraph "CI/CD Test Environment - GitHub Actions"
        CI[GitHub Actions Runner]
        CI_DB[(Test MongoDB)]
        CI_REDIS[(Test Redis)]
        CI_MOCK[Mocked Services]
        
        CI --> CI_DB
        CI --> CI_REDIS
        CI --> CI_MOCK
    end
    
    subgraph "Staging Environment - AWS"
        STAGE_ALB[ALB]
        STAGE_ECS[ECS Fargate Tasks]
        STAGE_DB[(MongoDB/Atlas)]
        STAGE_REDIS[(ElastiCache Redis)]
        STAGE_AUTH[Auth0<br/>Staging Tenant]
        STAGE_S3[(S3 Staging Bucket)]
        
        STAGE_ALB --> STAGE_ECS
        STAGE_ECS --> STAGE_DB
        STAGE_ECS --> STAGE_REDIS
        STAGE_ECS --> STAGE_AUTH
        STAGE_ECS --> STAGE_S3
    end
    
    subgraph "Production Environment - AWS"
        PROD_ALB[ALB]
        PROD_ECS[ECS Fargate Tasks]
        PROD_DB[(MongoDB/Atlas<br/>Replica Set)]
        PROD_REDIS[(ElastiCache Redis<br/>Cluster)]
        PROD_AUTH[Auth0<br/>Production Tenant]
        PROD_S3[(S3 Production Bucket)]
        CANARY[CloudWatch Synthetics<br/>Canaries]
        
        PROD_ALB --> PROD_ECS
        PROD_ECS --> PROD_DB
        PROD_ECS --> PROD_REDIS
        PROD_ECS --> PROD_AUTH
        PROD_ECS --> PROD_S3
        CANARY -.monitors.-> PROD_ALB
    end
    
    DEV -->|git push| CI
    CI -->|deploy on success| STAGE_ECS
    STAGE_ECS -->|manual approval| PROD_ECS
    
    style DEV fill:#e1f5ff
    style CI fill:#fff4e1
    style STAGE_ECS fill:#f0e1ff
    style PROD_ECS fill:#e1ffe1
    style CANARY fill:#ffe1e1
```

### 6.6.12 Test Data Management

#### 6.6.12.1 Test Data Strategy

**Test Data Categories**:

**Static Test Data**: Fixed, well-known test data used across multiple tests for consistency. Examples include:
- Sample user profiles with known attributes
- Reference documents with predictable content
- Configuration objects for common scenarios
- Mock API responses stored in fixture files

**Dynamic Test Data**: Generated programmatically for each test run to ensure uniqueness and prevent conflicts:
- Unique user email addresses (`test_user_${timestamp}@example.com`)
- Uniquely named documents preventing name collisions
- Random but realistic content using faker libraries
- Time-stamped resources enabling parallel test execution

**Anonymized Production Data**: For staging environment validation, production data anonymized with PII (Personally Identifiable Information) removed or replaced with synthetic data.

#### 6.6.12.2 Data Seeding and Teardown

**Unit Test Data Management**:
- **In-Memory Data**: Unit tests use in-memory data structures, avoiding database dependencies
- **Test Fixtures**: pytest fixtures with `scope="function"` create fresh test data for each test, automatically cleaned up after test completion
- **Database Mocking**: mongomock and fakeredis provide in-memory database implementations, reset automatically between tests

**Integration Test Data Management**:
- **Database Seeding**: pytest fixtures with `scope="session"` create test database once, with `scope="function"` fixtures cleaning collections between tests
- **Transactional Rollback**: For databases supporting transactions, wrap each test in transaction rolled back after test completion
- **Explicit Cleanup**: `yield` fixtures in pytest enable setup before test, cleanup after test using try-finally pattern

**E2E Test Data Management**:
- **Pre-Test Seeding**: Seed staging database with comprehensive test dataset before E2E suite execution
- **Idempotent Tests**: Each E2E test creates its own unique test data (unique usernames, document titles) preventing conflicts
- **Post-Test Cleanup**: Optional cleanup of E2E-created data, although full database refresh between test runs may be more practical

**Test Data Version Control**: Large fixture files (mock API responses, sample documents) stored in `tests/fixtures/` directory under version control, ensuring consistent test behavior across environments and over time.

### 6.6.13 Test Execution Flow

```mermaid
flowchart TD
    START([Developer Commits Code]) --> PUSH[git push to GitHub]
    PUSH --> TRIGGER{Which Files<br/>Changed?}
    
    TRIGGER -->|backend/**| BACKEND_PIPELINE
    TRIGGER -->|frontend/**| FRONTEND_PIPELINE
    TRIGGER -->|mobile/**| MOBILE_PIPELINE
    TRIGGER -->|terraform/**| INFRA_PIPELINE
    
    subgraph BACKEND_PIPELINE["Backend Test Pipeline"]
        B1[Setup Python 3.11] --> B2[Install Dependencies]
        B2 --> B3[Code Quality Checks]
        B3 --> B4{Quality<br/>Pass?}
        B4 -->|No| FAIL1[❌ Pipeline Fails]
        B4 -->|Yes| B5[Run pytest Suite]
        B5 --> B6{Tests<br/>Pass?}
        B6 -->|No| FAIL2[❌ Pipeline Fails]
        B6 -->|Yes| B7[Generate Coverage]
        B7 --> B8[Upload to Codecov]
        B8 --> B9{On main<br/>branch?}
        B9 -->|Yes| B10[Build Docker Image]
        B10 --> B11[Push to ECR]
        B11 --> B12[Deploy to ECS]
        B9 -->|No| SUCCESS1[✅ Tests Passed]
    end
    
    subgraph FRONTEND_PIPELINE["Frontend Test Pipeline"]
        F1[Setup Node.js 18] --> F2[Install Dependencies]
        F2 --> F3[Parallel Quality Checks]
        F3 --> F4{Quality<br/>Pass?}
        F4 -->|No| FAIL3[❌ Pipeline Fails]
        F4 -->|Yes| F5[Run Jest/Vitest]
        F5 --> F6{Tests<br/>Pass?}
        F6 -->|No| FAIL4[❌ Pipeline Fails]
        F6 -->|Yes| F7[Production Build]
        F7 --> F8{Build<br/>Success?}
        F8 -->|No| FAIL5[❌ Pipeline Fails]
        F8 -->|Yes| F9{On main<br/>branch?}
        F9 -->|Yes| F10[Deploy to S3/CloudFront]
        F9 -->|No| SUCCESS2[✅ Tests Passed]
    end
    
    subgraph MOBILE_PIPELINE["Mobile Test Pipeline"]
        M1[Setup Build Environment] --> M2[Install Dependencies]
        M2 --> M3[Platform-Specific Build]
        M3 --> M4{Build<br/>Success?}
        M4 -->|No| FAIL6[❌ Pipeline Fails]
        M4 -->|Yes| M5[Store Artifacts]
        M5 --> SUCCESS3[✅ Build Complete]
    end
    
    subgraph INFRA_PIPELINE["Infrastructure Test Pipeline"]
        I1[Setup Terraform] --> I2[Format Check]
        I2 --> I3{Format<br/>Valid?}
        I3 -->|No| FAIL7[❌ Pipeline Fails]
        I3 -->|Yes| I4[Terraform Init]
        I4 --> I5[Terraform Validate]
        I5 --> I6{Valid<br/>Config?}
        I6 -->|No| FAIL8[❌ Pipeline Fails]
        I6 -->|Yes| I7[Terraform Plan]
        I7 --> I8[Post Plan as PR Comment]
        I8 --> I9{On main<br/>branch?}
        I9 -->|Yes| I10[Terraform Apply]
        I9 -->|No| SUCCESS4[✅ Validation Passed]
    end
    
    B12 --> MONITORING[Production Monitoring]
    F10 --> MONITORING
    I10 --> MONITORING
    
    subgraph MONITORING["Continuous Production Testing"]
        C1[Health Check Canary<br/>Every 5 minutes]
        C2[Auth Flow Canary<br/>Every 15 minutes]
        C3[E2E Journey Canary<br/>Every 30 minutes]
        C4{Canary<br/>Pass?}
        C1 --> C4
        C2 --> C4
        C3 --> C4
        C4 -->|No| ALERT[🚨 Alert Operations]
        C4 -->|Yes| C5[✅ Production Healthy]
    end
    
    style START fill:#e1f5ff
    style FAIL1 fill:#ffe1e1
    style FAIL2 fill:#ffe1e1
    style FAIL3 fill:#ffe1e1
    style FAIL4 fill:#ffe1e1
    style FAIL5 fill:#ffe1e1
    style FAIL6 fill:#ffe1e1
    style FAIL7 fill:#ffe1e1
    style FAIL8 fill:#ffe1e1
    style SUCCESS1 fill:#e1ffe1
    style SUCCESS2 fill:#e1ffe1
    style SUCCESS3 fill:#e1ffe1
    style SUCCESS4 fill:#e1ffe1
    style ALERT fill:#ffe1e1
    style C5 fill:#e1ffe1
```

### 6.6.14 Test Data Flow Diagram

```mermaid
flowchart LR
    subgraph "Test Data Sources"
        FIXTURES[Static Fixtures<br/>tests/fixtures/]
        FACTORIES[Data Factories<br/>faker, factory_boy]
        MOCKS[Mock Responses<br/>MSW handlers]
        SEEDS[Database Seeds<br/>Staging data]
    end
    
    subgraph "Unit Tests"
        UT_BACKEND[Backend Unit Tests<br/>pytest]
        UT_FRONTEND[Frontend Unit Tests<br/>Jest/Vitest]
        
        FACTORIES --> UT_BACKEND
        FIXTURES --> UT_BACKEND
        MOCKS --> UT_FRONTEND
        FACTORIES --> UT_FRONTEND
    end
    
    subgraph "Integration Tests"
        IT_API[API Integration Tests]
        IT_DB[(Test Database<br/>MongoDB)]
        IT_CACHE[(Test Cache<br/>Redis)]
        
        FACTORIES --> IT_API
        IT_API --> IT_DB
        IT_API --> IT_CACHE
        MOCKS --> IT_API
    end
    
    subgraph "E2E Tests"
        E2E_TESTS[E2E Test Suite]
        E2E_STAGING[(Staging Database)]
        E2E_SERVICES[Staging Services<br/>Auth0, S3]
        
        SEEDS --> E2E_STAGING
        E2E_STAGING --> E2E_TESTS
        E2E_SERVICES --> E2E_TESTS
    end
    
    subgraph "Production Monitoring"
        CANARY[Synthetic Canaries]
        PROD_ENV[(Production<br/>Environment)]
        
        CANARY --> PROD_ENV
        PROD_ENV --> METRICS[CloudWatch Metrics]
    end
    
    UT_BACKEND --> COVERAGE[Coverage Reports<br/>Codecov]
    UT_FRONTEND --> COVERAGE
    IT_API --> COVERAGE
    
    E2E_TESTS --> RESULTS[Test Results<br/>GitHub Actions]
    CANARY --> ALERTS[CloudWatch Alarms]
    
    style FIXTURES fill:#e1f5ff
    style FACTORIES fill:#e1f5ff
    style MOCKS fill:#e1f5ff
    style SEEDS fill:#e1f5ff
    style IT_DB fill:#fff4e1
    style IT_CACHE fill:#fff4e1
    style E2E_STAGING fill:#f0e1ff
    style PROD_ENV fill:#e1ffe1
    style COVERAGE fill:#ffe1f5
    style RESULTS fill:#ffe1f5
    style ALERTS fill:#ffe1e1
```

### 6.6.15 References

#### Files Examined

- `README.md` - Project title documentation; repository in pre-implementation phase

#### Folders Explored

- `` (root directory) - Contains only README.md, no source code or test infrastructure implemented

#### Technical Specification Sections Referenced

- **Section 1.2 System Overview** - Project context and implementation status confirmation
- **Section 2.5 Non-Functional Requirements** - Quality standards including performance criteria, security requirements, reliability targets, and maintainability standards
- **Section 3.1 Technology Stack Overview** - Multi-tier architecture (Flask, React, React Native, Electron, MongoDB, Redis, Auth0, LangChain)
- **Section 3.3 Frameworks & Libraries** - Backend frameworks (Flask 3.0+, LangChain 0.1.0+), frontend frameworks (React 18.2+, React Native 0.72+, Electron 28+), UI frameworks (TailwindCSS 3.4+)
- **Section 3.7 Development & Deployment** - Comprehensive testing tools (pytest, pytest-cov, Black, Flake8, mypy, Jest/Vitest, React Testing Library, MSW, ESLint, Prettier), CI/CD implementation with GitHub Actions, Docker containerization, Terraform infrastructure as code
- **Section 4.2 CI/CD Workflows** - Detailed backend testing workflow (Section 4.2.1), frontend testing workflow (Section 4.2.2), mobile build testing (Section 4.2.3), infrastructure validation workflow (Section 4.2.4)
- **Section 5.1 High-Level Architecture** - Cloud-native microservices architecture, API-first design, stateless services, multi-AZ deployment, environment structure (development, staging, production)
- **Section 5.4 Cross-Cutting Concerns** - Performance requirements with specific API response time targets (p50/p95/p99 thresholds), availability targets (99.9% overall, 99.95% API/database), monitoring and observability, error handling patterns
- **Section 6.4 Security Architecture** - Auth0 OAuth 2.0 + OIDC authentication, JWT validation requirements, Permission-Based Access Control (PBAC), circuit breaker patterns, rate limiting (Redis token bucket, 100 req/min), encryption standards (AES-256 at rest, TLS 1.3 in transit), audit logging requirements
- **Section 6.5 Monitoring and Observability** - CloudWatch Logs aggregation, CloudWatch Metrics for performance tracking, AWS X-Ray distributed tracing, CloudWatch Alarms (high error rate, API latency spike, ECS CPU), CloudWatch Synthetics for synthetic monitoring (health check every 5 min, auth flow every 15 min, E2E journey every 30 min)

#### Testing Tools and Frameworks Referenced

| Category | Tool | Purpose |
|----------|------|---------|
| Backend Testing | pytest, pytest-cov, pytest-mock | Python test framework, coverage analysis, mocking |
| Backend Quality | Black, Flake8, mypy | Code formatting, linting, static type checking |
| Frontend Testing | Jest/Vitest, React Testing Library | JavaScript test framework, component testing |
| Frontend Quality | ESLint, Prettier, TypeScript | Linting, formatting, type checking |
| API Mocking | MSW (Mock Service Worker) | Network-level API mocking for frontend |
| Database Mocking | mongomock, fakeredis | In-memory database simulation |
| AWS Mocking | moto | AWS service mocking for integration tests |
| Load Testing | k6, Apache JMeter (recommended) | Performance and load testing |
| Security Testing | Bandit, ESLint Security, Snyk (recommended) | Security scanning and vulnerability detection |
| Mobile Testing | XCTest, Espresso, Detox (recommended) | iOS, Android, and React Native testing |
| E2E Testing | Playwright, Cypress (recommended) | Browser automation and E2E testing |
| Infrastructure Testing | Terraform (fmt, validate, plan) | Infrastructure configuration validation |
| Monitoring | CloudWatch Synthetics | Production synthetic monitoring |
| Coverage Reporting | Codecov | Coverage tracking and trend analysis |

#### Performance Targets Referenced (Section 5.4.5)

- Simple CRUD operations: p95 < 300ms, p99 < 500ms
- Complex queries: p95 < 800ms, p99 < 1200ms
- AI completions: p95 < 5000ms, p99 < 8000ms
- Overall application availability: 99.9% (43.2 min downtime/month)
- Flask API availability: 99.95% (21.6 min downtime/month)

#### Quality Standards Referenced

- Code coverage target: 80% minimum (backend)
- Test pass rate: 100% (zero-tolerance for failing tests)
- Flaky test rate target: < 1%
- Unit test execution time: < 5 minutes
- Integration test execution time: < 15 minutes
- Error rate threshold: < 1% normal, alert at > 5%
- API latency p95 threshold: < 1000ms

# 7. User Interface Design

## 7.1 IMPLEMENTATION STATUS AND SCOPE

### 7.1.1 Current Repository State

The CheckSameRepoNoPrompt repository is currently in **pre-implementation phase**, containing only a README.md file with the project title. No UI code, components, design files, mockups, or implementation exists at this time.

### 7.1.2 Documentation Scope

This section documents the **planned User Interface Design architecture** based on comprehensive technical specifications. All UI technologies, screen designs, component architectures, and interaction patterns described herein represent the intended design that will be implemented during the development phase. This documentation serves as the definitive reference for future UI implementation across all supported platforms.

### 7.1.3 Multi-Platform UI Strategy

The system is designed to support **six distinct user interface platforms**, each tailored to provide optimal user experience within their respective ecosystems:

- **Web Application**: Browser-based interface for desktop and mobile browsers
- **React Native Mobile Applications**: Cross-platform iOS and Android applications with shared codebase
- **iOS Native Application**: Platform-specific iOS application leveraging native capabilities
- **Android Native Application**: Platform-specific Android application with native integration
- **Electron Desktop Application**: Cross-platform desktop application for Windows, macOS, and Linux
- **macOS Native Application**: Pure native macOS application using AppKit and Cocoa frameworks

This multi-platform approach ensures users can access the system through their preferred interface while maintaining consistent functionality and user experience across all platforms.

---

## 7.2 CORE UI TECHNOLOGIES

### 7.2.1 Web Application Technology Stack

#### 7.2.1.1 Frontend Framework Architecture

**React 18.2+ with TypeScript 5.0+** forms the foundation of the web application, providing component-based architecture, virtual DOM rendering, and comprehensive type safety. React 18's concurrent features enable improved perceived performance through concurrent rendering and automatic batching.

**Build and Development Tools**:
- **Vite 5.0+**: Lightning-fast development server with Hot Module Replacement (HMR), optimized production builds with code splitting, and native ES modules support
- **TypeScript 5.0+**: Strict type checking, enhanced IDE support, and compile-time error detection

#### 7.2.1.2 UI Styling and Design System

**TailwindCSS 3.4+** provides utility-first CSS framework enabling:
- Rapid UI development through composable utility classes
- Built-in responsive design system with mobile-first breakpoints
- Consistent design tokens (colors, spacing, typography)
- Dark mode support through class-based variants
- Automatic removal of unused CSS via PurgeCSS integration
- Minimal bundle size in production builds

**Design System Implementation**:
- Custom Tailwind configuration extending default theme with brand colors
- Reusable component library built on Tailwind primitives
- Consistent spacing scale (4px base unit)
- Typography scale with responsive font sizing
- Color palette with semantic naming (primary, secondary, success, warning, error)

#### 7.2.1.3 State Management Architecture

**TanStack Query (React Query)** manages server state with:
- Automatic caching of API responses with configurable Time-To-Live (TTL)
- Background data refetching and synchronization
- Optimistic updates for improved perceived performance
- Request deduplication preventing redundant API calls
- Built-in loading and error states
- Pagination and infinite scroll support

**Local State Management**:
- React Context API for application-level state (theme, language preferences)
- useState and useReducer hooks for component-local state
- Zustand or Redux Toolkit (if global state complexity increases)

#### 7.2.1.4 Routing and Navigation

**React Router 6+** provides:
- Declarative routing with nested route structures
- Protected routes requiring authentication
- Dynamic route parameters
- Lazy loading routes for code splitting
- Programmatic navigation
- Browser history management

#### 7.2.1.5 HTTP Communication

**Axios HTTP Client** configured with:
- Base URL configuration pointing to Flask API (`/api/v1/`)
- Request interceptors for automatic JWT token injection
- Response interceptors for error handling and token refresh
- Request timeout configuration (30 seconds default)
- Retry logic with exponential backoff for transient failures

#### 7.2.1.6 Authentication Integration

**@auth0/auth0-react SDK** implements:
- Auth0Provider wrapper component encapsulating application
- OAuth 2.0 Authorization Code Flow with PKCE
- Automatic token management and refresh
- `useAuth0` hook providing authentication state and methods
- Redirect-based login/logout flows
- Silent authentication for seamless token renewal

**Authentication Configuration**:
```
Domain: {tenant}.auth0.com
Client ID: Web application client ID from Auth0
Redirect URI: https://app.example.com/callback
Logout URI: https://app.example.com/
Response Type: code (Authorization Code Flow)
Scope: openid profile email read:documents write:documents
```

#### 7.2.1.7 Deployment Architecture

**Static Asset Deployment Pipeline**:
1. GitHub Actions CI/CD builds production bundle via `npm run build`
2. Optimized static assets (HTML, CSS, JavaScript, images) generated in `/dist` directory
3. Assets uploaded to dedicated S3 bucket (`app-static-assets`)
4. CloudFront CDN distribution serves assets from edge locations globally
5. Route 53 DNS configured with custom domain pointing to CloudFront
6. CloudFront cache invalidation triggered post-deployment

**Performance Optimizations**:
- Code splitting by route reducing initial bundle size
- Lazy loading of heavy components
- Image optimization with modern formats (WebP, AVIF)
- Asset compression (Gzip, Brotli)
- Browser caching with cache-busting via content hashing

### 7.2.2 Mobile Application Technology Stack

#### 7.2.2.1 Cross-Platform Layer (React Native 0.72+)

**React Native Framework** enables:
- Single codebase shared between iOS and Android (70-80% code reuse)
- Native component rendering for performance
- Hot reloading for rapid development iteration
- Bridge to native modules for platform-specific functionality
- TypeScript support for type safety

**Core Libraries**:
- **React Navigation 6+**: Native-feel navigation patterns (stack, tab, drawer navigation)
- **React Native Paper**: Material Design component library for Android consistency
- **Axios**: HTTP client for API communication with JWT authentication
- **AsyncStorage**: Persistent key-value storage for preferences and cache
- **React Native Vector Icons**: Comprehensive icon library

#### 7.2.2.2 iOS Native Layer (Swift 5.9+)

**Native Capabilities**:
- **Biometric Authentication**: FaceID and TouchID for secure app unlock and transaction confirmation
- **HealthKit Integration**: Health data access (if application requires health metrics)
- **iOS Keychain**: Secure storage for JWT tokens with biometric protection
- **Native UI Elements**: Platform-specific components where React Native components insufficient
- **Handoff Support**: Continue tasks across Apple devices

**Authentication Integration**:
- **ASWebAuthenticationSession**: Secure OAuth 2.0 flow in ephemeral browser session
- **Universal Links**: Seamless deep linking for authentication callbacks
- **Custom URL Scheme**: Fallback for authentication redirects (`com.yourapp://callback`)

#### 7.2.2.3 Android Native Layer (Kotlin 1.9+)

**Native Capabilities**:
- **Biometric Authentication**: Fingerprint, face recognition for secure access
- **Android Keystore**: Hardware-backed secure storage for cryptographic keys and tokens
- **Material Design Components**: Native Android UI components
- **Google Services Integration**: Google Sign-In, Firebase Cloud Messaging
- **App Links**: Verified deep linking for authentication callbacks

**Authentication Integration**:
- **Chrome Custom Tabs**: Secure OAuth 2.0 authentication in embedded Chrome instance
- **Intent Filters**: Deep link handling for authentication callbacks
- **Package Name Configuration**: `com.yourcompany.yourapp`

#### 7.2.2.4 Mobile State Management

**Data Layer**:
- **TanStack Query**: Server state management with mobile-optimized caching strategies
- **AsyncStorage**: Persistent local storage for offline data and user preferences
- **SQLite** (Future): Local database for complex offline functionality

**Offline Support** (Planned):
- Queue write operations when offline
- Automatic synchronization when connection restored
- Optimistic UI updates
- Conflict resolution strategies

#### 7.2.2.5 Push Notification Architecture

**Firebase Cloud Messaging (FCM)**:
- Cross-platform push notification delivery
- Device token registration with backend
- Silent notifications for background data sync
- Rich notifications with images and actions
- Notification priority and categorization

### 7.2.3 Desktop Application Technology Stack

#### 7.2.3.1 Electron Framework (Version 28+)

**Architecture Components**:

**Main Process (Node.js Environment)**:
- Full system access including file system, networking, OS APIs
- Application lifecycle management (window creation, app quit)
- Native menu and tray icon integration
- Inter-Process Communication (IPC) bridge to renderer
- Automatic updates via electron-updater
- Crash reporting and telemetry

**Renderer Process (Chromium + React)**:
- React 18+ application rendered in Chromium web view
- Sandboxed environment for security
- Communication with main process via IPC
- Same React codebase as web application with Electron-specific adaptations

**Key Libraries**:
- **Electron Forge / Electron Builder**: Packaging and distribution for Windows (EXE/MSI), macOS (DMG), Linux (AppImage, Snap, Deb)
- **electron-store**: Encrypted persistent storage for user settings
- **electron-log**: Enhanced logging for desktop applications
- **electron-updater**: Automatic application updates with differential downloads

#### 7.2.3.2 Platform-Specific Features

**Windows Integration**:
- Native window controls and title bar customization
- Windows notification system
- File association for opening documents
- Windows jumplist for recent files
- Windows Defender SmartScreen compatibility

**macOS Integration**:
- Native macOS menu bar
- Dock icon with badge notifications
- Touch Bar support
- macOS notifications
- App Sandbox entitlements for distribution

**Linux Integration**:
- System tray integration
- Desktop notifications (libnotify)
- Wayland and X11 display server support
- FreeDesktop.org standards compliance

#### 7.2.3.3 macOS Native Application (Objective-C 2.0)

**Native Framework Integration**:
- **AppKit**: Native macOS UI framework for window management, controls, menus
- **Cocoa**: Foundational frameworks for macOS applications
- **Foundation**: Core services (networking, data structures, file management)
- **Core Data**: Data persistence and object graph management
- **CloudKit**: iCloud synchronization for user data

**Native Capabilities**:
- Native macOS look and feel
- System-level integration (Handoff, Spotlight, Quick Look)
- Native performance without Electron overhead
- macOS-specific features (Mission Control, Spaces, notifications)

### 7.2.4 UI Technology Decision Summary

| Platform | Primary Technology | UI Framework | Deployment Method |
|----------|-------------------|--------------|-------------------|
| **Web** | React 18.2+ + TypeScript 5.0+ | TailwindCSS 3.4+ | S3 + CloudFront CDN |
| **Mobile (Cross-Platform)** | React Native 0.72+ | React Native Paper | App Store, Google Play |
| **iOS Native** | Swift 5.9+ | UIKit, SwiftUI | Apple App Store |
| **Android Native** | Kotlin 1.9+ | Jetpack Compose, Material | Google Play Store |
| **Desktop (Cross-Platform)** | Electron 28+ + React 18+ | TailwindCSS 3.4+ | Direct download, App stores |
| **macOS Native** | Objective-C 2.0 | AppKit, Cocoa | Mac App Store, Direct download |

---

## 7.3 UI USE CASES AND USER FLOWS

### 7.3.1 Authentication Use Cases

#### 7.3.1.1 User Registration Flow

**Platforms**: All (Web, Mobile, Desktop)

**Flow Sequence**:
1. User clicks "Sign Up" button on landing page
2. Application redirects to Auth0 Universal Login page
3. User chooses registration method:
   - Email/password registration with email verification
   - Social login (Google, Facebook, Apple, GitHub)
4. If email/password: User enters credentials and receives verification email
5. User completes email verification by clicking link
6. Auth0 redirects back to application with authorization code
7. Application exchanges code for JWT tokens (access token, refresh token)
8. Application stores tokens securely and creates user profile in MongoDB
9. User redirected to onboarding flow or dashboard

#### 7.3.1.2 User Login Flow

**Platforms**: All (Web, Mobile, Desktop)

**Flow Sequence**:
1. User clicks "Login" button
2. Application initiates OAuth 2.0 Authorization Code Flow with PKCE
3. User redirected to Auth0 Universal Login
4. User enters credentials or selects social login
5. **Multi-Factor Authentication** (if enabled):
   - SMS code delivery and verification
   - Authenticator app TOTP verification
   - Email code verification
6. Auth0 validates credentials and MFA (if applicable)
7. Authorization code returned to application via callback URL
8. Application exchanges code for JWT tokens
9. Tokens stored securely:
   - **Web**: Memory or sessionStorage (managed by Auth0 SDK)
   - **Mobile**: iOS Keychain or Android Keystore
   - **Desktop**: Electron SafeStorage API
10. Application fetches user profile from backend API
11. User redirected to main application interface

#### 7.3.1.3 Biometric Authentication (Mobile Only)

**Platforms**: iOS, Android Native

**Flow Sequence**:
1. User enables biometric authentication in settings
2. Application associates biometric credential with stored JWT tokens
3. On subsequent app launches:
   - Application prompts for biometric verification (FaceID, TouchID, Fingerprint)
   - User provides biometric input
   - On success, application unlocks and retrieves stored JWT tokens
   - Application validates token expiration and refreshes if necessary
4. Biometric failure triggers fallback to full authentication flow

#### 7.3.1.4 Token Refresh Flow

**Platforms**: All (Background Process)

**Flow Sequence**:
1. Application monitors JWT access token expiration (15-minute lifetime)
2. **Automatic Refresh** (5 minutes before expiration):
   - Application sends refresh token to Auth0 token endpoint
   - Auth0 validates refresh token (7-day lifetime)
   - New access token and optionally new refresh token returned
   - Application updates stored tokens
3. **Silent Failure Handling**:
   - If refresh token expired, user redirected to login
   - If network error, retry with exponential backoff
   - If Auth0 unavailable, allow continued use with existing token until expiration

### 7.3.2 Core Application Use Cases

#### 7.3.2.1 Document Management Workflows

**Use Case 1: Browse Documents**

**Flow Sequence**:
1. User navigates to documents section
2. Application fetches document list from `/api/v1/documents` endpoint
3. TanStack Query caches response (5-minute TTL)
4. Documents displayed in grid or list view with:
   - Document thumbnail or icon
   - Filename
   - Upload date
   - File size
   - Last modified date
5. User can filter by date, type, or search by filename
6. Pagination or infinite scroll for large document collections

**Use Case 2: Upload Document**

**Flow Sequence**:
1. User clicks "Upload Document" button
2. File picker dialog opens (native system file picker)
3. User selects one or multiple files
4. For each file:
   - Application requests presigned S3 upload URL from `/api/v1/files/upload-url`
   - API returns presigned URL with 15-minute expiration
   - Application uploads file directly to S3 via PUT request
   - Progress indicator shows upload progress
   - On completion, application calls `/api/v1/files/complete` to confirm upload
5. Document metadata stored in MongoDB
6. Document list refreshed with new upload
7. **Future Enhancement**: Background processing for OCR and embedding generation

**Use Case 3: View Document**

**Flow Sequence**:
1. User clicks document in list
2. Application fetches document metadata from `/api/v1/documents/{id}`
3. Application generates presigned download URL for S3 access
4. Document rendered in appropriate viewer:
   - **PDF**: In-browser PDF viewer or native viewer
   - **Images**: Full-screen image viewer with zoom
   - **Text**: Code editor or rich text viewer
   - **Office Documents**: Preview or download prompt
5. User actions available:
   - Download original file
   - Share with other users
   - Delete document (with confirmation)
   - View metadata and version history

#### 7.3.2.2 AI-Powered Features

**Use Case 1: AI Text Completion**

**Flow Sequence**:
1. User accesses AI completion interface
2. User enters text prompt in input field
3. User optionally configures:
   - Model selection (GPT-3.5 Turbo, GPT-4, GPT-4 Turbo)
   - Temperature (creativity level)
   - Max tokens (response length)
4. User clicks "Generate" button
5. Application validates rate limit (10 AI requests/minute)
6. Request sent to `/api/v1/ai/completions`
7. Loading indicator displayed during LLM processing
8. Generated text streamed to UI (if streaming enabled) or displayed on completion
9. User can:
   - Copy result to clipboard
   - Regenerate with same prompt
   - Modify prompt and regenerate
   - Save to document

**Use Case 2: Conversational AI**

**Flow Sequence**:
1. User opens AI conversation interface
2. User sees conversation history (if existing conversation) or blank slate
3. User types message and sends
4. Application sends message to `/api/v1/ai/conversations`
5. Message displayed immediately in conversation thread (optimistic update)
6. Backend processes through LangChain conversation chain
7. AI response streamed back and displayed in real-time
8. Conversation history persisted to MongoDB
9. User can:
   - Continue conversation with context retained
   - Start new conversation
   - View conversation history
   - Delete conversation

**Use Case 3: Semantic Search (RAG)**

**Flow Sequence**:
1. User enters search query in search interface
2. User clicks "Semantic Search" (vs. traditional keyword search)
3. Application sends query to `/api/v1/ai/search`
4. Backend workflow:
   - Query converted to embedding vector via OpenAI
   - Vector database queried for similar documents
   - Top K relevant documents retrieved
   - LLM generates natural language answer with document citations
5. Results displayed with:
   - Natural language answer
   - Source document citations
   - Relevance scores
   - Original document snippets
6. User can:
   - Click citations to view source documents
   - Refine search query
   - Ask follow-up questions

#### 7.3.2.3 User Profile Management

**Flow Sequence**:
1. User navigates to profile settings
2. Application fetches user data from `/api/v1/users/me`
3. User profile displayed with:
   - Avatar (from Auth0 or uploaded)
   - Name and email
   - Account creation date
   - Subscription tier or permissions
4. User can update:
   - Display name
   - Profile picture (upload to S3)
   - Email (requires verification)
   - Password (redirects to Auth0)
   - Notification preferences
   - Theme (light/dark mode)
5. Changes saved to backend API
6. Success notification displayed

### 7.3.3 User Interaction Patterns

#### 7.3.3.1 Navigation Patterns

**Web Application Navigation**:
- **Top Navigation Bar**: Logo, main navigation links (Documents, AI Tools, Search)
- **User Menu**: Avatar dropdown with profile, settings, logout
- **Sidebar**: Collapsible sidebar for secondary navigation and filters
- **Breadcrumbs**: For hierarchical navigation within document folders

**Mobile Application Navigation**:
- **Tab Bar Navigation**: Bottom tabs for primary sections (Home, Documents, AI, Profile)
- **Stack Navigation**: Push/pop navigation for detail views
- **Drawer Navigation**: Side drawer for settings and secondary features
- **Swipe Gestures**: Back gesture, pull-to-refresh

**Desktop Application Navigation**:
- **Native Menu Bar**: File, Edit, View, Window, Help menus
- **Keyboard Shortcuts**: Ctrl/Cmd+N (new), Ctrl/Cmd+O (open), Ctrl/Cmd+S (save)
- **Context Menus**: Right-click menus for document actions

#### 7.3.3.2 Loading and Error States

**Loading States**:
- **Initial Page Load**: Full-page skeleton loaders matching content structure
- **Component Loading**: Spinner or skeleton for individual components
- **Optimistic Updates**: Show expected result immediately, rollback on error
- **Progress Indicators**: For file uploads and long-running operations

**Error States**:
- **Network Errors**: "Connection lost" banner with retry button
- **Authentication Errors**: Redirect to login with return URL
- **Authorization Errors**: "Access Denied" message with contact support link
- **Validation Errors**: Inline field-level error messages
- **Server Errors**: Generic error page with request ID for support

#### 7.3.3.3 Responsive Design Breakpoints

**TailwindCSS Default Breakpoints**:
- **sm**: 640px (Small tablets)
- **md**: 768px (Tablets)
- **lg**: 1024px (Small laptops)
- **xl**: 1280px (Desktop)
- **2xl**: 1536px (Large desktop)

**Mobile-First Approach**:
- Default styles target mobile devices
- Progressive enhancement for larger screens
- Touch-friendly tap targets (minimum 44x44px)
- Responsive typography scaling

---

## 7.4 UI/BACKEND INTERACTION BOUNDARIES

### 7.4.1 API Communication Protocol

#### 7.4.1.1 Protocol Specifications

**Communication Standards**:
- **Protocol**: HTTPS (TLS 1.3 with TLS 1.2 fallback)
- **Data Format**: JSON for request and response bodies
- **API Style**: RESTful with resource-based URLs
- **API Versioning**: URI path versioning (`/api/v1/`)
- **Base URL**: `https://api.example.com/api/v1/`

**HTTP Methods**:
- **GET**: Retrieve resources (safe, idempotent)
- **POST**: Create resources (non-idempotent)
- **PUT**: Update resources (idempotent)
- **DELETE**: Remove resources (idempotent)

#### 7.4.1.2 Authentication Mechanism

**JWT Bearer Token Authentication**:

All API requests from UI to backend include JWT access token in Authorization header:

```
Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImtleS1pZCJ9...
```

**Token Lifecycle**:
- **Access Token**: 15-minute lifetime, used for API authorization
- **Refresh Token**: 7-day lifetime, used to obtain new access tokens
- **Automatic Refresh**: UI automatically refreshes tokens before expiration
- **Silent Failure**: On refresh failure, user redirected to login

**JWT Validation Flow** (Backend):
1. Extract JWT from Authorization header
2. Fetch Auth0 JWKS (public keys) from cache or Auth0 endpoint
3. Verify JWT signature using RS256 algorithm
4. Validate claims:
   - `exp` (expiration): Ensure not expired
   - `iss` (issuer): Verify Auth0 domain
   - `aud` (audience): Verify API identifier
   - `sub` (subject): Extract Auth0 user ID
5. Extract permissions array for authorization
6. Attach user context to request for downstream processing

#### 7.4.1.3 API Endpoint Structure

**Endpoint Pattern**: `/api/{version}/{resource}/{id}/{sub-resource}`

**Core Endpoints**:

| Category | Endpoint | Method | Purpose |
|----------|----------|--------|---------|
| **Authentication** | `/api/v1/auth/refresh` | POST | Refresh access token |
| **Authentication** | `/api/v1/auth/logout` | POST | Revoke refresh token |
| **User Management** | `/api/v1/users/me` | GET | Get current user profile |
| **User Management** | `/api/v1/users/me` | PUT | Update user profile |
| **Documents** | `/api/v1/documents` | GET | List user documents |
| **Documents** | `/api/v1/documents` | POST | Create document metadata |
| **Documents** | `/api/v1/documents/{id}` | GET | Get document details |
| **Documents** | `/api/v1/documents/{id}` | PUT | Update document |
| **Documents** | `/api/v1/documents/{id}` | DELETE | Delete document |
| **Files** | `/api/v1/files/upload-url` | POST | Get presigned S3 upload URL |
| **Files** | `/api/v1/files/{id}` | GET | Get presigned S3 download URL |
| **Files** | `/api/v1/files/complete` | POST | Confirm upload completion |
| **AI** | `/api/v1/ai/completions` | POST | Generate AI text completion |
| **AI** | `/api/v1/ai/conversations` | POST | Create/continue conversation |
| **AI** | `/api/v1/ai/conversations/{id}` | GET | Get conversation history |
| **AI** | `/api/v1/ai/search` | POST | Semantic search (RAG) |
| **System** | `/health` | GET | Health check (no auth required) |
| **System** | `/api/version` | GET | API version info |

#### 7.4.1.4 Request/Response Standards

**API Request Headers**:
```
Authorization: Bearer {jwt_token}
Content-Type: application/json
Accept: application/json
X-Request-ID: {client_generated_uuid}
```

**Successful Response Format**:
```json
{
  "data": {
    "document_id": "507f1f77bcf86cd799439014",
    "filename": "example.pdf",
    "size": 2048576,
    "created_at": "2024-01-15T10:30:00Z"
  },
  "metadata": {
    "page": 1,
    "limit": 20,
    "total": 150
  }
}
```

**Error Response Format**:
```json
{
  "error": {
    "code": "VALID_INVALID_INPUT",
    "message": "Invalid document format",
    "details": {
      "filename": "Filename must not be empty",
      "mime_type": "Unsupported file type"
    },
    "request_id": "550e8400-e29b-41d4-a716-446655440000",
    "timestamp": "2024-01-15T10:30:00Z",
    "documentation_url": "https://docs.api.example.com/errors/VALID_INVALID_INPUT"
  }
}
```

**HTTP Status Codes**:
- **200 OK**: Successful GET, PUT, DELETE
- **201 Created**: Successful POST creating resource
- **204 No Content**: Successful DELETE with no response body
- **400 Bad Request**: Validation error, malformed request
- **401 Unauthorized**: Missing or invalid JWT token
- **403 Forbidden**: Valid authentication but insufficient permissions
- **404 Not Found**: Resource does not exist
- **429 Too Many Requests**: Rate limit exceeded
- **500 Internal Server Error**: Server-side error
- **503 Service Unavailable**: Service temporarily unavailable

### 7.4.2 Rate Limiting and Throttling

#### 7.4.2.1 Rate Limit Policy

**Per-User Rate Limits**:

| Endpoint Category | Rate Limit | Window | Enforcement |
|------------------|------------|--------|-------------|
| **General API Endpoints** | 100 requests | 60 seconds | Redis counter |
| **Write Operations** (POST, PUT, DELETE) | 20 requests | 60 seconds | Redis counter |
| **AI/LLM Endpoints** | 10 requests | 60 seconds | Redis counter |
| **File Uploads** | 20 uploads | 60 seconds | Redis counter |

**Rate Limit Response Headers**:
```
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 87
X-RateLimit-Reset: 1705320600
```

**Rate Limit Exceeded Response**:
```json
HTTP/1.1 429 Too Many Requests
Retry-After: 45

{
  "error": {
    "code": "RATE_LIMIT_EXCEEDED",
    "message": "Rate limit exceeded for this endpoint",
    "details": {
      "limit": 100,
      "window": "1 minute",
      "retry_after": 45
    }
  }
}
```

**Client-Side Handling**:
- UI displays rate limit warning when approaching limit
- Implement exponential backoff for retries
- Queue non-urgent requests when rate limit hit
- Show user-friendly message: "Please slow down. Try again in {retry_after} seconds."

#### 7.4.2.2 Caching Strategy

**Client-Side Caching (TanStack Query)**:

**Cache Configuration**:
- **API Responses**: Cache with staleTime and cacheTime
  - User profile: 15 minutes staleTime, 30 minutes cacheTime
  - Document list: 5 minutes staleTime, 10 minutes cacheTime
  - Document details: 5 minutes staleTime, 10 minutes cacheTime
  - AI responses: 1 hour staleTime (expensive to regenerate)
- **Cache Invalidation**: On write operations (POST, PUT, DELETE), invalidate related queries
- **Background Refetch**: Automatically refetch stale data in background
- **Request Deduplication**: Prevent multiple identical requests

**Server-Side Caching (Redis)**:
- API responses cached on backend with varying TTLs (5-60 minutes)
- UI benefits from fast response times even on cache miss
- Cache keys include user_id to prevent data leakage

### 7.4.3 Error Handling and Retry Logic

#### 7.4.3.1 Error Classification

**Network Errors**:
- **Connection Timeout**: Retry with exponential backoff (max 3 attempts)
- **Connection Refused**: Display offline banner, retry when online
- **DNS Resolution Failure**: Check internet connectivity

**HTTP Errors**:
- **4xx Client Errors**: Display validation errors to user, no retry
- **401 Unauthorized**: Attempt token refresh, redirect to login if fails
- **429 Rate Limit**: Wait for retry_after duration, then retry
- **5xx Server Errors**: Retry with exponential backoff (max 2 attempts)

#### 7.4.3.2 Retry Strategy

**Exponential Backoff Algorithm**:
- **Attempt 1**: Immediate retry
- **Attempt 2**: Wait 1 second + jitter (0-500ms)
- **Attempt 3**: Wait 2 seconds + jitter (0-1000ms)
- **Max Attempts**: 3 for transient errors, 0 for client errors

**Idempotency Considerations**:
- Only retry idempotent operations (GET, PUT, DELETE)
- POST requests not retried automatically (require idempotency keys)

#### 7.4.3.3 User Feedback

**Error Notifications**:
- **Toast Notifications**: Brief error messages with action buttons
- **Modal Dialogs**: Critical errors requiring user acknowledgment
- **Inline Errors**: Form validation errors next to fields
- **Banner Notifications**: Persistent connectivity issues

**Error Recovery Actions**:
- **Retry Button**: Allow manual retry for failed operations
- **Contact Support**: Include request ID for support investigation
- **Refresh Page**: For unexpected errors, offer page refresh

---

## 7.5 UI SCHEMAS AND DATA MODELS

### 7.5.1 JWT Token Structure

#### 7.5.1.1 Access Token (JWT)

**Token Format**: JSON Web Token (JWT) signed with RS256 algorithm

**Header**:
```json
{
  "alg": "RS256",
  "typ": "JWT",
  "kid": "key-identifier-from-auth0"
}
```

**Payload**:
```json
{
  "iss": "https://your-tenant.auth0.com/",
  "sub": "auth0|123456789",
  "aud": "your-api-identifier",
  "iat": 1672531200,
  "exp": 1672532100,
  "azp": "your-client-id",
  "scope": "openid profile email",
  "permissions": [
    "read:documents",
    "write:documents",
    "delete:documents",
    "ai:completions"
  ]
}
```

**Claims Explanation**:
- **iss** (Issuer): Auth0 tenant domain
- **sub** (Subject): Unique user identifier from Auth0
- **aud** (Audience): API identifier (validates JWT intended for this API)
- **iat** (Issued At): Timestamp when token issued
- **exp** (Expiration): Timestamp when token expires (15 minutes from iat)
- **azp** (Authorized Party): Client ID that requested token
- **scope**: OAuth 2.0 scopes granted
- **permissions**: Custom claim containing user permissions array

**UI Usage**:
- UI includes JWT in every API request Authorization header
- UI extracts user info from ID token for display (name, email, picture)
- UI checks token expiration and refreshes automatically

### 7.5.2 API Response Schemas

#### 7.5.2.1 Success Response Schema

**Standard Success Response**:
```json
{
  "data": {
    // Response payload specific to endpoint
  },
  "metadata": {
    "page": 1,
    "limit": 20,
    "total": 150,
    "has_more": true
  }
}
```

**Pagination Metadata**:
- **page**: Current page number (1-indexed)
- **limit**: Number of items per page
- **total**: Total number of items available
- **has_more**: Boolean indicating if more pages exist

#### 7.5.2.2 Error Response Schema

**Standard Error Response**:
```json
{
  "error": {
    "code": "ERROR_CODE",
    "message": "Human-readable error message",
    "details": {
      "field_name": "Field-specific error message"
    },
    "request_id": "550e8400-e29b-41d4-a716-446655440000",
    "timestamp": "2024-01-15T10:30:00Z",
    "documentation_url": "https://docs.api.example.com/errors/ERROR_CODE"
  }
}
```

**Error Codes**:
- **AUTH_*** (e.g., AUTH_INVALID_TOKEN, AUTH_TOKEN_EXPIRED): Authentication errors
- **AUTHZ_*** (e.g., AUTHZ_FORBIDDEN, AUTHZ_INSUFFICIENT_PERMISSIONS): Authorization errors
- **VALID_*** (e.g., VALID_INVALID_INPUT, VALID_MISSING_FIELD): Validation errors
- **RES_*** (e.g., RES_NOT_FOUND, RES_CONFLICT): Resource errors
- **RATE_*** (e.g., RATE_LIMIT_EXCEEDED): Rate limiting errors
- **SERVER_*** (e.g., SERVER_INTERNAL_ERROR, SERVER_UNAVAILABLE): Server errors

### 7.5.3 MongoDB Data Models (Backend)

#### 7.5.3.1 Users Collection

**Collection**: `users`

**Schema**:
```json
{
  "_id": "ObjectId('507f1f77bcf86cd799439011')",
  "auth0_id": "auth0|123456789",
  "email": "user@example.com",
  "name": "John Doe",
  "profile_picture_url": "https://s3.amazonaws.com/...",
  "preferences": {
    "theme": "dark",
    "language": "en",
    "notifications_enabled": true
  },
  "subscription_tier": "free",
  "created_at": "2024-01-15T10:30:00Z",
  "updated_at": "2024-01-20T14:22:00Z"
}
```

**Indexes**:
- `auth0_id`: Unique index for Auth0 user lookup
- `email`: Index for email-based queries

#### 7.5.3.2 Documents Collection

**Collection**: `documents`

**Schema**:
```json
{
  "_id": "ObjectId('507f1f77bcf86cd799439014')",
  "user_id": "auth0|123456789",
  "filename": "presentation.pdf",
  "s3_key": "uploads/2024/01/uuid-presentation.pdf",
  "size": 2048576,
  "mime_type": "application/pdf",
  "metadata": {
    "title": "Q4 Sales Presentation",
    "description": "Quarterly sales review",
    "tags": ["sales", "Q4", "2024"]
  },
  "processing_status": "complete",
  "shared_with": ["auth0|987654321"],
  "created_at": "2024-01-15T10:30:00Z",
  "updated_at": "2024-01-15T10:35:00Z"
}
```

**Indexes**:
- `user_id`: Index for user document queries
- `created_at`: Index for chronological sorting
- `metadata.tags`: Multikey index for tag-based filtering

#### 7.5.3.3 Conversations Collection

**Collection**: `conversations`

**Schema**:
```json
{
  "_id": "ObjectId('507f1f77bcf86cd799439015')",
  "user_id": "auth0|123456789",
  "title": "Product Ideas Brainstorm",
  "model": "gpt-4-turbo",
  "created_at": "2024-01-15T10:30:00Z",
  "updated_at": "2024-01-15T11:00:00Z"
}
```

#### 7.5.3.4 Messages Collection

**Collection**: `messages`

**Schema**:
```json
{
  "_id": "ObjectId('507f1f77bcf86cd799439016')",
  "conversation_id": "ObjectId('507f1f77bcf86cd799439015')",
  "role": "user",
  "content": "What are some innovative product ideas for small businesses?",
  "tokens": 15,
  "created_at": "2024-01-15T10:30:00Z"
}
```

**Roles**: `user`, `assistant`, `system`

#### 7.5.3.5 AI Interactions Collection

**Collection**: `ai_interactions`

**Schema**:
```json
{
  "_id": "ObjectId('507f1f77bcf86cd799439017')",
  "user_id": "auth0|123456789",
  "type": "completion",
  "model": "gpt-4-turbo",
  "prompt": "Summarize the following document...",
  "response": "The document discusses...",
  "tokens_used": 850,
  "cost_usd": 0.025,
  "created_at": "2024-01-15T10:30:00Z"
}
```

**Purpose**: Cost tracking, usage analytics, audit trail

---

## 7.6 SCREENS AND VIEWS (PLANNED)

### 7.6.1 Authentication Screens

#### 7.6.1.1 Landing Page / Welcome Screen

**Platforms**: Web, Desktop

**Purpose**: Introduce application and prompt authentication

**Key Elements**:
- Application logo and branding
- Value proposition headline
- Feature highlights with icons
- "Login" and "Sign Up" call-to-action buttons
- Screenshot carousel or demo video

#### 7.6.1.2 Auth0 Universal Login Page

**Platforms**: All (Hosted by Auth0)

**Purpose**: Centralized authentication interface

**Key Elements**:
- Email/password input fields
- Social login buttons (Google, Facebook, Apple, GitHub)
- "Forgot Password" link
- "Sign Up" / "Login" toggle
- MFA code input (when applicable)
- Remember me checkbox (web only)

**Customization**:
- Brand logo and colors
- Custom background image
- Localization for multiple languages

#### 7.6.1.3 Authentication Callback Screen

**Platforms**: All

**Purpose**: Handle OAuth 2.0 callback and token exchange

**Key Elements**:
- Loading spinner with "Logging you in..." message
- Brief delay while exchanging authorization code for tokens
- Redirect to dashboard on success
- Error message on failure with retry option

### 7.6.2 Main Application Screens

#### 7.6.2.1 Dashboard / Home Screen

**Platforms**: All

**Purpose**: Primary landing page after authentication

**Key Elements**:
- Welcome message with user name
- Quick action buttons (Upload Document, New Conversation, Search)
- Recent documents grid (last 6-10 documents)
- Recent AI conversations list
- Usage statistics (documents uploaded, AI queries this month)
- Activity feed (recent actions)

**Navigation**:
- Top navigation bar with main sections
- User avatar dropdown menu (Profile, Settings, Logout)

#### 7.6.2.2 Document List / Browse Screen

**Platforms**: All

**Purpose**: Browse and manage user documents

**Key Elements**:
- **Header**:
  - Page title: "Documents"
  - "Upload Document" button
  - View toggle (grid view / list view)
  - Sort dropdown (date, name, size)
- **Filters Sidebar** (collapsible on mobile):
  - Date range filter
  - File type filter (PDF, Image, Text, etc.)
  - Tag filter (multi-select)
- **Document Grid/List**:
  - Thumbnail or icon
  - Filename
  - Upload date
  - File size
  - Action menu (view, download, share, delete)
- **Pagination** or infinite scroll
- **Empty State**: "No documents yet. Upload your first document!"

#### 7.6.2.3 Document Detail / Viewer Screen

**Platforms**: All

**Purpose**: View and interact with specific document

**Key Elements**:
- **Document Viewer**:
  - PDF: Embedded PDF viewer with zoom controls
  - Images: Full-size image with zoom and pan
  - Text: Syntax-highlighted text viewer
- **Metadata Panel**:
  - Filename, size, type
  - Upload date, last modified
  - Tags (editable)
  - Shared with users (if applicable)
- **Action Buttons**:
  - Download original file
  - Share with other users (opens share dialog)
  - Edit metadata
  - Delete (with confirmation)
- **AI Features** (Future):
  - "Ask AI about this document"
  - Generate summary
  - Extract key points

#### 7.6.2.4 File Upload Screen / Modal

**Platforms**: All

**Purpose**: Upload single or multiple files

**Key Elements**:
- **Drag-and-Drop Zone**: "Drag files here or click to browse"
- **File Picker Button**: Opens native file selector
- **File List** (after selection):
  - Filename
  - Size
  - Upload progress bar
  - Remove button (before upload)
- **Upload Button**: Start upload for all selected files
- **Success Message**: "Files uploaded successfully" with link to documents
- **Error Handling**: Display errors for failed uploads with retry option

#### 7.6.2.5 AI Completion Screen

**Platforms**: All

**Purpose**: Generate AI text completions

**Key Elements**:
- **Prompt Input**:
  - Large text area for user prompt
  - Character counter
  - Placeholder text: "Enter your prompt here..."
- **Configuration Panel**:
  - Model dropdown (GPT-3.5 Turbo, GPT-4, GPT-4 Turbo)
  - Temperature slider (0.0 - 1.0)
  - Max tokens slider (50 - 2000)
- **Generate Button**: Submit prompt to AI
- **Response Display**:
  - Generated text in formatted text area
  - Copy to clipboard button
  - Regenerate button
  - Token usage indicator
- **History Sidebar** (optional): Recent completions

#### 7.6.2.6 Conversational AI Screen

**Platforms**: All

**Purpose**: Multi-turn AI conversations with context

**Key Elements**:
- **Conversation List** (sidebar or separate screen):
  - List of past conversations
  - Create new conversation button
  - Conversation titles with preview
  - Delete conversation option
- **Chat Interface**:
  - Message thread (scrollable)
  - User messages (right-aligned, blue background)
  - AI messages (left-aligned, gray background)
  - Timestamps
- **Input Area**:
  - Text input field
  - Send button
  - Microphone icon for voice input (future)
- **Loading State**: Typing indicator while AI generates response
- **Context Indicator**: Shows conversation token usage and model

#### 7.6.2.7 Semantic Search Screen

**Platforms**: All

**Purpose**: AI-powered semantic search across documents

**Key Elements**:
- **Search Input**:
  - Large search bar with placeholder: "Ask a question about your documents..."
  - Search button or Enter to submit
- **Search Results**:
  - **AI-Generated Answer**: Natural language answer at top
  - **Source Citations**: Referenced documents with relevance scores
  - **Document Snippets**: Relevant passages from source documents
- **Filters**:
  - Date range
  - Document types
  - Specific tags or collections
- **Empty State**: "No results found. Try rephrasing your question."

#### 7.6.2.8 User Profile Screen

**Platforms**: All

**Purpose**: View and edit user profile information

**Key Elements**:
- **Profile Picture**:
  - Avatar display
  - "Upload Photo" button
  - Crop and resize tool
- **Personal Information**:
  - Name (editable text field)
  - Email (display only, link to Auth0 to change)
  - Account creation date
- **Preferences**:
  - Theme toggle (Light / Dark / System)
  - Language selection dropdown
  - Notification preferences checkboxes
- **Account Management**:
  - Change password (redirects to Auth0)
  - Enable/disable MFA
  - View active sessions
  - Delete account (with confirmation)
- **Save Button**: Submit profile changes

#### 7.6.2.9 Settings Screen

**Platforms**: All

**Purpose**: Application configuration and preferences

**Key Elements**:
- **Tabs**:
  - General
  - Security
  - Notifications
  - Subscription (if applicable)
- **General Settings**:
  - Language
  - Theme
  - Default view preferences
- **Security Settings**:
  - Two-factor authentication toggle
  - Active sessions list with "Sign out all" option
  - Login activity log
- **Notification Settings**:
  - Email notifications toggle
  - Push notifications toggle (mobile)
  - Notification preferences by type

### 7.6.3 Mobile-Specific Screens

#### 7.6.3.1 Mobile Onboarding Flow

**Platforms**: iOS, Android

**Purpose**: Guide new users through app features

**Screens**:
1. **Welcome**: App overview
2. **Features**: Key capabilities with illustrations
3. **Permissions**: Request notifications, camera, file access
4. **Get Started**: Button to proceed to authentication

#### 7.6.3.2 Mobile Camera Integration Screen

**Platforms**: iOS, Android

**Purpose**: Capture documents directly from camera

**Key Elements**:
- Camera viewfinder with overlay guides
- Capture button
- Flash toggle
- Switch camera (front/back)
- Gallery button (to select from photos)
- Auto-detection of document edges (future)
- Preview captured image with retake option

### 7.6.4 Desktop-Specific Screens

#### 7.6.4.1 Desktop Preferences Window

**Platforms**: Electron, macOS Native

**Purpose**: Application settings in native window

**Key Elements**:
- Sidebar with settings categories
- Appearance settings (theme, font size)
- Keyboard shortcuts customization
- Default file locations
- Auto-update preferences
- Advanced settings (cache location, logging level)

#### 7.6.4.2 Desktop System Tray Menu

**Platforms**: Electron, macOS Native

**Purpose**: Quick access from system tray/menu bar

**Menu Items**:
- Show/Hide main window
- Quick upload
- Recent documents
- Notifications badge
- Preferences
- Quit application

---

## 7.7 USER INTERACTIONS AND BEHAVIORS

### 7.7.1 Navigation and Routing

#### 7.7.1.1 Web Application Routing

**React Router 6+ Implementation**:

**Route Structure**:
- `/` - Landing page (public)
- `/login` - Login page (redirects to Auth0)
- `/callback` - Auth0 callback handler
- `/dashboard` - Main dashboard (protected)
- `/documents` - Document list (protected)
- `/documents/:id` - Document detail (protected)
- `/ai/completions` - AI completions (protected)
- `/ai/conversations` - Conversation list (protected)
- `/ai/conversations/:id` - Conversation detail (protected)
- `/ai/search` - Semantic search (protected)
- `/profile` - User profile (protected)
- `/settings` - Settings (protected)

**Protected Routes**:
- Require authentication (valid JWT)
- Redirect unauthenticated users to `/login`
- Store intended destination for post-login redirect

**Route Transitions**:
- Page-level transitions with fade effect
- Loading indicators during navigation
- Preserve scroll position or reset to top

#### 7.7.1.2 Mobile Navigation Patterns

**Tab Navigation** (Bottom Tab Bar):
- **Home**: Dashboard with overview
- **Documents**: Document browser
- **AI**: AI features hub
- **Profile**: User profile and settings

**Stack Navigation**:
- Push detail views onto navigation stack
- Back button or swipe gesture to pop stack
- Navigation bar with title and back button

**Drawer Navigation** (Side Menu):
- Settings
- Help and support
- About
- Logout

#### 7.7.1.3 Desktop Navigation

**Menu Bar** (macOS Native, Electron):
- **File**: New, Open, Upload, Recent Files, Close
- **Edit**: Cut, Copy, Paste, Select All
- **View**: Toggle Sidebar, Toggle Full Screen, Zoom In/Out
- **Window**: Minimize, Zoom, Bring All to Front
- **Help**: Documentation, Report Issue, About

**Keyboard Shortcuts**:
- `Ctrl/Cmd + N`: New document/conversation
- `Ctrl/Cmd + O`: Open file
- `Ctrl/Cmd + S`: Save
- `Ctrl/Cmd + W`: Close window/tab
- `Ctrl/Cmd + F`: Search/Find
- `Ctrl/Cmd + ,`: Preferences

### 7.7.2 State Management Patterns

#### 7.7.2.1 Server State Management (TanStack Query)

**Query Configuration**:
```typescript
// Pseudocode: TanStack Query usage
const { data, isLoading, error } = useQuery({
  queryKey: ['documents', userId],
  queryFn: () => fetchDocuments(userId),
  staleTime: 5 * 60 * 1000, // 5 minutes
  cacheTime: 10 * 60 * 1000, // 10 minutes
  refetchOnWindowFocus: true,
  retry: 2
});
```

**Mutation Pattern**:
```typescript
// Pseudocode: Mutation with cache invalidation
const mutation = useMutation({
  mutationFn: (newDocument) => uploadDocument(newDocument),
  onSuccess: () => {
    // Invalidate and refetch document list
    queryClient.invalidateQueries(['documents']);
    // Show success notification
    showToast('Document uploaded successfully');
  },
  onError: (error) => {
    showToast('Upload failed: ' + error.message, 'error');
  }
});
```

#### 7.7.2.2 Local State Management

**Component-Level State** (useState, useReducer):
- Form input values
- UI toggle states (modals, dropdowns)
- Local loading indicators
- Temporary data before submission

**Application-Level State** (Context, Zustand):
- Current theme (light/dark)
- Language preference
- UI layout preferences (sidebar collapsed)
- Toast notification queue

#### 7.7.2.3 Persistent State

**localStorage / AsyncStorage**:
- User preferences (theme, language)
- Recently viewed documents
- Draft messages or forms
- UI state (sidebar expanded/collapsed)

**Secure Storage** (Keychain, Keystore, SafeStorage):
- JWT tokens
- API keys
- Sensitive user data

### 7.7.3 Performance Optimization Strategies

#### 7.7.3.1 Code Splitting and Lazy Loading

**Route-Based Code Splitting**:
```typescript
// Pseudocode: React lazy loading
const DocumentList = React.lazy(() => import('./pages/DocumentList'));
const AICompletions = React.lazy(() => import('./pages/AICompletions'));

// Wrap in Suspense with fallback
<Suspense fallback={<LoadingSpinner />}>
  <Routes>
    <Route path="/documents" element={<DocumentList />} />
    <Route path="/ai/completions" element={<AICompletions />} />
  </Routes>
</Suspense>
```

**Component-Level Lazy Loading**:
- Heavy components loaded on demand (PDF viewer, image editor)
- Conditional imports based on feature flags
- Dynamic imports for large libraries

#### 7.7.3.2 Rendering Optimization

**React Performance Techniques**:
- `React.memo` for expensive components preventing unnecessary re-renders
- `useMemo` for expensive calculations
- `useCallback` for function stability in dependencies
- Virtualization for long lists (react-window, react-virtuoso)

**Image Optimization**:
- Lazy loading images below fold
- Responsive images with srcset
- Modern formats (WebP, AVIF) with fallbacks
- Thumbnail generation for document previews

#### 7.7.3.3 Network Optimization

**Request Strategies**:
- Batch multiple requests when possible
- Debounce search queries (300ms delay)
- Prefetch data for likely next navigation
- Service worker for offline caching (future)

**Asset Optimization**:
- Minified and compressed JavaScript/CSS
- Tree-shaking to eliminate dead code
- CDN delivery for static assets
- Browser caching with cache-busting hashes

### 7.7.4 Accessibility Features

#### 7.7.4.1 WCAG Compliance

**Keyboard Navigation**:
- All interactive elements keyboard accessible
- Logical tab order
- Focus indicators visible
- Skip to content link

**Screen Reader Support**:
- Semantic HTML elements (nav, main, article)
- ARIA labels for icons and buttons
- ARIA live regions for dynamic updates
- Alt text for images

**Visual Accessibility**:
- Color contrast ratio minimum 4.5:1 (WCAG AA)
- Text resizable without breaking layout
- Focus indicators with high contrast
- Dark mode option reducing eye strain

#### 7.7.4.2 Internationalization (i18n)

**Language Support** (Planned):
- English (default)
- Spanish
- French
- German
- Japanese
- Chinese (Simplified)

**Implementation**:
- react-i18next or similar library
- Locale-aware date and number formatting
- Right-to-left (RTL) support for Arabic, Hebrew
- Translation keys for all user-facing text

### 7.7.5 User Feedback Mechanisms

#### 7.7.5.1 Toast Notifications

**Use Cases**:
- Success messages (document uploaded, settings saved)
- Error messages (upload failed, network error)
- Warning messages (approaching rate limit)
- Informational messages (new features available)

**Behavior**:
- Auto-dismiss after 3-5 seconds
- Dismiss button for immediate close
- Stack multiple toasts vertically
- Pause auto-dismiss on hover

#### 7.7.5.2 Loading States

**Skeleton Loaders**:
- Match content structure
- Animated shimmer effect
- Replace with actual content seamlessly

**Progress Indicators**:
- Circular spinner for indefinite waits
- Linear progress bar for file uploads
- Percentage indicator for quantifiable progress

**Optimistic UI Updates**:
- Show expected result immediately
- Rollback on error with error notification
- Improve perceived performance

#### 7.7.5.3 Empty States

**Context-Specific Empty States**:
- Documents: "No documents yet. Upload your first document!"
- Conversations: "Start a new conversation with AI"
- Search: "No results found. Try different keywords."

**Call-to-Action**:
- Primary action button relevant to context
- Illustration or icon reinforcing message
- Helpful tips or suggestions

---

## 7.8 VISUAL DESIGN CONSIDERATIONS

### 7.8.1 Design System Foundations

#### 7.8.1.1 Color Palette

**Primary Brand Colors** (Planned):
- **Primary**: Blue (#3B82F6) - Action buttons, links, focus states
- **Secondary**: Purple (#8B5CF6) - Accents, highlights
- **Success**: Green (#10B981) - Success messages, positive actions
- **Warning**: Yellow (#F59E0B) - Warnings, caution states
- **Error**: Red (#EF4444) - Error messages, destructive actions

**Neutral Colors**:
- **Gray Scale**: 9 shades from white to black
- **Text Primary**: Gray-900 (light mode), Gray-50 (dark mode)
- **Text Secondary**: Gray-600 (light mode), Gray-400 (dark mode)
- **Background**: White (light mode), Gray-900 (dark mode)
- **Surface**: Gray-50 (light mode), Gray-800 (dark mode)

#### 7.8.1.2 Typography System

**Font Family**:
- **Sans-Serif**: Inter, system-ui, -apple-system, sans-serif (UI text)
- **Monospace**: Fira Code, Menlo, Monaco, monospace (code snippets)

**Type Scale** (Tailwind Default):
- **xs**: 12px / 16px line-height
- **sm**: 14px / 20px
- **base**: 16px / 24px (body text)
- **lg**: 18px / 28px
- **xl**: 20px / 28px
- **2xl**: 24px / 32px
- **3xl**: 30px / 36px (headings)
- **4xl**: 36px / 40px (page titles)

**Font Weights**:
- Regular (400): Body text
- Medium (500): Emphasized text
- Semibold (600): Subheadings
- Bold (700): Headings, buttons

#### 7.8.1.3 Spacing and Layout

**Spacing Scale** (4px base unit):
- 0: 0px
- 1: 4px
- 2: 8px
- 3: 12px
- 4: 16px (standard padding)
- 6: 24px
- 8: 32px (section spacing)
- 12: 48px
- 16: 64px (large gaps)

**Layout Grid**:
- 12-column grid system
- Gutter: 16px (mobile), 24px (tablet), 32px (desktop)
- Container max-width: 1280px (2xl breakpoint)

#### 7.8.1.4 Border Radius and Shadows

**Border Radius**:
- **sm**: 4px (small buttons, tags)
- **DEFAULT**: 8px (cards, inputs)
- **lg**: 12px (modals)
- **full**: 9999px (circular avatars, pills)

**Shadow Scale**:
- **sm**: Subtle shadow for inputs
- **DEFAULT**: Standard shadow for cards
- **md**: Elevated cards, dropdowns
- **lg**: Modals, overlays
- **xl**: Floating action buttons

### 7.8.2 Component Design Patterns

#### 7.8.2.1 Buttons

**Button Variants**:
- **Primary**: Solid background, white text, for primary actions
- **Secondary**: Outlined, colored border and text
- **Ghost**: No border, colored text, hover background
- **Danger**: Red background for destructive actions

**Button Sizes**:
- **sm**: 32px height, 12px padding
- **md**: 40px height, 16px padding (default)
- **lg**: 48px height, 24px padding

**Button States**:
- Default
- Hover (darker background)
- Active (pressed state)
- Disabled (gray, 50% opacity, no pointer)
- Loading (spinner replacing text)

#### 7.8.2.2 Form Inputs

**Input Variants**:
- Text input
- Text area (multi-line)
- Select dropdown
- Checkbox
- Radio button
- Toggle switch
- File upload

**Input States**:
- Default (border gray-300)
- Focus (border primary, focus ring)
- Error (border error, red text helper)
- Disabled (gray background, no interaction)

**Form Validation**:
- Inline error messages below fields
- Red border on invalid fields
- Green checkmark on valid fields
- Required field indicator (asterisk)

#### 7.8.2.3 Cards and Containers

**Card Structure**:
- Border or shadow for separation
- Padding: 16px (mobile), 24px (desktop)
- Header with title and actions
- Content area
- Optional footer with actions

**Card Variants**:
- Default: White background, border
- Elevated: White background, shadow
- Interactive: Hover state, clickable
- Outlined: Transparent background, border

#### 7.8.2.4 Modal Dialogs

**Modal Structure**:
- Backdrop overlay (semi-transparent black)
- Modal container (centered, max-width 600px)
- Header with title and close button
- Content area (scrollable if needed)
- Footer with action buttons (Cancel, Confirm)

**Modal Types**:
- Informational (single OK button)
- Confirmation (Cancel + Confirm)
- Form modal (input fields + Submit)
- Full-screen modal (mobile)

### 7.8.3 Responsive Design Strategy

#### 7.8.3.1 Breakpoint Strategy

**Mobile-First Approach**:
- Default styles target smallest screens (320px+)
- Progressive enhancement with media queries
- Tailwind responsive prefixes: `md:`, `lg:`, `xl:`

**Layout Adaptations**:
- **Mobile** (< 768px):
  - Single column layout
  - Hamburger menu
  - Full-width inputs and buttons
  - Bottom tab navigation
- **Tablet** (768px - 1023px):
  - Two-column layout where appropriate
  - Side navigation (collapsible)
  - Larger touch targets
- **Desktop** (1024px+):
  - Multi-column layouts
  - Persistent side navigation
  - Hover interactions
  - Keyboard shortcuts

#### 7.8.3.2 Touch and Gesture Support

**Touch Targets**:
- Minimum size: 44x44px (Apple HIG)
- Minimum spacing: 8px between targets
- Larger buttons on mobile (48px height)

**Gestures** (Mobile):
- Swipe left: Delete item
- Swipe right: Archive/Mark as read
- Pull-to-refresh: Reload data
- Pinch-to-zoom: Images and documents
- Long-press: Context menu

### 7.8.4 Dark Mode Implementation

#### 7.8.4.1 Dark Mode Color Palette

**Background Colors**:
- Primary background: Gray-900
- Surface: Gray-800
- Elevated surface: Gray-700

**Text Colors**:
- Primary text: Gray-50
- Secondary text: Gray-400
- Disabled text: Gray-600

**Component Adjustments**:
- Reduce shadow intensity
- Increase border visibility
- Adjust color saturation for readability

#### 7.8.4.2 Dark Mode Toggle

**Implementation**:
- Theme toggle in settings
- System preference detection (prefers-color-scheme)
- Persistent user preference
- Smooth transition between modes

**Tailwind Dark Mode**:
```css
/* Automatic class-based dark mode */
.dark .card {
  @apply bg-gray-800 border-gray-700;
}
```

### 7.8.5 Platform-Specific Design Adaptations

#### 7.8.5.1 iOS Design Language

**UI Elements**:
- iOS native navigation bar
- iOS-style tab bar
- Cupertino design patterns
- iOS typography (San Francisco font)
- iOS action sheets and alerts

**Interactions**:
- Swipe gestures (back, delete)
- Pull-to-refresh
- Haptic feedback
- iOS keyboard behavior

#### 7.8.5.2 Android Design Language (Material Design)

**UI Elements**:
- Material Design components
- Floating Action Button (FAB)
- Bottom sheets
- Snackbar notifications
- Material ripple effects

**Interactions**:
- Material Design animations
- Android back button handling
- Material Design navigation drawer

#### 7.8.5.3 Desktop Design Patterns

**UI Elements**:
- Native window controls
- Menu bar (macOS) or title bar (Windows)
- Keyboard shortcut indicators
- Tooltips on hover
- Right-click context menus

**Interactions**:
- Hover states for all interactive elements
- Keyboard navigation
- Drag-and-drop file uploads
- Window resize and minimize

---

## 7.9 SECURITY CONSIDERATIONS IN UI

### 7.9.1 Token Storage Security

#### 7.9.1.1 Platform-Specific Secure Storage

**Web Application**:
- JWT tokens stored in memory only (Auth0 SDK manages)
- Alternative: sessionStorage (cleared on tab close)
- **Avoid localStorage** for sensitive tokens (XSS vulnerability)
- HttpOnly cookies for refresh tokens (server-side management)

**Mobile Applications**:
- **iOS**: Keychain Services with kSecAttrAccessibleWhenUnlocked
- **Android**: Android Keystore with StrongBox (hardware-backed)
- Biometric authentication gate for token access
- Automatic token deletion on biometric change

**Desktop Applications**:
- **Electron**: SafeStorage API (uses OS keychain)
- **macOS Native**: Keychain Access API
- Token encryption at rest

#### 7.9.1.2 Token Refresh Security

**Silent Refresh Pattern**:
- Background token refresh before expiration
- Use hidden iframe (web) or background API call
- Refresh token rotation (new refresh token with each refresh)
- Refresh token revocation on logout or suspicious activity

### 7.9.2 XSS and Injection Prevention

#### 7.9.2.1 Input Sanitization

**Client-Side Validation**:
- Validate all user inputs before submission
- Whitelist allowed characters for specific fields
- Maximum length enforcement
- Format validation (email, URL, phone)

**Output Encoding**:
- React automatically escapes JSX content
- Use DOMPurify for user-generated HTML (if allowed)
- Avoid `dangerouslySetInnerHTML` unless necessary

#### 7.9.2.2 Content Security Policy (CSP)

**Web Application CSP Headers**:
```
Content-Security-Policy:
  default-src 'self';
  script-src 'self' https://cdn.auth0.com;
  style-src 'self' 'unsafe-inline';
  img-src 'self' https://s3.amazonaws.com data:;
  connect-src 'self' https://api.example.com https://*.auth0.com;
  font-src 'self';
  object-src 'none';
  frame-ancestors 'none';
```

### 7.9.3 CORS and API Security

#### 7.9.3.1 CORS Configuration

**Backend CORS Settings**:
- Allow only specific origins (web app domain, mobile app identifiers)
- Restrict allowed methods (GET, POST, PUT, DELETE)
- Credentials allowed only for authenticated requests
- Preflight caching to reduce OPTIONS requests

### 7.9.4 Sensitive Data Handling

#### 7.9.4.1 Data Minimization

**UI Principles**:
- Display only necessary user data
- Mask sensitive information (show last 4 digits of payment info)
- Avoid logging sensitive data in browser console
- Clear sensitive form fields on blur

#### 7.9.4.2 Secure Communication

**HTTPS Enforcement**:
- All API communication over HTTPS (TLS 1.3)
- HSTS header enforcing HTTPS
- Certificate pinning (mobile apps)
- No mixed content (HTTP resources on HTTPS pages)

---

## 7.10 REFERENCES

### 7.10.1 Technical Specification Sections Examined

The following Technical Specification sections were retrieved and analyzed to document this User Interface Design:

- **1.2 System Overview** - Project context, implementation status, and multi-platform scope
- **3.1 Technology Stack Overview** - High-level technology architecture and integration approach
- **3.2 Programming Languages** - Frontend language specifications (TypeScript, Swift, Kotlin)
- **3.3 Frameworks & Libraries** - Detailed framework specifications:
  - React 18.2+ for web applications
  - React Native 0.72+ for cross-platform mobile
  - Electron 28+ for desktop applications
  - TailwindCSS 3.4+ for styling
- **3.5 Third-Party Services** - External service integrations (Auth0, AWS, OpenAI)
- **4.3 Authentication and Authorization Flows (Planned)** - OAuth 2.0 + PKCE flows, JWT token management, biometric authentication patterns
- **4.4 API Request Processing Flows (Planned)** - API request handling, caching strategies, error handling patterns
- **5.1 High-Level Architecture** - System architecture overview and data flows
- **5.2 Component Details** - Client layer component specifications:
  - Web application architecture (React + TypeScript + Vite)
  - Mobile application architecture (React Native + Native modules)
  - Desktop application architecture (Electron + macOS Native)
  - Technology stacks and deployment strategies
- **6.3 Integration Architecture** - API design specifications:
  - RESTful API endpoint structure
  - Authentication and authorization mechanisms
  - Rate limiting strategies
  - Request/response schemas
  - Error handling patterns
  - External service integration (Auth0, OpenAI, AWS)

### 7.10.2 Repository Files Examined

- **`README.md`** (root) - Only file in repository; contains project title "CheckSameRepoNoPrompt"

**Repository Status**: The repository is currently in **pre-implementation phase** with no source code, UI components, design files, mockups, or implementation present. All UI design specifications documented in this section represent planned architecture based on comprehensive technical specifications.

### 7.10.3 Repository Folders Explored

- **Root folder** (`""`) - Contains only README.md file; no additional folders or source code exists

### 7.10.4 Search Operations Performed

A comprehensive search strategy was executed to locate UI-related artifacts:

- **Folder searches**: UI directories, component folders, design system folders (0 results)
- **File searches**: React components, TypeScript files, CSS files, configuration files, mockups, wireframes, design specifications (0 results)
- **Total searches**: 23 repository searches performed within budget

**Conclusion**: No UI implementation, design files, or mockups exist in the current repository state. All documentation is based on planned architecture specifications.

### 7.10.5 Implementation Roadmap

This User Interface Design section documents the **comprehensive planned architecture** that will guide implementation during the development phase. Future implementation should:

1. Create React web application with documented technology stack
2. Develop mobile applications using React Native with native modules
3. Build desktop applications using Electron framework
4. Implement all documented authentication flows with Auth0 integration
5. Create screens and components as specified in Section 7.6
6. Integrate with backend API following documented patterns in Section 7.4
7. Apply visual design system specified in Section 7.8
8. Implement security measures documented in Section 7.9

This documentation serves as the authoritative reference for all UI implementation work across all six supported platforms.

# 8. Infrastructure

## 8.1 Infrastructure Overview and Implementation Status

### 8.1.1 Current Repository State

**Implementation Status**: The CheckSameRepoNoPrompt repository is in **pre-implementation phase**, containing only a `README.md` file with the project title. No infrastructure code, configuration files, Docker images, Terraform modules, or deployment pipelines exist at this time.

**Documentation Scope**: This Infrastructure section documents the **planned infrastructure architecture** based on comprehensive technical specifications. All deployment environments, cloud services, containerization strategies, orchestration platforms, CI/CD pipelines, and monitoring infrastructure described herein represent the intended infrastructure design that will be implemented during the development and deployment phases.

### 8.1.2 Infrastructure Architecture Philosophy

The CheckSameRepoNoPrompt system adopts a **cloud-native, serverless-first infrastructure architecture** designed for scalability, reliability, and operational simplicity. The infrastructure strategy prioritizes managed AWS services to minimize operational overhead while maintaining enterprise-grade availability and security.

**Core Infrastructure Principles**:

| Principle | Implementation | Benefit |
|-----------|----------------|---------|
| **Cloud-Native Architecture** | AWS ECS Fargate for serverless containers | No server management, automatic scaling, pay-per-use pricing |
| **Infrastructure as Code** | Terraform 1.6+ for all infrastructure | Version-controlled, reproducible, auditable infrastructure |
| **Multi-Availability Zone** | Resources distributed across 3 AZs | High availability, fault tolerance, 99.9%+ uptime |
| **Managed Services Preference** | Auth0, MongoDB Atlas, ElastiCache, S3 | Reduced operational complexity, enterprise-grade reliability |

**Infrastructure Layers**:

```mermaid
graph TB
    subgraph "Client Layer"
        Web[Web Application<br/>React + Vite]
        Mobile[Mobile Applications<br/>React Native + Native]
        Desktop[Desktop Applications<br/>Electron]
    end
    
    subgraph "Content Delivery - AWS CloudFront"
        CDN[CloudFront Distribution<br/>Global Edge Locations<br/>Static Asset Caching]
    end
    
    subgraph "Load Balancing - Public Subnet"
        ALB[Application Load Balancer<br/>Multi-AZ Deployment<br/>TLS Termination<br/>Health Checks]
    end
    
    subgraph "Container Orchestration - ECS Fargate"
        ECS[ECS Cluster: production-cluster]
        
        subgraph "Private Subnet A - us-east-1a"
            Task1[Fargate Task 1<br/>Flask API Container<br/>0.5 vCPU, 1 GB RAM]
        end
        
        subgraph "Private Subnet B - us-east-1b"
            Task2[Fargate Task 2<br/>Flask API Container<br/>0.5 vCPU, 1 GB RAM]
        end
        
        subgraph "Private Subnet C - us-east-1c"
            Task3[Fargate Task 3<br/>Flask API Container<br/>0.5 vCPU, 1 GB RAM]
        end
    end
    
    subgraph "Data Layer"
        subgraph "MongoDB Atlas - Multi-AZ"
            MongoDB[(MongoDB 7.0+<br/>3-Node Replica Set<br/>M10 Tier<br/>Primary + 2 Secondary)]
        end
        
        subgraph "ElastiCache - Multi-AZ"
            Redis[(Redis 7+<br/>cache.t3.micro<br/>Encryption Enabled)]
        end
        
        subgraph "Object Storage"
            S3[Amazon S3<br/>Multiple Buckets<br/>Server-Side Encryption<br/>Versioning Enabled]
        end
    end
    
    subgraph "External Services"
        Auth0[Auth0<br/>Identity Provider<br/>OAuth 2.0 + OIDC]
        OpenAI[OpenAI API<br/>LLM Services<br/>GPT-4, Embeddings]
    end
    
    subgraph "Infrastructure Management"
        Terraform[Terraform State<br/>S3 Backend<br/>DynamoDB Locking]
        ECR[Amazon ECR<br/>Container Registry<br/>Image Scanning]
    end
    
    subgraph "Monitoring & Logging"
        CloudWatch[Amazon CloudWatch<br/>Logs + Metrics + Alarms<br/>Dashboards]
    end
    
    Web -->|HTTPS| CDN
    Mobile -->|HTTPS| CDN
    Desktop -->|HTTPS| CDN
    CDN -->|Cache Miss| S3
    
    Web -->|HTTPS API Calls| ALB
    Mobile -->|HTTPS API Calls| ALB
    Desktop -->|HTTPS API Calls| ALB
    
    ALB -->|HTTP| Task1
    ALB -->|HTTP| Task2
    ALB -->|HTTP| Task3
    
    Task1 -->|MongoDB Protocol| MongoDB
    Task2 -->|MongoDB Protocol| MongoDB
    Task3 -->|MongoDB Protocol| MongoDB
    
    Task1 -->|Redis Protocol| Redis
    Task2 -->|Redis Protocol| Redis
    Task3 -->|Redis Protocol| Redis
    
    Task1 -->|HTTPS| S3
    Task2 -->|HTTPS| S3
    Task3 -->|HTTPS| S3
    
    Task1 -.->|HTTPS| Auth0
    Task2 -.->|HTTPS| Auth0
    Task3 -.->|HTTPS| Auth0
    
    Task1 -.->|HTTPS| OpenAI
    Task2 -.->|HTTPS| OpenAI
    Task3 -.->|HTTPS| OpenAI
    
    ECS -.->|Pull Images| ECR
    ECS -.->|Logs/Metrics| CloudWatch
    Task1 -.->|Application Logs| CloudWatch
    Task2 -.->|Application Logs| CloudWatch
    Task3 -.->|Application Logs| CloudWatch
    
    Terraform -.->|Provisions| ECS
    Terraform -.->|Provisions| ALB
    Terraform -.->|Provisions| S3
    
    style Web fill:#E3F2FD
    style Mobile fill:#E3F2FD
    style Desktop fill:#E3F2FD
    style CDN fill:#FFF3E0
    style ALB fill:#FFF9C4
    style Task1 fill:#C8E6C9
    style Task2 fill:#C8E6C9
    style Task3 fill:#C8E6C9
    style MongoDB fill:#BBDEFB
    style Redis fill:#FFE0B2
    style S3 fill:#F3E5F5
    style Auth0 fill:#FCE4EC
    style OpenAI fill:#FFF3E0
    style CloudWatch fill:#E1F5FE
```

---

## 8.2 Deployment Environment

### 8.2.1 Target Environment Assessment

#### 8.2.1.1 Environment Type

**Cloud Provider**: Amazon Web Services (AWS)

**Deployment Model**: Cloud-native, fully managed services

**Geographic Distribution**: Multi-availability zone deployment within single AWS region (us-east-1 primary)

**Justification for AWS**:
- **Comprehensive Service Portfolio**: Complete ecosystem of managed services (ECS, S3, CloudWatch, Secrets Manager) reducing operational complexity
- **ECS Fargate**: Serverless container orchestration eliminates EC2 instance management
- **Global Infrastructure**: Multi-AZ high availability and optional multi-region disaster recovery
- **Security and Compliance**: SOC 2, GDPR, HIPAA compliance certifications align with application requirements
- **Cost Optimization**: Pay-per-use pricing model with granular cost controls and monitoring

#### 8.2.1.2 Resource Requirements

**Compute Resources** (ECS Fargate Tasks):

| Component | Initial Configuration | Production Configuration | Justification |
|-----------|----------------------|-------------------------|---------------|
| **Task CPU** | 0.5 vCPU per task | 0.5-1.0 vCPU per task | Flask API with LangChain, moderate computational requirements |
| **Task Memory** | 1 GB per task | 1-2 GB per task | Python runtime, in-memory request processing, dependency libraries |
| **Task Count** | 2-3 tasks minimum | 2-10 tasks (auto-scaling) | High availability (2 min), horizontal scaling for traffic spikes |
| **Availability Zones** | 3 AZs | 3 AZs | us-east-1a, us-east-1b, us-east-1c for fault tolerance |

**Storage Requirements**:

| Storage Type | Initial Capacity | Growth Projection | Purpose |
|-------------|------------------|-------------------|---------|
| **MongoDB Storage** | 10 GB (M10 tier) | 10-50 GB (first year) | User profiles, conversations, AI interaction history, audit logs |
| **S3 Object Storage** | 50 GB | 100-500 GB (first year) | User file uploads, static assets, backups, Terraform state |
| **Redis Cache Memory** | 1 GB (cache.t3.micro) | 1-4 GB | API response caching, JWKS caching, rate limiting counters |
| **Container Image Storage** | 5 GB (ECR) | 10-20 GB | Docker images for backend services, frontend builds |

**Network Requirements**:

| Network Resource | Specification | Purpose |
|-----------------|---------------|---------|
| **VPC CIDR Block** | 10.0.0.0/16 (65,536 IP addresses) | Private network isolation for all AWS resources |
| **Public Subnets** | 3 subnets (10.0.1.0/24, 10.0.2.0/24, 10.0.3.0/24) | Application Load Balancer, NAT Gateways |
| **Private Subnets** | 3 subnets (10.0.10.0/24, 10.0.11.0/24, 10.0.12.0/24) | ECS Fargate tasks, databases (no public access) |
| **Bandwidth** | Standard AWS bandwidth | Elastic bandwidth with CloudFront CDN for global acceleration |

#### 8.2.1.3 Compliance and Regulatory Requirements

**Regulatory Alignment**:

| Regulation | Applicability | Infrastructure Controls | Status |
|-----------|---------------|------------------------|--------|
| **GDPR** (EU General Data Protection Regulation) | All EU users | Data encryption (AES-256), audit logging (7-year retention), right to deletion | Architecture aligned |
| **CCPA** (California Consumer Privacy Act) | California residents | Data access logs, user data export API, deletion workflows | Architecture aligned |
| **SOC 2 Type II** | Enterprise customers | Access controls, monitoring, incident response, audit trails | Architecture aligned |

**Infrastructure Security Requirements**:
- **Encryption at Rest**: AES-256 encryption for all persistent data (MongoDB, S3, Redis)
- **Encryption in Transit**: TLS 1.3 (fallback to TLS 1.2) for all network communication
- **Network Isolation**: Private VPC subnets for backend services, security groups for port restrictions
- **Access Control**: IAM roles with least privilege, AWS Secrets Manager for credential management
- **Audit Logging**: CloudWatch Logs with 30-day active retention, S3 Glacier for 7-year compliance archival

### 8.2.2 Environment Management

#### 8.2.2.1 Infrastructure as Code Approach

**Terraform 1.6+ Architecture**:

The entire infrastructure is defined as code using Terraform, enabling version-controlled, reproducible, and auditable infrastructure management.

**Terraform Project Structure**:

```
terraform/
├── modules/                      # Reusable infrastructure modules
│   ├── networking/              # VPC, subnets, security groups, NAT gateways
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   ├── compute/                 # ECS cluster, Fargate task definitions, services
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   ├── load_balancer/           # ALB, target groups, listeners, health checks
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   ├── storage/                 # S3 buckets, lifecycle policies, versioning
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   ├── monitoring/              # CloudWatch log groups, alarms, dashboards
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   └── outputs.tf
│   └── security/                # IAM roles, security groups, Secrets Manager
│       ├── main.tf
│       ├── variables.tf
│       └── outputs.tf
├── environments/                # Environment-specific configurations
│   ├── dev/
│   │   ├── main.tf             # Environment orchestration
│   │   ├── variables.tf
│   │   ├── terraform.tfvars    # Development-specific values
│   │   └── backend.tf          # S3 backend configuration
│   ├── staging/
│   │   ├── main.tf
│   │   ├── variables.tf
│   │   ├── terraform.tfvars    # Staging-specific values
│   │   └── backend.tf
│   └── production/
│       ├── main.tf
│       ├── variables.tf
│       ├── terraform.tfvars    # Production-specific values (sensitive)
│       └── backend.tf
├── backend.tf                   # Remote state configuration (S3 + DynamoDB)
└── providers.tf                 # AWS provider configuration
```

**Terraform State Management**:

| Configuration | Specification | Purpose |
|--------------|---------------|---------|
| **Backend** | S3 bucket with versioning | Centralized state storage, state history, disaster recovery |
| **State Locking** | DynamoDB table | Prevent concurrent Terraform operations, consistency guarantees |
| **State Encryption** | AES-256 server-side encryption | Protect sensitive infrastructure configuration data |
| **State Access** | IAM role-based access control | Restrict state file access to authorized users and CI/CD pipelines |

**Example Terraform Configuration** (ECS Service):

```hcl
# terraform/modules/compute/main.tf
resource "aws_ecs_cluster" "main" {
  name = "${var.environment}-cluster"
  
  setting {
    name  = "containerInsights"
    value = "enabled"
  }
  
  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}

resource "aws_ecs_task_definition" "api" {
  family                   = "${var.environment}-api"
  requires_compatibilities = ["FARGATE"]
  network_mode            = "awsvpc"
  cpu                     = var.task_cpu
  memory                  = var.task_memory
  execution_role_arn      = aws_iam_role.ecs_execution.arn
  task_role_arn           = aws_iam_role.ecs_task.arn
  
  container_definitions = jsonencode([
    {
      name      = "api"
      image     = "${var.ecr_repository_url}:${var.image_tag}"
      essential = true
      
      portMappings = [
        {
          containerPort = 5000
          protocol      = "tcp"
        }
      ]
      
      environment = [
        {
          name  = "ENVIRONMENT"
          value = var.environment
        }
      ]
      
      secrets = [
        {
          name      = "AUTH0_CLIENT_SECRET"
          valueFrom = "${aws_secretsmanager_secret.auth0_secret.arn}"
        }
      ]
      
      logConfiguration = {
        logDriver = "awslogs"
        options = {
          awslogs-group         = "/ecs/${var.environment}-api"
          awslogs-region        = var.aws_region
          awslogs-stream-prefix = "api"
        }
      }
    }
  ])
}

resource "aws_ecs_service" "api" {
  name            = "${var.environment}-api-service"
  cluster         = aws_ecs_cluster.main.id
  task_definition = aws_ecs_task_definition.api.arn
  desired_count   = var.desired_task_count
  launch_type     = "FARGATE"
  
  network_configuration {
    subnets          = var.private_subnet_ids
    security_groups  = [aws_security_group.ecs_tasks.id]
    assign_public_ip = false
  }
  
  load_balancer {
    target_group_arn = var.alb_target_group_arn
    container_name   = "api"
    container_port   = 5000
  }
  
  deployment_configuration {
    maximum_percent         = 200
    minimum_healthy_percent = 100
  }
  
  health_check_grace_period_seconds = 60
  
  depends_on = [var.alb_listener]
}
```

#### 8.2.2.2 Configuration Management Strategy

**Environment-Specific Configuration**:

| Environment | Purpose | Configuration Source | Deployment Trigger |
|-------------|---------|---------------------|-------------------|
| **Development** | Feature development, testing | `.env.dev`, Terraform `dev/terraform.tfvars` | Push to `develop` branch |
| **Staging** | Pre-production validation, QA | `.env.staging`, Terraform `staging/terraform.tfvars` | Push to `staging` branch |
| **Production** | Live user traffic | AWS Secrets Manager, Terraform `production/terraform.tfvars` | Push to `main` branch (manual approval) |

**Secrets Management**:

All sensitive configuration (API keys, database credentials, encryption keys) stored in AWS Secrets Manager:

| Secret Name | Content | Accessed By | Rotation Policy |
|-------------|---------|-------------|-----------------|
| `production/auth0-credentials` | Auth0 client ID, client secret, domain | ECS tasks | Manual (on Auth0 key rotation) |
| `production/openai-api-key` | OpenAI API key for LLM access | ECS tasks | Manual (on OpenAI key rotation) |
| `production/mongodb-connection` | MongoDB Atlas connection string with credentials | ECS tasks | Automatic (90-day rotation) |
| `production/jwt-signing-secret` | Fallback JWT validation secret | ECS tasks | Automatic (90-day rotation) |

**Configuration Injection Methods**:

1. **Environment Variables**: Non-sensitive configuration injected via ECS task definition environment variables
2. **AWS Secrets Manager**: Sensitive credentials injected at runtime via ECS secrets integration
3. **Parameter Store**: Application configuration (feature flags, API endpoints) stored in AWS Systems Manager Parameter Store
4. **Terraform Variables**: Infrastructure configuration (VPC CIDR, instance types) defined in Terraform `terraform.tfvars` files

#### 8.2.2.3 Environment Promotion Strategy

**Promotion Workflow**:

```mermaid
graph LR
    subgraph "Development Environment"
        DevCode[Developer Push<br/>to develop branch]
        DevCI[GitHub Actions<br/>Dev CI/CD Pipeline]
        DevDeploy[Deploy to<br/>dev-cluster]
        DevTest[Automated Tests<br/>+ Manual QA]
    end
    
    subgraph "Staging Environment"
        StageMerge[Merge develop<br/>to staging branch]
        StageCI[GitHub Actions<br/>Staging CI/CD Pipeline]
        StageDeploy[Deploy to<br/>staging-cluster]
        StageTest[Full Regression<br/>+ Performance Testing]
    end
    
    subgraph "Production Environment"
        ProdMerge[Merge staging<br/>to main branch]
        ProdApproval[Manual Approval<br/>by Tech Lead]
        ProdCI[GitHub Actions<br/>Production CI/CD Pipeline]
        ProdDeploy[Rolling Deployment<br/>to production-cluster]
        ProdMonitor[CloudWatch<br/>Monitoring + Alarms]
    end
    
    DevCode --> DevCI
    DevCI --> DevDeploy
    DevDeploy --> DevTest
    DevTest -->|Tests Pass| StageMerge
    
    StageMerge --> StageCI
    StageCI --> StageDeploy
    StageDeploy --> StageTest
    StageTest -->|Tests Pass| ProdMerge
    
    ProdMerge --> ProdApproval
    ProdApproval -->|Approved| ProdCI
    ProdCI --> ProdDeploy
    ProdDeploy --> ProdMonitor
    ProdMonitor -->|Issues Detected| Rollback[Automatic Rollback]
    
    style DevTest fill:#FFF9C4
    style StageTest fill:#FFE0B2
    style ProdApproval fill:#FFCDD2
    style ProdMonitor fill:#C8E6C9
    style Rollback fill:#FFCDD2
```

**Environment Promotion Gates**:

| Gate | Requirement | Validation Method | Failure Action |
|------|-------------|-------------------|----------------|
| **Dev → Staging** | All automated tests pass (unit, integration) | GitHub Actions test suite | Block merge, require fixes |
| **Staging → Production** | Performance benchmarks met, manual QA approval | Load testing, manual sign-off | Block merge, investigate regressions |
| **Production Deployment** | Manual approval by tech lead or engineering manager | GitHub Environment protection rules | Deployment canceled |
| **Post-Deployment** | No critical CloudWatch alarms for 15 minutes | CloudWatch alarm monitoring | Automatic rollback to previous version |

#### 8.2.2.4 Backup and Disaster Recovery

**Backup Strategy**:

| Resource | Backup Method | Frequency | Retention Period | Recovery Objective |
|----------|---------------|-----------|------------------|-------------------|
| **MongoDB Atlas** | Automated snapshots | Daily full + 6-hour incremental | 7-day point-in-time recovery | RPO: < 6 hours, RTO: < 1 hour |
| **S3 Buckets** (user uploads) | Cross-region replication | Real-time continuous replication | Indefinite (user-controlled deletion) | RPO: < 15 minutes, RTO: < 5 minutes |
| **S3 Buckets** (backups) | Versioning + lifecycle policies | Continuous versioning | 90 days (transition to Glacier) | RPO: 0 (versioning), RTO: < 30 minutes |
| **Terraform State** | S3 versioning | Every state change | Indefinite (all versions retained) | RPO: 0, RTO: < 5 minutes |
| **Container Images** | ECR image retention | On every build | Last 10 images | RPO: 0 (immutable), RTO: < 2 minutes |

**Disaster Recovery Scenarios**:

| Scenario | Impact | Recovery Procedure | RTO Target | RPO Target |
|----------|--------|-------------------|-----------|-----------|
| **Single ECS Task Failure** | No user impact (health checks route around failed task) | ECS automatically restarts task, health checks verify recovery | < 1 minute | 0 (no data loss) |
| **Availability Zone Failure** | Reduced capacity, but service remains available | ALB routes traffic to healthy AZs, ECS launches replacement tasks | < 5 minutes | 0 (no data loss) |
| **MongoDB Primary Failure** | Brief write unavailability during failover | MongoDB replica set auto-elects new primary | < 10 seconds | 0 (write concern majority) |
| **Full Application Outage** | Complete service disruption | Rollback to previous ECS task definition, restart services | < 30 minutes | 0 (stateless application) |
| **Region-Wide AWS Failure** | Total service unavailability (rare) | Failover to disaster recovery region (manual process) | < 4 hours | < 1 hour |

**Recovery Procedures**:

**Rollback to Previous Deployment**:
```bash
# Retrieve previous task definition ARN
aws ecs describe-services --cluster production-cluster --services api-service \
  --query 'services[0].taskDefinition' --output text

#### Update service to use previous task definition (revision N-1)
aws ecs update-service --cluster production-cluster --service api-service \
  --task-definition api-production:PREVIOUS_REVISION --force-new-deployment

#### Monitor rollback progress
aws ecs describe-services --cluster production-cluster --services api-service \
  --query 'services[0].deployments'
```

**MongoDB Point-in-Time Restore** (MongoDB Atlas):
```
1. Access MongoDB Atlas dashboard
2. Navigate to Clusters → Backups → Restore
3. Select restore point (any point within last 7 days)
4. Choose restore target:
   - Option A: Restore to existing cluster (brief downtime)
   - Option B: Restore to new cluster (test recovery, then promote)
5. Update ECS task environment variable with new connection string (if new cluster)
6. Deploy updated task definition
7. Verify data integrity and application functionality
```

---

## 8.3 Cloud Services

### 8.3.1 Cloud Provider Selection and Justification

**Primary Cloud Provider**: Amazon Web Services (AWS)

**Selection Rationale**:

| Factor | AWS Advantage | Specific Benefit for This System |
|--------|---------------|----------------------------------|
| **Serverless Container Platform** | ECS Fargate eliminates EC2 management | No server patching, auto-scaling, pay-per-use pricing reduces operational overhead |
| **Managed Service Ecosystem** | Comprehensive portfolio (S3, CloudWatch, Secrets Manager, Certificate Manager) | Single vendor integration, consistent IAM access control, unified billing |
| **Global Infrastructure** | 32 regions, 102 availability zones | Multi-AZ high availability (us-east-1a/b/c), future multi-region expansion capability |
| **Security and Compliance** | SOC 2, GDPR, HIPAA, ISO 27001 certifications | Alignment with application security requirements, regulatory compliance out-of-box |
| **Developer Ecosystem** | Extensive documentation, Terraform support, boto3 SDK | Rapid development, infrastructure-as-code maturity, Python SDK integration |
| **Cost Optimization** | Pay-per-use pricing, Free Tier, Savings Plans | Minimize startup costs, predictable pricing for mature workloads |

### 8.3.2 Core AWS Services with Versions

#### 8.3.2.1 Compute Services

| Service | Version/Configuration | Purpose | Scaling Model |
|---------|----------------------|---------|---------------|
| **Amazon ECS** | ECS Platform Version: Latest | Serverless container orchestration | Horizontal scaling (2-10 tasks) based on CPU/memory metrics |
| **AWS Fargate** | Fargate Platform Version 1.4.0+ | Serverless compute engine for containers | Auto-provision compute resources per task requirements |
| **Application Load Balancer** | ALB (Layer 7) | Traffic distribution, TLS termination, health checks | Automatic scaling to handle traffic spikes |

**ECS Task Resource Allocation**:

```
Task Definition Specification:
- Family: production-api
- Launch Type: FARGATE
- Platform Version: 1.4.0
- CPU: 0.5 vCPU (512 CPU units)
- Memory: 1 GB (1024 MiB)
- Network Mode: awsvpc (dedicated ENI per task)
- Task Role: ecs-task-role (permissions for S3, Secrets Manager, CloudWatch)
- Execution Role: ecs-execution-role (permissions to pull ECR images, create CloudWatch logs)
```

#### 8.3.2.2 Storage Services

| Service | Configuration | Purpose | Redundancy |
|---------|--------------|---------|------------|
| **Amazon S3** | Standard storage class | Object storage for user uploads, static assets, backups, Terraform state | 99.999999999% (11 9's) durability, cross-AZ replication |
| **S3 Glacier** | Archive storage class | Long-term log archival (compliance retention) | 99.999999999% durability, retrieval time: 1-5 hours |
| **Amazon EBS** | gp3 volumes (if self-hosting MongoDB) | Persistent block storage for databases (optional) | Automatic AZ-level replication |

**S3 Bucket Strategy**:

| Bucket Name | Purpose | Encryption | Versioning | Lifecycle Policy |
|------------|---------|------------|------------|------------------|
| `app-uploads-prod` | User-uploaded files | SSE-S3 (AES-256) | Enabled | Retain indefinitely (user-controlled deletion) |
| `app-static-assets-prod` | Frontend builds, images, CSS/JS | SSE-S3 (AES-256) | Disabled | Retain indefinitely, CloudFront origin |
| `app-backups-prod` | Database backups, system backups | SSE-KMS (customer-managed key) | Enabled | Standard (30 days) → IA (60 days) → Glacier (90+ days) |
| `terraform-state-prod` | Terraform state files | SSE-S3 (AES-256) | Enabled | Retain all versions indefinitely |

#### 8.3.2.3 Database Services

**MongoDB Atlas** (Managed MongoDB, Optional):

| Configuration | Specification | Justification |
|--------------|---------------|---------------|
| **Cluster Tier** | M10 (2 vCPU, 4 GB RAM) | Initial production workload, supports 100GB storage, 500 connections |
| **Replication** | 3-node replica set (1 Primary + 2 Secondary) | High availability, automatic failover < 10 seconds |
| **Backup** | Daily snapshots + point-in-time recovery (7 days) | Data protection, disaster recovery |
| **Region** | AWS us-east-1 | Co-location with ECS tasks for low latency |

**Alternative**: Self-hosted MongoDB on ECS Fargate with EBS volumes (reduced cost, increased operational complexity)

**Amazon ElastiCache for Redis** (Managed Redis, Optional):

| Configuration | Specification | Justification |
|--------------|---------------|---------------|
| **Node Type** | cache.t3.micro (2 vCPU, 0.5 GB RAM) | Initial caching workload, supports 1000 connections |
| **Engine Version** | Redis 7.0+ | Latest stable version with enhanced JSON support |
| **Cluster Mode** | Single node (development), Redis Cluster (production future) | Simplified management initially, horizontal scaling path |
| **Encryption** | In-transit TLS encryption, at-rest encryption | Security compliance requirements |

**Alternative**: Self-hosted Redis on ECS Fargate (reduced cost, no managed backups)

#### 8.3.2.4 Networking Services

| Service | Configuration | Purpose |
|---------|--------------|---------|
| **Amazon VPC** | CIDR: 10.0.0.0/16 | Private network isolation for all resources |
| **Public Subnets** | 3 subnets across 3 AZs (10.0.1.0/24, 10.0.2.0/24, 10.0.3.0/24) | ALB, NAT Gateways, public-facing resources |
| **Private Subnets** | 3 subnets across 3 AZs (10.0.10.0/24, 10.0.11.0/24, 10.0.12.0/24) | ECS tasks, databases (no public IP addresses) |
| **Internet Gateway** | 1 per VPC | Outbound internet access for public subnets |
| **NAT Gateway** | 1 per AZ (3 total for high availability) | Outbound internet access for private subnets (API calls to Auth0, OpenAI) |
| **Security Groups** | Stateful firewall rules per resource type | ECS tasks, ALB, databases (port-level access control) |

**Network Architecture Diagram**:

```mermaid
graph TB
    subgraph "AWS Region: us-east-1"
        IGW[Internet Gateway]
        
        subgraph "VPC: 10.0.0.0/16"
            subgraph "Availability Zone A: us-east-1a"
                PublicA[Public Subnet<br/>10.0.1.0/24]
                PrivateA[Private Subnet<br/>10.0.10.0/24]
                NATA[NAT Gateway A]
                ECSA[ECS Task A<br/>No Public IP]
            end
            
            subgraph "Availability Zone B: us-east-1b"
                PublicB[Public Subnet<br/>10.0.2.0/24]
                PrivateB[Private Subnet<br/>10.0.11.0/24]
                NATB[NAT Gateway B]
                ECSB[ECS Task B<br/>No Public IP]
            end
            
            subgraph "Availability Zone C: us-east-1c"
                PublicC[Public Subnet<br/>10.0.3.0/24]
                PrivateC[Private Subnet<br/>10.0.12.0/24]
                NATC[NAT Gateway C]
                ECSC[ECS Task C<br/>No Public IP]
            end
            
            ALB[Application Load Balancer<br/>Multi-AZ<br/>Public IP<br/>Ports: 443 HTTPS]
        end
    end
    
    Internet[Internet<br/>Clients] -->|HTTPS 443| IGW
    IGW --> ALB
    
    ALB -->|HTTP 5000| ECSA
    ALB -->|HTTP 5000| ECSB
    ALB -->|HTTP 5000| ECSC
    
    ECSA -.->|External API Calls<br/>Auth0, OpenAI| NATA
    ECSB -.->|External API Calls<br/>Auth0, OpenAI| NATB
    ECSC -.->|External API Calls<br/>Auth0, OpenAI| NATC
    
    NATA --> IGW
    NATB --> IGW
    NATC --> IGW
    
    PublicA -.->|Contains| NATA
    PublicB -.->|Contains| NATB
    PublicC -.->|Contains| NATC
    
    PrivateA -.->|Contains| ECSA
    PrivateB -.->|Contains| ECSB
    PrivateC -.->|Contains| ECSC
    
    style Internet fill:#FFCDD2
    style ALB fill:#FFF9C4
    style ECSA fill:#C8E6C9
    style ECSB fill:#C8E6C9
    style ECSC fill:#C8E6C9
    style NATA fill:#E1F5FE
    style NATB fill:#E1F5FE
    style NATC fill:#E1F5FE
```

#### 8.3.2.5 Security Services

| Service | Purpose | Configuration |
|---------|---------|---------------|
| **AWS Secrets Manager** | Secure storage for API keys, database credentials | Automatic rotation (90 days), encrypted with AWS KMS |
| **AWS Certificate Manager (ACM)** | TLS/SSL certificates for HTTPS | Free certificates, automatic renewal, wildcard support |
| **AWS IAM** | Identity and access management for AWS resources | Least privilege roles for ECS tasks, CI/CD pipelines |
| **AWS Key Management Service (KMS)** | Encryption key management | Customer-managed keys for S3 backup encryption |
| **Security Groups** | Virtual firewalls for network access control | Stateful rules, default deny all inbound |

#### 8.3.2.6 Monitoring and Logging Services

| Service | Purpose | Configuration |
|---------|---------|---------------|
| **Amazon CloudWatch Logs** | Centralized log aggregation | Log groups per service, 30-day retention |
| **Amazon CloudWatch Metrics** | Performance metrics collection | 1-minute resolution, 15-month retention |
| **Amazon CloudWatch Alarms** | Automated alerting | Multi-dimensional metrics, SNS notifications |
| **Amazon CloudWatch Dashboards** | Real-time monitoring visualization | Role-specific dashboards (operations, business, security) |
| **AWS X-Ray** (Optional) | Distributed tracing and service maps | Request sampling (10% success, 100% errors) |

#### 8.3.2.7 Additional AWS Services

| Service | Purpose | Usage |
|---------|---------|-------|
| **Amazon ECR** | Docker container registry | Private registry for Flask API images, vulnerability scanning |
| **Amazon SNS** | Notification service | CloudWatch alarm notifications (email, PagerDuty, Slack webhooks) |
| **Amazon CloudFront** | Content delivery network | Global edge caching for static assets, reduced latency |
| **AWS Systems Manager Parameter Store** | Application configuration | Non-sensitive config (feature flags, API endpoints) |
| **Amazon Route 53** | DNS management | Domain registration, hosted zones, health checks |

### 8.3.3 High Availability Design

**Multi-Availability Zone Architecture**:

All critical infrastructure components are deployed across three availability zones (us-east-1a, us-east-1b, us-east-1c) to ensure fault tolerance and eliminate single points of failure.

**Component Availability Design**:

| Component | Availability Strategy | Failure Impact | Recovery Time |
|-----------|---------------------|----------------|---------------|
| **Application Load Balancer** | Multi-AZ deployment (3 AZs) | No impact (ALB automatically routes to healthy AZs) | Automatic (< 1 second) |
| **ECS Fargate Tasks** | Distributed across 3 AZs (minimum 2 tasks) | Reduced capacity, but service remains available | < 1 minute (auto-restart) |
| **MongoDB Replica Set** | 3-node cluster (1 primary + 2 secondaries across AZs) | < 10 second failover to secondary node | < 10 seconds (automatic) |
| **Redis Cache** | Single node (development), ElastiCache cluster (production) | Cache misses during recovery, fallback to database | < 5 minutes (manual failover) |
| **S3 Storage** | Automatic cross-AZ replication | No impact (S3 automatically routes to available AZ) | Transparent (no downtime) |

**SLA Targets**:

| Metric | Target | Measurement Method |
|--------|--------|--------------------|
| **Application Availability** | 99.9% uptime (43.2 minutes downtime/month) | CloudWatch Synthetics canary monitoring |
| **API Response Time** | p95 < 300ms for CRUD, p95 < 5000ms for AI requests | CloudWatch metrics aggregation |
| **Data Durability** | 99.999999999% (S3), 99.995% (MongoDB Atlas) | AWS SLA, MongoDB Atlas SLA |

### 8.3.4 Cost Optimization Strategy

**Right-Sizing Resources**:

- **ECS Fargate**: Start with 0.5 vCPU, 1 GB RAM tasks; scale up only when CPU/memory utilization consistently > 70%
- **MongoDB Atlas**: Begin with M10 tier (2 vCPU, 4 GB RAM); upgrade to M20 only when storage > 80GB or IOPS insufficient
- **Redis ElastiCache**: Start with cache.t3.micro; scale up when eviction rate > 10% or latency increases

**Cost Monitoring**:

| Cost Category | Monthly Budget | Monitoring Method | Alert Threshold |
|--------------|----------------|-------------------|-----------------|
| **ECS Fargate Compute** | $50-250 | CloudWatch metrics + AWS Cost Explorer | > $300/month |
| **MongoDB Atlas** | $60 | MongoDB Atlas billing dashboard | > $80/month |
| **Data Transfer** | $20-50 | AWS Cost Explorer | > $100/month |
| **CloudWatch Logs** | $30 | AWS Cost Explorer | > $50/month |
| **Total Infrastructure** | $200-400 | AWS Budgets with email alerts | > $500/month |

**Cost Optimization Techniques**:

1. **Reserved Capacity**: Consider Fargate Savings Plans after 3-6 months of stable usage (up to 50% cost reduction)
2. **S3 Lifecycle Policies**: Automatic transition to lower-cost storage classes (Standard → Standard-IA → Glacier)
3. **CloudWatch Logs Sampling**: Sample high-volume health check logs (10% sampling) while logging all errors (100%)
4. **Spot Instances**: Not applicable for ECS Fargate (serverless), but consider for future Kubernetes migration if needed
5. **CloudFront Caching**: Aggressive caching of static assets reduces origin requests and data transfer costs

**Estimated Monthly Infrastructure Costs** (Production Environment):

| Component | Configuration | Estimated Monthly Cost |
|-----------|--------------|----------------------|
| **ECS Fargate** | 2-10 tasks (0.5 vCPU, 1GB) × 720 hours/month | $50-250 |
| **Application Load Balancer** | Standard ALB, 100GB data processed | $20 |
| **MongoDB Atlas** | M10 tier (2 vCPU, 4GB RAM, 10GB storage) | $60 |
| **ElastiCache Redis** | cache.t3.micro (0.5GB memory) | $12 |
| **Amazon S3** | 100GB storage, 1TB data transfer out | $3 (storage) + $90 (transfer) = $93 |
| **CloudWatch** | Logs (20GB ingestion), Metrics, Alarms | $30 |
| **Amazon ECR** | 10GB image storage, 1TB data transfer | $5 |
| **NAT Gateway** | 3 NAT gateways × 1TB data processed | $108 |
| **AWS Secrets Manager** | 10 secrets | $4 |
| **Amazon SNS** | 1000 notifications/month | $0.50 |
| **AWS Certificate Manager** | TLS certificates | Free |
| **Total Estimated** | Initial production deployment | **$382-582/month** |

---

## 8.4 Containerization

### 8.4.1 Container Platform Selection

**Platform**: Docker 24+

**Justification**:
- **Industry Standard**: Most widely adopted containerization platform with mature ecosystem
- **AWS ECS Compatibility**: Native support for Docker containers on ECS Fargate
- **Developer Experience**: Consistent local development environment matching production runtime
- **Multi-Stage Builds**: Optimize image size and build times
- **Security Scanning**: Integration with AWS ECR vulnerability scanning

### 8.4.2 Base Image Strategy

**Backend (Python/Flask) Base Images**:

```dockerfile
# Multi-stage build for optimized production image
FROM python:3.11-slim as builder

#### Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

#### Install Python dependencies
COPY requirements.txt .
RUN pip install --user --no-cache-dir --no-warn-script-location -r requirements.txt

#### Production stage
FROM python:3.11-slim

#### Install runtime dependencies only
RUN apt-get update && apt-get install -y \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

#### Copy installed packages from builder
COPY --from=builder /root/.local /root/.local

#### Copy application code
COPY . .

#### Create non-root user for security
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

#### Add local bin to PATH
ENV PATH=/root/.local/bin:$PATH

#### Expose application port
EXPOSE 5000

#### Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:5000/health')"

#### Run application with Gunicorn
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "4", "--timeout", "120", "app:app"]
```

**Base Image Rationale**:

| Base Image | Size | Advantages | Use Case |
|------------|------|------------|----------|
| `python:3.11-slim` | ~125 MB | Minimal Debian-based image, security updates | Production backend containers |
| `python:3.11-alpine` | ~45 MB | Smallest image size, reduced attack surface | Alternative for ultra-low resource environments |
| `python:3.11` (full) | ~900 MB | All development tools included | Local development only (not production) |

**Frontend (React) Base Images**:

```dockerfile
# Build stage - Node.js for React build
FROM node:18-alpine as builder

WORKDIR /app

#### Copy package files
COPY package*.json ./

#### Install dependencies
RUN npm ci --only=production

#### Copy source code
COPY . .

#### Build React application
RUN npm run build

#### Production stage - Nginx for serving static files
FROM nginx:alpine

#### Copy custom nginx configuration
COPY nginx.conf /etc/nginx/nginx.conf

#### Copy built React app from builder stage
COPY --from=builder /app/dist /usr/share/nginx/html

#### Expose port 80
EXPOSE 80

#### Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
  CMD wget --quiet --tries=1 --spider http://localhost/health || exit 1

#### Run nginx
CMD ["nginx", "-g", "daemon off;"]
```

### 8.4.3 Image Versioning and Tagging Strategy

**Docker Image Tagging Convention**:

| Tag Format | Example | Purpose |
|-----------|---------|---------|
| `{git-sha}` | `a3f5b8c2` | Immutable reference to specific commit for traceability |
| `{environment}-latest` | `production-latest` | Most recent deployment for environment |
| `{semantic-version}` | `v1.2.3` | Official release versions for production deployments |
| `{environment}-{timestamp}` | `staging-20240115-1430` | Timestamped deployments for audit trail |

**Example Tagging Workflow**:

```bash
# Build Docker image
docker build -t backend:${GIT_SHA} -f backend/Dockerfile backend/

#### Tag image for ECR registry
docker tag backend:${GIT_SHA} ${ECR_REGISTRY}/backend:${GIT_SHA}
docker tag backend:${GIT_SHA} ${ECR_REGISTRY}/backend:${ENVIRONMENT}-latest
docker tag backend:${GIT_SHA} ${ECR_REGISTRY}/backend:${VERSION}

#### Push all tags to ECR
docker push ${ECR_REGISTRY}/backend:${GIT_SHA}
docker push ${ECR_REGISTRY}/backend:${ENVIRONMENT}-latest
docker push ${ECR_REGISTRY}/backend:${VERSION}
```

**Image Retention Policy**:

| Repository | Retention Rule | Rationale |
|-----------|---------------|-----------|
| **backend** | Keep last 10 images, delete older | Balance storage costs with rollback capability |
| **frontend** | Keep last 10 images, delete older | Rapid iteration requires frequent builds |
| **production-tagged** | Keep all `v*.*.*` semantic versions indefinitely | Production releases retained for audit |

### 8.4.4 Build Optimization Techniques

**Docker Build Performance Optimizations**:

1. **Layer Caching**: Order Dockerfile commands from least to most frequently changing
   - Base image → System dependencies → Application dependencies → Application code
2. **Multi-Stage Builds**: Separate build dependencies from runtime dependencies (reduces image size by 60-80%)
3. **.dockerignore**: Exclude unnecessary files from build context (node_modules, .git, *.md)
4. **BuildKit**: Enable Docker BuildKit for parallel layer builds and improved caching

**Example .dockerignore**:

```
# Version control
.git
.gitignore
.gitattributes

#### Python artifacts
__pycache__
*.pyc
*.pyo
*.pyd
.Python
*.so
*.egg
*.egg-info
dist/
build/

#### Node artifacts
node_modules/
npm-debug.log
yarn-error.log

#### IDE files
.vscode/
.idea/
*.swp
*.swo

#### Documentation
README.md
CHANGELOG.md
docs/

#### Environment files
.env
.env.local
*.env

#### Testing artifacts
.coverage
htmlcov/
.pytest_cache/
```

**Image Size Optimization Results**:

| Optimization Technique | Image Size Reduction | Build Time Improvement |
|-----------------------|---------------------|----------------------|
| Multi-stage builds | 65% reduction (900MB → 315MB) | N/A |
| Slim base images | 85% reduction vs. full image | N/A |
| .dockerignore | 20% faster build (reduced context) | 20% faster |
| Layer caching | Minimal size impact | 70% faster (cached builds) |
| **Combined** | **Final image: ~150MB (backend), ~25MB (frontend)** | **80% faster incremental builds** |

### 8.4.5 Security Scanning Requirements

**Amazon ECR Image Scanning**:

- **Scan Trigger**: Automatic scan on image push to ECR
- **Scan Type**: Basic scanning (CVE database), Enhanced scanning (Inspector integration, optional)
- **Vulnerability Severity Levels**: Critical, High, Medium, Low, Informational
- **Remediation Policy**:
  - **Critical vulnerabilities**: Block deployment, require immediate patch
  - **High vulnerabilities**: Alert engineering team, remediate within 7 days
  - **Medium/Low vulnerabilities**: Track in backlog, remediate in next sprint

**Security Scan Workflow Integration**:

```yaml
# .github/workflows/backend-ci-cd.yml (excerpt)
- name: Scan Docker image for vulnerabilities
  run: |
    # Wait for ECR scan to complete
    aws ecr wait image-scan-complete \
      --repository-name backend \
      --image-id imageTag=${GIT_SHA}
    
    # Retrieve scan findings
    aws ecr describe-image-scan-findings \
      --repository-name backend \
      --image-id imageTag=${GIT_SHA} \
      --output json > scan-results.json
    
    # Check for critical vulnerabilities
    CRITICAL_COUNT=$(jq '.imageScanFindings.findingSeverityCounts.CRITICAL // 0' scan-results.json)
    if [ $CRITICAL_COUNT -gt 0 ]; then
      echo "ERROR: $CRITICAL_COUNT critical vulnerabilities found"
      exit 1
    fi
```

**Security Best Practices**:

- **Non-Root User**: Run containers as non-root user (appuser with UID 1000)
- **Read-Only Root Filesystem**: Mount root filesystem as read-only where possible
- **No Secrets in Images**: Use AWS Secrets Manager for sensitive configuration (never bake into images)
- **Minimal Base Images**: Use slim/alpine images to reduce attack surface

---

## 8.5 Orchestration

### 8.5.1 Orchestration Platform Selection

**Platform**: Amazon ECS (Elastic Container Service) with AWS Fargate launch type

**Justification**:

| Factor | ECS Fargate Advantage | Alternative (Kubernetes) |
|--------|----------------------|-------------------------|
| **Operational Complexity** | Serverless, no cluster management | Requires Kubernetes expertise, control plane management |
| **AWS Integration** | Native integration with ALB, CloudWatch, Secrets Manager, IAM | Requires add-ons for AWS service integration |
| **Pricing Model** | Pay only for task runtime (vCPU-seconds, GB-seconds) | Pay for EC2 instances (always running) or EKS control plane ($0.10/hour) |
| **Scaling** | Auto-scaling at task level, instant provisioning | Requires node scaling + pod scaling (more complex) |
| **Learning Curve** | Simpler task definition model | Steep learning curve (pods, deployments, services, ingresses) |
| **Maturity** | Proven for Flask APIs and containerized workloads | More flexible but overkill for this use case |

**When to Consider Kubernetes Migration**: If the system grows to 20+ microservices with complex inter-service communication, or if multi-cloud deployment becomes a requirement, reevaluate Kubernetes (EKS) as a more flexible orchestration platform.

### 8.5.2 ECS Cluster Architecture

**Cluster Configuration**:

```
Cluster Name: production-cluster
Launch Type: AWS Fargate (serverless)
Container Insights: Enabled (CloudWatch metrics and logs)
Capacity Providers: FARGATE, FARGATE_SPOT (for cost optimization on non-critical tasks)
```

**ECS Task Definition Structure**:

```json
{
  "family": "production-api",
  "taskRoleArn": "arn:aws:iam::ACCOUNT_ID:role/ecs-task-role",
  "executionRoleArn": "arn:aws:iam::ACCOUNT_ID:role/ecs-execution-role",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "containerDefinitions": [
    {
      "name": "api",
      "image": "ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/backend:GIT_SHA",
      "essential": true,
      "portMappings": [
        {
          "containerPort": 5000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "ENVIRONMENT",
          "value": "production"
        },
        {
          "name": "AWS_REGION",
          "value": "us-east-1"
        }
      ],
      "secrets": [
        {
          "name": "AUTH0_CLIENT_SECRET",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:ACCOUNT_ID:secret:production/auth0-credentials"
        },
        {
          "name": "OPENAI_API_KEY",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:ACCOUNT_ID:secret:production/openai-api-key"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/production-api",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "api"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:5000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

### 8.5.3 Service Deployment Strategy

**ECS Service Configuration**:

```
Service Name: production-api-service
Launch Type: FARGATE
Desired Count: 3 tasks (minimum 2, maximum 10)
Deployment Type: Rolling deployment
Deployment Configuration:
  - Maximum Percent: 200 (allow double capacity during deployment)
  - Minimum Healthy Percent: 100 (maintain full capacity during deployment)
Health Check Grace Period: 60 seconds
Load Balancer: Application Load Balancer (ALB)
  - Target Group: production-api-tg
  - Container Port: 5000
  - Health Check Path: /health
Network Configuration:
  - VPC: production-vpc
  - Subnets: private-subnet-a, private-subnet-b, private-subnet-c
  - Security Group: ecs-tasks-sg
  - Assign Public IP: No
```

**Deployment Process**:

```mermaid
sequenceDiagram
    participant CI as GitHub Actions<br/>CI/CD Pipeline
    participant ECR as Amazon ECR<br/>Container Registry
    participant ECS as Amazon ECS<br/>Control Plane
    participant ALB as Application<br/>Load Balancer
    participant OldTask as Old ECS Task<br/>(Version N)
    participant NewTask as New ECS Task<br/>(Version N+1)
    participant CW as CloudWatch<br/>Monitoring
    
    CI->>ECR: Push new Docker image<br/>Tag: ${GIT_SHA}
    CI->>ECS: Update ECS Service<br/>New task definition revision
    
    ECS->>ECS: Calculate deployment plan<br/>Max 200%, Min 100%
    ECS->>NewTask: Launch new task<br/>(Version N+1)
    NewTask->>NewTask: Container starts<br/>Health check grace period (60s)
    NewTask->>ALB: Register with target group<br/>Start health checks
    
    ALB->>NewTask: HTTP GET /health<br/>Every 30 seconds
    NewTask-->>ALB: 200 OK<br/>Healthy status
    
    ALB->>ALB: Mark new task as healthy<br/>Start routing traffic
    ALB->>NewTask: Route 50% traffic<br/>Gradual transition
    ALB->>OldTask: Route 50% traffic<br/>Maintain stability
    
    Note over ALB,NewTask: Both versions running<br/>(200% capacity)
    
    ECS->>ECS: Verify new tasks healthy<br/>for 5 minutes
    ECS->>OldTask: Initiate graceful shutdown<br/>SIGTERM signal
    OldTask->>OldTask: Complete in-flight requests<br/>30-second drain period
    OldTask->>ALB: Deregister from target group
    ECS->>OldTask: Terminate task
    
    Note over ALB,NewTask: Deployment complete<br/>(100% new version)
    
    NewTask->>CW: Emit metrics<br/>Logs, CPU, Memory
    CW->>CW: Monitor CloudWatch alarms<br/>Error rate, latency
    
    alt Deployment Successful
        CW-->>ECS: All alarms OK<br/>Deployment validated
        ECS->>CI: Deployment SUCCESS
    else Deployment Failed
        CW-->>ECS: Critical alarm triggered<br/>Error rate > 5%
        ECS->>NewTask: Terminate new tasks
        ECS->>OldTask: Rollback to previous<br/>task definition
        ECS->>CI: Deployment FAILED<br/>Automatic rollback
    end
```

### 8.5.4 Auto-Scaling Configuration

**Target Tracking Auto-Scaling Policies**:

**Policy 1: CPU-Based Scaling**
```
Metric: ECSServiceAverageCPUUtilization
Target Value: 70%
Scale-Out Cooldown: 180 seconds (3 minutes)
Scale-In Cooldown: 600 seconds (10 minutes)
Logic: If average CPU > 70% for 3 consecutive minutes → add 1 task
       If average CPU < 70% for 10 consecutive minutes → remove 1 task
```

**Policy 2: Memory-Based Scaling**
```
Metric: ECSServiceAverageMemoryUtilization
Target Value: 80%
Scale-Out Cooldown: 180 seconds
Scale-In Cooldown: 600 seconds
Logic: If average memory > 80% for 3 consecutive minutes → add 1 task
       If average memory < 80% for 10 consecutive minutes → remove 1 task
```

**Scaling Limits**:

| Metric | Minimum | Maximum | Rationale |
|--------|---------|---------|-----------|
| **Task Count** | 2 tasks | 10 tasks | Min 2 for high availability, max 10 to prevent cost overruns |
| **Scale-Out Rate** | +1 task/3 minutes | +3 tasks/15 minutes | Gradual scaling prevents ALB target group overwhelm |
| **Scale-In Rate** | -1 task/10 minutes | -2 tasks/30 minutes | Conservative scale-in prevents premature capacity reduction |

**Scheduled Scaling** (Optional for known traffic patterns):

```
# Scale up during business hours (8am-6pm EST, Monday-Friday)
Schedule: cron(0 13 ? * MON-FRI *)  # 8am EST (13:00 UTC)
Action: Set desired count to 5 tasks

#### Scale down during off-hours
Schedule: cron(0 23 ? * MON-FRI *)  # 6pm EST (23:00 UTC)
Action: Set desired count to 2 tasks
```

### 8.5.5 Resource Allocation and Limits

**Task Resource Allocation**:

| Resource | Allocated | Limit (Hard Cap) | Rationale |
|----------|-----------|------------------|-----------|
| **CPU** | 0.5 vCPU (512 CPU units) | 0.5 vCPU | Flask API with gunicorn workers, moderate CPU requirements |
| **Memory** | 1 GB (1024 MiB) | 1 GB | Python runtime, dependencies, in-memory request processing |
| **Network Bandwidth** | Elastic (no hard limit) | ECS Fargate network performance scales with task size | Sufficient for API workload |
| **Storage** | 20 GB ephemeral (default) | 20 GB | Temporary files, logs (persistent storage in S3/EBS) |

**Gunicorn Worker Configuration** (Inside Container):

```python
# gunicorn.conf.py
workers = 4  # Number of worker processes
worker_class = 'sync'  # Synchronous workers for Flask
threads = 1  # Single-threaded per worker (simplicity)
timeout = 120  # Request timeout (2 minutes for AI operations)
keepalive = 5  # Keep-alive connections
max_requests = 1000  # Restart worker after 1000 requests (memory leak prevention)
max_requests_jitter = 50  # Randomize restart timing
```

**Resource Allocation Rationale**:
- **4 Gunicorn workers**: Matches CPU allocation (0.5 vCPU ≈ 1 physical core, 4 workers for I/O concurrency)
- **1 GB memory**: ~250 MB per worker + overhead for Flask, LangChain, dependencies
- **Timeout 120s**: Accommodate slow AI/LLM operations (typical OpenAI response: 1-5 seconds, max 30 seconds)

---

## 8.6 CI/CD Pipeline

### 8.6.1 CI/CD Platform Selection

**Platform**: GitHub Actions

**Justification**:

| Factor | GitHub Actions Advantage |
|--------|-------------------------|
| **Native Integration** | Built into GitHub repository, no external CI/CD service required |
| **YAML Configuration** | Declarative pipeline-as-code, version-controlled with application code |
| **Secrets Management** | GitHub Secrets integration for AWS credentials, API keys |
| **Matrix Builds** | Test across multiple Python/Node versions simultaneously |
| **Marketplace Ecosystem** | 10,000+ pre-built actions for common tasks (AWS, Docker, testing) |
| **Free Tier** | 2,000 minutes/month (public repos), 3,000 minutes/month (private repos) |

### 8.6.2 Build Pipeline

**Backend Build Pipeline Stages**:

```mermaid
flowchart LR
    Trigger[Git Push<br/>to develop/staging/main] --> Checkout[Checkout Code<br/>actions/checkout@v4]
    Checkout --> SetupPython[Setup Python 3.11<br/>actions/setup-python@v4]
    SetupPython --> InstallDeps[Install Dependencies<br/>pip install -r requirements.txt]
    InstallDeps --> Lint[Lint & Format<br/>black, flake8, mypy]
    Lint --> Test[Run Tests<br/>pytest with coverage]
    Test --> CodeCov[Upload Coverage<br/>codecov/codecov-action@v3]
    CodeCov --> BuildDocker[Build Docker Image<br/>docker build]
    BuildDocker --> ScanImage[ECR Vulnerability Scan<br/>AWS ECR scan]
    ScanImage --> PushECR[Push to ECR<br/>docker push]
    PushECR --> Deploy{Deploy?}
    Deploy -->|develop branch| DevDeploy[Deploy to Dev<br/>ECS update-service]
    Deploy -->|staging branch| StageDeploy[Deploy to Staging<br/>ECS update-service]
    Deploy -->|main branch| ProdApproval[Manual Approval<br/>GitHub Environment]
    ProdApproval --> ProdDeploy[Deploy to Production<br/>ECS update-service]
    
    style Trigger fill:#E3F2FD
    style Lint fill:#FFF9C4
    style Test fill:#FFF9C4
    style ScanImage fill:#FFE0B2
    style ProdApproval fill:#FFCDD2
    style ProdDeploy fill:#C8E6C9
```

**Backend CI/CD Workflow** (`.github/workflows/backend-ci-cd.yml`):

```yaml
name: Backend CI/CD

on:
  push:
    branches: [main, staging, develop]
    paths:
      - 'backend/**'
      - '.github/workflows/backend-ci-cd.yml'
  pull_request:
    branches: [main]
    paths:
      - 'backend/**'

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: backend
  ECS_CLUSTER: production-cluster
  ECS_SERVICE: api-service

jobs:
  test:
    name: Test Backend
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          cd backend
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      
      - name: Run linters
        run: |
          cd backend
          black --check .
          flake8 . --max-line-length=100
          mypy . --ignore-missing-imports
      
      - name: Run tests with coverage
        run: |
          cd backend
          pytest --cov=. --cov-report=xml --cov-report=term
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./backend/coverage.xml
          flags: backend
          fail_ci_if_error: true

  build-and-deploy:
    name: Build and Deploy Backend
    needs: test
    if: github.event_name == 'push'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      
      - name: Build, tag, and push Docker image
        id: build-image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          cd backend
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          
          # Tag as latest for environment
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:$GITHUB_REF_NAME-latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$GITHUB_REF_NAME-latest
          
          echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT
      
      - name: Wait for ECR vulnerability scan
        run: |
          aws ecr wait image-scan-complete \
            --repository-name $ECR_REPOSITORY \
            --image-id imageTag=${{ github.sha }} \
            --region $AWS_REGION
      
      - name: Check for critical vulnerabilities
        run: |
          SCAN_FINDINGS=$(aws ecr describe-image-scan-findings \
            --repository-name $ECR_REPOSITORY \
            --image-id imageTag=${{ github.sha }} \
            --region $AWS_REGION)
          
          CRITICAL=$(echo $SCAN_FINDINGS | jq '.imageScanFindings.findingSeverityCounts.CRITICAL // 0')
          
          if [ $CRITICAL -gt 0 ]; then
            echo "ERROR: $CRITICAL critical vulnerabilities found"
            exit 1
          fi
      
      - name: Deploy to ECS (Development)
        if: github.ref == 'refs/heads/develop'
        run: |
          aws ecs update-service \
            --cluster dev-cluster \
            --service api-service \
            --force-new-deployment \
            --region $AWS_REGION
      
      - name: Deploy to ECS (Staging)
        if: github.ref == 'refs/heads/staging'
        run: |
          aws ecs update-service \
            --cluster staging-cluster \
            --service api-service \
            --force-new-deployment \
            --region $AWS_REGION
      
      - name: Deploy to ECS (Production)
        if: github.ref == 'refs/heads/main'
        environment:
          name: production
          url: https://api.example.com
        run: |
          # Update task definition with new image
          TASK_DEFINITION=$(aws ecs describe-task-definition \
            --task-definition production-api \
            --region $AWS_REGION)
          
          NEW_TASK_DEF=$(echo $TASK_DEFINITION | jq --arg IMAGE "${{ steps.build-image.outputs.image }}" \
            '.taskDefinition | .containerDefinitions[0].image = $IMAGE | del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)')
          
          NEW_TASK_INFO=$(aws ecs register-task-definition \
            --cli-input-json "$NEW_TASK_DEF" \
            --region $AWS_REGION)
          
          NEW_REVISION=$(echo $NEW_TASK_INFO | jq -r '.taskDefinition.revision')
          
          # Deploy new task definition
          aws ecs update-service \
            --cluster $ECS_CLUSTER \
            --service $ECS_SERVICE \
            --task-definition production-api:$NEW_REVISION \
            --region $AWS_REGION
          
          # Wait for deployment to complete
          aws ecs wait services-stable \
            --cluster $ECS_CLUSTER \
            --services $ECS_SERVICE \
            --region $AWS_REGION
```

**Frontend Build Pipeline** (`.github/workflows/frontend-ci-cd.yml` - Summary):

```yaml
name: Frontend CI/CD

on:
  push:
    branches: [main, staging, develop]
    paths:
      - 'frontend/**'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - Setup Node.js 18
      - npm ci (install dependencies)
      - npm run lint (ESLint)
      - npm run format:check (Prettier)
      - npm run type-check (TypeScript)
      - npm run test:ci (Vitest)
  
  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - Build production bundle (npm run build)
      - Upload to S3 (aws s3 sync dist/ s3://app-static-assets-prod)
      - Invalidate CloudFront cache (aws cloudfront create-invalidation)
```

### 8.6.3 Deployment Pipeline

#### 8.6.3.1 Deployment Strategy

**Rolling Deployment (Default)**:

- **Process**: Gradually replace old tasks with new tasks while maintaining full capacity
- **Configuration**: Maximum 200% capacity, minimum 100% healthy
- **Duration**: Typically 5-10 minutes for 3-task service
- **Advantages**: Zero downtime, automatic rollback on health check failures, simple implementation
- **Disadvantages**: Mixed version traffic during deployment (both old and new versions running simultaneously)

**Blue-Green Deployment (Optional for Production)**:

- **Process**: Deploy new version to separate task set (Green), validate, then switch ALB traffic
- **Implementation**: Requires duplicate target groups and weighted target group routing
- **Advantages**: Instant rollback (switch traffic back to Blue), full pre-production validation
- **Disadvantages**: Requires 2x capacity during deployment (higher cost), more complex setup

**Canary Deployment (Future Enhancement)**:

- **Process**: Route small percentage of traffic (5-10%) to new version, gradually increase if metrics healthy
- **Implementation**: Requires ALB weighted target groups with gradual traffic shifting
- **Advantages**: Minimize blast radius, detect issues before full rollout
- **Disadvantages**: Complex implementation, longer deployment duration (hours vs. minutes)

#### 8.6.3.2 Environment Promotion Workflow

**Promotion Path**:

```
Developer Local → Feature Branch → develop Branch (Dev Environment) 
  → staging Branch (Staging Environment) → main Branch (Production Environment)
```

**Environment-Specific Configuration**:

| Environment | Branch | Auto-Deploy | Approval Required | Deployment Frequency |
|-------------|--------|-------------|------------------|---------------------|
| **Development** | `develop` | Yes (on every push) | No | Multiple times/day |
| **Staging** | `staging` | Yes (on every push) | No | Daily (after feature completion) |
| **Production** | `main` | Yes (after approval) | Yes (manual approval) | Weekly or as-needed (hotfixes) |

#### 8.6.3.3 Rollback Procedures

**Automatic Rollback**:

CloudWatch alarms monitor deployment health; ECS automatically rolls back if alarms trigger:

```yaml
# Rollback trigger configuration (in ECS service definition)
deploymentConfiguration:
  deploymentCircuitBreaker:
    enable: true
    rollback: true

#### CloudWatch Alarms that trigger rollback:
#### - API error rate > 5% for 5 minutes
#### - API latency p95 > 2000ms for 5 minutes
#### - Task health check failures > 50% for 3 minutes
```

**Manual Rollback**:

```bash
# List recent task definitions
aws ecs list-task-definitions --family-prefix production-api --max-items 5

#### Identify previous stable revision (e.g., production-api:42)
PREVIOUS_REVISION=42

#### Update ECS service to use previous task definition
aws ecs update-service \
  --cluster production-cluster \
  --service api-service \
  --task-definition production-api:$PREVIOUS_REVISION \
  --force-new-deployment

#### Monitor rollback progress
aws ecs describe-services \
  --cluster production-cluster \
  --services api-service \
  --query 'services[0].deployments'

#### Wait for rollback to stabilize
aws ecs wait services-stable \
  --cluster production-cluster \
  --services api-service
```

#### 8.6.3.4 Post-Deployment Validation

**Automated Health Checks**:

1. **ALB Target Health**: Verify all new tasks pass ALB health checks (`/health` endpoint returns 200 OK)
2. **CloudWatch Alarms**: Monitor error rate, latency, CPU, memory for 15 minutes post-deployment
3. **Synthetic Monitoring**: CloudWatch Synthetics canary runs end-to-end API tests every 5 minutes
4. **Log Analysis**: CloudWatch Logs Insights query for ERROR/CRITICAL log entries

**Manual Validation Checklist** (Production Deployments):

- [ ] Check CloudWatch dashboard: All metrics within normal ranges
- [ ] Test critical user journeys: Login, document creation, AI completion
- [ ] Review ALB access logs: No abnormal 4xx/5xx error spike
- [ ] Verify external integrations: Auth0 authentication, OpenAI API calls successful
- [ ] Monitor Slack #alerts channel: No automated alerts triggered

#### 8.6.3.5 Release Management Process

**Semantic Versioning**: Application versions follow SemVer (Major.Minor.Patch)

| Version Component | Increment Trigger | Example |
|------------------|-------------------|---------|
| **Major** | Breaking API changes, incompatible schema changes | 1.0.0 → 2.0.0 |
| **Minor** | New features, backwards-compatible changes | 1.0.0 → 1.1.0 |
| **Patch** | Bug fixes, security patches | 1.0.0 → 1.0.1 |

**Release Workflow**:

```
1. Development Phase:
   - Feature branches merged to develop
   - Deployed to dev-cluster for testing

2. QA Phase:
   - develop merged to staging
   - Full regression testing on staging-cluster
   - Performance testing, load testing

3. Release Preparation:
   - Create release branch: release/v1.2.0
   - Update CHANGELOG.md with release notes
   - Tag release: git tag v1.2.0

4. Production Deployment:
   - Merge release branch to main
   - Manual approval in GitHub Actions
   - Deploy to production-cluster
   - Monitor for 1 hour post-deployment

5. Hotfix (if needed):
   - Create hotfix branch from main
   - Deploy directly to production after approval
   - Backport to develop and staging
```

---

## 8.7 Infrastructure Monitoring

### 8.7.1 Monitoring Platform Architecture

**Primary Monitoring Platform**: Amazon CloudWatch

**Monitoring Coverage**:

```mermaid
graph TB
    subgraph "Infrastructure Layer"
        ECS[ECS Fargate Tasks<br/>CPU, Memory, Network]
        ALB[Application Load Balancer<br/>Request Count, Latency, Errors]
        MongoDB[(MongoDB Atlas<br/>Connections, Query Time, Disk IOPS)]
        Redis[(Redis ElastiCache<br/>Memory, Evictions, Cache Hit Rate)]
        S3[S3 Buckets<br/>Storage Size, Request Metrics]
    end
    
    subgraph "Application Layer"
        API[Flask API Application<br/>Custom Metrics, Structured Logs]
        LangChain[LangChain Service<br/>AI Token Usage, Model Calls]
    end
    
    subgraph "CloudWatch - Central Monitoring Hub"
        Logs[CloudWatch Logs<br/>Structured JSON Logs<br/>30-day retention]
        Metrics[CloudWatch Metrics<br/>Infrastructure + Application<br/>15-month retention]
        Alarms[CloudWatch Alarms<br/>Multi-dimensional<br/>SNS notifications]
        Dashboards[CloudWatch Dashboards<br/>Operations, Business, Security]
        Synthetics[CloudWatch Synthetics<br/>Canary Monitoring<br/>5-minute intervals]
    end
    
    subgraph "Alerting & Notification"
        SNS[Amazon SNS Topics]
        Email[Email<br/>Operations Team]
        PagerDuty[PagerDuty<br/>On-Call Escalation]
        Slack[Slack<br/>#alerts Channel]
    end
    
    ECS -->|Container Logs| Logs
    ALB -->|Access Logs| Logs
    API -->|Structured JSON Logs| Logs
    LangChain -->|AI Operation Logs| Logs
    
    ECS -->|CPU, Memory, Network Metrics| Metrics
    ALB -->|Request Metrics| Metrics
    MongoDB -->|Database Metrics| Metrics
    Redis -->|Cache Metrics| Metrics
    S3 -->|Storage Metrics| Metrics
    API -->|Custom Application Metrics| Metrics
    LangChain -->|AI Token Metrics| Metrics
    
    Metrics -->|Threshold Evaluation| Alarms
    Alarms -->|Notifications| SNS
    
    SNS --> Email
    SNS --> PagerDuty
    SNS --> Slack
    
    Metrics --> Dashboards
    Logs --> Dashboards
    
    Synthetics -.->|HTTP Probes| ALB
    Synthetics -->|Success/Failure Metrics| Metrics
    
    style Logs fill:#E3F2FD
    style Metrics fill:#FFF3E0
    style Alarms fill:#FFCDD2
    style Dashboards fill:#C8E6C9
```

### 8.7.2 Resource Monitoring Approach

#### 8.7.2.1 ECS Infrastructure Metrics

**Automatic CloudWatch Metrics** (No instrumentation required):

| Metric Name | Dimension | Unit | Alert Threshold |
|------------|-----------|------|----------------|
| `CPUUtilization` | Service | Percent | > 80% for 10 minutes |
| `MemoryUtilization` | Service | Percent | > 85% for 10 minutes |
| `RunningTaskCount` | Service | Count | < 2 tasks (insufficient capacity) |
| `DesiredTaskCount` | Service | Count | N/A (informational) |

**CloudWatch Container Insights Metrics**:

| Metric Category | Metrics Collected | Purpose |
|----------------|------------------|---------|
| **Task-Level** | CPU reserved, CPU utilized, memory reserved, memory utilized | Per-task resource consumption |
| **Service-Level** | CPU utilization %, memory utilization %, task count | Service-wide aggregation |
| **Network** | Network RX bytes, network TX bytes | Network traffic patterns |

#### 8.7.2.2 Application Load Balancer Metrics

| Metric Name | Unit | Dimension | Purpose |
|------------|------|-----------|---------|
| `RequestCount` | Count | TargetGroup | Total API requests received |
| `TargetResponseTime` | Seconds | TargetGroup | API latency at ALB level (includes ECS processing time) |
| `HTTPCode_Target_4XX_Count` | Count | TargetGroup | Client errors (authentication failures, bad requests) |
| `HTTPCode_Target_5XX_Count` | Count | TargetGroup | Server errors (application crashes, database failures) |
| `HealthyHostCount` | Count | TargetGroup | Number of healthy ECS tasks |
| `UnHealthyHostCount` | Count | TargetGroup | Number of failing ECS tasks |

### 8.7.3 Performance Metrics Collection

**Custom Application Metrics** (Emitted via CloudWatch PutMetricData API):

| Metric Name | Type | Unit | Dimensions | Purpose |
|------------|------|------|------------|---------|
| `api.request.count` | Counter | Count | Service, Environment, Endpoint, Method | Request volume per endpoint |
| `api.request.duration` | Histogram | Milliseconds | Service, Environment, Endpoint | Latency distribution (p50, p95, p99) |
| `api.error.rate` | Gauge | Percent | Service, Environment, Endpoint | Error percentage per endpoint |
| `api.cache.hit_rate` | Gauge | Percent | Service, Environment | Redis cache effectiveness |
| `ai.tokens.consumed` | Counter | Count | Service, Model | OpenAI token usage for cost tracking |
| `ai.request.duration` | Histogram | Milliseconds | Service, Model | AI operation latency |
| `auth.jwt.validation.latency` | Histogram | Milliseconds | Service | Authentication performance |

**Metric Emission Implementation**:

```python
# backend/app/monitoring.py (pseudocode illustration)
import boto3
from datetime import datetime

cloudwatch = boto3.client('cloudwatch')

def emit_metric(metric_name, value, unit, dimensions):
    """Emit custom CloudWatch metric"""
    cloudwatch.put_metric_data(
        Namespace='CheckSameRepoNoPrompt/API',
        MetricData=[
            {
                'MetricName': metric_name,
                'Value': value,
                'Unit': unit,
                'Timestamp': datetime.utcnow(),
                'Dimensions': dimensions
            }
        ]
    )

#### Usage in API request handler
@app.route('/api/v1/documents', methods=['GET'])
def get_documents():
    start_time = time.time()
    
    try:
#### Business logic
        documents = fetch_documents_from_db()
        
#### Emit success metrics
        duration_ms = (time.time() - start_time) * 1000
        emit_metric(
            metric_name='api.request.duration',
            value=duration_ms,
            unit='Milliseconds',
            dimensions=[
                {'Name': 'Service', 'Value': 'api'},
                {'Name': 'Endpoint', 'Value': '/api/v1/documents'},
                {'Name': 'Environment', 'Value': 'production'}
            ]
        )
        
        return jsonify(documents), 200
        
    except Exception as e:
#### Emit error metrics
        emit_metric(
            metric_name='api.error.count',
            value=1,
            unit='Count',
            dimensions=[
                {'Name': 'Service', 'Value': 'api'},
                {'Name': 'Endpoint', 'Value': '/api/v1/documents'},
                {'Name': 'ErrorType', 'Value': type(e).__name__}
            ]
        )
        raise
```

### 8.7.4 Cost Monitoring and Optimization

**AWS Cost Explorer Integration**:

- **Daily Cost Reports**: Automated email with previous day's infrastructure costs
- **Budget Alerts**: AWS Budgets configured to alert at 80%, 100%, 120% of monthly budget
- **Cost Allocation Tags**: All resources tagged with `Environment`, `Service`, `ManagedBy` for cost attribution

**Cost Monitoring Metrics**:

| Cost Category | Monthly Budget | Monitoring Method | Optimization Strategy |
|--------------|----------------|-------------------|----------------------|
| **ECS Fargate Compute** | $50-250 | CloudWatch metrics → cost per task-hour | Fargate Savings Plans after 6 months stable usage |
| **Data Transfer** | $20-50 | CloudWatch metrics → data transfer out | CloudFront caching to reduce origin requests |
| **CloudWatch Logs** | $30 | AWS Cost Explorer | Log sampling for high-volume endpoints (health checks) |
| **NAT Gateway** | $108 | AWS Cost Explorer → GB processed | VPC endpoints for S3 (eliminate NAT costs for S3 traffic) |
| **Total Infrastructure** | $200-400 | AWS Budgets with SNS alerts | Monthly review, right-sizing resources |

### 8.7.5 Security Monitoring

**Security Event Tracking via CloudWatch**:

| Security Event Type | Log Source | Alert Threshold | Response Action |
|--------------------|-----------|----------------|----------------|
| **Failed Authentication** | Application logs (WARNING level) | > 5 attempts/min from single IP | Temporary IP ban, security team notification |
| **Invalid JWT Token** | Application logs (WARNING level) | > 10/min | Investigate token source, potential Auth0 compromise |
| **Permission Denied** | Audit logs (INFO level) | > 50/min for single user | Review user permissions, investigate potential attack |
| **Rate Limit Exceeded** | Application logs (WARNING level) | > 100/min across all users | DDoS detection, enable stricter rate limiting |
| **ECS Task Launch Failures** | CloudWatch Events | > 0 failures | Deployment issue investigation, rollback if widespread |

**CloudWatch Logs Insights Security Queries**:

```sql
# Query 1: Failed authentication attempts by IP address (last hour)
fields @timestamp, ip_address, user_id, message
| filter level = "WARNING" and message like /authentication failed/
| stats count() as attempts by ip_address
| sort attempts desc

#### Query 2: Top 10 users with permission denied errors (last 24 hours)
fields @timestamp, user_id, endpoint, message
| filter level = "INFO" and message like /permission denied/
| stats count() as denied_count by user_id
| sort denied_count desc
| limit 10

#### Query 3: Critical errors requiring immediate attention
fields @timestamp, request_id, level, message, metadata
| filter level = "CRITICAL"
| sort @timestamp desc
```

### 8.7.6 Compliance Auditing

**Audit Log Monitoring**:

- **Log Group**: `/ecs/production-api/audit`
- **Retention**: 90 days active (CloudWatch Logs), 7 years archived (S3 Glacier)
- **Contents**: Authentication events, authorization decisions, data modifications, administrative actions

**Compliance Metrics**:

| Compliance Requirement | Monitoring Method | Evidence Collection |
|-----------------------|-------------------|-------------------|
| **SOC 2 CC6.1** (Logical Access) | Authentication success/failure rate, MFA challenge rate | Monthly audit log exports to S3 |
| **SOC 2 CC7.2** (System Monitoring) | CloudWatch alarm triggers, incident response time | Incident reports in MongoDB `incidents` collection |
| **GDPR Art. 30** (Records of Processing) | Data access logs, modification events, deletion requests | Immutable audit logs, 7-year retention |

---

## 8.8 Infrastructure Cost Estimates

### 8.8.1 Detailed Monthly Cost Breakdown

**Production Environment Cost Estimate** (Based on moderate usage):

| Component | Configuration | Unit Cost | Usage | Monthly Cost |
|-----------|--------------|-----------|-------|-------------|
| **ECS Fargate (vCPU)** | 0.5 vCPU × 3 tasks | $0.04048 per vCPU-hour | 3 tasks × 730 hours × 0.5 vCPU | $44.43 |
| **ECS Fargate (Memory)** | 1 GB × 3 tasks | $0.004445 per GB-hour | 3 tasks × 730 hours × 1 GB | $9.74 |
| **Application Load Balancer** | Standard ALB | $0.0225 per hour + $0.008 per LCU | 730 hours + 50 LCUs | $20.83 |
| **NAT Gateway** | 3 NAT gateways (Multi-AZ) | $0.045 per hour + $0.045 per GB | 3 × 730 hours + 500 GB | $121.05 |
| **MongoDB Atlas** | M10 tier (2 vCPU, 4 GB RAM) | $0.08 per hour | 730 hours | $58.40 |
| **ElastiCache Redis** | cache.t3.micro | $0.017 per hour | 730 hours | $12.41 |
| **Amazon S3** | Storage (100 GB) + Requests | $0.023 per GB + API costs | 100 GB + 1M requests | $5.30 |
| **S3 Data Transfer Out** | 500 GB to internet | $0.09 per GB | 500 GB | $45.00 |
| **Amazon ECR** | 10 GB image storage | $0.10 per GB/month | 10 GB | $1.00 |
| **CloudWatch Logs** | 20 GB ingestion/month | $0.50 per GB ingestion | 20 GB | $10.00 |
| **CloudWatch Metrics** | Custom metrics | $0.30 per metric/month | 50 metrics | $15.00 |
| **CloudWatch Alarms** | Standard alarms | $0.10 per alarm/month | 20 alarms | $2.00 |
| **AWS Secrets Manager** | 10 secrets | $0.40 per secret/month | 10 secrets | $4.00 |
| **Amazon SNS** | Email notifications | $0.50 per 1M requests | 1,000 notifications | $0.05 |
| **AWS Certificate Manager** | TLS certificates | Free | N/A | $0.00 |
| **CloudFront CDN** | 1 TB data transfer | $0.085 per GB | 1,000 GB | $85.00 |
| **Route 53** | Hosted zone + queries | $0.50 per zone + $0.40 per 1M queries | 1 zone + 10M queries | $4.50 |
| **Data Transfer (Inter-AZ)** | ECS ↔ MongoDB/Redis | $0.01 per GB | 200 GB | $2.00 |
| **Miscellaneous** | CloudWatch Synthetics, X-Ray, etc. | Various | Low usage | $5.00 |
| | | | **TOTAL** | **$445.71/month** |

**Cost Optimization Scenarios**:

| Scenario | Changes | Monthly Cost | Savings |
|----------|---------|-------------|---------|
| **Minimal Deployment** | 2 tasks min, cache.t3.nano Redis, single NAT gateway | $285/month | -36% ($160 saved) |
| **Production (Current)** | 3 tasks avg, cache.t3.micro Redis, 3 NAT gateways (HA) | $446/month | Baseline |
| **High Traffic** | 6 tasks avg, MongoDB M20 tier, cache.t3.small Redis | $725/month | +63% ($279 additional) |
| **Reserved Capacity** | Fargate Savings Plan (1-year), reserved NAT | $362/month | -19% ($84 saved) |

### 8.8.2 Cost Scaling Projections

**Infrastructure Cost Scaling** (First Year Projections):

| Month | Expected Users | Tasks Avg | MongoDB Tier | Monthly Cost | Cumulative Cost |
|-------|---------------|-----------|--------------|-------------|----------------|
| **Month 1-3** | 100-500 | 2-3 | M10 | $320 | $960 |
| **Month 4-6** | 500-2000 | 3-5 | M10 | $420 | $2,220 |
| **Month 7-9** | 2000-5000 | 5-7 | M20 ($116/mo) | $580 | $3,960 |
| **Month 10-12** | 5000-10000 | 7-10 | M30 ($200/mo) | $780 | $6,300 |
| | | | **Year 1 Total** | **$515 avg/month** | **~$6,180** |

---

## 8.9 Infrastructure References

### 8.9.1 Technical Specification Sections Referenced

- **Section 1.2 - System Overview**: Project implementation status, planned architecture context
- **Section 3.1 - Technology Stack Overview**: Overall technology architecture, cloud services selection
- **Section 3.5 - Third-Party Services**: Auth0, AWS services, OpenAI API integration specifications
- **Section 3.6 - Databases & Storage**: MongoDB, Redis, S3 architecture and configuration details
- **Section 3.7 - Development & Deployment**: Comprehensive CI/CD, Docker, Terraform, GitHub Actions specifications
- **Section 4.2 - CI/CD Workflows**: Detailed pipeline specifications for backend, frontend, mobile, infrastructure
- **Section 5.1 - High-Level Architecture**: System architecture, multi-AZ deployment, service boundaries
- **Section 6.1 - Core Services Architecture**: Service component details, scaling strategies, resilience patterns
- **Section 6.4 - Security Architecture**: Network security, VPC design, security groups, encryption, IAM roles
- **Section 6.5 - Monitoring and Observability**: CloudWatch monitoring, logging, metrics, alerting, dashboards

### 8.9.2 Repository Files Examined

- **`README.md`** (root directory): Project title "CheckSameRepoNoPrompt"; repository in pre-implementation phase with no infrastructure code, configuration files, or implementation

### 8.9.3 Repository Folders Explored

- **Root Directory** (`/`): Contains only README.md file; no infrastructure code, Terraform modules, Dockerfiles, docker-compose.yml, GitHub Actions workflows, or deployment scripts

### 8.9.4 AWS Services and Technologies Referenced

**Compute & Container Services**:
- Amazon ECS (Elastic Container Service) - Container orchestration platform
- AWS Fargate - Serverless compute engine for containers (version 1.4.0+)
- Application Load Balancer (ALB) - Layer 7 load balancing with health checks
- Amazon ECR (Elastic Container Registry) - Private Docker image registry with vulnerability scanning

**Networking Services**:
- Amazon VPC - Virtual Private Cloud for network isolation (10.0.0.0/16 CIDR)
- Internet Gateway - Public internet access for public subnets
- NAT Gateway - Outbound internet access for private subnets (3 gateways for Multi-AZ HA)
- Security Groups - Stateful virtual firewalls for port-level access control
- Route 53 - DNS management and health checks

**Storage Services**:
- Amazon S3 - Object storage (Standard, Standard-IA, Glacier storage classes)
- Amazon EBS - Block storage (gp3 volumes for self-hosted databases, optional)
- S3 Lifecycle Policies - Automatic storage class transitions for cost optimization

**Database Services**:
- MongoDB Atlas - Managed MongoDB (M10-M30 tiers, 3-node replica sets)
- Amazon ElastiCache for Redis - Managed Redis (cache.t3.micro-small instances)

**Security Services**:
- AWS Secrets Manager - Secure credential storage with automatic rotation
- AWS Certificate Manager (ACM) - Free TLS/SSL certificates with auto-renewal
- AWS IAM - Identity and Access Management (roles, policies, least privilege)
- AWS Key Management Service (KMS) - Encryption key management (customer-managed keys)

**Monitoring & Logging**:
- Amazon CloudWatch Logs - Centralized log aggregation (30-day retention, S3 archival)
- Amazon CloudWatch Metrics - Performance metrics (1-minute resolution, 15-month retention)
- Amazon CloudWatch Alarms - Automated alerting with multi-dimensional metrics
- Amazon CloudWatch Dashboards - Real-time monitoring visualization
- AWS X-Ray - Distributed tracing and service maps (optional)
- CloudWatch Synthetics - Automated canary monitoring

**Developer Tools & CI/CD**:
- GitHub Actions - CI/CD platform for automated testing and deployment
- AWS CLI - Command-line interface for AWS service management
- AWS SDK (Boto3) - Python SDK for AWS service integration
- Docker 24+ - Containerization platform
- Terraform 1.6+ - Infrastructure as Code (IaC) tool

**Additional Services**:
- Amazon SNS - Notification service for CloudWatch alarm routing
- Amazon CloudFront - Global content delivery network (CDN) for static assets
- AWS Systems Manager Parameter Store - Application configuration storage
- AWS Cost Explorer - Cost analysis and optimization
- AWS Budgets - Cost monitoring with automated alerts

### 8.9.5 Third-Party Tools and Services Referenced

**Infrastructure as Code**:
- Terraform 1.6+ (HashiCorp) - Declarative infrastructure provisioning
- Terraform AWS Provider - Official AWS resource definitions
- Terraform S3 Backend - Remote state storage with DynamoDB locking

**Containerization & Orchestration**:
- Docker 24+ - Container runtime and image building
- Docker Compose - Local multi-container development orchestration
- Multi-stage Dockerfiles - Build optimization technique

**CI/CD & DevOps**:
- GitHub Actions - Native CI/CD platform (2,000-3,000 free minutes/month)
- GitHub Environments - Deployment protection rules and manual approvals
- GitHub Secrets - Secure credential storage for CI/CD pipelines

**Monitoring & Alerting (Optional Integrations)**:
- PagerDuty - On-call management and incident escalation
- Slack - Team collaboration and alert notifications
- DataDog APM - Advanced application performance monitoring (optional)
- Sentry - Error tracking and debugging (optional)

**External Services**:
- Auth0 - Identity-as-a-Service provider (OAuth 2.0, OIDC, MFA)
- MongoDB Atlas - Managed MongoDB database hosting
- OpenAI API - LLM services (GPT-4, GPT-3.5, embeddings)

### 8.9.6 Key Implementation Findings

**Infrastructure Architecture Summary**:

1. **Cloud-Native AWS Deployment**: Fully serverless container architecture using ECS Fargate eliminates server management, enabling focus on application development rather than infrastructure operations.

2. **Multi-Availability Zone High Availability**: All critical components deployed across 3 availability zones (us-east-1a/b/c) ensures 99.9% uptime SLA with automatic failover for both application and database layers.

3. **Infrastructure as Code**: Complete Terraform 1.6+ implementation enables version-controlled, reproducible infrastructure with separate modules for networking, compute, storage, monitoring, and security.

4. **Comprehensive CI/CD Automation**: GitHub Actions workflows automate the entire deployment pipeline from code commit through production deployment, including automated testing, Docker image building, vulnerability scanning, and ECS service updates.

5. **Advanced Monitoring & Observability**: CloudWatch provides centralized monitoring with structured JSON logs, custom application metrics, multi-dimensional alarms, and role-specific dashboards for operations, business, and security teams.

6. **Security-First Network Design**: Private VPC subnets isolate backend services from public access, security groups enforce port-level restrictions, and all data encrypted at rest (AES-256) and in transit (TLS 1.3).

7. **Cost-Optimized Architecture**: Initial production deployment estimated at $446/month with clear scaling path; right-sizing resources, CloudWatch log sampling, and S3 lifecycle policies minimize costs while maintaining performance.

8. **Pre-Implementation Status**: Repository contains only README.md file; all infrastructure components, Terraform modules, Dockerfiles, CI/CD workflows, and monitoring configuration represent planned architecture pending development phase execution.

**Total Research Depth**: 17 comprehensive searches across repository and technical specification sections, synthesized into complete infrastructure documentation spanning deployment environments, cloud services, containerization, orchestration, CI/CD pipelines, and monitoring infrastructure.

---

**Document Metadata**:
- **Section**: 8. Infrastructure
- **Version**: 1.0 (Planned Architecture)
- **Date**: January 2024
- **Status**: Pre-Implementation (Design Phase)
- **Implementation Code**: None (repository contains only README.md)
- **Next Steps**: Development team to implement infrastructure per this specification, beginning with Terraform module development, Docker container creation, and CI/CD pipeline configuration during initial deployment phase.

# 9. Appendices

## 9.1 Additional Technical Information

### 9.1.1 AWS Infrastructure Configuration Details

#### 9.1.1.1 ECS Task Definition Specifications

The ECS Fargate deployment utilizes containerized Flask API instances with the following resource allocations:

**Task Resource Configuration:**
- **Task CPU**: 512 CPU units (0.5 vCPU)
- **Task Memory**: 1024 MiB (1 GB RAM)
- **Task Execution Role**: ECS task execution role with permissions for ECR image pulling, CloudWatch log creation, and Secrets Manager access
- **Task Role**: Application-specific role with permissions for S3, MongoDB access, and AWS service interactions

**Container Configuration:**
- **Container CPU**: 512 CPU units (100% of task CPU)
- **Container Memory**: Hard limit 1024 MiB
- **Memory Reservation**: Soft limit 512 MiB
- **Essential Container**: True (task fails if container stops)

**Health Check Configuration:**
```json
{
  "command": ["CMD-SHELL", "curl -f http://localhost:5000/health || exit 1"],
  "interval": 30,
  "timeout": 5,
  "retries": 3,
  "startPeriod": 60
}
```

#### 9.1.1.2 Application Load Balancer Configuration

**Target Group Settings:**
- **Protocol**: HTTP (internal VPC traffic)
- **Port**: 5000
- **Health Check Path**: `/health`
- **Health Check Interval**: 30 seconds
- **Health Check Timeout**: 5 seconds
- **Healthy Threshold**: 2 consecutive successful checks
- **Unhealthy Threshold**: 2 consecutive failed checks
- **Deregistration Delay**: 30 seconds (connection draining)

**Listener Rules:**
- **Port 443**: HTTPS listener with SSL/TLS termination
- **Certificate**: AWS Certificate Manager (ACM) certificate
- **Security Policy**: ELBSecurityPolicy-TLS-1-3-2021-06 (TLS 1.3 with TLS 1.2 fallback)
- **Default Action**: Forward to ECS target group

#### 9.1.1.3 VPC Network Configuration

**VPC Architecture:**
- **CIDR Block**: 10.0.0.0/16 (65,536 IP addresses)
- **Availability Zones**: 3 AZs for high availability
- **Public Subnets**: 3 subnets (one per AZ) for ALB
  - CIDR: 10.0.1.0/24, 10.0.2.0/24, 10.0.3.0/24
- **Private Subnets**: 3 subnets (one per AZ) for ECS tasks and databases
  - CIDR: 10.0.11.0/24, 10.0.12.0/24, 10.0.13.0/24
- **NAT Gateway**: One NAT Gateway per AZ for high availability
- **Internet Gateway**: Single IGW attached to VPC for public subnet internet access

**Security Group Rules:**

| Security Group | Inbound Rules | Outbound Rules |
|---------------|---------------|----------------|
| ALB Security Group | Port 443 from 0.0.0.0/0 (internet) | Port 5000 to ECS Security Group |
| ECS Security Group | Port 5000 from ALB Security Group | All ports to 0.0.0.0/0 (MongoDB, Redis, S3, internet) |
| MongoDB Security Group | Port 27017 from ECS Security Group | None required |
| Redis Security Group | Port 6379 from ECS Security Group | None required |

#### 9.1.1.4 CloudWatch Monitoring Configuration

**Log Groups:**
- `/aws/ecs/flask-api`: Application logs from ECS tasks
  - **Retention**: 30 days
  - **Log Stream**: One per ECS task (task-id)
- `/aws/ecs/langchain-service`: LangChain AI service logs
  - **Retention**: 30 days

**Metrics and Alarms:**

| Metric | Alarm Threshold | Evaluation Period | Action |
|--------|----------------|-------------------|--------|
| ECS CPU Utilization | > 80% | 2 consecutive 5-minute periods | Scale out (add tasks) |
| ECS Memory Utilization | > 80% | 2 consecutive 5-minute periods | Scale out (add tasks) |
| ALB 5XX Error Rate | > 5% | 1 minute | Alert operations team |
| ALB Target Health | < 2 healthy targets | 1 minute | Alert operations team |
| MongoDB Replica Set Lag | > 5 seconds | 2 consecutive 1-minute periods | Alert database team |
| Redis Cache Hit Rate | < 60% | 5 consecutive 5-minute periods | Review cache strategy |

### 9.1.2 Token Lifecycle Management Specifications

#### 9.1.2.1 JWT Token Structure and Validation

**Access Token Claims:**
```json
{
  "iss": "https://{tenant}.auth0.com/",
  "sub": "auth0|{user-id}",
  "aud": "{api-identifier}",
  "iat": 1705320000,
  "exp": 1705320900,
  "azp": "{client-id}",
  "scope": "openid profile email",
  "permissions": ["read:documents", "write:documents", "ai:completions"]
}
```

**Token Validation Steps:**
1. **Signature Verification**: Verify JWT signature using RS256 algorithm with Auth0 public keys (JWKS)
2. **Issuer Validation**: Confirm `iss` claim matches expected Auth0 domain
3. **Audience Validation**: Verify `aud` claim matches API identifier
4. **Expiration Validation**: Ensure current time < `exp` claim (with 30-second clock skew tolerance)
5. **Issued At Validation**: Verify `iat` claim is in the past
6. **Permission Extraction**: Extract `permissions` array for authorization checks

#### 9.1.2.2 Token Refresh Flow

**Silent Token Renewal Process:**
1. Client detects access token expiration (within 5 minutes of `exp`)
2. Client sends refresh token to Auth0 token endpoint
3. Auth0 validates refresh token and issues new access token
4. Client stores new access token and continues API requests
5. If refresh token expired, redirect user to login

**Refresh Token Rotation (Optional Security Enhancement):**
- Each token refresh issues new refresh token
- Previous refresh token invalidated immediately
- Prevents replay attacks with stolen refresh tokens

### 9.1.3 Cache TTL Strategy Details

**Time-to-Live Configuration by Data Type:**

| Data Type | TTL | Rationale | Invalidation Strategy |
|-----------|-----|-----------|----------------------|
| User Profile | 15 minutes | Matches JWT token lifetime | Event-based on profile update |
| Document List | 5 minutes | Balance freshness and performance | Event-based on document CRUD |
| Single Document | 5 minutes | Frequently accessed content | Event-based on document update |
| AI Completion Response | 1 hour | Expensive to regenerate, acceptable staleness | Prompt hash-based cache key |
| Search Results | 5 minutes | Dynamic content | Event-based on document changes |
| JWKS Public Keys | 1 hour | Auth0 rotates keys infrequently | TTL-based only |
| Rate Limit Counter | 60 seconds | Sliding window rate limiting | TTL-based expiration |
| Static Configuration | 24 hours | Rarely changes | Event-based on configuration update |

### 9.1.4 Database Index Performance Characteristics

**Index Selectivity Analysis:**

| Collection | Index | Cardinality | Selectivity | Impact on Query Performance |
|-----------|-------|-------------|-------------|----------------------------|
| `users` | `auth0_id` (unique) | 1:1 | Very High | Excellent (< 5ms lookups) |
| `users` | `email` | 1:1 | Very High | Excellent (< 5ms lookups) |
| `conversations` | `user_id` | 1:N (avg 50) | Medium | Good (< 20ms for user conversations) |
| `conversations` | `created_at` | 1:Many | Low | Poor alone, excellent with compound |
| `conversations` | `{user_id, created_at}` compound | 1:1 effectively | Very High | Excellent (< 10ms paginated queries) |
| `messages` | `conversation_id` | 1:N (avg 20) | Medium | Good (< 15ms for conversation messages) |
| `documents` | `user_id` | 1:N (avg 100) | Medium | Good (< 30ms for user documents) |
| `documents` | `filename` (text) | 1:Many | Low | Moderate (50-200ms full-text search) |

**Index Size Estimates:**

| Collection | Documents | Average Doc Size | Index Overhead | Total Index Size |
|-----------|-----------|-----------------|----------------|-----------------|
| `users` | 100,000 | 100 KB | 8% | 800 MB |
| `conversations` | 5,000,000 | 10 KB | 10% | 5 GB |
| `messages` | 100,000,000 | 5 KB | 12% | 60 GB |
| `documents` | 10,000,000 | 50 KB | 9% | 45 GB |
| `ai_interactions` | 50,000,000 | 20 KB | 11% | 110 GB |
| `analytics` | 200,000,000 | 5 KB | 10% | 100 GB |

### 9.1.5 Deployment Strategies Specifications

#### 9.1.5.1 Rolling Deployment Configuration

**ECS Rolling Deployment Settings:**
- **Minimum Healthy Percent**: 100% (no capacity reduction during deployment)
- **Maximum Percent**: 200% (double capacity during deployment)
- **Deployment Circuit Breaker**: Enabled (automatic rollback on repeated failures)
- **Failure Threshold**: 3 consecutive task failures trigger rollback

**Deployment Sequence:**
1. ECS starts new tasks with updated Docker image
2. New tasks pass health checks (ALB target group health checks)
3. ECS drains connections from old tasks (30-second deregistration delay)
4. ECS stops old tasks
5. Deployment complete when all new tasks healthy

**Rollback Triggers:**
- Task fails to start (e.g., image pull error, container crash)
- Task fails health checks after 3 retries
- Manual rollback initiated by operations team

#### 9.1.5.2 Blue-Green Deployment (Future Enhancement)

**Planned Blue-Green Deployment Architecture:**
- **Blue Environment**: Current production environment
- **Green Environment**: New version deployed to separate ECS service
- **Traffic Switch**: ALB listener rule weighted routing (0% → 100% to green)
- **Validation**: Test green environment with 5% traffic before full cutover
- **Rollback**: Instant traffic switch back to blue if issues detected
- **Cleanup**: Terminate blue environment after green stable for 24 hours

#### 9.1.5.3 Canary Deployment (Future Enhancement)

**Planned Canary Deployment Strategy:**
1. Deploy new version to 5% of tasks
2. Monitor metrics for 15 minutes (error rates, latency, resource utilization)
3. If metrics acceptable, increase to 25% of tasks
4. Continue monitoring for 15 minutes
5. If metrics still acceptable, proceed to 50%, then 100%
6. Automatic rollback if error rate exceeds baseline + 2 standard deviations

### 9.1.6 Disaster Recovery Procedures

#### 9.1.6.1 MongoDB Replica Set Failover

**Automatic Failover Process:**
1. **Failure Detection**: Secondary nodes detect Primary failure via missed heartbeats (10 seconds)
2. **Election Initiation**: Remaining replica set members initiate Raft consensus election
3. **Priority Evaluation**: Secondary with highest priority and most recent oplog elected
4. **Election Completion**: New Primary elected in < 5 seconds
5. **Application Reconnection**: PyMongo driver automatically detects new Primary and reconnects
6. **Total Downtime**: < 15 seconds from failure to new Primary operational

**Manual Failover (Maintenance Scenarios):**
```javascript
// Connect to replica set
rs.stepDown(60)  // Primary steps down for 60 seconds, triggers election
```

#### 9.1.6.2 Multi-AZ Failure Recovery

**Availability Zone Failure Scenario:**
- **Impact**: 33% capacity loss (1 of 3 AZs)
- **ALB Response**: Automatically routes all traffic to healthy AZs
- **Auto-Scaling**: Detects capacity reduction, launches new tasks in healthy AZs
- **Recovery Time**: < 5 minutes for full capacity restoration
- **User Impact**: None (seamless failover)

#### 9.1.6.3 Database Restore Procedures

**Point-in-Time Recovery (MongoDB Atlas):**
1. Access MongoDB Atlas console
2. Navigate to cluster → Backup tab
3. Select "Restore to Point in Time"
4. Specify target timestamp (within 7-day window)
5. Choose restore target:
   - Same cluster (replace production data)
   - New cluster (restore to separate cluster for validation)
6. Initiate restore (15-60 minutes for 100GB database)
7. Verify data integrity after restore
8. Update application connection strings if restored to new cluster

**Manual Backup Restore (S3-based backups):**
1. Download backup from S3: `aws s3 cp s3://app-backups/mongodb/backup-2024-01-15.tar.gz .`
2. Extract backup: `tar -xzf backup-2024-01-15.tar.gz`
3. Restore to MongoDB: `mongorestore --uri="mongodb://..." --dir=./backup-2024-01-15/`
4. Verify document counts match expected values
5. Rebuild indexes if necessary: `db.collection.reIndex()`
6. Update application to point to restored database

---

## 9.2 GLOSSARY

#### A

**API-First Design**: An architectural approach where the API is designed and implemented before any client applications, ensuring consistent business logic and simplified maintenance across multiple platforms.

**Asynchronous Replication**: A database replication method where write operations are immediately acknowledged after writing to the primary database, with replication to secondary databases occurring afterward, typically within milliseconds to seconds.

**Authentication**: The process of verifying the identity of a user or system through credentials such as username/password, JWT tokens, or multi-factor authentication mechanisms.

**Authorization**: The process of determining whether an authenticated user has permission to access specific resources or perform specific actions, typically implemented through Permission-Based Access Control (PBAC).

**Auto-Scaling**: An automated cloud infrastructure capability that dynamically adjusts the number of running application instances based on current load, ensuring optimal resource utilization and performance.

#### B

**Blue-Green Deployment**: A deployment strategy that maintains two identical production environments (blue and green), allowing instant traffic switching between versions for zero-downtime deployments and rapid rollback capability.

**Bulk Write Operation**: A database optimization technique that batches multiple write operations (inserts, updates, deletes) into a single network request, significantly reducing round-trip time and improving throughput.

#### C

**Cache-Aside Pattern**: A caching strategy where the application code is responsible for loading data into the cache on cache misses and invalidating cache entries on updates, providing fine-grained control over cache behavior.

**Cache Hit Rate**: The percentage of cache requests that return cached data without requiring a database query, with higher rates (70%+) indicating effective caching and improved application performance.

**Cache Stampede**: A scenario where multiple concurrent requests for the same expired cache key simultaneously query the database, potentially overwhelming it; prevented using distributed locks.

**Canary Deployment**: A progressive deployment strategy that gradually rolls out new versions to increasing percentages of users, allowing real-time validation and automatic rollback if metrics indicate issues.

**Circuit Breaker Pattern**: A fault tolerance pattern that prevents cascading failures by detecting service failures and temporarily blocking requests to failing services, returning cached or fallback responses instead.

**Cloud-Native Architecture**: An application architecture designed specifically for cloud environments, leveraging containerization, microservices, auto-scaling, and managed services for scalability and resilience.

**Compound Index**: A database index that includes multiple fields, enabling efficient queries that filter or sort by multiple criteria simultaneously and improving query performance by 10-100x.

**Connection Pooling**: A technique that maintains a pool of reusable database connections, eliminating per-request connection establishment overhead and enabling burst traffic handling with pre-warmed connections.

**Container Orchestration**: The automated management of containerized application lifecycle, including deployment, scaling, networking, and health monitoring, typically implemented using Amazon ECS or Kubernetes.

#### D

**Defense-in-Depth Security**: A layered security approach that implements multiple independent security controls at different levels (network, application, data), ensuring that compromise of one layer doesn't compromise the entire system.

**Distributed Lock**: A synchronization mechanism that coordinates access to shared resources across multiple application instances, preventing race conditions and ensuring data consistency in distributed systems.

**Document Database**: A NoSQL database (like MongoDB) that stores data as flexible JSON-like documents, allowing schema evolution and naturally mapping to application objects without impedance mismatch.

#### E

**Embedding (Vector Embedding)**: A high-dimensional numerical representation of text or data (e.g., 1536 dimensions) that captures semantic meaning, enabling similarity searches and AI-powered features like document retrieval.

**Event-Based Invalidation**: A cache invalidation strategy that immediately removes or updates cached data when the underlying data changes, ensuring cache consistency across distributed systems.

**Exponential Backoff**: A retry strategy that progressively increases wait time between retry attempts (e.g., 0.1s, 0.2s, 0.4s), reducing load on failing services while allowing recovery time.

#### F

**Failover**: The automatic process of switching from a failed primary system to a backup secondary system, typically completed in seconds for database replica sets or application load balancers.

**Full-Text Search**: A database feature that indexes text content and enables efficient keyword searches, supporting use cases like document title and content searches with relevance ranking.

#### H

**Horizontal Scaling**: The ability to increase system capacity by adding more instances of application or database nodes, enabling near-linear scalability for read-heavy and write-heavy workloads.

**HNSW (Hierarchical Navigable Small World)**: An algorithm for approximate nearest neighbor search in high-dimensional vector spaces, enabling fast similarity searches in vector databases with slight accuracy trade-offs.

#### I

**Idempotent Operation**: An operation that produces the same result when executed multiple times, critical for safely retrying failed requests without unintended side effects (e.g., PUT and DELETE HTTP methods).

**Index Covering**: A database optimization where a query can be satisfied entirely from index data without accessing the underlying documents, reducing query latency by 90%+ for projection queries.

**Infrastructure as Code (IaC)**: The practice of managing infrastructure through version-controlled configuration files (e.g., Terraform), enabling reproducible deployments, change tracking, and automated provisioning.

#### J

**JSON Web Token (JWT)**: A compact, URL-safe token format that contains cryptographically signed claims about a user's identity and permissions, used for stateless authentication in API requests.

**JWKS (JSON Web Key Set)**: A set of public keys published by an identity provider (e.g., Auth0) that API servers use to verify JWT signatures, typically cached for 1 hour to reduce latency.

#### L

**LangChain**: An open-source framework for building applications with Large Language Models (LLMs), providing abstractions for prompt management, chain composition, and RAG (Retrieval-Augmented Generation) workflows.

**Load Balancer**: A network service that distributes incoming traffic across multiple application instances, providing high availability, fault tolerance, and horizontal scaling capabilities.

#### M

**Microservices Architecture**: An architectural style that structures an application as a collection of loosely coupled services, each implementing specific business capabilities and communicating via APIs.

**Multi-Availability Zone (Multi-AZ)**: A deployment strategy that distributes application and database instances across physically separate data centers within the same region, providing high availability and disaster recovery.

**Multi-Factor Authentication (MFA)**: A security mechanism requiring users to provide multiple forms of verification (e.g., password + SMS code), significantly reducing account compromise risk.

#### O

**OAuth 2.0**: An industry-standard authorization framework that enables third-party applications to obtain limited access to user accounts without exposing passwords, using authorization codes and access tokens.

**OpenID Connect (OIDC)**: An identity layer built on OAuth 2.0 that adds user authentication and profile information, enabling single sign-on (SSO) across multiple applications.

**Oplog (Operations Log)**: MongoDB's internal log of all write operations on the primary database, used by secondary replicas to replicate changes asynchronously.

#### P

**Permission-Based Access Control (PBAC)**: An authorization model that grants users specific permissions (e.g., `read:documents`, `write:documents`) embedded in JWT tokens, enabling fine-grained access control.

**PKCE (Proof Key for Code Exchange)**: An OAuth 2.0 security extension that protects against authorization code interception attacks in public clients (mobile and single-page applications) using dynamically generated code challenges.

**Point-in-Time Recovery (PITR)**: A database backup feature that allows restoring data to any specific second within a retention window (e.g., 7 days), useful for recovering from data corruption or accidental deletions.

**Presigned URL**: A time-limited URL that grants temporary access to private S3 objects, enabling secure direct client-to-S3 uploads without routing data through application servers.

**Probabilistic Early Expiration**: A cache refresh strategy that probabilistically refreshes cache entries before TTL expiration, preventing cache stampedes and ensuring fresh data availability.

#### R

**RAG (Retrieval-Augmented Generation)**: An AI technique that retrieves relevant documents from a knowledge base and includes them as context in LLM prompts, improving answer accuracy and reducing hallucinations.

**Rate Limiting**: A technique that restricts the number of API requests a user can make within a time window (e.g., 100 requests/minute), preventing abuse and ensuring fair resource allocation.

**Read Preference**: A MongoDB configuration that specifies which replica set members (primary or secondaries) should serve read queries, enabling read scaling by distributing load across multiple nodes.

**Replica Set**: A MongoDB deployment with multiple database copies (primary + secondaries) that provide high availability through automatic failover and read scalability through distributed queries.

**Rolling Deployment**: A deployment strategy that gradually replaces old application instances with new versions, maintaining full capacity throughout the process and enabling automatic rollback on failures.

#### S

**Semantic Search**: A search technique that finds documents based on meaning rather than exact keyword matches, using vector embeddings and similarity metrics like cosine similarity.

**Serverless Containers**: A container execution model (e.g., AWS Fargate) where the cloud provider manages server infrastructure, allowing developers to focus on application code while automatically scaling and charging per resource usage.

**Stateless Architecture**: An application design where servers don't store session state between requests, instead deriving context from JWT tokens, enabling horizontal scaling and simplified infrastructure.

**Structured Logging**: A logging approach that outputs logs in structured formats (JSON) with consistent fields, enabling efficient log parsing, searching, and analysis in monitoring systems like CloudWatch.

#### T

**Three-Tier Architecture**: An application structure divided into presentation layer (UI), application layer (business logic), and data layer (databases), enabling separation of concerns and independent scaling.

**TLS (Transport Layer Security)**: A cryptographic protocol that provides encryption, authentication, and integrity for network communications, ensuring secure HTTPS connections.

**Token Bucket Algorithm**: A rate limiting algorithm that allows a burst of requests up to a bucket capacity, then limits requests to a steady refill rate, providing flexibility for legitimate traffic spikes.

#### V

**Vector Database**: A specialized database optimized for storing and querying high-dimensional vector embeddings, enabling fast similarity searches for AI features like semantic search and recommendations.

**Vertical Scaling**: Increasing system capacity by upgrading individual servers with more CPU, memory, or storage, providing a simpler scaling approach than horizontal scaling but with physical limits.

#### W

**Write Concern**: A MongoDB configuration specifying how many replica set members must acknowledge a write operation before it's considered successful (e.g., `majority` requires acknowledgment from most replicas).

#### Z

**Zero Trust Architecture**: A security model that assumes no implicit trust and verifies every request regardless of origin, implementing authentication, authorization, and encryption at every layer.

---

## 9.3 ACRONYMS

#### A

**AAB** - Android App Bundle  
**ACM** - AWS Certificate Manager  
**ACL** - Access Control List  
**AES** - Advanced Encryption Standard  
**AI** - Artificial Intelligence  
**ALB** - Application Load Balancer  
**API** - Application Programming Interface  
**APM** - Application Performance Monitoring  
**ARN** - Amazon Resource Name  
**AWS** - Amazon Web Services  
**AZ** - Availability Zone

#### B

**BSON** - Binary JSON

#### C

**CA** - Certificate Authority  
**CCPA** - California Consumer Privacy Act  
**CDN** - Content Delivery Network  
**CI/CD** - Continuous Integration / Continuous Deployment  
**CLI** - Command-Line Interface  
**CORS** - Cross-Origin Resource Sharing  
**CPU** - Central Processing Unit  
**CRUD** - Create, Read, Update, Delete  
**CSS** - Cascading Style Sheets

#### D

**DB** - Database  
**DNS** - Domain Name System  
**DOM** - Document Object Model

#### E

**EBS** - Elastic Block Store  
**EC2** - Elastic Compute Cloud  
**ECR** - Elastic Container Registry  
**ECS** - Elastic Container Service  
**ES** - ECMAScript

#### F

**FIPS** - Federal Information Processing Standards

#### G

**GB** - Gigabyte  
**GDPR** - General Data Protection Regulation  
**GUI** - Graphical User Interface

#### H

**HCL** - HashiCorp Configuration Language  
**HMAC** - Hash-based Message Authentication Code  
**HNSW** - Hierarchical Navigable Small World  
**HTML** - HyperText Markup Language  
**HTTP** - HyperText Transfer Protocol  
**HTTPS** - HyperText Transfer Protocol Secure

#### I

**IA** - Infrequent Access  
**IAM** - Identity and Access Management  
**IDE** - Integrated Development Environment  
**IOPS** - Input/Output Operations Per Second  
**IP** - Internet Protocol  
**IPA** - iOS App Archive

#### J

**JDK** - Java Development Kit  
**JSON** - JavaScript Object Notation  
**JSX** - JavaScript XML  
**JWT** - JSON Web Token  
**JWKS** - JSON Web Key Set

#### K

**KB** - Kilobyte  
**KMS** - Key Management Service  
**KPI** - Key Performance Indicator

#### L

**LLM** - Large Language Model

#### M

**MB** - Megabyte  
**MFA** - Multi-Factor Authentication  
**MIME** - Multipurpose Internet Mail Extensions  
**ML** - Machine Learning  
**MS** - Millisecond

#### N

**NAT** - Network Address Translation  
**NFR** - Non-Functional Requirement  
**NIST** - National Institute of Standards and Technology  
**NLP** - Natural Language Processing  
**NPM** - Node Package Manager  
**NoSQL** - Not Only SQL

#### O

**OAuth** - Open Authorization  
**OCR** - Optical Character Recognition  
**OIDC** - OpenID Connect  
**OOM** - Out Of Memory  
**ORM** - Object-Relational Mapping

#### P

**PBAC** - Permission-Based Access Control  
**PDF** - Portable Document Format  
**PEP** - Python Enhancement Proposal  
**PII** - Personally Identifiable Information  
**PITR** - Point-in-Time Recovery  
**PKCE** - Proof Key for Code Exchange  
**PyPI** - Python Package Index

#### Q

**QPS** - Queries Per Second

#### R

**RAG** - Retrieval-Augmented Generation  
**RAM** - Random Access Memory  
**RBAC** - Role-Based Access Control  
**REST** - Representational State Transfer  
**RN** - React Native  
**RPO** - Recovery Point Objective  
**RTO** - Recovery Time Objective

#### S

**S3** - Simple Storage Service  
**SaaS** - Software as a Service  
**SBOM** - Software Bill of Materials  
**SDK** - Software Development Kit  
**SHA** - Secure Hash Algorithm  
**SLA** - Service Level Agreement  
**SLO** - Service Level Objective  
**SMS** - Short Message Service  
**SOC** - Service Organization Control  
**SPA** - Single-Page Application  
**SQL** - Structured Query Language  
**SSH** - Secure Shell  
**SSL** - Secure Sockets Layer  
**SSE** - Server-Side Encryption  
**SSO** - Single Sign-On

#### T

**TBD** - To Be Determined  
**TCP** - Transmission Control Protocol  
**TDD** - Test-Driven Development  
**TLS** - Transport Layer Security  
**TOTP** - Time-based One-Time Password  
**TS** - TypeScript  
**TSX** - TypeScript XML  
**TTL** - Time To Live

#### U

**UI** - User Interface  
**URI** - Uniform Resource Identifier  
**URL** - Uniform Resource Locator  
**UUID** - Universally Unique Identifier  
**UX** - User Experience

#### V

**vCPU** - Virtual Central Processing Unit  
**VPC** - Virtual Private Cloud

#### W

**WORM** - Write Once Read Many

#### X

**XML** - eXtensible Markup Language

#### Y

**YAML** - YAML Ain't Markup Language

---

## 9.4 REFERENCES

### 9.4.1 Technical Specification Sections Referenced

This Appendices section synthesizes information from the following Technical Specification sections:

1. **Section 1.1 - Executive Summary**: Project stage, implementation status, development phase context
2. **Section 2.5 - Non-Functional Requirements**: Performance criteria, scalability requirements, security requirements, reliability targets, maintainability standards
3. **Section 3.1 - Technology Stack Overview**: Architectural approach, technology philosophy, cloud-native principles
4. **Section 3.2 - Programming Languages**: Python, TypeScript, JavaScript, Swift, Kotlin version specifications
5. **Section 3.3 - Frameworks & Libraries**: Flask, LangChain, React, React Native, Electron, TailwindCSS specifications
6. **Section 3.4 - Open Source Dependencies**: PyPI packages, npm packages, CocoaPods, Gradle dependencies with version numbers
7. **Section 3.5 - Third-Party Services**: Auth0, AWS services, OpenAI API integration specifications
8. **Section 3.6 - Databases & Storage**: MongoDB, Redis, S3, vector database architecture and configuration
9. **Section 3.7 - Development & Deployment**: CI/CD tools, containerization, deployment strategies
10. **Section 4.2 - CI/CD Workflows**: Backend, frontend, mobile, and infrastructure pipeline specifications
11. **Section 5.1 - High-Level Architecture**: System architecture diagrams, data flows, component interactions
12. **Section 6.1 - Core Services Architecture**: Service-level architecture, API specifications, scalability patterns
13. **Section 6.2 - Database Design**: MongoDB schema design, indexes, replication, backup strategies, performance optimization
14. **Section 6.3 - Integration Architecture**: API design, authentication methods, external service integrations, message processing
15. **Section 6.4 - Security Architecture**: Authentication framework, encryption standards, authorization patterns, compliance requirements
16. **Section 8.1 - Infrastructure Overview**: AWS infrastructure, ECS Fargate, multi-AZ deployment architecture
17. **Section 8.6 - CI/CD Pipeline**: GitHub Actions workflows, deployment automation, pipeline stages

### 9.4.2 Repository Files Examined

- **`README.md`** (root directory): Project title documentation containing only "CheckSameRepoNoPrompt"

**Implementation Status Note**: The repository is in pre-implementation phase and contains only a README.md file with no source code, configuration files, or infrastructure implementations. All technical information documented in this appendix represents planned architecture specifications from the technical specification document.

### 9.4.3 Repository Folders Explored

- **Root Directory (`/`)**: Contains only README.md; no implementation code, no `backend/`, `frontend/`, `mobile/`, or `terraform/` directories exist yet

### 9.4.4 External Documentation Sources

While this appendix is based exclusively on the repository and technical specification, the following external documentation sources provide additional context for the technologies and standards referenced:

**Technology Documentation:**
- MongoDB Documentation: https://docs.mongodb.com/
- Redis Documentation: https://redis.io/documentation
- AWS Documentation: https://docs.aws.amazon.com/
- LangChain Documentation: https://python.langchain.com/
- Auth0 Documentation: https://auth0.com/docs

**Standards and Specifications:**
- OAuth 2.0 Specification (RFC 6749): https://tools.ietf.org/html/rfc6749
- OpenID Connect Specification: https://openid.net/connect/
- JWT Specification (RFC 7519): https://tools.ietf.org/html/rfc7519
- RESTful API Design Standards: https://restfulapi.net/
- OpenAPI Specification: https://swagger.io/specification/

**Security and Compliance:**
- GDPR Official Text: https://gdpr.eu/
- NIST 800-53 Security Controls: https://csrc.nist.gov/publications/detail/sp/800-53/rev-5/final
- SOC 2 Compliance Framework: https://www.aicpa.org/soc

### 9.4.5 Document Metadata

**Appendices Section Information:**
- **Section**: 9. Appendices
- **Version**: 1.0
- **Documentation Scope**: Planned architecture (pre-implementation phase)
- **Last Updated**: January 2024
- **Total Sections Referenced**: 17 technical specification sections
- **Total Repository Files Examined**: 1 file (README.md)
- **Implementation Code Status**: None (repository contains only project title)

---

**End of Appendices Section**